Command run: ./job.sh 
WARNING: Logging before InitGoogleLogging() is written to STDERR
E1110 22:09:08.090549  2593 common.cpp:118] DeviceQuery:
I1110 22:09:08.092016  2593 common.cpp:177] Device id:                     0
I1110 22:09:08.092037  2593 common.cpp:178] Major revision number:         3
I1110 22:09:08.092047  2593 common.cpp:179] Minor revision number:         5
I1110 22:09:08.092056  2593 common.cpp:180] Name:                          GeForce GTX TITAN
I1110 22:09:08.092900  2593 common.cpp:181] Total global memory:           6442254336
I1110 22:09:08.092910  2593 common.cpp:182] Total shared memory per block: 49152
I1110 22:09:08.092917  2593 common.cpp:183] Total registers per block:     65536
I1110 22:09:08.092926  2593 common.cpp:184] Warp size:                     32
I1110 22:09:08.092933  2593 common.cpp:185] Maximum memory pitch:          2147483647
I1110 22:09:08.092941  2593 common.cpp:186] Maximum threads per block:     1024
I1110 22:09:08.092949  2593 common.cpp:187] Maximum dimension of block:    1024, 1024, 64
I1110 22:09:08.092958  2593 common.cpp:190] Maximum dimension of grid:     2147483647, 65535, 65535
I1110 22:09:08.092967  2593 common.cpp:193] Clock rate:                    875500
I1110 22:09:08.092974  2593 common.cpp:194] Total constant memory:         65536
I1110 22:09:08.092983  2593 common.cpp:195] Texture alignment:             512
I1110 22:09:08.092990  2593 common.cpp:196] Concurrent copy and execution: Yes
I1110 22:09:08.092998  2593 common.cpp:198] Number of multiprocessors:     14
I1110 22:09:08.093008  2593 common.cpp:199] Kernel execution timeout:      No
I1110 22:09:08.096371  2593 solver.cpp:47] Initializing solver from parameters: 
base_lr: 0.001
display: 1
max_iter: 10000000
lr_policy: "step"
gamma: 0.5
momentum: 0.98
weight_decay: 0
stepsize: 1500
snapshot: 1000
snapshot_prefix: "stitch"
solver_mode: GPU
random_seed: 0
net: "network.prototxt"
regularization_type: "L1"
I1110 22:09:08.097791  2593 solver.cpp:90] Creating training net from net file: network.prototxt
I1110 22:09:08.132202  2593 net.cpp:49] Initializing net from parameters: 
name: "StitchNet"
input: "net0"
input: "net1"
input_dim: 32
input_dim: 256
input_dim: 27
input_dim: 27
input_dim: 32
input_dim: 256
input_dim: 27
input_dim: 27
state {
  phase: TRAIN
}
debug_info: true
layer {
  name: "stitch0"
  type: "Convolution"
  bottom: "net0"
  top: "stitch0"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "stitch0"
  bottom: "net1"
  top: "loss"
  loss_weight: 1
}
I1110 22:09:08.132364  2593 net.cpp:413] Input 0 -> net0
I1110 22:09:08.173967  2593 net.cpp:413] Input 1 -> net1
I1110 22:09:08.174109  2593 layer_factory.hpp:76] Creating layer stitch0
I1110 22:09:08.174177  2593 net.cpp:106] Creating Layer stitch0
I1110 22:09:08.174199  2593 net.cpp:454] stitch0 <- net0
I1110 22:09:08.174237  2593 net.cpp:411] stitch0 -> stitch0
I1110 22:09:08.183038  2593 net.cpp:150] Setting up stitch0
I1110 22:09:08.183099  2593 net.cpp:157] Top shape: 32 256 27 27 (5971968)
I1110 22:09:08.183121  2593 net.cpp:165] Memory required for data: 23887872
I1110 22:09:08.183200  2593 layer_factory.hpp:76] Creating layer loss
I1110 22:09:08.183253  2593 net.cpp:106] Creating Layer loss
I1110 22:09:08.183275  2593 net.cpp:454] loss <- stitch0
I1110 22:09:08.183303  2593 net.cpp:454] loss <- net1
I1110 22:09:08.183332  2593 net.cpp:411] loss -> loss
I1110 22:09:08.183420  2593 net.cpp:150] Setting up loss
I1110 22:09:08.183445  2593 net.cpp:157] Top shape: (1)
I1110 22:09:08.183457  2593 net.cpp:160]     with loss weight 1
I1110 22:09:08.183475  2593 net.cpp:165] Memory required for data: 23887876
I1110 22:09:08.183493  2593 net.cpp:226] loss needs backward computation.
I1110 22:09:08.183511  2593 net.cpp:226] stitch0 needs backward computation.
I1110 22:09:08.183526  2593 net.cpp:270] This network produces output loss
I1110 22:09:08.183552  2593 net.cpp:283] Network initialization done.
I1110 22:09:08.183612  2593 solver.cpp:59] Solver scaffolding done.
I1110 22:09:08.319272  2593 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 227
input_dim: 227
force_backward: true
state {
  phase: TEST
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1110 22:09:08.319578  2593 net.cpp:413] Input 0 -> data
I1110 22:09:08.319790  2593 layer_factory.hpp:76] Creating layer conv1
I1110 22:09:08.319912  2593 net.cpp:106] Creating Layer conv1
I1110 22:09:08.319942  2593 net.cpp:454] conv1 <- data
I1110 22:09:08.319985  2593 net.cpp:411] conv1 -> conv1
I1110 22:09:08.321244  2593 net.cpp:150] Setting up conv1
I1110 22:09:08.321285  2593 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1110 22:09:08.321297  2593 net.cpp:165] Memory required for data: 1161600
I1110 22:09:08.321358  2593 layer_factory.hpp:76] Creating layer relu1
I1110 22:09:08.321399  2593 net.cpp:106] Creating Layer relu1
I1110 22:09:08.321419  2593 net.cpp:454] relu1 <- conv1
I1110 22:09:08.321446  2593 net.cpp:397] relu1 -> conv1 (in-place)
I1110 22:09:08.321485  2593 net.cpp:150] Setting up relu1
I1110 22:09:08.321503  2593 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1110 22:09:08.321513  2593 net.cpp:165] Memory required for data: 2323200
I1110 22:09:08.321527  2593 layer_factory.hpp:76] Creating layer pool1
I1110 22:09:08.321557  2593 net.cpp:106] Creating Layer pool1
I1110 22:09:08.321574  2593 net.cpp:454] pool1 <- conv1
I1110 22:09:08.321604  2593 net.cpp:411] pool1 -> pool1
I1110 22:09:08.321707  2593 net.cpp:150] Setting up pool1
I1110 22:09:08.321734  2593 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1110 22:09:08.321745  2593 net.cpp:165] Memory required for data: 2603136
I1110 22:09:08.321759  2593 layer_factory.hpp:76] Creating layer norm1
I1110 22:09:08.321791  2593 net.cpp:106] Creating Layer norm1
I1110 22:09:08.321810  2593 net.cpp:454] norm1 <- pool1
I1110 22:09:08.321841  2593 net.cpp:411] norm1 -> norm1
I1110 22:09:08.321926  2593 net.cpp:150] Setting up norm1
I1110 22:09:08.321952  2593 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1110 22:09:08.321964  2593 net.cpp:165] Memory required for data: 2883072
I1110 22:09:08.321979  2593 layer_factory.hpp:76] Creating layer conv2
I1110 22:09:08.322012  2593 net.cpp:106] Creating Layer conv2
I1110 22:09:08.322032  2593 net.cpp:454] conv2 <- norm1
I1110 22:09:08.322063  2593 net.cpp:411] conv2 -> conv2
I1110 22:09:08.325566  2593 net.cpp:150] Setting up conv2
I1110 22:09:08.325600  2593 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1110 22:09:08.325613  2593 net.cpp:165] Memory required for data: 3629568
I1110 22:09:08.325655  2593 layer_factory.hpp:76] Creating layer relu2
I1110 22:09:08.325685  2593 net.cpp:106] Creating Layer relu2
I1110 22:09:08.325702  2593 net.cpp:454] relu2 <- conv2
I1110 22:09:08.325734  2593 net.cpp:397] relu2 -> conv2 (in-place)
I1110 22:09:08.325767  2593 net.cpp:150] Setting up relu2
I1110 22:09:08.325784  2593 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1110 22:09:08.325800  2593 net.cpp:165] Memory required for data: 4376064
I1110 22:09:08.325842  2593 layer_factory.hpp:76] Creating layer pool2
I1110 22:09:08.325877  2593 net.cpp:106] Creating Layer pool2
I1110 22:09:08.325896  2593 net.cpp:454] pool2 <- conv2
I1110 22:09:08.325934  2593 net.cpp:411] pool2 -> pool2
I1110 22:09:08.326026  2593 net.cpp:150] Setting up pool2
I1110 22:09:08.326052  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:08.326063  2593 net.cpp:165] Memory required for data: 4549120
I1110 22:09:08.326077  2593 layer_factory.hpp:76] Creating layer norm2
I1110 22:09:08.326107  2593 net.cpp:106] Creating Layer norm2
I1110 22:09:08.326125  2593 net.cpp:454] norm2 <- pool2
I1110 22:09:08.326155  2593 net.cpp:411] norm2 -> norm2
I1110 22:09:08.326236  2593 net.cpp:150] Setting up norm2
I1110 22:09:08.326261  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:08.326272  2593 net.cpp:165] Memory required for data: 4722176
I1110 22:09:08.326285  2593 layer_factory.hpp:76] Creating layer conv3
I1110 22:09:08.326320  2593 net.cpp:106] Creating Layer conv3
I1110 22:09:08.326339  2593 net.cpp:454] conv3 <- norm2
I1110 22:09:08.326373  2593 net.cpp:411] conv3 -> conv3
I1110 22:09:08.333101  2593 net.cpp:150] Setting up conv3
I1110 22:09:08.333183  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:08.333195  2593 net.cpp:165] Memory required for data: 4981760
I1110 22:09:08.333269  2593 layer_factory.hpp:76] Creating layer relu3
I1110 22:09:08.333319  2593 net.cpp:106] Creating Layer relu3
I1110 22:09:08.333346  2593 net.cpp:454] relu3 <- conv3
I1110 22:09:08.333386  2593 net.cpp:397] relu3 -> conv3 (in-place)
I1110 22:09:08.333431  2593 net.cpp:150] Setting up relu3
I1110 22:09:08.333447  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:08.333457  2593 net.cpp:165] Memory required for data: 5241344
I1110 22:09:08.333470  2593 layer_factory.hpp:76] Creating layer conv4
I1110 22:09:08.333506  2593 net.cpp:106] Creating Layer conv4
I1110 22:09:08.333523  2593 net.cpp:454] conv4 <- conv3
I1110 22:09:08.333557  2593 net.cpp:411] conv4 -> conv4
I1110 22:09:08.341343  2593 net.cpp:150] Setting up conv4
I1110 22:09:08.341434  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:08.341449  2593 net.cpp:165] Memory required for data: 5500928
I1110 22:09:08.341493  2593 layer_factory.hpp:76] Creating layer relu4
I1110 22:09:08.341547  2593 net.cpp:106] Creating Layer relu4
I1110 22:09:08.341574  2593 net.cpp:454] relu4 <- conv4
I1110 22:09:08.341615  2593 net.cpp:397] relu4 -> conv4 (in-place)
I1110 22:09:08.341665  2593 net.cpp:150] Setting up relu4
I1110 22:09:08.341683  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:08.341696  2593 net.cpp:165] Memory required for data: 5760512
I1110 22:09:08.341709  2593 layer_factory.hpp:76] Creating layer conv5
I1110 22:09:08.341749  2593 net.cpp:106] Creating Layer conv5
I1110 22:09:08.341768  2593 net.cpp:454] conv5 <- conv4
I1110 22:09:08.341801  2593 net.cpp:411] conv5 -> conv5
I1110 22:09:08.347053  2593 net.cpp:150] Setting up conv5
I1110 22:09:08.347082  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:08.347093  2593 net.cpp:165] Memory required for data: 5933568
I1110 22:09:08.347146  2593 layer_factory.hpp:76] Creating layer relu5
I1110 22:09:08.347172  2593 net.cpp:106] Creating Layer relu5
I1110 22:09:08.347189  2593 net.cpp:454] relu5 <- conv5
I1110 22:09:08.347218  2593 net.cpp:397] relu5 -> conv5 (in-place)
I1110 22:09:08.347247  2593 net.cpp:150] Setting up relu5
I1110 22:09:08.347265  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:08.347275  2593 net.cpp:165] Memory required for data: 6106624
I1110 22:09:08.347288  2593 layer_factory.hpp:76] Creating layer pool5
I1110 22:09:08.347327  2593 net.cpp:106] Creating Layer pool5
I1110 22:09:08.347347  2593 net.cpp:454] pool5 <- conv5
I1110 22:09:08.347378  2593 net.cpp:411] pool5 -> pool5
I1110 22:09:08.347465  2593 net.cpp:150] Setting up pool5
I1110 22:09:08.347489  2593 net.cpp:157] Top shape: 1 256 6 6 (9216)
I1110 22:09:08.347501  2593 net.cpp:165] Memory required for data: 6143488
I1110 22:09:08.347514  2593 layer_factory.hpp:76] Creating layer fc6
I1110 22:09:08.347548  2593 net.cpp:106] Creating Layer fc6
I1110 22:09:08.347568  2593 net.cpp:454] fc6 <- pool5
I1110 22:09:08.347600  2593 net.cpp:411] fc6 -> fc6
I1110 22:09:08.538967  2593 net.cpp:150] Setting up fc6
I1110 22:09:08.539052  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:08.539064  2593 net.cpp:165] Memory required for data: 6159872
I1110 22:09:08.539109  2593 layer_factory.hpp:76] Creating layer relu6
I1110 22:09:08.539173  2593 net.cpp:106] Creating Layer relu6
I1110 22:09:08.539201  2593 net.cpp:454] relu6 <- fc6
I1110 22:09:08.539253  2593 net.cpp:397] relu6 -> fc6 (in-place)
I1110 22:09:08.539299  2593 net.cpp:150] Setting up relu6
I1110 22:09:08.539315  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:08.539325  2593 net.cpp:165] Memory required for data: 6176256
I1110 22:09:08.539338  2593 layer_factory.hpp:76] Creating layer drop6
I1110 22:09:08.539377  2593 net.cpp:106] Creating Layer drop6
I1110 22:09:08.539394  2593 net.cpp:454] drop6 <- fc6
I1110 22:09:08.539425  2593 net.cpp:397] drop6 -> fc6 (in-place)
I1110 22:09:08.539490  2593 net.cpp:150] Setting up drop6
I1110 22:09:08.539511  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:08.539522  2593 net.cpp:165] Memory required for data: 6192640
I1110 22:09:08.539535  2593 layer_factory.hpp:76] Creating layer fc7
I1110 22:09:08.539566  2593 net.cpp:106] Creating Layer fc7
I1110 22:09:08.539582  2593 net.cpp:454] fc7 <- fc6
I1110 22:09:08.539615  2593 net.cpp:411] fc7 -> fc7
I1110 22:09:08.625546  2593 net.cpp:150] Setting up fc7
I1110 22:09:08.625630  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:08.625650  2593 net.cpp:165] Memory required for data: 6209024
I1110 22:09:08.625695  2593 layer_factory.hpp:76] Creating layer relu7
I1110 22:09:08.625748  2593 net.cpp:106] Creating Layer relu7
I1110 22:09:08.625776  2593 net.cpp:454] relu7 <- fc7
I1110 22:09:08.625816  2593 net.cpp:397] relu7 -> fc7 (in-place)
I1110 22:09:08.625859  2593 net.cpp:150] Setting up relu7
I1110 22:09:08.625875  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:08.625886  2593 net.cpp:165] Memory required for data: 6225408
I1110 22:09:08.625900  2593 layer_factory.hpp:76] Creating layer drop7
I1110 22:09:08.625928  2593 net.cpp:106] Creating Layer drop7
I1110 22:09:08.625944  2593 net.cpp:454] drop7 <- fc7
I1110 22:09:08.625972  2593 net.cpp:397] drop7 -> fc7 (in-place)
I1110 22:09:08.626034  2593 net.cpp:150] Setting up drop7
I1110 22:09:08.626055  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:08.626065  2593 net.cpp:165] Memory required for data: 6241792
I1110 22:09:08.626078  2593 layer_factory.hpp:76] Creating layer fc8
I1110 22:09:08.626112  2593 net.cpp:106] Creating Layer fc8
I1110 22:09:08.626129  2593 net.cpp:454] fc8 <- fc7
I1110 22:09:08.626160  2593 net.cpp:411] fc8 -> fc8
I1110 22:09:08.647411  2593 net.cpp:150] Setting up fc8
I1110 22:09:08.647508  2593 net.cpp:157] Top shape: 1 1000 (1000)
I1110 22:09:08.647521  2593 net.cpp:165] Memory required for data: 6245792
I1110 22:09:08.647564  2593 layer_factory.hpp:76] Creating layer prob
I1110 22:09:08.647625  2593 net.cpp:106] Creating Layer prob
I1110 22:09:08.647658  2593 net.cpp:454] prob <- fc8
I1110 22:09:08.647706  2593 net.cpp:411] prob -> prob
I1110 22:09:08.647843  2593 net.cpp:150] Setting up prob
I1110 22:09:08.647868  2593 net.cpp:157] Top shape: 1 1000 (1000)
I1110 22:09:08.647881  2593 net.cpp:165] Memory required for data: 6249792
I1110 22:09:08.647897  2593 net.cpp:228] prob does not need backward computation.
I1110 22:09:08.647912  2593 net.cpp:228] fc8 does not need backward computation.
I1110 22:09:08.647925  2593 net.cpp:228] drop7 does not need backward computation.
I1110 22:09:08.647938  2593 net.cpp:228] relu7 does not need backward computation.
I1110 22:09:08.647950  2593 net.cpp:228] fc7 does not need backward computation.
I1110 22:09:08.647964  2593 net.cpp:228] drop6 does not need backward computation.
I1110 22:09:08.647975  2593 net.cpp:228] relu6 does not need backward computation.
I1110 22:09:08.647987  2593 net.cpp:228] fc6 does not need backward computation.
I1110 22:09:08.648001  2593 net.cpp:228] pool5 does not need backward computation.
I1110 22:09:08.648015  2593 net.cpp:228] relu5 does not need backward computation.
I1110 22:09:08.648026  2593 net.cpp:228] conv5 does not need backward computation.
I1110 22:09:08.648041  2593 net.cpp:228] relu4 does not need backward computation.
I1110 22:09:08.648052  2593 net.cpp:228] conv4 does not need backward computation.
I1110 22:09:08.648066  2593 net.cpp:228] relu3 does not need backward computation.
I1110 22:09:08.648078  2593 net.cpp:228] conv3 does not need backward computation.
I1110 22:09:08.648092  2593 net.cpp:228] norm2 does not need backward computation.
I1110 22:09:08.648107  2593 net.cpp:228] pool2 does not need backward computation.
I1110 22:09:08.648119  2593 net.cpp:228] relu2 does not need backward computation.
I1110 22:09:08.648133  2593 net.cpp:228] conv2 does not need backward computation.
I1110 22:09:08.648146  2593 net.cpp:228] norm1 does not need backward computation.
I1110 22:09:08.648159  2593 net.cpp:228] pool1 does not need backward computation.
I1110 22:09:08.648177  2593 net.cpp:228] relu1 does not need backward computation.
I1110 22:09:08.648191  2593 net.cpp:228] conv1 does not need backward computation.
I1110 22:09:08.648223  2593 net.cpp:270] This network produces output prob
I1110 22:09:08.648286  2593 net.cpp:283] Network initialization done.
I1110 22:09:10.931347  2593 net.cpp:920] Ignoring source layer data
I1110 22:09:10.931376  2593 net.cpp:923] Copying source layer conv1
I1110 22:09:10.931874  2593 net.cpp:923] Copying source layer relu1
I1110 22:09:10.931892  2593 net.cpp:923] Copying source layer pool1
I1110 22:09:10.931901  2593 net.cpp:923] Copying source layer norm1
I1110 22:09:10.931911  2593 net.cpp:923] Copying source layer conv2
I1110 22:09:10.939733  2593 net.cpp:923] Copying source layer relu2
I1110 22:09:10.939762  2593 net.cpp:923] Copying source layer pool2
I1110 22:09:10.939772  2593 net.cpp:923] Copying source layer norm2
I1110 22:09:10.939782  2593 net.cpp:923] Copying source layer conv3
I1110 22:09:10.950999  2593 net.cpp:923] Copying source layer relu3
I1110 22:09:10.951027  2593 net.cpp:923] Copying source layer conv4
I1110 22:09:10.967828  2593 net.cpp:923] Copying source layer relu4
I1110 22:09:10.967860  2593 net.cpp:923] Copying source layer conv5
I1110 22:09:10.979053  2593 net.cpp:923] Copying source layer relu5
I1110 22:09:10.979081  2593 net.cpp:923] Copying source layer pool5
I1110 22:09:10.979092  2593 net.cpp:923] Copying source layer fc6
I1110 22:09:11.453233  2593 net.cpp:923] Copying source layer relu6
I1110 22:09:11.453287  2593 net.cpp:923] Copying source layer drop6
I1110 22:09:11.453299  2593 net.cpp:923] Copying source layer fc7
I1110 22:09:11.664243  2593 net.cpp:923] Copying source layer relu7
I1110 22:09:11.664294  2593 net.cpp:923] Copying source layer drop7
I1110 22:09:11.664305  2593 net.cpp:923] Copying source layer fc8
I1110 22:09:11.715828  2593 net.cpp:920] Ignoring source layer loss
I1110 22:09:11.780668  2593 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 227
input_dim: 227
force_backward: true
state {
  phase: TEST
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1110 22:09:11.780954  2593 net.cpp:413] Input 0 -> data
I1110 22:09:11.781152  2593 layer_factory.hpp:76] Creating layer conv1
I1110 22:09:11.781218  2593 net.cpp:106] Creating Layer conv1
I1110 22:09:11.781237  2593 net.cpp:454] conv1 <- data
I1110 22:09:11.781267  2593 net.cpp:411] conv1 -> conv1
I1110 22:09:11.781703  2593 net.cpp:150] Setting up conv1
I1110 22:09:11.781733  2593 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1110 22:09:11.781744  2593 net.cpp:165] Memory required for data: 1161600
I1110 22:09:11.781790  2593 layer_factory.hpp:76] Creating layer relu1
I1110 22:09:11.781837  2593 net.cpp:106] Creating Layer relu1
I1110 22:09:11.781854  2593 net.cpp:454] relu1 <- conv1
I1110 22:09:11.781880  2593 net.cpp:397] relu1 -> conv1 (in-place)
I1110 22:09:11.781908  2593 net.cpp:150] Setting up relu1
I1110 22:09:11.781924  2593 net.cpp:157] Top shape: 1 96 55 55 (290400)
I1110 22:09:11.781932  2593 net.cpp:165] Memory required for data: 2323200
I1110 22:09:11.781956  2593 layer_factory.hpp:76] Creating layer pool1
I1110 22:09:11.781985  2593 net.cpp:106] Creating Layer pool1
I1110 22:09:11.782001  2593 net.cpp:454] pool1 <- conv1
I1110 22:09:11.782027  2593 net.cpp:411] pool1 -> pool1
I1110 22:09:11.782104  2593 net.cpp:150] Setting up pool1
I1110 22:09:11.782127  2593 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1110 22:09:11.782137  2593 net.cpp:165] Memory required for data: 2603136
I1110 22:09:11.782150  2593 layer_factory.hpp:76] Creating layer norm1
I1110 22:09:11.782176  2593 net.cpp:106] Creating Layer norm1
I1110 22:09:11.782191  2593 net.cpp:454] norm1 <- pool1
I1110 22:09:11.782219  2593 net.cpp:411] norm1 -> norm1
I1110 22:09:11.782286  2593 net.cpp:150] Setting up norm1
I1110 22:09:11.782306  2593 net.cpp:157] Top shape: 1 96 27 27 (69984)
I1110 22:09:11.782317  2593 net.cpp:165] Memory required for data: 2883072
I1110 22:09:11.782328  2593 layer_factory.hpp:76] Creating layer conv2
I1110 22:09:11.782366  2593 net.cpp:106] Creating Layer conv2
I1110 22:09:11.782397  2593 net.cpp:454] conv2 <- norm1
I1110 22:09:11.782428  2593 net.cpp:411] conv2 -> conv2
I1110 22:09:11.786257  2593 net.cpp:150] Setting up conv2
I1110 22:09:11.786347  2593 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1110 22:09:11.786358  2593 net.cpp:165] Memory required for data: 3629568
I1110 22:09:11.786434  2593 layer_factory.hpp:76] Creating layer relu2
I1110 22:09:11.786484  2593 net.cpp:106] Creating Layer relu2
I1110 22:09:11.786509  2593 net.cpp:454] relu2 <- conv2
I1110 22:09:11.786542  2593 net.cpp:397] relu2 -> conv2 (in-place)
I1110 22:09:11.786579  2593 net.cpp:150] Setting up relu2
I1110 22:09:11.786595  2593 net.cpp:157] Top shape: 1 256 27 27 (186624)
I1110 22:09:11.786604  2593 net.cpp:165] Memory required for data: 4376064
I1110 22:09:11.786617  2593 layer_factory.hpp:76] Creating layer pool2
I1110 22:09:11.786645  2593 net.cpp:106] Creating Layer pool2
I1110 22:09:11.786661  2593 net.cpp:454] pool2 <- conv2
I1110 22:09:11.786689  2593 net.cpp:411] pool2 -> pool2
I1110 22:09:11.786767  2593 net.cpp:150] Setting up pool2
I1110 22:09:11.786789  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:11.786800  2593 net.cpp:165] Memory required for data: 4549120
I1110 22:09:11.786813  2593 layer_factory.hpp:76] Creating layer norm2
I1110 22:09:11.786844  2593 net.cpp:106] Creating Layer norm2
I1110 22:09:11.786870  2593 net.cpp:454] norm2 <- pool2
I1110 22:09:11.786900  2593 net.cpp:411] norm2 -> norm2
I1110 22:09:11.786967  2593 net.cpp:150] Setting up norm2
I1110 22:09:11.786988  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:11.786998  2593 net.cpp:165] Memory required for data: 4722176
I1110 22:09:11.787010  2593 layer_factory.hpp:76] Creating layer conv3
I1110 22:09:11.787051  2593 net.cpp:106] Creating Layer conv3
I1110 22:09:11.787067  2593 net.cpp:454] conv3 <- norm2
I1110 22:09:11.787096  2593 net.cpp:411] conv3 -> conv3
I1110 22:09:11.792613  2593 net.cpp:150] Setting up conv3
I1110 22:09:11.792686  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:11.792697  2593 net.cpp:165] Memory required for data: 4981760
I1110 22:09:11.792769  2593 layer_factory.hpp:76] Creating layer relu3
I1110 22:09:11.792814  2593 net.cpp:106] Creating Layer relu3
I1110 22:09:11.792835  2593 net.cpp:454] relu3 <- conv3
I1110 22:09:11.792866  2593 net.cpp:397] relu3 -> conv3 (in-place)
I1110 22:09:11.792901  2593 net.cpp:150] Setting up relu3
I1110 22:09:11.792917  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:11.792927  2593 net.cpp:165] Memory required for data: 5241344
I1110 22:09:11.792937  2593 layer_factory.hpp:76] Creating layer conv4
I1110 22:09:11.792968  2593 net.cpp:106] Creating Layer conv4
I1110 22:09:11.792984  2593 net.cpp:454] conv4 <- conv3
I1110 22:09:11.793015  2593 net.cpp:411] conv4 -> conv4
I1110 22:09:11.799784  2593 net.cpp:150] Setting up conv4
I1110 22:09:11.799850  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:11.799861  2593 net.cpp:165] Memory required for data: 5500928
I1110 22:09:11.799901  2593 layer_factory.hpp:76] Creating layer relu4
I1110 22:09:11.799948  2593 net.cpp:106] Creating Layer relu4
I1110 22:09:11.799973  2593 net.cpp:454] relu4 <- conv4
I1110 22:09:11.800009  2593 net.cpp:397] relu4 -> conv4 (in-place)
I1110 22:09:11.800046  2593 net.cpp:150] Setting up relu4
I1110 22:09:11.800061  2593 net.cpp:157] Top shape: 1 384 13 13 (64896)
I1110 22:09:11.800071  2593 net.cpp:165] Memory required for data: 5760512
I1110 22:09:11.800082  2593 layer_factory.hpp:76] Creating layer conv5
I1110 22:09:11.800114  2593 net.cpp:106] Creating Layer conv5
I1110 22:09:11.800129  2593 net.cpp:454] conv5 <- conv4
I1110 22:09:11.800156  2593 net.cpp:411] conv5 -> conv5
I1110 22:09:11.804711  2593 net.cpp:150] Setting up conv5
I1110 22:09:11.804762  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:11.804774  2593 net.cpp:165] Memory required for data: 5933568
I1110 22:09:11.804841  2593 layer_factory.hpp:76] Creating layer relu5
I1110 22:09:11.804880  2593 net.cpp:106] Creating Layer relu5
I1110 22:09:11.804899  2593 net.cpp:454] relu5 <- conv5
I1110 22:09:11.804929  2593 net.cpp:397] relu5 -> conv5 (in-place)
I1110 22:09:11.804960  2593 net.cpp:150] Setting up relu5
I1110 22:09:11.804975  2593 net.cpp:157] Top shape: 1 256 13 13 (43264)
I1110 22:09:11.804983  2593 net.cpp:165] Memory required for data: 6106624
I1110 22:09:11.804996  2593 layer_factory.hpp:76] Creating layer pool5
I1110 22:09:11.805027  2593 net.cpp:106] Creating Layer pool5
I1110 22:09:11.805042  2593 net.cpp:454] pool5 <- conv5
I1110 22:09:11.805069  2593 net.cpp:411] pool5 -> pool5
I1110 22:09:11.805151  2593 net.cpp:150] Setting up pool5
I1110 22:09:11.805173  2593 net.cpp:157] Top shape: 1 256 6 6 (9216)
I1110 22:09:11.805192  2593 net.cpp:165] Memory required for data: 6143488
I1110 22:09:11.805207  2593 layer_factory.hpp:76] Creating layer fc6
I1110 22:09:11.805234  2593 net.cpp:106] Creating Layer fc6
I1110 22:09:11.805249  2593 net.cpp:454] fc6 <- pool5
I1110 22:09:11.805279  2593 net.cpp:411] fc6 -> fc6
I1110 22:09:11.985929  2593 net.cpp:150] Setting up fc6
I1110 22:09:11.986050  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:11.986062  2593 net.cpp:165] Memory required for data: 6159872
I1110 22:09:11.986112  2593 layer_factory.hpp:76] Creating layer relu6
I1110 22:09:11.986202  2593 net.cpp:106] Creating Layer relu6
I1110 22:09:11.986230  2593 net.cpp:454] relu6 <- fc6
I1110 22:09:11.986277  2593 net.cpp:397] relu6 -> fc6 (in-place)
I1110 22:09:11.986320  2593 net.cpp:150] Setting up relu6
I1110 22:09:11.986335  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:11.986345  2593 net.cpp:165] Memory required for data: 6176256
I1110 22:09:11.986356  2593 layer_factory.hpp:76] Creating layer drop6
I1110 22:09:11.986385  2593 net.cpp:106] Creating Layer drop6
I1110 22:09:11.986399  2593 net.cpp:454] drop6 <- fc6
I1110 22:09:11.986426  2593 net.cpp:397] drop6 -> fc6 (in-place)
I1110 22:09:11.986488  2593 net.cpp:150] Setting up drop6
I1110 22:09:11.986507  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:11.986517  2593 net.cpp:165] Memory required for data: 6192640
I1110 22:09:11.986529  2593 layer_factory.hpp:76] Creating layer fc7
I1110 22:09:11.986565  2593 net.cpp:106] Creating Layer fc7
I1110 22:09:11.986579  2593 net.cpp:454] fc7 <- fc6
I1110 22:09:11.986608  2593 net.cpp:411] fc7 -> fc7
I1110 22:09:12.065239  2593 net.cpp:150] Setting up fc7
I1110 22:09:12.065348  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:12.065359  2593 net.cpp:165] Memory required for data: 6209024
I1110 22:09:12.065404  2593 layer_factory.hpp:76] Creating layer relu7
I1110 22:09:12.065464  2593 net.cpp:106] Creating Layer relu7
I1110 22:09:12.065496  2593 net.cpp:454] relu7 <- fc7
I1110 22:09:12.065546  2593 net.cpp:397] relu7 -> fc7 (in-place)
I1110 22:09:12.065594  2593 net.cpp:150] Setting up relu7
I1110 22:09:12.065609  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:12.065618  2593 net.cpp:165] Memory required for data: 6225408
I1110 22:09:12.065630  2593 layer_factory.hpp:76] Creating layer drop7
I1110 22:09:12.065666  2593 net.cpp:106] Creating Layer drop7
I1110 22:09:12.065680  2593 net.cpp:454] drop7 <- fc7
I1110 22:09:12.065708  2593 net.cpp:397] drop7 -> fc7 (in-place)
I1110 22:09:12.065778  2593 net.cpp:150] Setting up drop7
I1110 22:09:12.065795  2593 net.cpp:157] Top shape: 1 4096 (4096)
I1110 22:09:12.065805  2593 net.cpp:165] Memory required for data: 6241792
I1110 22:09:12.065817  2593 layer_factory.hpp:76] Creating layer fc8
I1110 22:09:12.065855  2593 net.cpp:106] Creating Layer fc8
I1110 22:09:12.065870  2593 net.cpp:454] fc8 <- fc7
I1110 22:09:12.065897  2593 net.cpp:411] fc8 -> fc8
I1110 22:09:12.086330  2593 net.cpp:150] Setting up fc8
I1110 22:09:12.086448  2593 net.cpp:157] Top shape: 1 1000 (1000)
I1110 22:09:12.086460  2593 net.cpp:165] Memory required for data: 6245792
I1110 22:09:12.086516  2593 layer_factory.hpp:76] Creating layer prob
I1110 22:09:12.086601  2593 net.cpp:106] Creating Layer prob
I1110 22:09:12.086633  2593 net.cpp:454] prob <- fc8
I1110 22:09:12.086685  2593 net.cpp:411] prob -> prob
I1110 22:09:12.086827  2593 net.cpp:150] Setting up prob
I1110 22:09:12.086853  2593 net.cpp:157] Top shape: 1 1000 (1000)
I1110 22:09:12.086863  2593 net.cpp:165] Memory required for data: 6249792
I1110 22:09:12.086880  2593 net.cpp:228] prob does not need backward computation.
I1110 22:09:12.086894  2593 net.cpp:228] fc8 does not need backward computation.
I1110 22:09:12.086906  2593 net.cpp:228] drop7 does not need backward computation.
I1110 22:09:12.086918  2593 net.cpp:228] relu7 does not need backward computation.
I1110 22:09:12.086930  2593 net.cpp:228] fc7 does not need backward computation.
I1110 22:09:12.086942  2593 net.cpp:228] drop6 does not need backward computation.
I1110 22:09:12.086954  2593 net.cpp:228] relu6 does not need backward computation.
I1110 22:09:12.086966  2593 net.cpp:228] fc6 does not need backward computation.
I1110 22:09:12.086977  2593 net.cpp:228] pool5 does not need backward computation.
I1110 22:09:12.086989  2593 net.cpp:228] relu5 does not need backward computation.
I1110 22:09:12.087002  2593 net.cpp:228] conv5 does not need backward computation.
I1110 22:09:12.087013  2593 net.cpp:228] relu4 does not need backward computation.
I1110 22:09:12.087024  2593 net.cpp:228] conv4 does not need backward computation.
I1110 22:09:12.087036  2593 net.cpp:228] relu3 does not need backward computation.
I1110 22:09:12.087049  2593 net.cpp:228] conv3 does not need backward computation.
I1110 22:09:12.087061  2593 net.cpp:228] norm2 does not need backward computation.
I1110 22:09:12.087074  2593 net.cpp:228] pool2 does not need backward computation.
I1110 22:09:12.087086  2593 net.cpp:228] relu2 does not need backward computation.
I1110 22:09:12.087097  2593 net.cpp:228] conv2 does not need backward computation.
I1110 22:09:12.087110  2593 net.cpp:228] norm1 does not need backward computation.
I1110 22:09:12.087122  2593 net.cpp:228] pool1 does not need backward computation.
I1110 22:09:12.087134  2593 net.cpp:228] relu1 does not need backward computation.
I1110 22:09:12.087146  2593 net.cpp:228] conv1 does not need backward computation.
I1110 22:09:12.087177  2593 net.cpp:270] This network produces output prob
I1110 22:09:12.087234  2593 net.cpp:283] Network initialization done.
I1110 22:09:14.296607  2593 net.cpp:920] Ignoring source layer data
I1110 22:09:14.296646  2593 net.cpp:923] Copying source layer conv1
I1110 22:09:14.297133  2593 net.cpp:923] Copying source layer relu1
I1110 22:09:14.297149  2593 net.cpp:923] Copying source layer pool1
I1110 22:09:14.297159  2593 net.cpp:923] Copying source layer norm1
I1110 22:09:14.297168  2593 net.cpp:923] Copying source layer conv2
I1110 22:09:14.304985  2593 net.cpp:923] Copying source layer relu2
I1110 22:09:14.305016  2593 net.cpp:923] Copying source layer pool2
I1110 22:09:14.305027  2593 net.cpp:923] Copying source layer norm2
I1110 22:09:14.305035  2593 net.cpp:923] Copying source layer conv3
I1110 22:09:14.316221  2593 net.cpp:923] Copying source layer relu3
I1110 22:09:14.316252  2593 net.cpp:923] Copying source layer conv4
I1110 22:09:14.332986  2593 net.cpp:923] Copying source layer relu4
I1110 22:09:14.333017  2593 net.cpp:923] Copying source layer conv5
I1110 22:09:14.344200  2593 net.cpp:923] Copying source layer relu5
I1110 22:09:14.344231  2593 net.cpp:923] Copying source layer pool5
I1110 22:09:14.344241  2593 net.cpp:923] Copying source layer fc6
I1110 22:09:14.818776  2593 net.cpp:923] Copying source layer relu6
I1110 22:09:14.818828  2593 net.cpp:923] Copying source layer drop6
I1110 22:09:14.818840  2593 net.cpp:923] Copying source layer fc7
I1110 22:09:15.029398  2593 net.cpp:923] Copying source layer relu7
I1110 22:09:15.029441  2593 net.cpp:923] Copying source layer drop7
I1110 22:09:15.029453  2593 net.cpp:923] Copying source layer fc8
I1110 22:09:15.080991  2593 net.cpp:920] Ignoring source layer loss
I1110 22:09:21.058640  2593 net.cpp:717]     [Forward] Input net0 data: 0.00121633
I1110 22:09:21.060812  2593 net.cpp:717]     [Forward] Input net1 data: 0.00123902
I1110 22:09:21.066987  2593 net.cpp:728]     [Forward] Layer stitch0, top blob stitch0 data: 0.000285671
I1110 22:09:21.067184  2593 net.cpp:740]     [Forward] Layer stitch0, param blob 0 data: 0.00796935
I1110 22:09:21.067241  2593 net.cpp:740]     [Forward] Layer stitch0, param blob 1 data: 0
I1110 22:09:21.072506  2593 net.cpp:728]     [Forward] Layer loss, top blob loss data: 0.531972
I1110 22:09:21.123610  2593 net.cpp:717]     [Forward] Input net0 data: 0.00121633
I1110 22:09:21.127174  2593 net.cpp:717]     [Forward] Input net1 data: 0.00123902
I1110 22:09:21.143841  2593 net.cpp:728]     [Forward] Layer stitch0, top blob stitch0 data: 0.00177711
I1110 22:09:21.147280  2593 net.cpp:740]     [Forward] Layer stitch0, param blob 0 data: 0.0495761
I1110 22:09:21.150743  2593 net.cpp:740]     [Forward] Layer stitch0, param blob 1 data: 0
I1110 22:09:21.157850  2593 net.cpp:728]     [Forward] Layer loss, top blob loss data: 1.01959
I1110 22:09:21.159445  2593 net.cpp:756]     [Backward] Layer loss, bottom blob stitch0 diff: 7.11164e-05
I1110 22:09:21.165449  2593 net.cpp:767]     [Backward] Layer stitch0, param blob 0 diff: 0.000422138
I1110 22:09:21.165879  2593 net.cpp:767]     [Backward] Layer stitch0, param blob 1 diff: 0.0883258
I1110 22:09:21.192870  2593 solver.cpp:295] Iteration 0 (no loss supplied for SingleUpdateStep)
I1110 22:09:21.192970  2593 solver.cpp:310]     Train net output #0: loss = 1.01959 (* 1 = 1.01959 loss)
I1110 22:09:21.192984  2593 solver.cpp:324] Taking special snapshot at iter 0
I1110 22:09:21.193002  2593 solver.cpp:534] Snapshotting to binary proto file stitch_iter_0.caffemodel
I1110 22:09:21.193028  2593 net.cpp:1022] Serializing 2 layers
I1110 22:09:21.197813  2593 sgd_solver.cpp:269] Snapshotting solver state to binary proto file stitch_iter_0.solverstate
I1110 22:09:21.202905  2593 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1110 22:09:23.517101  2593 solver.cpp:295] Iteration 1 (no loss supplied for SingleUpdateStep)
I1110 22:09:23.517225  2593 solver.cpp:310]     Train net output #0: loss = 0.976725 (* 1 = 0.976725 loss)
I1110 22:09:23.517252  2593 sgd_solver.cpp:106] Iteration 1, lr = 0.001
I1110 22:09:25.980861  2593 solver.cpp:295] Iteration 2 (no loss supplied for SingleUpdateStep)
I1110 22:09:25.980993  2593 solver.cpp:310]     Train net output #0: loss = 1.01557 (* 1 = 1.01557 loss)
I1110 22:09:25.981019  2593 sgd_solver.cpp:106] Iteration 2, lr = 0.001
I1110 22:09:28.387298  2593 solver.cpp:295] Iteration 3 (no loss supplied for SingleUpdateStep)
I1110 22:09:28.387351  2593 solver.cpp:310]     Train net output #0: loss = 0.944301 (* 1 = 0.944301 loss)
I1110 22:09:28.387369  2593 sgd_solver.cpp:106] Iteration 3, lr = 0.001
I1110 22:09:30.657822  2593 solver.cpp:295] Iteration 4 (no loss supplied for SingleUpdateStep)
I1110 22:09:30.657977  2593 solver.cpp:310]     Train net output #0: loss = 1.01644 (* 1 = 1.01644 loss)
I1110 22:09:30.658001  2593 sgd_solver.cpp:106] Iteration 4, lr = 0.001
I1110 22:09:33.222834  2593 solver.cpp:295] Iteration 5 (no loss supplied for SingleUpdateStep)
I1110 22:09:33.222889  2593 solver.cpp:310]     Train net output #0: loss = 0.997278 (* 1 = 0.997278 loss)
I1110 22:09:33.222908  2593 sgd_solver.cpp:106] Iteration 5, lr = 0.001
I1110 22:09:35.432816  2593 solver.cpp:295] Iteration 6 (no loss supplied for SingleUpdateStep)
I1110 22:09:35.432952  2593 solver.cpp:310]     Train net output #0: loss = 0.993324 (* 1 = 0.993324 loss)
I1110 22:09:35.432981  2593 sgd_solver.cpp:106] Iteration 6, lr = 0.001
I1110 22:09:37.279510  2593 solver.cpp:295] Iteration 7 (no loss supplied for SingleUpdateStep)
I1110 22:09:37.304324  2593 solver.cpp:310]     Train net output #0: loss = 0.925577 (* 1 = 0.925577 loss)
I1110 22:09:37.304378  2593 sgd_solver.cpp:106] Iteration 7, lr = 0.001
I1110 22:09:39.110730  2593 solver.cpp:295] Iteration 8 (no loss supplied for SingleUpdateStep)
I1110 22:09:39.110838  2593 solver.cpp:310]     Train net output #0: loss = 0.968648 (* 1 = 0.968648 loss)
I1110 22:09:39.110862  2593 sgd_solver.cpp:106] Iteration 8, lr = 0.001
I1110 22:09:41.107080  2593 solver.cpp:295] Iteration 9 (no loss supplied for SingleUpdateStep)
I1110 22:09:41.107179  2593 solver.cpp:310]     Train net output #0: loss = 1.04947 (* 1 = 1.04947 loss)
I1110 22:09:41.107202  2593 sgd_solver.cpp:106] Iteration 9, lr = 0.001
I1110 22:09:43.028957  2593 solver.cpp:295] Iteration 10 (no loss supplied for SingleUpdateStep)
I1110 22:09:43.029106  2593 solver.cpp:310]     Train net output #0: loss = 1.03385 (* 1 = 1.03385 loss)
I1110 22:09:43.029129  2593 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I1110 22:09:45.065680  2593 solver.cpp:295] Iteration 11 (no loss supplied for SingleUpdateStep)
I1110 22:09:45.065826  2593 solver.cpp:310]     Train net output #0: loss = 1.04829 (* 1 = 1.04829 loss)
I1110 22:09:45.065856  2593 sgd_solver.cpp:106] Iteration 11, lr = 0.001
I1110 22:09:47.732328  2593 solver.cpp:295] Iteration 12 (no loss supplied for SingleUpdateStep)
I1110 22:09:47.732468  2593 solver.cpp:310]     Train net output #0: loss = 1.01746 (* 1 = 1.01746 loss)
I1110 22:09:47.732492  2593 sgd_solver.cpp:106] Iteration 12, lr = 0.001
I1110 22:09:50.097501  2593 solver.cpp:295] Iteration 13 (no loss supplied for SingleUpdateStep)
I1110 22:09:50.097622  2593 solver.cpp:310]     Train net output #0: loss = 1.04585 (* 1 = 1.04585 loss)
I1110 22:09:50.097645  2593 sgd_solver.cpp:106] Iteration 13, lr = 0.001
I1110 22:09:52.465262  2593 solver.cpp:295] Iteration 14 (no loss supplied for SingleUpdateStep)
I1110 22:09:52.465375  2593 solver.cpp:310]     Train net output #0: loss = 0.978582 (* 1 = 0.978582 loss)
I1110 22:09:52.465400  2593 sgd_solver.cpp:106] Iteration 14, lr = 0.001
I1110 22:09:54.818235  2593 solver.cpp:295] Iteration 15 (no loss supplied for SingleUpdateStep)
I1110 22:09:54.818349  2593 solver.cpp:310]     Train net output #0: loss = 0.9211 (* 1 = 0.9211 loss)
I1110 22:09:54.818372  2593 sgd_solver.cpp:106] Iteration 15, lr = 0.001
I1110 22:09:57.043673  2593 solver.cpp:295] Iteration 16 (no loss supplied for SingleUpdateStep)
I1110 22:09:57.043866  2593 solver.cpp:310]     Train net output #0: loss = 1.03671 (* 1 = 1.03671 loss)
I1110 22:09:57.043897  2593 sgd_solver.cpp:106] Iteration 16, lr = 0.001
I1110 22:09:59.404536  2593 solver.cpp:295] Iteration 17 (no loss supplied for SingleUpdateStep)
I1110 22:09:59.404616  2593 solver.cpp:310]     Train net output #0: loss = 0.936196 (* 1 = 0.936196 loss)
I1110 22:09:59.404636  2593 sgd_solver.cpp:106] Iteration 17, lr = 0.001
I1110 22:10:01.603355  2593 solver.cpp:295] Iteration 18 (no loss supplied for SingleUpdateStep)
I1110 22:10:01.603497  2593 solver.cpp:310]     Train net output #0: loss = 1.05049 (* 1 = 1.05049 loss)
I1110 22:10:01.603521  2593 sgd_solver.cpp:106] Iteration 18, lr = 0.001
I1110 22:10:03.906211  2593 solver.cpp:295] Iteration 19 (no loss supplied for SingleUpdateStep)
I1110 22:10:03.906327  2593 solver.cpp:310]     Train net output #0: loss = 1.05363 (* 1 = 1.05363 loss)
I1110 22:10:03.906349  2593 sgd_solver.cpp:106] Iteration 19, lr = 0.001
I1110 22:10:06.141716  2593 solver.cpp:295] Iteration 20 (no loss supplied for SingleUpdateStep)
I1110 22:10:06.141845  2593 solver.cpp:310]     Train net output #0: loss = 1.02052 (* 1 = 1.02052 loss)
I1110 22:10:06.141870  2593 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I1110 22:10:08.484154  2593 solver.cpp:295] Iteration 21 (no loss supplied for SingleUpdateStep)
I1110 22:10:08.484308  2593 solver.cpp:310]     Train net output #0: loss = 1.11344 (* 1 = 1.11344 loss)
I1110 22:10:08.484340  2593 sgd_solver.cpp:106] Iteration 21, lr = 0.001
I1110 22:10:10.810026  2593 solver.cpp:295] Iteration 22 (no loss supplied for SingleUpdateStep)
I1110 22:10:10.810127  2593 solver.cpp:310]     Train net output #0: loss = 0.99301 (* 1 = 0.99301 loss)
I1110 22:10:10.810149  2593 sgd_solver.cpp:106] Iteration 22, lr = 0.001
I1110 22:10:13.073179  2593 solver.cpp:295] Iteration 23 (no loss supplied for SingleUpdateStep)
I1110 22:10:13.073282  2593 solver.cpp:310]     Train net output #0: loss = 0.99825 (* 1 = 0.99825 loss)
I1110 22:10:13.073302  2593 sgd_solver.cpp:106] Iteration 23, lr = 0.001
I1110 22:10:15.527930  2593 solver.cpp:295] Iteration 24 (no loss supplied for SingleUpdateStep)
I1110 22:10:15.527999  2593 solver.cpp:310]     Train net output #0: loss = 1.03375 (* 1 = 1.03375 loss)
I1110 22:10:15.528018  2593 sgd_solver.cpp:106] Iteration 24, lr = 0.001
I1110 22:10:17.860875  2593 solver.cpp:295] Iteration 25 (no loss supplied for SingleUpdateStep)
I1110 22:10:17.860966  2593 solver.cpp:310]     Train net output #0: loss = 1.07048 (* 1 = 1.07048 loss)
I1110 22:10:17.860988  2593 sgd_solver.cpp:106] Iteration 25, lr = 0.001
I1110 22:10:20.248169  2593 solver.cpp:295] Iteration 26 (no loss supplied for SingleUpdateStep)
I1110 22:10:20.248301  2593 solver.cpp:310]     Train net output #0: loss = 0.988011 (* 1 = 0.988011 loss)
I1110 22:10:20.248323  2593 sgd_solver.cpp:106] Iteration 26, lr = 0.001
I1110 22:10:22.602603  2593 solver.cpp:295] Iteration 27 (no loss supplied for SingleUpdateStep)
I1110 22:10:22.602712  2593 solver.cpp:310]     Train net output #0: loss = 1.02629 (* 1 = 1.02629 loss)
I1110 22:10:22.602736  2593 sgd_solver.cpp:106] Iteration 27, lr = 0.001
I1110 22:10:24.778952  2593 solver.cpp:295] Iteration 28 (no loss supplied for SingleUpdateStep)
I1110 22:10:24.779055  2593 solver.cpp:310]     Train net output #0: loss = 1.03256 (* 1 = 1.03256 loss)
I1110 22:10:24.779078  2593 sgd_solver.cpp:106] Iteration 28, lr = 0.001
I1110 22:10:27.136415  2593 solver.cpp:295] Iteration 29 (no loss supplied for SingleUpdateStep)
I1110 22:10:27.136523  2593 solver.cpp:310]     Train net output #0: loss = 0.988004 (* 1 = 0.988004 loss)
I1110 22:10:27.136548  2593 sgd_solver.cpp:106] Iteration 29, lr = 0.001
I1110 22:10:29.537024  2593 solver.cpp:295] Iteration 30 (no loss supplied for SingleUpdateStep)
I1110 22:10:29.537173  2593 solver.cpp:310]     Train net output #0: loss = 0.986445 (* 1 = 0.986445 loss)
I1110 22:10:29.537201  2593 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I1110 22:10:31.931166  2593 solver.cpp:295] Iteration 31 (no loss supplied for SingleUpdateStep)
I1110 22:10:31.931289  2593 solver.cpp:310]     Train net output #0: loss = 1.01588 (* 1 = 1.01588 loss)
I1110 22:10:31.931313  2593 sgd_solver.cpp:106] Iteration 31, lr = 0.001
I1110 22:10:34.412948  2593 solver.cpp:295] Iteration 32 (no loss supplied for SingleUpdateStep)
I1110 22:10:34.413040  2593 solver.cpp:310]     Train net output #0: loss = 1.08299 (* 1 = 1.08299 loss)
I1110 22:10:34.413064  2593 sgd_solver.cpp:106] Iteration 32, lr = 0.001
I1110 22:10:36.749632  2593 solver.cpp:295] Iteration 33 (no loss supplied for SingleUpdateStep)
I1110 22:10:36.749713  2593 solver.cpp:310]     Train net output #0: loss = 1.00558 (* 1 = 1.00558 loss)
I1110 22:10:36.749733  2593 sgd_solver.cpp:106] Iteration 33, lr = 0.001
I1110 22:10:39.421540  2593 solver.cpp:295] Iteration 34 (no loss supplied for SingleUpdateStep)
I1110 22:10:39.421653  2593 solver.cpp:310]     Train net output #0: loss = 0.950754 (* 1 = 0.950754 loss)
I1110 22:10:39.421674  2593 sgd_solver.cpp:106] Iteration 34, lr = 0.001
I1110 22:10:41.835296  2593 solver.cpp:295] Iteration 35 (no loss supplied for SingleUpdateStep)
I1110 22:10:41.835364  2593 solver.cpp:310]     Train net output #0: loss = 0.991866 (* 1 = 0.991866 loss)
I1110 22:10:41.835384  2593 sgd_solver.cpp:106] Iteration 35, lr = 0.001
I1110 22:10:44.241060  2593 solver.cpp:295] Iteration 36 (no loss supplied for SingleUpdateStep)
I1110 22:10:44.241153  2593 solver.cpp:310]     Train net output #0: loss = 1.05361 (* 1 = 1.05361 loss)
I1110 22:10:44.241176  2593 sgd_solver.cpp:106] Iteration 36, lr = 0.001
I1110 22:10:46.527660  2593 solver.cpp:295] Iteration 37 (no loss supplied for SingleUpdateStep)
I1110 22:10:46.527729  2593 solver.cpp:310]     Train net output #0: loss = 1.00465 (* 1 = 1.00465 loss)
I1110 22:10:46.527748  2593 sgd_solver.cpp:106] Iteration 37, lr = 0.001
I1110 22:10:49.041242  2593 solver.cpp:295] Iteration 38 (no loss supplied for SingleUpdateStep)
I1110 22:10:49.041373  2593 solver.cpp:310]     Train net output #0: loss = 0.982366 (* 1 = 0.982366 loss)
I1110 22:10:49.041402  2593 sgd_solver.cpp:106] Iteration 38, lr = 0.001
I1110 22:10:51.640949  2593 solver.cpp:295] Iteration 39 (no loss supplied for SingleUpdateStep)
I1110 22:10:51.641010  2593 solver.cpp:310]     Train net output #0: loss = 0.996819 (* 1 = 0.996819 loss)
I1110 22:10:51.641031  2593 sgd_solver.cpp:106] Iteration 39, lr = 0.001
I1110 22:10:54.128837  2593 solver.cpp:295] Iteration 40 (no loss supplied for SingleUpdateStep)
I1110 22:10:54.128950  2593 solver.cpp:310]     Train net output #0: loss = 1.05252 (* 1 = 1.05252 loss)
I1110 22:10:54.128973  2593 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I1110 22:10:56.560813  2593 solver.cpp:295] Iteration 41 (no loss supplied for SingleUpdateStep)
I1110 22:10:56.560881  2593 solver.cpp:310]     Train net output #0: loss = 1.02573 (* 1 = 1.02573 loss)
I1110 22:10:56.560901  2593 sgd_solver.cpp:106] Iteration 41, lr = 0.001
I1110 22:10:58.944304  2593 solver.cpp:295] Iteration 42 (no loss supplied for SingleUpdateStep)
I1110 22:10:58.944406  2593 solver.cpp:310]     Train net output #0: loss = 1.02776 (* 1 = 1.02776 loss)
I1110 22:10:58.944427  2593 sgd_solver.cpp:106] Iteration 42, lr = 0.001
I1110 22:11:01.379030  2593 solver.cpp:295] Iteration 43 (no loss supplied for SingleUpdateStep)
I1110 22:11:01.379147  2593 solver.cpp:310]     Train net output #0: loss = 0.976106 (* 1 = 0.976106 loss)
I1110 22:11:01.379168  2593 sgd_solver.cpp:106] Iteration 43, lr = 0.001
I1110 22:11:03.722569  2593 solver.cpp:295] Iteration 44 (no loss supplied for SingleUpdateStep)
I1110 22:11:03.722625  2593 solver.cpp:310]     Train net output #0: loss = 1.02385 (* 1 = 1.02385 loss)
I1110 22:11:03.722674  2593 sgd_solver.cpp:106] Iteration 44, lr = 0.001
I1110 22:11:06.100477  2593 solver.cpp:295] Iteration 45 (no loss supplied for SingleUpdateStep)
I1110 22:11:06.100587  2593 solver.cpp:310]     Train net output #0: loss = 0.989126 (* 1 = 0.989126 loss)
I1110 22:11:06.100611  2593 sgd_solver.cpp:106] Iteration 45, lr = 0.001
I1110 22:11:08.626716  2593 solver.cpp:295] Iteration 46 (no loss supplied for SingleUpdateStep)
I1110 22:11:08.626778  2593 solver.cpp:310]     Train net output #0: loss = 1.14505 (* 1 = 1.14505 loss)
I1110 22:11:08.626799  2593 sgd_solver.cpp:106] Iteration 46, lr = 0.001
I1110 22:11:11.396890  2593 solver.cpp:295] Iteration 47 (no loss supplied for SingleUpdateStep)
I1110 22:11:11.396976  2593 solver.cpp:310]     Train net output #0: loss = 1.06286 (* 1 = 1.06286 loss)
I1110 22:11:11.396997  2593 sgd_solver.cpp:106] Iteration 47, lr = 0.001
I1110 22:11:13.825763  2593 solver.cpp:295] Iteration 48 (no loss supplied for SingleUpdateStep)
I1110 22:11:13.825860  2593 solver.cpp:310]     Train net output #0: loss = 1.14594 (* 1 = 1.14594 loss)
I1110 22:11:13.825884  2593 sgd_solver.cpp:106] Iteration 48, lr = 0.001
I1110 22:11:16.556534  2593 solver.cpp:295] Iteration 49 (no loss supplied for SingleUpdateStep)
I1110 22:11:16.556643  2593 solver.cpp:310]     Train net output #0: loss = 1.06807 (* 1 = 1.06807 loss)
I1110 22:11:16.556664  2593 sgd_solver.cpp:106] Iteration 49, lr = 0.001
I1110 22:11:19.290628  2593 solver.cpp:295] Iteration 50 (no loss supplied for SingleUpdateStep)
I1110 22:11:19.290724  2593 solver.cpp:310]     Train net output #0: loss = 1.06589 (* 1 = 1.06589 loss)
I1110 22:11:19.290745  2593 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1110 22:11:21.697249  2593 solver.cpp:295] Iteration 51 (no loss supplied for SingleUpdateStep)
I1110 22:11:21.697302  2593 solver.cpp:310]     Train net output #0: loss = 0.906592 (* 1 = 0.906592 loss)
I1110 22:11:21.697320  2593 sgd_solver.cpp:106] Iteration 51, lr = 0.001
I1110 22:11:23.919131  2593 solver.cpp:295] Iteration 52 (no loss supplied for SingleUpdateStep)
I1110 22:11:23.919250  2593 solver.cpp:310]     Train net output #0: loss = 1.0064 (* 1 = 1.0064 loss)
I1110 22:11:23.919276  2593 sgd_solver.cpp:106] Iteration 52, lr = 0.001
I1110 22:11:26.170426  2593 solver.cpp:295] Iteration 53 (no loss supplied for SingleUpdateStep)
I1110 22:11:26.170524  2593 solver.cpp:310]     Train net output #0: loss = 0.953998 (* 1 = 0.953998 loss)
I1110 22:11:26.170547  2593 sgd_solver.cpp:106] Iteration 53, lr = 0.001
I1110 22:11:28.453685  2593 solver.cpp:295] Iteration 54 (no loss supplied for SingleUpdateStep)
I1110 22:11:28.453763  2593 solver.cpp:310]     Train net output #0: loss = 1.05152 (* 1 = 1.05152 loss)
I1110 22:11:28.453784  2593 sgd_solver.cpp:106] Iteration 54, lr = 0.001
I1110 22:11:31.625610  2593 solver.cpp:295] Iteration 55 (no loss supplied for SingleUpdateStep)
I1110 22:11:31.625705  2593 solver.cpp:310]     Train net output #0: loss = 0.964453 (* 1 = 0.964453 loss)
I1110 22:11:31.625728  2593 sgd_solver.cpp:106] Iteration 55, lr = 0.001
I1110 22:11:34.133502  2593 solver.cpp:295] Iteration 56 (no loss supplied for SingleUpdateStep)
I1110 22:11:34.133615  2593 solver.cpp:310]     Train net output #0: loss = 1.04686 (* 1 = 1.04686 loss)
I1110 22:11:34.133638  2593 sgd_solver.cpp:106] Iteration 56, lr = 0.001
I1110 22:11:36.698001  2593 solver.cpp:295] Iteration 57 (no loss supplied for SingleUpdateStep)
I1110 22:11:36.698117  2593 solver.cpp:310]     Train net output #0: loss = 1.01024 (* 1 = 1.01024 loss)
I1110 22:11:36.698140  2593 sgd_solver.cpp:106] Iteration 57, lr = 0.001
I1110 22:11:39.204231  2593 solver.cpp:295] Iteration 58 (no loss supplied for SingleUpdateStep)
I1110 22:11:39.204331  2593 solver.cpp:310]     Train net output #0: loss = 0.94942 (* 1 = 0.94942 loss)
I1110 22:11:39.204355  2593 sgd_solver.cpp:106] Iteration 58, lr = 0.001
I1110 22:11:41.426702  2593 solver.cpp:295] Iteration 59 (no loss supplied for SingleUpdateStep)
I1110 22:11:41.426820  2593 solver.cpp:310]     Train net output #0: loss = 1.07329 (* 1 = 1.07329 loss)
I1110 22:11:41.426844  2593 sgd_solver.cpp:106] Iteration 59, lr = 0.001
I1110 22:11:43.766463  2593 solver.cpp:295] Iteration 60 (no loss supplied for SingleUpdateStep)
I1110 22:11:43.766582  2593 solver.cpp:310]     Train net output #0: loss = 1.07949 (* 1 = 1.07949 loss)
I1110 22:11:43.766605  2593 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I1110 22:11:46.299559  2593 solver.cpp:295] Iteration 61 (no loss supplied for SingleUpdateStep)
I1110 22:11:46.299682  2593 solver.cpp:310]     Train net output #0: loss = 1.02771 (* 1 = 1.02771 loss)
I1110 22:11:46.299705  2593 sgd_solver.cpp:106] Iteration 61, lr = 0.001
I1110 22:11:48.856866  2593 solver.cpp:295] Iteration 62 (no loss supplied for SingleUpdateStep)
I1110 22:11:48.857054  2593 solver.cpp:310]     Train net output #0: loss = 1.03934 (* 1 = 1.03934 loss)
I1110 22:11:48.857082  2593 sgd_solver.cpp:106] Iteration 62, lr = 0.001
I1110 22:11:51.507313  2593 solver.cpp:295] Iteration 63 (no loss supplied for SingleUpdateStep)
I1110 22:11:51.507452  2593 solver.cpp:310]     Train net output #0: loss = 1.02607 (* 1 = 1.02607 loss)
I1110 22:11:51.507478  2593 sgd_solver.cpp:106] Iteration 63, lr = 0.001
I1110 22:11:53.842728  2593 solver.cpp:295] Iteration 64 (no loss supplied for SingleUpdateStep)
I1110 22:11:53.842871  2593 solver.cpp:310]     Train net output #0: loss = 0.995906 (* 1 = 0.995906 loss)
I1110 22:11:53.842896  2593 sgd_solver.cpp:106] Iteration 64, lr = 0.001
I1110 22:11:56.212904  2593 solver.cpp:295] Iteration 65 (no loss supplied for SingleUpdateStep)
I1110 22:11:56.213002  2593 solver.cpp:310]     Train net output #0: loss = 1.05931 (* 1 = 1.05931 loss)
I1110 22:11:56.213024  2593 sgd_solver.cpp:106] Iteration 65, lr = 0.001
I1110 22:11:58.642444  2593 solver.cpp:295] Iteration 66 (no loss supplied for SingleUpdateStep)
I1110 22:11:58.642560  2593 solver.cpp:310]     Train net output #0: loss = 0.992409 (* 1 = 0.992409 loss)
I1110 22:11:58.642585  2593 sgd_solver.cpp:106] Iteration 66, lr = 0.001
I1110 22:12:00.840554  2593 solver.cpp:295] Iteration 67 (no loss supplied for SingleUpdateStep)
I1110 22:12:00.840685  2593 solver.cpp:310]     Train net output #0: loss = 0.972244 (* 1 = 0.972244 loss)
I1110 22:12:00.840714  2593 sgd_solver.cpp:106] Iteration 67, lr = 0.001
I1110 22:12:03.170168  2593 solver.cpp:295] Iteration 68 (no loss supplied for SingleUpdateStep)
I1110 22:12:03.170248  2593 solver.cpp:310]     Train net output #0: loss = 0.937547 (* 1 = 0.937547 loss)
I1110 22:12:03.170269  2593 sgd_solver.cpp:106] Iteration 68, lr = 0.001
I1110 22:12:05.381932  2593 solver.cpp:295] Iteration 69 (no loss supplied for SingleUpdateStep)
I1110 22:12:05.382064  2593 solver.cpp:310]     Train net output #0: loss = 0.990161 (* 1 = 0.990161 loss)
I1110 22:12:05.382087  2593 sgd_solver.cpp:106] Iteration 69, lr = 0.001
I1110 22:12:07.937563  2593 solver.cpp:295] Iteration 70 (no loss supplied for SingleUpdateStep)
I1110 22:12:07.937757  2593 solver.cpp:310]     Train net output #0: loss = 1.07969 (* 1 = 1.07969 loss)
I1110 22:12:07.937798  2593 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I1110 22:12:10.312935  2593 solver.cpp:295] Iteration 71 (no loss supplied for SingleUpdateStep)
I1110 22:12:10.313066  2593 solver.cpp:310]     Train net output #0: loss = 1.05972 (* 1 = 1.05972 loss)
I1110 22:12:10.313089  2593 sgd_solver.cpp:106] Iteration 71, lr = 0.001
I1110 22:12:12.500625  2593 solver.cpp:295] Iteration 72 (no loss supplied for SingleUpdateStep)
I1110 22:12:12.500721  2593 solver.cpp:310]     Train net output #0: loss = 0.993374 (* 1 = 0.993374 loss)
I1110 22:12:12.500743  2593 sgd_solver.cpp:106] Iteration 72, lr = 0.001
I1110 22:12:14.880216  2593 solver.cpp:295] Iteration 73 (no loss supplied for SingleUpdateStep)
I1110 22:12:14.880308  2593 solver.cpp:310]     Train net output #0: loss = 0.984472 (* 1 = 0.984472 loss)
I1110 22:12:14.880329  2593 sgd_solver.cpp:106] Iteration 73, lr = 0.001
I1110 22:12:17.221335  2593 solver.cpp:295] Iteration 74 (no loss supplied for SingleUpdateStep)
I1110 22:12:17.221441  2593 solver.cpp:310]     Train net output #0: loss = 1.00041 (* 1 = 1.00041 loss)
I1110 22:12:17.221462  2593 sgd_solver.cpp:106] Iteration 74, lr = 0.001
I1110 22:12:19.456918  2593 solver.cpp:295] Iteration 75 (no loss supplied for SingleUpdateStep)
I1110 22:12:19.457039  2593 solver.cpp:310]     Train net output #0: loss = 1.0353 (* 1 = 1.0353 loss)
I1110 22:12:19.457062  2593 sgd_solver.cpp:106] Iteration 75, lr = 0.001
I1110 22:12:21.633234  2593 solver.cpp:295] Iteration 76 (no loss supplied for SingleUpdateStep)
I1110 22:12:21.633290  2593 solver.cpp:310]     Train net output #0: loss = 0.987916 (* 1 = 0.987916 loss)
I1110 22:12:21.633308  2593 sgd_solver.cpp:106] Iteration 76, lr = 0.001
I1110 22:12:23.843488  2593 solver.cpp:295] Iteration 77 (no loss supplied for SingleUpdateStep)
I1110 22:12:23.843600  2593 solver.cpp:310]     Train net output #0: loss = 0.973766 (* 1 = 0.973766 loss)
I1110 22:12:23.843631  2593 sgd_solver.cpp:106] Iteration 77, lr = 0.001
I1110 22:12:26.296707  2593 solver.cpp:295] Iteration 78 (no loss supplied for SingleUpdateStep)
I1110 22:12:26.296890  2593 solver.cpp:310]     Train net output #0: loss = 1.02025 (* 1 = 1.02025 loss)
I1110 22:12:26.296931  2593 sgd_solver.cpp:106] Iteration 78, lr = 0.001
I1110 22:12:28.870363  2593 solver.cpp:295] Iteration 79 (no loss supplied for SingleUpdateStep)
I1110 22:12:28.870445  2593 solver.cpp:310]     Train net output #0: loss = 0.990023 (* 1 = 0.990023 loss)
I1110 22:12:28.870465  2593 sgd_solver.cpp:106] Iteration 79, lr = 0.001
I1110 22:12:31.650070  2593 solver.cpp:295] Iteration 80 (no loss supplied for SingleUpdateStep)
I1110 22:12:31.650125  2593 solver.cpp:310]     Train net output #0: loss = 1.03548 (* 1 = 1.03548 loss)
I1110 22:12:31.650142  2593 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I1110 22:12:34.043756  2593 solver.cpp:295] Iteration 81 (no loss supplied for SingleUpdateStep)
I1110 22:12:34.043874  2593 solver.cpp:310]     Train net output #0: loss = 1.02695 (* 1 = 1.02695 loss)
I1110 22:12:34.043895  2593 sgd_solver.cpp:106] Iteration 81, lr = 0.001
I1110 22:12:36.427268  2593 solver.cpp:295] Iteration 82 (no loss supplied for SingleUpdateStep)
I1110 22:12:36.427387  2593 solver.cpp:310]     Train net output #0: loss = 0.949968 (* 1 = 0.949968 loss)
I1110 22:12:36.427413  2593 sgd_solver.cpp:106] Iteration 82, lr = 0.001
I1110 22:12:39.052625  2593 solver.cpp:295] Iteration 83 (no loss supplied for SingleUpdateStep)
I1110 22:12:39.052742  2593 solver.cpp:310]     Train net output #0: loss = 0.911451 (* 1 = 0.911451 loss)
I1110 22:12:39.052767  2593 sgd_solver.cpp:106] Iteration 83, lr = 0.001
I1110 22:12:41.484215  2593 solver.cpp:295] Iteration 84 (no loss supplied for SingleUpdateStep)
I1110 22:12:41.484349  2593 solver.cpp:310]     Train net output #0: loss = 1.01071 (* 1 = 1.01071 loss)
I1110 22:12:41.484375  2593 sgd_solver.cpp:106] Iteration 84, lr = 0.001
I1110 22:12:43.353925  2593 solver.cpp:295] Iteration 85 (no loss supplied for SingleUpdateStep)
I1110 22:12:43.354023  2593 solver.cpp:310]     Train net output #0: loss = 0.946895 (* 1 = 0.946895 loss)
I1110 22:12:43.354048  2593 sgd_solver.cpp:106] Iteration 85, lr = 0.001
I1110 22:12:45.338889  2593 solver.cpp:295] Iteration 86 (no loss supplied for SingleUpdateStep)
I1110 22:12:45.339059  2593 solver.cpp:310]     Train net output #0: loss = 1.0033 (* 1 = 1.0033 loss)
I1110 22:12:45.339084  2593 sgd_solver.cpp:106] Iteration 86, lr = 0.001
I1110 22:12:47.508183  2593 solver.cpp:295] Iteration 87 (no loss supplied for SingleUpdateStep)
I1110 22:12:47.508307  2593 solver.cpp:310]     Train net output #0: loss = 1.07905 (* 1 = 1.07905 loss)
I1110 22:12:47.508335  2593 sgd_solver.cpp:106] Iteration 87, lr = 0.001
I1110 22:12:49.592437  2593 solver.cpp:295] Iteration 88 (no loss supplied for SingleUpdateStep)
I1110 22:12:49.592537  2593 solver.cpp:310]     Train net output #0: loss = 1.02404 (* 1 = 1.02404 loss)
I1110 22:12:49.592560  2593 sgd_solver.cpp:106] Iteration 88, lr = 0.001
I1110 22:12:51.421643  2593 solver.cpp:295] Iteration 89 (no loss supplied for SingleUpdateStep)
I1110 22:12:51.421700  2593 solver.cpp:310]     Train net output #0: loss = 0.94419 (* 1 = 0.94419 loss)
I1110 22:12:51.421720  2593 sgd_solver.cpp:106] Iteration 89, lr = 0.001
I1110 22:12:53.424304  2593 solver.cpp:295] Iteration 90 (no loss supplied for SingleUpdateStep)
I1110 22:12:53.424401  2593 solver.cpp:310]     Train net output #0: loss = 0.944589 (* 1 = 0.944589 loss)
I1110 22:12:53.424422  2593 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I1110 22:12:55.407162  2593 solver.cpp:295] Iteration 91 (no loss supplied for SingleUpdateStep)
I1110 22:12:55.407259  2593 solver.cpp:310]     Train net output #0: loss = 0.939049 (* 1 = 0.939049 loss)
I1110 22:12:55.407279  2593 sgd_solver.cpp:106] Iteration 91, lr = 0.001
I1110 22:12:57.649899  2593 solver.cpp:295] Iteration 92 (no loss supplied for SingleUpdateStep)
I1110 22:12:57.650003  2593 solver.cpp:310]     Train net output #0: loss = 1.02607 (* 1 = 1.02607 loss)
I1110 22:12:57.650025  2593 sgd_solver.cpp:106] Iteration 92, lr = 0.001
I1110 22:12:59.463935  2593 solver.cpp:295] Iteration 93 (no loss supplied for SingleUpdateStep)
I1110 22:12:59.464035  2593 solver.cpp:310]     Train net output #0: loss = 1.04986 (* 1 = 1.04986 loss)
I1110 22:12:59.464056  2593 sgd_solver.cpp:106] Iteration 93, lr = 0.001
I1110 22:13:01.442332  2593 solver.cpp:295] Iteration 94 (no loss supplied for SingleUpdateStep)
I1110 22:13:01.442577  2593 solver.cpp:310]     Train net output #0: loss = 1.01464 (* 1 = 1.01464 loss)
I1110 22:13:01.442608  2593 sgd_solver.cpp:106] Iteration 94, lr = 0.001
I1110 22:13:03.438127  2593 solver.cpp:295] Iteration 95 (no loss supplied for SingleUpdateStep)
I1110 22:13:03.438228  2593 solver.cpp:310]     Train net output #0: loss = 1.05945 (* 1 = 1.05945 loss)
I1110 22:13:03.438251  2593 sgd_solver.cpp:106] Iteration 95, lr = 0.001
I1110 22:13:05.333752  2593 solver.cpp:295] Iteration 96 (no loss supplied for SingleUpdateStep)
I1110 22:13:05.333859  2593 solver.cpp:310]     Train net output #0: loss = 1.0305 (* 1 = 1.0305 loss)
I1110 22:13:05.333881  2593 sgd_solver.cpp:106] Iteration 96, lr = 0.001
I1110 22:13:07.079918  2593 solver.cpp:295] Iteration 97 (no loss supplied for SingleUpdateStep)
I1110 22:13:07.079999  2593 solver.cpp:310]     Train net output #0: loss = 1.05603 (* 1 = 1.05603 loss)
I1110 22:13:07.080021  2593 sgd_solver.cpp:106] Iteration 97, lr = 0.001
I1110 22:13:08.910249  2593 solver.cpp:295] Iteration 98 (no loss supplied for SingleUpdateStep)
I1110 22:13:08.910367  2593 solver.cpp:310]     Train net output #0: loss = 1.03352 (* 1 = 1.03352 loss)
I1110 22:13:08.910392  2593 sgd_solver.cpp:106] Iteration 98, lr = 0.001
I1110 22:13:10.744734  2593 solver.cpp:295] Iteration 99 (no loss supplied for SingleUpdateStep)
I1110 22:13:10.744848  2593 solver.cpp:310]     Train net output #0: loss = 1.00931 (* 1 = 1.00931 loss)
I1110 22:13:10.744870  2593 sgd_solver.cpp:106] Iteration 99, lr = 0.001
I1110 22:13:12.672372  2593 solver.cpp:295] Iteration 100 (no loss supplied for SingleUpdateStep)
I1110 22:13:12.672569  2593 solver.cpp:310]     Train net output #0: loss = 1.01048 (* 1 = 1.01048 loss)
I1110 22:13:12.672595  2593 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1110 22:13:14.440707  2593 solver.cpp:295] Iteration 101 (no loss supplied for SingleUpdateStep)
I1110 22:13:14.440767  2593 solver.cpp:310]     Train net output #0: loss = 0.982323 (* 1 = 0.982323 loss)
I1110 22:13:14.440786  2593 sgd_solver.cpp:106] Iteration 101, lr = 0.001
I1110 22:13:16.443781  2593 solver.cpp:295] Iteration 102 (no loss supplied for SingleUpdateStep)
I1110 22:13:16.443892  2593 solver.cpp:310]     Train net output #0: loss = 0.993946 (* 1 = 0.993946 loss)
I1110 22:13:16.443922  2593 sgd_solver.cpp:106] Iteration 102, lr = 0.001
I1110 22:13:18.450718  2593 solver.cpp:295] Iteration 103 (no loss supplied for SingleUpdateStep)
I1110 22:13:18.450861  2593 solver.cpp:310]     Train net output #0: loss = 0.922809 (* 1 = 0.922809 loss)
I1110 22:13:18.450886  2593 sgd_solver.cpp:106] Iteration 103, lr = 0.001
I1110 22:13:20.366531  2593 solver.cpp:295] Iteration 104 (no loss supplied for SingleUpdateStep)
I1110 22:13:20.366591  2593 solver.cpp:310]     Train net output #0: loss = 0.998258 (* 1 = 0.998258 loss)
I1110 22:13:20.366612  2593 sgd_solver.cpp:106] Iteration 104, lr = 0.001
I1110 22:13:22.465028  2593 solver.cpp:295] Iteration 105 (no loss supplied for SingleUpdateStep)
I1110 22:13:22.465179  2593 solver.cpp:310]     Train net output #0: loss = 0.971788 (* 1 = 0.971788 loss)
I1110 22:13:22.465205  2593 sgd_solver.cpp:106] Iteration 105, lr = 0.001
I1110 22:13:24.436600  2593 solver.cpp:295] Iteration 106 (no loss supplied for SingleUpdateStep)
I1110 22:13:24.436705  2593 solver.cpp:310]     Train net output #0: loss = 1.00645 (* 1 = 1.00645 loss)
I1110 22:13:24.436728  2593 sgd_solver.cpp:106] Iteration 106, lr = 0.001
I1110 22:13:26.327141  2593 solver.cpp:295] Iteration 107 (no loss supplied for SingleUpdateStep)
I1110 22:13:26.327226  2593 solver.cpp:310]     Train net output #0: loss = 0.949502 (* 1 = 0.949502 loss)
I1110 22:13:26.327251  2593 sgd_solver.cpp:106] Iteration 107, lr = 0.001
I1110 22:13:28.193016  2593 solver.cpp:295] Iteration 108 (no loss supplied for SingleUpdateStep)
I1110 22:13:28.193109  2593 solver.cpp:310]     Train net output #0: loss = 1.04101 (* 1 = 1.04101 loss)
I1110 22:13:28.193131  2593 sgd_solver.cpp:106] Iteration 108, lr = 0.001
I1110 22:13:30.163257  2593 solver.cpp:295] Iteration 109 (no loss supplied for SingleUpdateStep)
I1110 22:13:30.163370  2593 solver.cpp:310]     Train net output #0: loss = 0.977299 (* 1 = 0.977299 loss)
I1110 22:13:30.163393  2593 sgd_solver.cpp:106] Iteration 109, lr = 0.001
I1110 22:13:32.178879  2593 solver.cpp:295] Iteration 110 (no loss supplied for SingleUpdateStep)
I1110 22:13:32.179059  2593 solver.cpp:310]     Train net output #0: loss = 0.931696 (* 1 = 0.931696 loss)
I1110 22:13:32.179090  2593 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I1110 22:13:34.091727  2593 solver.cpp:295] Iteration 111 (no loss supplied for SingleUpdateStep)
I1110 22:13:34.091804  2593 solver.cpp:310]     Train net output #0: loss = 0.905368 (* 1 = 0.905368 loss)
I1110 22:13:34.091828  2593 sgd_solver.cpp:106] Iteration 111, lr = 0.001
I1110 22:13:36.026702  2593 solver.cpp:295] Iteration 112 (no loss supplied for SingleUpdateStep)
I1110 22:13:36.026782  2593 solver.cpp:310]     Train net output #0: loss = 0.969347 (* 1 = 0.969347 loss)
I1110 22:13:36.026803  2593 sgd_solver.cpp:106] Iteration 112, lr = 0.001
I1110 22:13:38.009690  2593 solver.cpp:295] Iteration 113 (no loss supplied for SingleUpdateStep)
I1110 22:13:38.009865  2593 solver.cpp:310]     Train net output #0: loss = 1.00937 (* 1 = 1.00937 loss)
I1110 22:13:38.009897  2593 sgd_solver.cpp:106] Iteration 113, lr = 0.001
I1110 22:13:39.855337  2593 solver.cpp:295] Iteration 114 (no loss supplied for SingleUpdateStep)
I1110 22:13:39.855448  2593 solver.cpp:310]     Train net output #0: loss = 0.965071 (* 1 = 0.965071 loss)
I1110 22:13:39.855469  2593 sgd_solver.cpp:106] Iteration 114, lr = 0.001
I1110 22:13:41.791499  2593 solver.cpp:295] Iteration 115 (no loss supplied for SingleUpdateStep)
I1110 22:13:41.791596  2593 solver.cpp:310]     Train net output #0: loss = 0.961503 (* 1 = 0.961503 loss)
I1110 22:13:41.791620  2593 sgd_solver.cpp:106] Iteration 115, lr = 0.001
I1110 22:13:43.783915  2593 solver.cpp:295] Iteration 116 (no loss supplied for SingleUpdateStep)
I1110 22:13:43.783994  2593 solver.cpp:310]     Train net output #0: loss = 1.03846 (* 1 = 1.03846 loss)
I1110 22:13:43.784019  2593 sgd_solver.cpp:106] Iteration 116, lr = 0.001
I1110 22:13:46.349709  2593 solver.cpp:295] Iteration 117 (no loss supplied for SingleUpdateStep)
I1110 22:13:46.349792  2593 solver.cpp:310]     Train net output #0: loss = 0.971944 (* 1 = 0.971944 loss)
I1110 22:13:46.349812  2593 sgd_solver.cpp:106] Iteration 117, lr = 0.001
I1110 22:13:48.475591  2593 solver.cpp:295] Iteration 118 (no loss supplied for SingleUpdateStep)
I1110 22:13:48.475690  2593 solver.cpp:310]     Train net output #0: loss = 0.982066 (* 1 = 0.982066 loss)
I1110 22:13:48.475713  2593 sgd_solver.cpp:106] Iteration 118, lr = 0.001
I1110 22:13:50.692890  2593 solver.cpp:295] Iteration 119 (no loss supplied for SingleUpdateStep)
I1110 22:13:50.692998  2593 solver.cpp:310]     Train net output #0: loss = 1.00944 (* 1 = 1.00944 loss)
I1110 22:13:50.693022  2593 sgd_solver.cpp:106] Iteration 119, lr = 0.001
I1110 22:13:52.828616  2593 solver.cpp:295] Iteration 120 (no loss supplied for SingleUpdateStep)
I1110 22:13:52.828665  2593 solver.cpp:310]     Train net output #0: loss = 1.03298 (* 1 = 1.03298 loss)
I1110 22:13:52.828682  2593 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I1110 22:13:54.619736  2593 solver.cpp:295] Iteration 121 (no loss supplied for SingleUpdateStep)
I1110 22:13:54.619855  2593 solver.cpp:310]     Train net output #0: loss = 0.921441 (* 1 = 0.921441 loss)
I1110 22:13:54.619879  2593 sgd_solver.cpp:106] Iteration 121, lr = 0.001
I1110 22:13:56.888890  2593 solver.cpp:295] Iteration 122 (no loss supplied for SingleUpdateStep)
I1110 22:13:56.888988  2593 solver.cpp:310]     Train net output #0: loss = 0.955833 (* 1 = 0.955833 loss)
I1110 22:13:56.889011  2593 sgd_solver.cpp:106] Iteration 122, lr = 0.001
I1110 22:13:59.058151  2593 solver.cpp:295] Iteration 123 (no loss supplied for SingleUpdateStep)
I1110 22:13:59.058215  2593 solver.cpp:310]     Train net output #0: loss = 0.97557 (* 1 = 0.97557 loss)
I1110 22:13:59.058234  2593 sgd_solver.cpp:106] Iteration 123, lr = 0.001
I1110 22:14:01.082229  2593 solver.cpp:295] Iteration 124 (no loss supplied for SingleUpdateStep)
I1110 22:14:01.082314  2593 solver.cpp:310]     Train net output #0: loss = 0.952467 (* 1 = 0.952467 loss)
I1110 22:14:01.082334  2593 sgd_solver.cpp:106] Iteration 124, lr = 0.001
I1110 22:14:03.089027  2593 solver.cpp:295] Iteration 125 (no loss supplied for SingleUpdateStep)
I1110 22:14:03.089162  2593 solver.cpp:310]     Train net output #0: loss = 0.995201 (* 1 = 0.995201 loss)
I1110 22:14:03.089185  2593 sgd_solver.cpp:106] Iteration 125, lr = 0.001
I1110 22:14:05.240159  2593 solver.cpp:295] Iteration 126 (no loss supplied for SingleUpdateStep)
I1110 22:14:05.240272  2593 solver.cpp:310]     Train net output #0: loss = 0.934516 (* 1 = 0.934516 loss)
I1110 22:14:05.240295  2593 sgd_solver.cpp:106] Iteration 126, lr = 0.001
I1110 22:14:07.133196  2593 solver.cpp:295] Iteration 127 (no loss supplied for SingleUpdateStep)
I1110 22:14:07.188532  2593 solver.cpp:310]     Train net output #0: loss = 0.948688 (* 1 = 0.948688 loss)
I1110 22:14:07.188593  2593 sgd_solver.cpp:106] Iteration 127, lr = 0.001
I1110 22:14:08.899437  2593 solver.cpp:295] Iteration 128 (no loss supplied for SingleUpdateStep)
I1110 22:14:08.899555  2593 solver.cpp:310]     Train net output #0: loss = 1.00412 (* 1 = 1.00412 loss)
I1110 22:14:08.899580  2593 sgd_solver.cpp:106] Iteration 128, lr = 0.001
I1110 22:14:10.720054  2593 solver.cpp:295] Iteration 129 (no loss supplied for SingleUpdateStep)
I1110 22:14:10.720209  2593 solver.cpp:310]     Train net output #0: loss = 0.960517 (* 1 = 0.960517 loss)
I1110 22:14:10.720238  2593 sgd_solver.cpp:106] Iteration 129, lr = 0.001
I1110 22:14:12.722430  2593 solver.cpp:295] Iteration 130 (no loss supplied for SingleUpdateStep)
I1110 22:14:12.722558  2593 solver.cpp:310]     Train net output #0: loss = 0.912414 (* 1 = 0.912414 loss)
I1110 22:14:12.722584  2593 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I1110 22:14:14.636123  2593 solver.cpp:295] Iteration 131 (no loss supplied for SingleUpdateStep)
I1110 22:14:14.636256  2593 solver.cpp:310]     Train net output #0: loss = 0.883836 (* 1 = 0.883836 loss)
I1110 22:14:14.636281  2593 sgd_solver.cpp:106] Iteration 131, lr = 0.001
I1110 22:14:16.630130  2593 solver.cpp:295] Iteration 132 (no loss supplied for SingleUpdateStep)
I1110 22:14:16.630250  2593 solver.cpp:310]     Train net output #0: loss = 0.980178 (* 1 = 0.980178 loss)
I1110 22:14:16.630275  2593 sgd_solver.cpp:106] Iteration 132, lr = 0.001
I1110 22:14:18.385946  2593 solver.cpp:295] Iteration 133 (no loss supplied for SingleUpdateStep)
I1110 22:14:18.386011  2593 solver.cpp:310]     Train net output #0: loss = 0.934251 (* 1 = 0.934251 loss)
I1110 22:14:18.386030  2593 sgd_solver.cpp:106] Iteration 133, lr = 0.001
I1110 22:14:20.328995  2593 solver.cpp:295] Iteration 134 (no loss supplied for SingleUpdateStep)
I1110 22:14:20.329073  2593 solver.cpp:310]     Train net output #0: loss = 0.973111 (* 1 = 0.973111 loss)
I1110 22:14:20.329093  2593 sgd_solver.cpp:106] Iteration 134, lr = 0.001
I1110 22:14:22.210306  2593 solver.cpp:295] Iteration 135 (no loss supplied for SingleUpdateStep)
I1110 22:14:22.210402  2593 solver.cpp:310]     Train net output #0: loss = 0.902684 (* 1 = 0.902684 loss)
I1110 22:14:22.210422  2593 sgd_solver.cpp:106] Iteration 135, lr = 0.001
I1110 22:14:24.100780  2593 solver.cpp:295] Iteration 136 (no loss supplied for SingleUpdateStep)
I1110 22:14:24.100883  2593 solver.cpp:310]     Train net output #0: loss = 0.952094 (* 1 = 0.952094 loss)
I1110 22:14:24.100908  2593 sgd_solver.cpp:106] Iteration 136, lr = 0.001
I1110 22:14:26.130111  2593 solver.cpp:295] Iteration 137 (no loss supplied for SingleUpdateStep)
I1110 22:14:26.130261  2593 solver.cpp:310]     Train net output #0: loss = 0.906315 (* 1 = 0.906315 loss)
I1110 22:14:26.130288  2593 sgd_solver.cpp:106] Iteration 137, lr = 0.001
I1110 22:14:27.927769  2593 solver.cpp:295] Iteration 138 (no loss supplied for SingleUpdateStep)
I1110 22:14:27.927847  2593 solver.cpp:310]     Train net output #0: loss = 0.967713 (* 1 = 0.967713 loss)
I1110 22:14:27.927867  2593 sgd_solver.cpp:106] Iteration 138, lr = 0.001
I1110 22:14:29.665918  2593 solver.cpp:295] Iteration 139 (no loss supplied for SingleUpdateStep)
I1110 22:14:29.665977  2593 solver.cpp:310]     Train net output #0: loss = 0.9986 (* 1 = 0.9986 loss)
I1110 22:14:29.665997  2593 sgd_solver.cpp:106] Iteration 139, lr = 0.001
I1110 22:14:31.496675  2593 solver.cpp:295] Iteration 140 (no loss supplied for SingleUpdateStep)
I1110 22:14:31.496779  2593 solver.cpp:310]     Train net output #0: loss = 0.979944 (* 1 = 0.979944 loss)
I1110 22:14:31.496801  2593 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I1110 22:14:33.418618  2593 solver.cpp:295] Iteration 141 (no loss supplied for SingleUpdateStep)
I1110 22:14:33.418715  2593 solver.cpp:310]     Train net output #0: loss = 0.955839 (* 1 = 0.955839 loss)
I1110 22:14:33.418736  2593 sgd_solver.cpp:106] Iteration 141, lr = 0.001
I1110 22:14:35.304850  2593 solver.cpp:295] Iteration 142 (no loss supplied for SingleUpdateStep)
I1110 22:14:35.305009  2593 solver.cpp:310]     Train net output #0: loss = 0.93409 (* 1 = 0.93409 loss)
I1110 22:14:35.305038  2593 sgd_solver.cpp:106] Iteration 142, lr = 0.001
I1110 22:14:37.355372  2593 solver.cpp:295] Iteration 143 (no loss supplied for SingleUpdateStep)
I1110 22:14:37.355474  2593 solver.cpp:310]     Train net output #0: loss = 1.02852 (* 1 = 1.02852 loss)
I1110 22:14:37.355494  2593 sgd_solver.cpp:106] Iteration 143, lr = 0.001
I1110 22:14:39.190042  2593 solver.cpp:295] Iteration 144 (no loss supplied for SingleUpdateStep)
I1110 22:14:39.190130  2593 solver.cpp:310]     Train net output #0: loss = 1.03023 (* 1 = 1.03023 loss)
I1110 22:14:39.190152  2593 sgd_solver.cpp:106] Iteration 144, lr = 0.001
I1110 22:14:41.203372  2593 solver.cpp:295] Iteration 145 (no loss supplied for SingleUpdateStep)
I1110 22:14:41.203501  2593 solver.cpp:310]     Train net output #0: loss = 0.939169 (* 1 = 0.939169 loss)
I1110 22:14:41.203532  2593 sgd_solver.cpp:106] Iteration 145, lr = 0.001
I1110 22:14:43.093482  2593 solver.cpp:295] Iteration 146 (no loss supplied for SingleUpdateStep)
I1110 22:14:43.093621  2593 solver.cpp:310]     Train net output #0: loss = 1.02291 (* 1 = 1.02291 loss)
I1110 22:14:43.093648  2593 sgd_solver.cpp:106] Iteration 146, lr = 0.001
I1110 22:14:44.835357  2593 solver.cpp:295] Iteration 147 (no loss supplied for SingleUpdateStep)
I1110 22:14:44.835464  2593 solver.cpp:310]     Train net output #0: loss = 0.961667 (* 1 = 0.961667 loss)
I1110 22:14:44.835487  2593 sgd_solver.cpp:106] Iteration 147, lr = 0.001
I1110 22:14:46.864035  2593 solver.cpp:295] Iteration 148 (no loss supplied for SingleUpdateStep)
I1110 22:14:46.864153  2593 solver.cpp:310]     Train net output #0: loss = 0.923597 (* 1 = 0.923597 loss)
I1110 22:14:46.864176  2593 sgd_solver.cpp:106] Iteration 148, lr = 0.001
I1110 22:14:48.898299  2593 solver.cpp:295] Iteration 149 (no loss supplied for SingleUpdateStep)
I1110 22:14:48.898408  2593 solver.cpp:310]     Train net output #0: loss = 0.957277 (* 1 = 0.957277 loss)
I1110 22:14:48.898434  2593 sgd_solver.cpp:106] Iteration 149, lr = 0.001
I1110 22:14:51.065404  2593 solver.cpp:295] Iteration 150 (no loss supplied for SingleUpdateStep)
I1110 22:14:51.065521  2593 solver.cpp:310]     Train net output #0: loss = 0.917006 (* 1 = 0.917006 loss)
I1110 22:14:51.065544  2593 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1110 22:14:52.977774  2593 solver.cpp:295] Iteration 151 (no loss supplied for SingleUpdateStep)
I1110 22:14:52.977924  2593 solver.cpp:310]     Train net output #0: loss = 0.992484 (* 1 = 0.992484 loss)
I1110 22:14:52.977951  2593 sgd_solver.cpp:106] Iteration 151, lr = 0.001
I1110 22:14:54.931165  2593 solver.cpp:295] Iteration 152 (no loss supplied for SingleUpdateStep)
I1110 22:14:54.931300  2593 solver.cpp:310]     Train net output #0: loss = 0.97287 (* 1 = 0.97287 loss)
I1110 22:14:54.931323  2593 sgd_solver.cpp:106] Iteration 152, lr = 0.001
I1110 22:14:56.764663  2593 solver.cpp:295] Iteration 153 (no loss supplied for SingleUpdateStep)
I1110 22:14:56.764735  2593 solver.cpp:310]     Train net output #0: loss = 0.882969 (* 1 = 0.882969 loss)
I1110 22:14:56.764756  2593 sgd_solver.cpp:106] Iteration 153, lr = 0.001
I1110 22:14:58.905580  2593 solver.cpp:295] Iteration 154 (no loss supplied for SingleUpdateStep)
I1110 22:14:58.905699  2593 solver.cpp:310]     Train net output #0: loss = 0.964227 (* 1 = 0.964227 loss)
I1110 22:14:58.905724  2593 sgd_solver.cpp:106] Iteration 154, lr = 0.001
I1110 22:15:00.762645  2593 solver.cpp:295] Iteration 155 (no loss supplied for SingleUpdateStep)
I1110 22:15:00.762727  2593 solver.cpp:310]     Train net output #0: loss = 0.863251 (* 1 = 0.863251 loss)
I1110 22:15:00.762748  2593 sgd_solver.cpp:106] Iteration 155, lr = 0.001
I1110 22:15:02.511308  2593 solver.cpp:295] Iteration 156 (no loss supplied for SingleUpdateStep)
I1110 22:15:02.511387  2593 solver.cpp:310]     Train net output #0: loss = 0.969973 (* 1 = 0.969973 loss)
I1110 22:15:02.511409  2593 sgd_solver.cpp:106] Iteration 156, lr = 0.001
I1110 22:15:04.633137  2593 solver.cpp:295] Iteration 157 (no loss supplied for SingleUpdateStep)
I1110 22:15:04.633239  2593 solver.cpp:310]     Train net output #0: loss = 0.908191 (* 1 = 0.908191 loss)
I1110 22:15:04.633265  2593 sgd_solver.cpp:106] Iteration 157, lr = 0.001
I1110 22:15:06.436472  2593 solver.cpp:295] Iteration 158 (no loss supplied for SingleUpdateStep)
I1110 22:15:06.436573  2593 solver.cpp:310]     Train net output #0: loss = 0.979142 (* 1 = 0.979142 loss)
I1110 22:15:06.436594  2593 sgd_solver.cpp:106] Iteration 158, lr = 0.001
I1110 22:15:08.356118  2593 solver.cpp:295] Iteration 159 (no loss supplied for SingleUpdateStep)
I1110 22:15:08.356261  2593 solver.cpp:310]     Train net output #0: loss = 0.978264 (* 1 = 0.978264 loss)
I1110 22:15:08.356282  2593 sgd_solver.cpp:106] Iteration 159, lr = 0.001
I1110 22:15:10.373226  2593 solver.cpp:295] Iteration 160 (no loss supplied for SingleUpdateStep)
I1110 22:15:10.373278  2593 solver.cpp:310]     Train net output #0: loss = 0.89668 (* 1 = 0.89668 loss)
I1110 22:15:10.373297  2593 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I1110 22:15:12.338886  2593 solver.cpp:295] Iteration 161 (no loss supplied for SingleUpdateStep)
I1110 22:15:12.338990  2593 solver.cpp:310]     Train net output #0: loss = 0.976353 (* 1 = 0.976353 loss)
I1110 22:15:12.339014  2593 sgd_solver.cpp:106] Iteration 161, lr = 0.001
I1110 22:15:14.520285  2593 solver.cpp:295] Iteration 162 (no loss supplied for SingleUpdateStep)
I1110 22:15:14.520401  2593 solver.cpp:310]     Train net output #0: loss = 0.961654 (* 1 = 0.961654 loss)
I1110 22:15:14.520422  2593 sgd_solver.cpp:106] Iteration 162, lr = 0.001
I1110 22:15:16.954221  2593 solver.cpp:295] Iteration 163 (no loss supplied for SingleUpdateStep)
I1110 22:15:16.954330  2593 solver.cpp:310]     Train net output #0: loss = 0.950538 (* 1 = 0.950538 loss)
I1110 22:15:16.954351  2593 sgd_solver.cpp:106] Iteration 163, lr = 0.001
I1110 22:15:18.876967  2593 solver.cpp:295] Iteration 164 (no loss supplied for SingleUpdateStep)
I1110 22:15:18.877048  2593 solver.cpp:310]     Train net output #0: loss = 0.961175 (* 1 = 0.961175 loss)
I1110 22:15:18.877068  2593 sgd_solver.cpp:106] Iteration 164, lr = 0.001
I1110 22:15:20.868584  2593 solver.cpp:295] Iteration 165 (no loss supplied for SingleUpdateStep)
I1110 22:15:20.868636  2593 solver.cpp:310]     Train net output #0: loss = 0.890516 (* 1 = 0.890516 loss)
I1110 22:15:20.868655  2593 sgd_solver.cpp:106] Iteration 165, lr = 0.001
I1110 22:15:23.051254  2593 solver.cpp:295] Iteration 166 (no loss supplied for SingleUpdateStep)
I1110 22:15:23.051374  2593 solver.cpp:310]     Train net output #0: loss = 0.88027 (* 1 = 0.88027 loss)
I1110 22:15:23.051401  2593 sgd_solver.cpp:106] Iteration 166, lr = 0.001
I1110 22:15:25.208660  2593 solver.cpp:295] Iteration 167 (no loss supplied for SingleUpdateStep)
I1110 22:15:25.208732  2593 solver.cpp:310]     Train net output #0: loss = 0.890944 (* 1 = 0.890944 loss)
I1110 22:15:25.208752  2593 sgd_solver.cpp:106] Iteration 167, lr = 0.001
I1110 22:15:27.670172  2593 solver.cpp:295] Iteration 168 (no loss supplied for SingleUpdateStep)
I1110 22:15:27.670246  2593 solver.cpp:310]     Train net output #0: loss = 0.942681 (* 1 = 0.942681 loss)
I1110 22:15:27.670266  2593 sgd_solver.cpp:106] Iteration 168, lr = 0.001
I1110 22:15:29.511049  2593 solver.cpp:295] Iteration 169 (no loss supplied for SingleUpdateStep)
I1110 22:15:29.511162  2593 solver.cpp:310]     Train net output #0: loss = 0.889006 (* 1 = 0.889006 loss)
I1110 22:15:29.511186  2593 sgd_solver.cpp:106] Iteration 169, lr = 0.001
I1110 22:15:31.668517  2593 solver.cpp:295] Iteration 170 (no loss supplied for SingleUpdateStep)
I1110 22:15:31.668637  2593 solver.cpp:310]     Train net output #0: loss = 0.929661 (* 1 = 0.929661 loss)
I1110 22:15:31.668659  2593 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I1110 22:15:33.709477  2593 solver.cpp:295] Iteration 171 (no loss supplied for SingleUpdateStep)
I1110 22:15:33.709565  2593 solver.cpp:310]     Train net output #0: loss = 0.878914 (* 1 = 0.878914 loss)
I1110 22:15:33.709586  2593 sgd_solver.cpp:106] Iteration 171, lr = 0.001
I1110 22:15:35.686516  2593 solver.cpp:295] Iteration 172 (no loss supplied for SingleUpdateStep)
I1110 22:15:35.686609  2593 solver.cpp:310]     Train net output #0: loss = 0.903923 (* 1 = 0.903923 loss)
I1110 22:15:35.686631  2593 sgd_solver.cpp:106] Iteration 172, lr = 0.001
I1110 22:15:37.707876  2593 solver.cpp:295] Iteration 173 (no loss supplied for SingleUpdateStep)
I1110 22:15:37.707962  2593 solver.cpp:310]     Train net output #0: loss = 0.924394 (* 1 = 0.924394 loss)
I1110 22:15:37.707983  2593 sgd_solver.cpp:106] Iteration 173, lr = 0.001
I1110 22:15:39.546672  2593 solver.cpp:295] Iteration 174 (no loss supplied for SingleUpdateStep)
I1110 22:15:39.546797  2593 solver.cpp:310]     Train net output #0: loss = 0.908576 (* 1 = 0.908576 loss)
I1110 22:15:39.546820  2593 sgd_solver.cpp:106] Iteration 174, lr = 0.001
I1110 22:15:41.446457  2593 solver.cpp:295] Iteration 175 (no loss supplied for SingleUpdateStep)
I1110 22:15:41.446533  2593 solver.cpp:310]     Train net output #0: loss = 0.981976 (* 1 = 0.981976 loss)
I1110 22:15:41.446553  2593 sgd_solver.cpp:106] Iteration 175, lr = 0.001
I1110 22:15:43.469930  2593 solver.cpp:295] Iteration 176 (no loss supplied for SingleUpdateStep)
I1110 22:15:43.470038  2593 solver.cpp:310]     Train net output #0: loss = 0.941521 (* 1 = 0.941521 loss)
I1110 22:15:43.470064  2593 sgd_solver.cpp:106] Iteration 176, lr = 0.001
I1110 22:15:45.366279  2593 solver.cpp:295] Iteration 177 (no loss supplied for SingleUpdateStep)
I1110 22:15:45.366394  2593 solver.cpp:310]     Train net output #0: loss = 0.912033 (* 1 = 0.912033 loss)
I1110 22:15:45.366417  2593 sgd_solver.cpp:106] Iteration 177, lr = 0.001
I1110 22:15:47.184769  2593 solver.cpp:295] Iteration 178 (no loss supplied for SingleUpdateStep)
I1110 22:15:47.184866  2593 solver.cpp:310]     Train net output #0: loss = 1.01826 (* 1 = 1.01826 loss)
I1110 22:15:47.184885  2593 sgd_solver.cpp:106] Iteration 178, lr = 0.001
I1110 22:15:49.017722  2593 solver.cpp:295] Iteration 179 (no loss supplied for SingleUpdateStep)
I1110 22:15:49.017859  2593 solver.cpp:310]     Train net output #0: loss = 0.965959 (* 1 = 0.965959 loss)
I1110 22:15:49.017882  2593 sgd_solver.cpp:106] Iteration 179, lr = 0.001
I1110 22:15:51.017743  2593 solver.cpp:295] Iteration 180 (no loss supplied for SingleUpdateStep)
I1110 22:15:51.017823  2593 solver.cpp:310]     Train net output #0: loss = 0.919784 (* 1 = 0.919784 loss)
I1110 22:15:51.017844  2593 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I1110 22:15:52.937548  2593 solver.cpp:295] Iteration 181 (no loss supplied for SingleUpdateStep)
I1110 22:15:52.937628  2593 solver.cpp:310]     Train net output #0: loss = 0.983068 (* 1 = 0.983068 loss)
I1110 22:15:52.937649  2593 sgd_solver.cpp:106] Iteration 181, lr = 0.001
I1110 22:15:54.826025  2593 solver.cpp:295] Iteration 182 (no loss supplied for SingleUpdateStep)
I1110 22:15:54.826077  2593 solver.cpp:310]     Train net output #0: loss = 0.951291 (* 1 = 0.951291 loss)
I1110 22:15:54.826097  2593 sgd_solver.cpp:106] Iteration 182, lr = 0.001
I1110 22:15:56.834488  2593 solver.cpp:295] Iteration 183 (no loss supplied for SingleUpdateStep)
I1110 22:15:56.834605  2593 solver.cpp:310]     Train net output #0: loss = 0.941328 (* 1 = 0.941328 loss)
I1110 22:15:56.834627  2593 sgd_solver.cpp:106] Iteration 183, lr = 0.001
I1110 22:15:58.758247  2593 solver.cpp:295] Iteration 184 (no loss supplied for SingleUpdateStep)
I1110 22:15:58.758353  2593 solver.cpp:310]     Train net output #0: loss = 0.92988 (* 1 = 0.92988 loss)
I1110 22:15:58.758376  2593 sgd_solver.cpp:106] Iteration 184, lr = 0.001
I1110 22:16:00.560952  2593 solver.cpp:295] Iteration 185 (no loss supplied for SingleUpdateStep)
I1110 22:16:00.561053  2593 solver.cpp:310]     Train net output #0: loss = 0.960723 (* 1 = 0.960723 loss)
I1110 22:16:00.561074  2593 sgd_solver.cpp:106] Iteration 185, lr = 0.001
I1110 22:16:02.493113  2593 solver.cpp:295] Iteration 186 (no loss supplied for SingleUpdateStep)
I1110 22:16:02.493222  2593 solver.cpp:310]     Train net output #0: loss = 0.994679 (* 1 = 0.994679 loss)
I1110 22:16:02.493245  2593 sgd_solver.cpp:106] Iteration 186, lr = 0.001
I1110 22:16:04.406013  2593 solver.cpp:295] Iteration 187 (no loss supplied for SingleUpdateStep)
I1110 22:16:04.406152  2593 solver.cpp:310]     Train net output #0: loss = 1.00397 (* 1 = 1.00397 loss)
I1110 22:16:04.406177  2593 sgd_solver.cpp:106] Iteration 187, lr = 0.001
I1110 22:16:06.479300  2593 solver.cpp:295] Iteration 188 (no loss supplied for SingleUpdateStep)
I1110 22:16:06.479403  2593 solver.cpp:310]     Train net output #0: loss = 0.964648 (* 1 = 0.964648 loss)
I1110 22:16:06.479425  2593 sgd_solver.cpp:106] Iteration 188, lr = 0.001
I1110 22:16:08.732846  2593 solver.cpp:295] Iteration 189 (no loss supplied for SingleUpdateStep)
I1110 22:16:08.732995  2593 solver.cpp:310]     Train net output #0: loss = 0.928898 (* 1 = 0.928898 loss)
I1110 22:16:08.733017  2593 sgd_solver.cpp:106] Iteration 189, lr = 0.001
I1110 22:16:10.618557  2593 solver.cpp:295] Iteration 190 (no loss supplied for SingleUpdateStep)
I1110 22:16:10.618650  2593 solver.cpp:310]     Train net output #0: loss = 1.00444 (* 1 = 1.00444 loss)
I1110 22:16:10.618674  2593 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I1110 22:16:12.417357  2593 solver.cpp:295] Iteration 191 (no loss supplied for SingleUpdateStep)
I1110 22:16:12.417446  2593 solver.cpp:310]     Train net output #0: loss = 0.926002 (* 1 = 0.926002 loss)
I1110 22:16:12.417469  2593 sgd_solver.cpp:106] Iteration 191, lr = 0.001
I1110 22:16:14.345012  2593 solver.cpp:295] Iteration 192 (no loss supplied for SingleUpdateStep)
I1110 22:16:14.345161  2593 solver.cpp:310]     Train net output #0: loss = 0.918626 (* 1 = 0.918626 loss)
I1110 22:16:14.345190  2593 sgd_solver.cpp:106] Iteration 192, lr = 0.001
I1110 22:16:16.272482  2593 solver.cpp:295] Iteration 193 (no loss supplied for SingleUpdateStep)
I1110 22:16:16.272600  2593 solver.cpp:310]     Train net output #0: loss = 0.957363 (* 1 = 0.957363 loss)
I1110 22:16:16.272625  2593 sgd_solver.cpp:106] Iteration 193, lr = 0.001
I1110 22:16:18.388146  2593 solver.cpp:295] Iteration 194 (no loss supplied for SingleUpdateStep)
I1110 22:16:18.388212  2593 solver.cpp:310]     Train net output #0: loss = 0.90674 (* 1 = 0.90674 loss)
I1110 22:16:18.388233  2593 sgd_solver.cpp:106] Iteration 194, lr = 0.001
I1110 22:16:20.583694  2593 solver.cpp:295] Iteration 195 (no loss supplied for SingleUpdateStep)
I1110 22:16:20.583765  2593 solver.cpp:310]     Train net output #0: loss = 0.942842 (* 1 = 0.942842 loss)
I1110 22:16:20.583786  2593 sgd_solver.cpp:106] Iteration 195, lr = 0.001
I1110 22:16:23.047065  2593 solver.cpp:295] Iteration 196 (no loss supplied for SingleUpdateStep)
I1110 22:16:23.047147  2593 solver.cpp:310]     Train net output #0: loss = 0.998614 (* 1 = 0.998614 loss)
I1110 22:16:23.047169  2593 sgd_solver.cpp:106] Iteration 196, lr = 0.001
I1110 22:16:25.127252  2593 solver.cpp:295] Iteration 197 (no loss supplied for SingleUpdateStep)
I1110 22:16:25.127413  2593 solver.cpp:310]     Train net output #0: loss = 0.947416 (* 1 = 0.947416 loss)
I1110 22:16:25.127441  2593 sgd_solver.cpp:106] Iteration 197, lr = 0.001
I1110 22:16:27.171681  2593 solver.cpp:295] Iteration 198 (no loss supplied for SingleUpdateStep)
I1110 22:16:27.171824  2593 solver.cpp:310]     Train net output #0: loss = 0.882081 (* 1 = 0.882081 loss)
I1110 22:16:27.171852  2593 sgd_solver.cpp:106] Iteration 198, lr = 0.001
I1110 22:16:29.051560  2593 solver.cpp:295] Iteration 199 (no loss supplied for SingleUpdateStep)
I1110 22:16:29.051630  2593 solver.cpp:310]     Train net output #0: loss = 0.959231 (* 1 = 0.959231 loss)
I1110 22:16:29.051651  2593 sgd_solver.cpp:106] Iteration 199, lr = 0.001
I1110 22:16:31.168637  2593 solver.cpp:295] Iteration 200 (no loss supplied for SingleUpdateStep)
I1110 22:16:31.168740  2593 solver.cpp:310]     Train net output #0: loss = 0.906527 (* 1 = 0.906527 loss)
I1110 22:16:31.168764  2593 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1110 22:16:33.528029  2593 solver.cpp:295] Iteration 201 (no loss supplied for SingleUpdateStep)
I1110 22:16:33.528163  2593 solver.cpp:310]     Train net output #0: loss = 0.894225 (* 1 = 0.894225 loss)
I1110 22:16:33.528192  2593 sgd_solver.cpp:106] Iteration 201, lr = 0.001
I1110 22:16:35.826751  2593 solver.cpp:295] Iteration 202 (no loss supplied for SingleUpdateStep)
I1110 22:16:35.826841  2593 solver.cpp:310]     Train net output #0: loss = 0.868037 (* 1 = 0.868037 loss)
I1110 22:16:35.826860  2593 sgd_solver.cpp:106] Iteration 202, lr = 0.001
I1110 22:16:38.272958  2593 solver.cpp:295] Iteration 203 (no loss supplied for SingleUpdateStep)
I1110 22:16:38.273071  2593 solver.cpp:310]     Train net output #0: loss = 0.922105 (* 1 = 0.922105 loss)
I1110 22:16:38.273092  2593 sgd_solver.cpp:106] Iteration 203, lr = 0.001
I1110 22:16:40.790057  2593 solver.cpp:295] Iteration 204 (no loss supplied for SingleUpdateStep)
I1110 22:16:40.790179  2593 solver.cpp:310]     Train net output #0: loss = 0.940612 (* 1 = 0.940612 loss)
I1110 22:16:40.790202  2593 sgd_solver.cpp:106] Iteration 204, lr = 0.001
I1110 22:16:43.494767  2593 solver.cpp:295] Iteration 205 (no loss supplied for SingleUpdateStep)
I1110 22:16:43.494824  2593 solver.cpp:310]     Train net output #0: loss = 0.921352 (* 1 = 0.921352 loss)
I1110 22:16:43.494843  2593 sgd_solver.cpp:106] Iteration 205, lr = 0.001
I1110 22:16:46.685791  2593 solver.cpp:295] Iteration 206 (no loss supplied for SingleUpdateStep)
I1110 22:16:46.685905  2593 solver.cpp:310]     Train net output #0: loss = 0.919389 (* 1 = 0.919389 loss)
I1110 22:16:46.685927  2593 sgd_solver.cpp:106] Iteration 206, lr = 0.001
I1110 22:16:49.280306  2593 solver.cpp:295] Iteration 207 (no loss supplied for SingleUpdateStep)
I1110 22:16:49.280360  2593 solver.cpp:310]     Train net output #0: loss = 0.925071 (* 1 = 0.925071 loss)
I1110 22:16:49.280380  2593 sgd_solver.cpp:106] Iteration 207, lr = 0.001
I1110 22:16:51.600257  2593 solver.cpp:295] Iteration 208 (no loss supplied for SingleUpdateStep)
I1110 22:16:51.600399  2593 solver.cpp:310]     Train net output #0: loss = 0.904195 (* 1 = 0.904195 loss)
I1110 22:16:51.600422  2593 sgd_solver.cpp:106] Iteration 208, lr = 0.001
I1110 22:16:54.085820  2593 solver.cpp:295] Iteration 209 (no loss supplied for SingleUpdateStep)
I1110 22:16:54.085948  2593 solver.cpp:310]     Train net output #0: loss = 0.964215 (* 1 = 0.964215 loss)
I1110 22:16:54.085975  2593 sgd_solver.cpp:106] Iteration 209, lr = 0.001
I1110 22:16:56.584556  2593 solver.cpp:295] Iteration 210 (no loss supplied for SingleUpdateStep)
I1110 22:16:56.584722  2593 solver.cpp:310]     Train net output #0: loss = 0.889684 (* 1 = 0.889684 loss)
I1110 22:16:56.584754  2593 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I1110 22:16:59.475833  2593 solver.cpp:295] Iteration 211 (no loss supplied for SingleUpdateStep)
I1110 22:16:59.475939  2593 solver.cpp:310]     Train net output #0: loss = 0.849294 (* 1 = 0.849294 loss)
I1110 22:16:59.475966  2593 sgd_solver.cpp:106] Iteration 211, lr = 0.001
I1110 22:17:01.798790  2593 solver.cpp:295] Iteration 212 (no loss supplied for SingleUpdateStep)
I1110 22:17:01.798894  2593 solver.cpp:310]     Train net output #0: loss = 0.878072 (* 1 = 0.878072 loss)
I1110 22:17:01.798916  2593 sgd_solver.cpp:106] Iteration 212, lr = 0.001
I1110 22:17:04.360991  2593 solver.cpp:295] Iteration 213 (no loss supplied for SingleUpdateStep)
I1110 22:17:04.361068  2593 solver.cpp:310]     Train net output #0: loss = 0.908435 (* 1 = 0.908435 loss)
I1110 22:17:04.361090  2593 sgd_solver.cpp:106] Iteration 213, lr = 0.001
I1110 22:17:06.822032  2593 solver.cpp:295] Iteration 214 (no loss supplied for SingleUpdateStep)
I1110 22:17:06.822149  2593 solver.cpp:310]     Train net output #0: loss = 0.932476 (* 1 = 0.932476 loss)
I1110 22:17:06.822175  2593 sgd_solver.cpp:106] Iteration 214, lr = 0.001
I1110 22:17:09.079200  2593 solver.cpp:295] Iteration 215 (no loss supplied for SingleUpdateStep)
I1110 22:17:09.079306  2593 solver.cpp:310]     Train net output #0: loss = 1.05623 (* 1 = 1.05623 loss)
I1110 22:17:09.079334  2593 sgd_solver.cpp:106] Iteration 215, lr = 0.001
I1110 22:17:11.498520  2593 solver.cpp:295] Iteration 216 (no loss supplied for SingleUpdateStep)
I1110 22:17:11.498603  2593 solver.cpp:310]     Train net output #0: loss = 0.925155 (* 1 = 0.925155 loss)
I1110 22:17:11.498623  2593 sgd_solver.cpp:106] Iteration 216, lr = 0.001
I1110 22:17:13.758847  2593 solver.cpp:295] Iteration 217 (no loss supplied for SingleUpdateStep)
I1110 22:17:13.758952  2593 solver.cpp:310]     Train net output #0: loss = 0.959706 (* 1 = 0.959706 loss)
I1110 22:17:13.758975  2593 sgd_solver.cpp:106] Iteration 217, lr = 0.001
I1110 22:17:15.973397  2593 solver.cpp:295] Iteration 218 (no loss supplied for SingleUpdateStep)
I1110 22:17:15.973513  2593 solver.cpp:310]     Train net output #0: loss = 0.937283 (* 1 = 0.937283 loss)
I1110 22:17:15.973538  2593 sgd_solver.cpp:106] Iteration 218, lr = 0.001
I1110 22:17:18.133159  2593 solver.cpp:295] Iteration 219 (no loss supplied for SingleUpdateStep)
I1110 22:17:18.133235  2593 solver.cpp:310]     Train net output #0: loss = 0.935276 (* 1 = 0.935276 loss)
I1110 22:17:18.133255  2593 sgd_solver.cpp:106] Iteration 219, lr = 0.001
I1110 22:17:20.389646  2593 solver.cpp:295] Iteration 220 (no loss supplied for SingleUpdateStep)
I1110 22:17:20.389694  2593 solver.cpp:310]     Train net output #0: loss = 0.877099 (* 1 = 0.877099 loss)
I1110 22:17:20.389714  2593 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I1110 22:17:22.636862  2593 solver.cpp:295] Iteration 221 (no loss supplied for SingleUpdateStep)
I1110 22:17:22.637045  2593 solver.cpp:310]     Train net output #0: loss = 0.949064 (* 1 = 0.949064 loss)
I1110 22:17:22.637076  2593 sgd_solver.cpp:106] Iteration 221, lr = 0.001
I1110 22:17:24.967350  2593 solver.cpp:295] Iteration 222 (no loss supplied for SingleUpdateStep)
I1110 22:17:24.967411  2593 solver.cpp:310]     Train net output #0: loss = 0.893194 (* 1 = 0.893194 loss)
I1110 22:17:24.967432  2593 sgd_solver.cpp:106] Iteration 222, lr = 0.001
I1110 22:17:27.238225  2593 solver.cpp:295] Iteration 223 (no loss supplied for SingleUpdateStep)
I1110 22:17:27.238296  2593 solver.cpp:310]     Train net output #0: loss = 0.811628 (* 1 = 0.811628 loss)
I1110 22:17:27.238317  2593 sgd_solver.cpp:106] Iteration 223, lr = 0.001
I1110 22:17:29.385262  2593 solver.cpp:295] Iteration 224 (no loss supplied for SingleUpdateStep)
I1110 22:17:29.385375  2593 solver.cpp:310]     Train net output #0: loss = 1.01482 (* 1 = 1.01482 loss)
I1110 22:17:29.385397  2593 sgd_solver.cpp:106] Iteration 224, lr = 0.001
I1110 22:17:31.653070  2593 solver.cpp:295] Iteration 225 (no loss supplied for SingleUpdateStep)
I1110 22:17:31.653211  2593 solver.cpp:310]     Train net output #0: loss = 0.874816 (* 1 = 0.874816 loss)
I1110 22:17:31.653234  2593 sgd_solver.cpp:106] Iteration 225, lr = 0.001
I1110 22:17:33.999673  2593 solver.cpp:295] Iteration 226 (no loss supplied for SingleUpdateStep)
I1110 22:17:33.999774  2593 solver.cpp:310]     Train net output #0: loss = 0.89226 (* 1 = 0.89226 loss)
I1110 22:17:33.999795  2593 sgd_solver.cpp:106] Iteration 226, lr = 0.001
I1110 22:17:36.230316  2593 solver.cpp:295] Iteration 227 (no loss supplied for SingleUpdateStep)
I1110 22:17:36.230419  2593 solver.cpp:310]     Train net output #0: loss = 0.834 (* 1 = 0.834 loss)
I1110 22:17:36.230442  2593 sgd_solver.cpp:106] Iteration 227, lr = 0.001
I1110 22:17:38.623128  2593 solver.cpp:295] Iteration 228 (no loss supplied for SingleUpdateStep)
I1110 22:17:38.623216  2593 solver.cpp:310]     Train net output #0: loss = 0.947696 (* 1 = 0.947696 loss)
I1110 22:17:38.623236  2593 sgd_solver.cpp:106] Iteration 228, lr = 0.001
I1110 22:17:40.786877  2593 solver.cpp:295] Iteration 229 (no loss supplied for SingleUpdateStep)
I1110 22:17:40.786993  2593 solver.cpp:310]     Train net output #0: loss = 0.870578 (* 1 = 0.870578 loss)
I1110 22:17:40.787022  2593 sgd_solver.cpp:106] Iteration 229, lr = 0.001
I1110 22:17:43.214500  2593 solver.cpp:295] Iteration 230 (no loss supplied for SingleUpdateStep)
I1110 22:17:43.214632  2593 solver.cpp:310]     Train net output #0: loss = 0.905111 (* 1 = 0.905111 loss)
I1110 22:17:43.214661  2593 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I1110 22:17:45.527021  2593 solver.cpp:295] Iteration 231 (no loss supplied for SingleUpdateStep)
I1110 22:17:45.527073  2593 solver.cpp:310]     Train net output #0: loss = 0.870103 (* 1 = 0.870103 loss)
I1110 22:17:45.527092  2593 sgd_solver.cpp:106] Iteration 231, lr = 0.001
I1110 22:17:47.867110  2593 solver.cpp:295] Iteration 232 (no loss supplied for SingleUpdateStep)
I1110 22:17:47.867297  2593 solver.cpp:310]     Train net output #0: loss = 0.903522 (* 1 = 0.903522 loss)
I1110 22:17:47.867331  2593 sgd_solver.cpp:106] Iteration 232, lr = 0.001
I1110 22:17:50.264788  2593 solver.cpp:295] Iteration 233 (no loss supplied for SingleUpdateStep)
I1110 22:17:50.264925  2593 solver.cpp:310]     Train net output #0: loss = 0.917859 (* 1 = 0.917859 loss)
I1110 22:17:50.264947  2593 sgd_solver.cpp:106] Iteration 233, lr = 0.001
I1110 22:17:52.911882  2593 solver.cpp:295] Iteration 234 (no loss supplied for SingleUpdateStep)
I1110 22:17:52.911969  2593 solver.cpp:310]     Train net output #0: loss = 0.920513 (* 1 = 0.920513 loss)
I1110 22:17:52.911989  2593 sgd_solver.cpp:106] Iteration 234, lr = 0.001
I1110 22:17:55.229616  2593 solver.cpp:295] Iteration 235 (no loss supplied for SingleUpdateStep)
I1110 22:17:55.229796  2593 solver.cpp:310]     Train net output #0: loss = 0.913122 (* 1 = 0.913122 loss)
I1110 22:17:55.229826  2593 sgd_solver.cpp:106] Iteration 235, lr = 0.001
I1110 22:17:57.524137  2593 solver.cpp:295] Iteration 236 (no loss supplied for SingleUpdateStep)
I1110 22:17:57.524241  2593 solver.cpp:310]     Train net output #0: loss = 0.879968 (* 1 = 0.879968 loss)
I1110 22:17:57.524268  2593 sgd_solver.cpp:106] Iteration 236, lr = 0.001
I1110 22:17:59.872357  2593 solver.cpp:295] Iteration 237 (no loss supplied for SingleUpdateStep)
I1110 22:17:59.872476  2593 solver.cpp:310]     Train net output #0: loss = 0.883188 (* 1 = 0.883188 loss)
I1110 22:17:59.872500  2593 sgd_solver.cpp:106] Iteration 237, lr = 0.001
I1110 22:18:02.091169  2593 solver.cpp:295] Iteration 238 (no loss supplied for SingleUpdateStep)
I1110 22:18:02.091277  2593 solver.cpp:310]     Train net output #0: loss = 0.938039 (* 1 = 0.938039 loss)
I1110 22:18:02.091301  2593 sgd_solver.cpp:106] Iteration 238, lr = 0.001
I1110 22:18:04.446877  2593 solver.cpp:295] Iteration 239 (no loss supplied for SingleUpdateStep)
I1110 22:18:04.447006  2593 solver.cpp:310]     Train net output #0: loss = 0.855811 (* 1 = 0.855811 loss)
I1110 22:18:04.447032  2593 sgd_solver.cpp:106] Iteration 239, lr = 0.001
I1110 22:18:06.697119  2593 solver.cpp:295] Iteration 240 (no loss supplied for SingleUpdateStep)
I1110 22:18:06.697227  2593 solver.cpp:310]     Train net output #0: loss = 0.930567 (* 1 = 0.930567 loss)
I1110 22:18:06.697248  2593 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I1110 22:18:09.472880  2593 solver.cpp:295] Iteration 241 (no loss supplied for SingleUpdateStep)
I1110 22:18:09.473031  2593 solver.cpp:310]     Train net output #0: loss = 0.9804 (* 1 = 0.9804 loss)
I1110 22:18:09.473053  2593 sgd_solver.cpp:106] Iteration 241, lr = 0.001
I1110 22:18:12.433017  2593 solver.cpp:295] Iteration 242 (no loss supplied for SingleUpdateStep)
I1110 22:18:12.433069  2593 solver.cpp:310]     Train net output #0: loss = 0.946691 (* 1 = 0.946691 loss)
I1110 22:18:12.433087  2593 sgd_solver.cpp:106] Iteration 242, lr = 0.001
I1110 22:18:14.988318  2593 solver.cpp:295] Iteration 243 (no loss supplied for SingleUpdateStep)
I1110 22:18:14.988453  2593 solver.cpp:310]     Train net output #0: loss = 0.905104 (* 1 = 0.905104 loss)
I1110 22:18:14.988476  2593 sgd_solver.cpp:106] Iteration 243, lr = 0.001
I1110 22:18:18.009474  2593 solver.cpp:295] Iteration 244 (no loss supplied for SingleUpdateStep)
I1110 22:18:18.009555  2593 solver.cpp:310]     Train net output #0: loss = 0.896099 (* 1 = 0.896099 loss)
I1110 22:18:18.009574  2593 sgd_solver.cpp:106] Iteration 244, lr = 0.001
I1110 22:18:20.760226  2593 solver.cpp:295] Iteration 245 (no loss supplied for SingleUpdateStep)
I1110 22:18:20.760318  2593 solver.cpp:310]     Train net output #0: loss = 0.917959 (* 1 = 0.917959 loss)
I1110 22:18:20.760339  2593 sgd_solver.cpp:106] Iteration 245, lr = 0.001
I1110 22:18:23.369108  2593 solver.cpp:295] Iteration 246 (no loss supplied for SingleUpdateStep)
I1110 22:18:23.369227  2593 solver.cpp:310]     Train net output #0: loss = 0.856305 (* 1 = 0.856305 loss)
I1110 22:18:23.369249  2593 sgd_solver.cpp:106] Iteration 246, lr = 0.001
I1110 22:18:25.816455  2593 solver.cpp:295] Iteration 247 (no loss supplied for SingleUpdateStep)
I1110 22:18:25.816551  2593 solver.cpp:310]     Train net output #0: loss = 0.893606 (* 1 = 0.893606 loss)
I1110 22:18:25.816572  2593 sgd_solver.cpp:106] Iteration 247, lr = 0.001
I1110 22:18:28.221920  2593 solver.cpp:295] Iteration 248 (no loss supplied for SingleUpdateStep)
I1110 22:18:28.222033  2593 solver.cpp:310]     Train net output #0: loss = 0.907716 (* 1 = 0.907716 loss)
I1110 22:18:28.222054  2593 sgd_solver.cpp:106] Iteration 248, lr = 0.001
I1110 22:18:30.872462  2593 solver.cpp:295] Iteration 249 (no loss supplied for SingleUpdateStep)
I1110 22:18:30.872573  2593 solver.cpp:310]     Train net output #0: loss = 0.977229 (* 1 = 0.977229 loss)
I1110 22:18:30.872602  2593 sgd_solver.cpp:106] Iteration 249, lr = 0.001
I1110 22:18:33.159021  2593 solver.cpp:295] Iteration 250 (no loss supplied for SingleUpdateStep)
I1110 22:18:33.159142  2593 solver.cpp:310]     Train net output #0: loss = 0.903001 (* 1 = 0.903001 loss)
I1110 22:18:33.159163  2593 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I1110 22:18:35.370350  2593 solver.cpp:295] Iteration 251 (no loss supplied for SingleUpdateStep)
I1110 22:18:35.370537  2593 solver.cpp:310]     Train net output #0: loss = 0.844846 (* 1 = 0.844846 loss)
I1110 22:18:35.370573  2593 sgd_solver.cpp:106] Iteration 251, lr = 0.001
I1110 22:18:37.745118  2593 solver.cpp:295] Iteration 252 (no loss supplied for SingleUpdateStep)
I1110 22:18:37.745215  2593 solver.cpp:310]     Train net output #0: loss = 0.913559 (* 1 = 0.913559 loss)
I1110 22:18:37.745234  2593 sgd_solver.cpp:106] Iteration 252, lr = 0.001
I1110 22:18:40.011894  2593 solver.cpp:295] Iteration 253 (no loss supplied for SingleUpdateStep)
I1110 22:18:40.011971  2593 solver.cpp:310]     Train net output #0: loss = 0.910749 (* 1 = 0.910749 loss)
I1110 22:18:40.011992  2593 sgd_solver.cpp:106] Iteration 253, lr = 0.001
I1110 22:18:42.671109  2593 solver.cpp:295] Iteration 254 (no loss supplied for SingleUpdateStep)
I1110 22:18:42.671165  2593 solver.cpp:310]     Train net output #0: loss = 0.916615 (* 1 = 0.916615 loss)
I1110 22:18:42.671185  2593 sgd_solver.cpp:106] Iteration 254, lr = 0.001
I1110 22:18:44.897599  2593 solver.cpp:295] Iteration 255 (no loss supplied for SingleUpdateStep)
I1110 22:18:44.897735  2593 solver.cpp:310]     Train net output #0: loss = 0.865636 (* 1 = 0.865636 loss)
I1110 22:18:44.897759  2593 sgd_solver.cpp:106] Iteration 255, lr = 0.001
I1110 22:18:47.266432  2593 solver.cpp:295] Iteration 256 (no loss supplied for SingleUpdateStep)
I1110 22:18:47.266609  2593 solver.cpp:310]     Train net output #0: loss = 0.848648 (* 1 = 0.848648 loss)
I1110 22:18:47.266638  2593 sgd_solver.cpp:106] Iteration 256, lr = 0.001
I1110 22:18:49.543642  2593 solver.cpp:295] Iteration 257 (no loss supplied for SingleUpdateStep)
I1110 22:18:49.543750  2593 solver.cpp:310]     Train net output #0: loss = 0.933183 (* 1 = 0.933183 loss)
I1110 22:18:49.543772  2593 sgd_solver.cpp:106] Iteration 257, lr = 0.001
I1110 22:18:52.405393  2593 solver.cpp:295] Iteration 258 (no loss supplied for SingleUpdateStep)
I1110 22:18:52.405535  2593 solver.cpp:310]     Train net output #0: loss = 0.921485 (* 1 = 0.921485 loss)
I1110 22:18:52.405563  2593 sgd_solver.cpp:106] Iteration 258, lr = 0.001
I1110 22:18:55.625906  2593 solver.cpp:295] Iteration 259 (no loss supplied for SingleUpdateStep)
I1110 22:18:55.625988  2593 solver.cpp:310]     Train net output #0: loss = 0.902042 (* 1 = 0.902042 loss)
I1110 22:18:55.626006  2593 sgd_solver.cpp:106] Iteration 259, lr = 0.001
I1110 22:18:58.877223  2593 solver.cpp:295] Iteration 260 (no loss supplied for SingleUpdateStep)
I1110 22:18:58.877499  2593 solver.cpp:310]     Train net output #0: loss = 0.8464 (* 1 = 0.8464 loss)
I1110 22:18:58.877548  2593 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I1110 22:19:01.388553  2593 solver.cpp:295] Iteration 261 (no loss supplied for SingleUpdateStep)
I1110 22:19:01.388706  2593 solver.cpp:310]     Train net output #0: loss = 0.811538 (* 1 = 0.811538 loss)
I1110 22:19:01.388736  2593 sgd_solver.cpp:106] Iteration 261, lr = 0.001
I1110 22:19:03.810132  2593 solver.cpp:295] Iteration 262 (no loss supplied for SingleUpdateStep)
I1110 22:19:03.810230  2593 solver.cpp:310]     Train net output #0: loss = 0.945904 (* 1 = 0.945904 loss)
I1110 22:19:03.810251  2593 sgd_solver.cpp:106] Iteration 262, lr = 0.001
I1110 22:19:06.425930  2593 solver.cpp:295] Iteration 263 (no loss supplied for SingleUpdateStep)
I1110 22:19:06.426030  2593 solver.cpp:310]     Train net output #0: loss = 0.904702 (* 1 = 0.904702 loss)
I1110 22:19:06.426054  2593 sgd_solver.cpp:106] Iteration 263, lr = 0.001
I1110 22:19:08.858783  2593 solver.cpp:295] Iteration 264 (no loss supplied for SingleUpdateStep)
I1110 22:19:08.858949  2593 solver.cpp:310]     Train net output #0: loss = 0.813958 (* 1 = 0.813958 loss)
I1110 22:19:08.858974  2593 sgd_solver.cpp:106] Iteration 264, lr = 0.001
I1110 22:19:11.433361  2593 solver.cpp:295] Iteration 265 (no loss supplied for SingleUpdateStep)
I1110 22:19:11.433456  2593 solver.cpp:310]     Train net output #0: loss = 0.940276 (* 1 = 0.940276 loss)
I1110 22:19:11.433480  2593 sgd_solver.cpp:106] Iteration 265, lr = 0.001
I1110 22:19:14.211982  2593 solver.cpp:295] Iteration 266 (no loss supplied for SingleUpdateStep)
I1110 22:19:14.212049  2593 solver.cpp:310]     Train net output #0: loss = 0.827672 (* 1 = 0.827672 loss)
I1110 22:19:14.212067  2593 sgd_solver.cpp:106] Iteration 266, lr = 0.001
I1110 22:19:17.349689  2593 solver.cpp:295] Iteration 267 (no loss supplied for SingleUpdateStep)
I1110 22:19:17.349784  2593 solver.cpp:310]     Train net output #0: loss = 0.85297 (* 1 = 0.85297 loss)
I1110 22:19:17.349804  2593 sgd_solver.cpp:106] Iteration 267, lr = 0.001
I1110 22:19:21.687501  2593 solver.cpp:295] Iteration 268 (no loss supplied for SingleUpdateStep)
I1110 22:19:21.687587  2593 solver.cpp:310]     Train net output #0: loss = 0.901431 (* 1 = 0.901431 loss)
I1110 22:19:21.687609  2593 sgd_solver.cpp:106] Iteration 268, lr = 0.001
I1110 22:19:25.424513  2593 solver.cpp:295] Iteration 269 (no loss supplied for SingleUpdateStep)
I1110 22:19:25.424624  2593 solver.cpp:310]     Train net output #0: loss = 0.860035 (* 1 = 0.860035 loss)
I1110 22:19:25.424648  2593 sgd_solver.cpp:106] Iteration 269, lr = 0.001
I1110 22:19:29.215950  2593 solver.cpp:295] Iteration 270 (no loss supplied for SingleUpdateStep)
I1110 22:19:29.216001  2593 solver.cpp:310]     Train net output #0: loss = 0.930466 (* 1 = 0.930466 loss)
I1110 22:19:29.216019  2593 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I1110 22:19:32.970723  2593 solver.cpp:295] Iteration 271 (no loss supplied for SingleUpdateStep)
I1110 22:19:32.970808  2593 solver.cpp:310]     Train net output #0: loss = 0.862459 (* 1 = 0.862459 loss)
I1110 22:19:32.970834  2593 sgd_solver.cpp:106] Iteration 271, lr = 0.001
I1110 22:19:36.466914  2593 solver.cpp:295] Iteration 272 (no loss supplied for SingleUpdateStep)
I1110 22:19:36.467020  2593 solver.cpp:310]     Train net output #0: loss = 0.858316 (* 1 = 0.858316 loss)
I1110 22:19:36.467042  2593 sgd_solver.cpp:106] Iteration 272, lr = 0.001
I1110 22:19:39.905640  2593 solver.cpp:295] Iteration 273 (no loss supplied for SingleUpdateStep)
I1110 22:19:39.905736  2593 solver.cpp:310]     Train net output #0: loss = 0.921876 (* 1 = 0.921876 loss)
I1110 22:19:39.905762  2593 sgd_solver.cpp:106] Iteration 273, lr = 0.001
I1110 22:19:42.349165  2593 solver.cpp:295] Iteration 274 (no loss supplied for SingleUpdateStep)
I1110 22:19:42.349246  2593 solver.cpp:310]     Train net output #0: loss = 0.875712 (* 1 = 0.875712 loss)
I1110 22:19:42.349266  2593 sgd_solver.cpp:106] Iteration 274, lr = 0.001
I1110 22:19:44.881006  2593 solver.cpp:295] Iteration 275 (no loss supplied for SingleUpdateStep)
I1110 22:19:44.881108  2593 solver.cpp:310]     Train net output #0: loss = 0.939381 (* 1 = 0.939381 loss)
I1110 22:19:44.881131  2593 sgd_solver.cpp:106] Iteration 275, lr = 0.001
I1110 22:19:47.389953  2593 solver.cpp:295] Iteration 276 (no loss supplied for SingleUpdateStep)
I1110 22:19:47.390069  2593 solver.cpp:310]     Train net output #0: loss = 0.876499 (* 1 = 0.876499 loss)
I1110 22:19:47.390094  2593 sgd_solver.cpp:106] Iteration 276, lr = 0.001
I1110 22:19:49.967329  2593 solver.cpp:295] Iteration 277 (no loss supplied for SingleUpdateStep)
I1110 22:19:49.967408  2593 solver.cpp:310]     Train net output #0: loss = 0.807024 (* 1 = 0.807024 loss)
I1110 22:19:49.967430  2593 sgd_solver.cpp:106] Iteration 277, lr = 0.001
I1110 22:19:52.239950  2593 solver.cpp:295] Iteration 278 (no loss supplied for SingleUpdateStep)
I1110 22:19:52.240066  2593 solver.cpp:310]     Train net output #0: loss = 0.889436 (* 1 = 0.889436 loss)
I1110 22:19:52.240094  2593 sgd_solver.cpp:106] Iteration 278, lr = 0.001
I1110 22:19:54.960613  2593 solver.cpp:295] Iteration 279 (no loss supplied for SingleUpdateStep)
I1110 22:19:54.960685  2593 solver.cpp:310]     Train net output #0: loss = 0.910136 (* 1 = 0.910136 loss)
I1110 22:19:54.960706  2593 sgd_solver.cpp:106] Iteration 279, lr = 0.001
I1110 22:19:57.537111  2593 solver.cpp:295] Iteration 280 (no loss supplied for SingleUpdateStep)
I1110 22:19:57.537231  2593 solver.cpp:310]     Train net output #0: loss = 0.945381 (* 1 = 0.945381 loss)
I1110 22:19:57.537252  2593 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I1110 22:20:00.012006  2593 solver.cpp:295] Iteration 281 (no loss supplied for SingleUpdateStep)
I1110 22:20:00.012133  2593 solver.cpp:310]     Train net output #0: loss = 0.872802 (* 1 = 0.872802 loss)
I1110 22:20:00.012157  2593 sgd_solver.cpp:106] Iteration 281, lr = 0.001
I1110 22:20:02.454959  2593 solver.cpp:295] Iteration 282 (no loss supplied for SingleUpdateStep)
I1110 22:20:02.455082  2593 solver.cpp:310]     Train net output #0: loss = 0.877328 (* 1 = 0.877328 loss)
I1110 22:20:02.455104  2593 sgd_solver.cpp:106] Iteration 282, lr = 0.001
I1110 22:20:04.817783  2593 solver.cpp:295] Iteration 283 (no loss supplied for SingleUpdateStep)
I1110 22:20:04.817881  2593 solver.cpp:310]     Train net output #0: loss = 0.957193 (* 1 = 0.957193 loss)
I1110 22:20:04.817903  2593 sgd_solver.cpp:106] Iteration 283, lr = 0.001
I1110 22:20:07.051247  2593 solver.cpp:295] Iteration 284 (no loss supplied for SingleUpdateStep)
I1110 22:20:07.051393  2593 solver.cpp:310]     Train net output #0: loss = 0.933096 (* 1 = 0.933096 loss)
I1110 22:20:07.051419  2593 sgd_solver.cpp:106] Iteration 284, lr = 0.001
I1110 22:20:09.497942  2593 solver.cpp:295] Iteration 285 (no loss supplied for SingleUpdateStep)
I1110 22:20:09.498109  2593 solver.cpp:310]     Train net output #0: loss = 0.81928 (* 1 = 0.81928 loss)
I1110 22:20:09.498136  2593 sgd_solver.cpp:106] Iteration 285, lr = 0.001
I1110 22:20:11.741358  2593 solver.cpp:295] Iteration 286 (no loss supplied for SingleUpdateStep)
I1110 22:20:11.741564  2593 solver.cpp:310]     Train net output #0: loss = 0.902394 (* 1 = 0.902394 loss)
I1110 22:20:11.741591  2593 sgd_solver.cpp:106] Iteration 286, lr = 0.001
I1110 22:20:13.910235  2593 solver.cpp:295] Iteration 287 (no loss supplied for SingleUpdateStep)
I1110 22:20:13.910347  2593 solver.cpp:310]     Train net output #0: loss = 0.888687 (* 1 = 0.888687 loss)
I1110 22:20:13.910372  2593 sgd_solver.cpp:106] Iteration 287, lr = 0.001
I1110 22:20:16.321163  2593 solver.cpp:295] Iteration 288 (no loss supplied for SingleUpdateStep)
I1110 22:20:16.321305  2593 solver.cpp:310]     Train net output #0: loss = 0.871029 (* 1 = 0.871029 loss)
I1110 22:20:16.321326  2593 sgd_solver.cpp:106] Iteration 288, lr = 0.001
I1110 22:20:18.588315  2593 solver.cpp:295] Iteration 289 (no loss supplied for SingleUpdateStep)
I1110 22:20:18.588373  2593 solver.cpp:310]     Train net output #0: loss = 0.866199 (* 1 = 0.866199 loss)
I1110 22:20:18.588397  2593 sgd_solver.cpp:106] Iteration 289, lr = 0.001
I1110 22:20:20.989387  2593 solver.cpp:295] Iteration 290 (no loss supplied for SingleUpdateStep)
I1110 22:20:20.989442  2593 solver.cpp:310]     Train net output #0: loss = 0.934456 (* 1 = 0.934456 loss)
I1110 22:20:20.989461  2593 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I1110 22:20:23.336030  2593 solver.cpp:295] Iteration 291 (no loss supplied for SingleUpdateStep)
I1110 22:20:23.336108  2593 solver.cpp:310]     Train net output #0: loss = 0.856526 (* 1 = 0.856526 loss)
I1110 22:20:23.336128  2593 sgd_solver.cpp:106] Iteration 291, lr = 0.001
I1110 22:20:25.708282  2593 solver.cpp:295] Iteration 292 (no loss supplied for SingleUpdateStep)
I1110 22:20:25.708422  2593 solver.cpp:310]     Train net output #0: loss = 0.780845 (* 1 = 0.780845 loss)
I1110 22:20:25.708453  2593 sgd_solver.cpp:106] Iteration 292, lr = 0.001
I1110 22:20:27.955703  2593 solver.cpp:295] Iteration 293 (no loss supplied for SingleUpdateStep)
I1110 22:20:27.955804  2593 solver.cpp:310]     Train net output #0: loss = 0.933394 (* 1 = 0.933394 loss)
I1110 22:20:27.955824  2593 sgd_solver.cpp:106] Iteration 293, lr = 0.001
I1110 22:20:30.261939  2593 solver.cpp:295] Iteration 294 (no loss supplied for SingleUpdateStep)
I1110 22:20:30.262019  2593 solver.cpp:310]     Train net output #0: loss = 0.897465 (* 1 = 0.897465 loss)
I1110 22:20:30.262040  2593 sgd_solver.cpp:106] Iteration 294, lr = 0.001
I1110 22:20:32.816946  2593 solver.cpp:295] Iteration 295 (no loss supplied for SingleUpdateStep)
I1110 22:20:32.817041  2593 solver.cpp:310]     Train net output #0: loss = 0.906322 (* 1 = 0.906322 loss)
I1110 22:20:32.817064  2593 sgd_solver.cpp:106] Iteration 295, lr = 0.001
I1110 22:20:35.052994  2593 solver.cpp:295] Iteration 296 (no loss supplied for SingleUpdateStep)
I1110 22:20:35.053089  2593 solver.cpp:310]     Train net output #0: loss = 0.794008 (* 1 = 0.794008 loss)
I1110 22:20:35.053110  2593 sgd_solver.cpp:106] Iteration 296, lr = 0.001
I1110 22:20:37.314584  2593 solver.cpp:295] Iteration 297 (no loss supplied for SingleUpdateStep)
I1110 22:20:37.314682  2593 solver.cpp:310]     Train net output #0: loss = 0.984062 (* 1 = 0.984062 loss)
I1110 22:20:37.314703  2593 sgd_solver.cpp:106] Iteration 297, lr = 0.001
I1110 22:20:39.792616  2593 solver.cpp:295] Iteration 298 (no loss supplied for SingleUpdateStep)
I1110 22:20:39.792762  2593 solver.cpp:310]     Train net output #0: loss = 0.879516 (* 1 = 0.879516 loss)
I1110 22:20:39.792785  2593 sgd_solver.cpp:106] Iteration 298, lr = 0.001
I1110 22:20:42.166847  2593 solver.cpp:295] Iteration 299 (no loss supplied for SingleUpdateStep)
I1110 22:20:42.166954  2593 solver.cpp:310]     Train net output #0: loss = 0.798808 (* 1 = 0.798808 loss)
I1110 22:20:42.166976  2593 sgd_solver.cpp:106] Iteration 299, lr = 0.001
I1110 22:20:44.504375  2593 solver.cpp:295] Iteration 300 (no loss supplied for SingleUpdateStep)
I1110 22:20:44.504443  2593 solver.cpp:310]     Train net output #0: loss = 0.856831 (* 1 = 0.856831 loss)
I1110 22:20:44.504463  2593 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I1110 22:20:46.973371  2593 solver.cpp:295] Iteration 301 (no loss supplied for SingleUpdateStep)
I1110 22:20:46.973484  2593 solver.cpp:310]     Train net output #0: loss = 0.896562 (* 1 = 0.896562 loss)
I1110 22:20:46.973507  2593 sgd_solver.cpp:106] Iteration 301, lr = 0.001
I1110 22:20:49.517738  2593 solver.cpp:295] Iteration 302 (no loss supplied for SingleUpdateStep)
I1110 22:20:49.517863  2593 solver.cpp:310]     Train net output #0: loss = 0.88602 (* 1 = 0.88602 loss)
I1110 22:20:49.517889  2593 sgd_solver.cpp:106] Iteration 302, lr = 0.001
I1110 22:20:52.127473  2593 solver.cpp:295] Iteration 303 (no loss supplied for SingleUpdateStep)
I1110 22:20:52.127580  2593 solver.cpp:310]     Train net output #0: loss = 0.778672 (* 1 = 0.778672 loss)
I1110 22:20:52.127604  2593 sgd_solver.cpp:106] Iteration 303, lr = 0.001
I1110 22:20:54.518255  2593 solver.cpp:295] Iteration 304 (no loss supplied for SingleUpdateStep)
I1110 22:20:54.518362  2593 solver.cpp:310]     Train net output #0: loss = 0.869093 (* 1 = 0.869093 loss)
I1110 22:20:54.518388  2593 sgd_solver.cpp:106] Iteration 304, lr = 0.001
I1110 22:20:56.964408  2593 solver.cpp:295] Iteration 305 (no loss supplied for SingleUpdateStep)
I1110 22:20:56.964530  2593 solver.cpp:310]     Train net output #0: loss = 0.902866 (* 1 = 0.902866 loss)
I1110 22:20:56.964555  2593 sgd_solver.cpp:106] Iteration 305, lr = 0.001
I1110 22:20:59.315526  2593 solver.cpp:295] Iteration 306 (no loss supplied for SingleUpdateStep)
I1110 22:20:59.315621  2593 solver.cpp:310]     Train net output #0: loss = 0.84161 (* 1 = 0.84161 loss)
I1110 22:20:59.315642  2593 sgd_solver.cpp:106] Iteration 306, lr = 0.001
I1110 22:21:01.607091  2593 solver.cpp:295] Iteration 307 (no loss supplied for SingleUpdateStep)
I1110 22:21:01.607230  2593 solver.cpp:310]     Train net output #0: loss = 0.8343 (* 1 = 0.8343 loss)
I1110 22:21:01.607257  2593 sgd_solver.cpp:106] Iteration 307, lr = 0.001
I1110 22:21:03.911267  2593 solver.cpp:295] Iteration 308 (no loss supplied for SingleUpdateStep)
I1110 22:21:03.911389  2593 solver.cpp:310]     Train net output #0: loss = 0.987992 (* 1 = 0.987992 loss)
I1110 22:21:03.911415  2593 sgd_solver.cpp:106] Iteration 308, lr = 0.001
I1110 22:21:06.331497  2593 solver.cpp:295] Iteration 309 (no loss supplied for SingleUpdateStep)
I1110 22:21:06.331616  2593 solver.cpp:310]     Train net output #0: loss = 0.843909 (* 1 = 0.843909 loss)
I1110 22:21:06.331640  2593 sgd_solver.cpp:106] Iteration 309, lr = 0.001
I1110 22:21:08.745069  2593 solver.cpp:295] Iteration 310 (no loss supplied for SingleUpdateStep)
I1110 22:21:08.745179  2593 solver.cpp:310]     Train net output #0: loss = 0.797997 (* 1 = 0.797997 loss)
I1110 22:21:08.745205  2593 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I1110 22:21:11.443872  2593 solver.cpp:295] Iteration 311 (no loss supplied for SingleUpdateStep)
I1110 22:21:11.443946  2593 solver.cpp:310]     Train net output #0: loss = 0.894279 (* 1 = 0.894279 loss)
I1110 22:21:11.443966  2593 sgd_solver.cpp:106] Iteration 311, lr = 0.001
I1110 22:21:13.783455  2593 solver.cpp:295] Iteration 312 (no loss supplied for SingleUpdateStep)
I1110 22:21:13.783536  2593 solver.cpp:310]     Train net output #0: loss = 0.880809 (* 1 = 0.880809 loss)
I1110 22:21:13.783565  2593 sgd_solver.cpp:106] Iteration 312, lr = 0.001
I1110 22:21:16.250602  2593 solver.cpp:295] Iteration 313 (no loss supplied for SingleUpdateStep)
I1110 22:21:16.250679  2593 solver.cpp:310]     Train net output #0: loss = 0.909373 (* 1 = 0.909373 loss)
I1110 22:21:16.250699  2593 sgd_solver.cpp:106] Iteration 313, lr = 0.001
I1110 22:21:19.032096  2593 solver.cpp:295] Iteration 314 (no loss supplied for SingleUpdateStep)
I1110 22:21:19.032176  2593 solver.cpp:310]     Train net output #0: loss = 0.920232 (* 1 = 0.920232 loss)
I1110 22:21:19.032198  2593 sgd_solver.cpp:106] Iteration 314, lr = 0.001
I1110 22:21:22.030596  2593 solver.cpp:295] Iteration 315 (no loss supplied for SingleUpdateStep)
I1110 22:21:22.030699  2593 solver.cpp:310]     Train net output #0: loss = 0.858675 (* 1 = 0.858675 loss)
I1110 22:21:22.030719  2593 sgd_solver.cpp:106] Iteration 315, lr = 0.001
I1110 22:21:24.611666  2593 solver.cpp:295] Iteration 316 (no loss supplied for SingleUpdateStep)
I1110 22:21:24.611784  2593 solver.cpp:310]     Train net output #0: loss = 0.880878 (* 1 = 0.880878 loss)
I1110 22:21:24.611806  2593 sgd_solver.cpp:106] Iteration 316, lr = 0.001
I1110 22:21:27.266758  2593 solver.cpp:295] Iteration 317 (no loss supplied for SingleUpdateStep)
I1110 22:21:27.266978  2593 solver.cpp:310]     Train net output #0: loss = 0.863972 (* 1 = 0.863972 loss)
I1110 22:21:27.267006  2593 sgd_solver.cpp:106] Iteration 317, lr = 0.001
I1110 22:21:29.653493  2593 solver.cpp:295] Iteration 318 (no loss supplied for SingleUpdateStep)
I1110 22:21:29.653640  2593 solver.cpp:310]     Train net output #0: loss = 0.933106 (* 1 = 0.933106 loss)
I1110 22:21:29.653666  2593 sgd_solver.cpp:106] Iteration 318, lr = 0.001
I1110 22:21:32.068964  2593 solver.cpp:295] Iteration 319 (no loss supplied for SingleUpdateStep)
I1110 22:21:32.069087  2593 solver.cpp:310]     Train net output #0: loss = 0.902917 (* 1 = 0.902917 loss)
I1110 22:21:32.069110  2593 sgd_solver.cpp:106] Iteration 319, lr = 0.001
I1110 22:21:34.307647  2593 solver.cpp:295] Iteration 320 (no loss supplied for SingleUpdateStep)
I1110 22:21:34.307698  2593 solver.cpp:310]     Train net output #0: loss = 0.863574 (* 1 = 0.863574 loss)
I1110 22:21:34.307715  2593 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I1110 22:21:36.793742  2593 solver.cpp:295] Iteration 321 (no loss supplied for SingleUpdateStep)
I1110 22:21:36.793850  2593 solver.cpp:310]     Train net output #0: loss = 0.911244 (* 1 = 0.911244 loss)
I1110 22:21:36.793870  2593 sgd_solver.cpp:106] Iteration 321, lr = 0.001
I1110 22:21:38.962483  2593 solver.cpp:295] Iteration 322 (no loss supplied for SingleUpdateStep)
I1110 22:21:38.962599  2593 solver.cpp:310]     Train net output #0: loss = 0.878293 (* 1 = 0.878293 loss)
I1110 22:21:38.962623  2593 sgd_solver.cpp:106] Iteration 322, lr = 0.001
I1110 22:21:41.459151  2593 solver.cpp:295] Iteration 323 (no loss supplied for SingleUpdateStep)
I1110 22:21:41.459219  2593 solver.cpp:310]     Train net output #0: loss = 0.865989 (* 1 = 0.865989 loss)
I1110 22:21:41.459239  2593 sgd_solver.cpp:106] Iteration 323, lr = 0.001
I1110 22:21:43.762902  2593 solver.cpp:295] Iteration 324 (no loss supplied for SingleUpdateStep)
I1110 22:21:43.763015  2593 solver.cpp:310]     Train net output #0: loss = 0.833424 (* 1 = 0.833424 loss)
I1110 22:21:43.763038  2593 sgd_solver.cpp:106] Iteration 324, lr = 0.001
I1110 22:21:46.162462  2593 solver.cpp:295] Iteration 325 (no loss supplied for SingleUpdateStep)
I1110 22:21:46.166582  2593 solver.cpp:310]     Train net output #0: loss = 0.831417 (* 1 = 0.831417 loss)
I1110 22:21:46.166631  2593 sgd_solver.cpp:106] Iteration 325, lr = 0.001
I1110 22:21:48.630192  2593 solver.cpp:295] Iteration 326 (no loss supplied for SingleUpdateStep)
I1110 22:21:48.630266  2593 solver.cpp:310]     Train net output #0: loss = 0.794746 (* 1 = 0.794746 loss)
I1110 22:21:48.630286  2593 sgd_solver.cpp:106] Iteration 326, lr = 0.001
I1110 22:21:51.063554  2593 solver.cpp:295] Iteration 327 (no loss supplied for SingleUpdateStep)
I1110 22:21:51.063679  2593 solver.cpp:310]     Train net output #0: loss = 0.839708 (* 1 = 0.839708 loss)
I1110 22:21:51.063704  2593 sgd_solver.cpp:106] Iteration 327, lr = 0.001
I1110 22:21:53.443694  2593 solver.cpp:295] Iteration 328 (no loss supplied for SingleUpdateStep)
I1110 22:21:53.443864  2593 solver.cpp:310]     Train net output #0: loss = 0.901371 (* 1 = 0.901371 loss)
I1110 22:21:53.443892  2593 sgd_solver.cpp:106] Iteration 328, lr = 0.001
I1110 22:21:55.810647  2593 solver.cpp:295] Iteration 329 (no loss supplied for SingleUpdateStep)
I1110 22:21:55.825920  2593 solver.cpp:310]     Train net output #0: loss = 0.877816 (* 1 = 0.877816 loss)
I1110 22:21:55.825966  2593 sgd_solver.cpp:106] Iteration 329, lr = 0.001
I1110 22:21:58.241991  2593 solver.cpp:295] Iteration 330 (no loss supplied for SingleUpdateStep)
I1110 22:21:58.242097  2593 solver.cpp:310]     Train net output #0: loss = 0.872572 (* 1 = 0.872572 loss)
I1110 22:21:58.242120  2593 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I1110 22:22:00.539093  2593 solver.cpp:295] Iteration 331 (no loss supplied for SingleUpdateStep)
I1110 22:22:00.539173  2593 solver.cpp:310]     Train net output #0: loss = 0.842944 (* 1 = 0.842944 loss)
I1110 22:22:00.539194  2593 sgd_solver.cpp:106] Iteration 331, lr = 0.001
I1110 22:22:02.953613  2593 solver.cpp:295] Iteration 332 (no loss supplied for SingleUpdateStep)
I1110 22:22:02.953774  2593 solver.cpp:310]     Train net output #0: loss = 0.825928 (* 1 = 0.825928 loss)
I1110 22:22:02.953801  2593 sgd_solver.cpp:106] Iteration 332, lr = 0.001
I1110 22:22:05.545285  2593 solver.cpp:295] Iteration 333 (no loss supplied for SingleUpdateStep)
I1110 22:22:05.545506  2593 solver.cpp:310]     Train net output #0: loss = 0.869759 (* 1 = 0.869759 loss)
I1110 22:22:05.545541  2593 sgd_solver.cpp:106] Iteration 333, lr = 0.001
I1110 22:22:08.163875  2593 solver.cpp:295] Iteration 334 (no loss supplied for SingleUpdateStep)
I1110 22:22:08.163975  2593 solver.cpp:310]     Train net output #0: loss = 0.807535 (* 1 = 0.807535 loss)
I1110 22:22:08.164001  2593 sgd_solver.cpp:106] Iteration 334, lr = 0.001
I1110 22:22:10.782141  2593 solver.cpp:295] Iteration 335 (no loss supplied for SingleUpdateStep)
I1110 22:22:10.782199  2593 solver.cpp:310]     Train net output #0: loss = 0.855036 (* 1 = 0.855036 loss)
I1110 22:22:10.782217  2593 sgd_solver.cpp:106] Iteration 335, lr = 0.001
I1110 22:22:13.659548  2593 solver.cpp:295] Iteration 336 (no loss supplied for SingleUpdateStep)
I1110 22:22:13.659662  2593 solver.cpp:310]     Train net output #0: loss = 0.828997 (* 1 = 0.828997 loss)
I1110 22:22:13.659685  2593 sgd_solver.cpp:106] Iteration 336, lr = 0.001
I1110 22:22:16.542990  2593 solver.cpp:295] Iteration 337 (no loss supplied for SingleUpdateStep)
I1110 22:22:16.543041  2593 solver.cpp:310]     Train net output #0: loss = 0.830939 (* 1 = 0.830939 loss)
I1110 22:22:16.543059  2593 sgd_solver.cpp:106] Iteration 337, lr = 0.001
I1110 22:22:19.914391  2593 solver.cpp:295] Iteration 338 (no loss supplied for SingleUpdateStep)
I1110 22:22:19.914484  2593 solver.cpp:310]     Train net output #0: loss = 0.819303 (* 1 = 0.819303 loss)
I1110 22:22:19.914507  2593 sgd_solver.cpp:106] Iteration 338, lr = 0.001
I1110 22:22:22.357794  2593 solver.cpp:295] Iteration 339 (no loss supplied for SingleUpdateStep)
I1110 22:22:22.357935  2593 solver.cpp:310]     Train net output #0: loss = 0.857297 (* 1 = 0.857297 loss)
I1110 22:22:22.357966  2593 sgd_solver.cpp:106] Iteration 339, lr = 0.001
I1110 22:22:24.847021  2593 solver.cpp:295] Iteration 340 (no loss supplied for SingleUpdateStep)
I1110 22:22:24.847100  2593 solver.cpp:310]     Train net output #0: loss = 0.827381 (* 1 = 0.827381 loss)
I1110 22:22:24.847120  2593 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I1110 22:22:27.442371  2593 solver.cpp:295] Iteration 341 (no loss supplied for SingleUpdateStep)
I1110 22:22:27.442477  2593 solver.cpp:310]     Train net output #0: loss = 0.838821 (* 1 = 0.838821 loss)
I1110 22:22:27.442500  2593 sgd_solver.cpp:106] Iteration 341, lr = 0.001
I1110 22:22:29.955279  2593 solver.cpp:295] Iteration 342 (no loss supplied for SingleUpdateStep)
I1110 22:22:29.955391  2593 solver.cpp:310]     Train net output #0: loss = 0.875497 (* 1 = 0.875497 loss)
I1110 22:22:29.955413  2593 sgd_solver.cpp:106] Iteration 342, lr = 0.001
I1110 22:22:32.492480  2593 solver.cpp:295] Iteration 343 (no loss supplied for SingleUpdateStep)
I1110 22:22:32.492537  2593 solver.cpp:310]     Train net output #0: loss = 0.828342 (* 1 = 0.828342 loss)
I1110 22:22:32.492555  2593 sgd_solver.cpp:106] Iteration 343, lr = 0.001
I1110 22:22:34.932840  2593 solver.cpp:295] Iteration 344 (no loss supplied for SingleUpdateStep)
I1110 22:22:34.932955  2593 solver.cpp:310]     Train net output #0: loss = 0.815523 (* 1 = 0.815523 loss)
I1110 22:22:34.932978  2593 sgd_solver.cpp:106] Iteration 344, lr = 0.001
I1110 22:22:37.452386  2593 solver.cpp:295] Iteration 345 (no loss supplied for SingleUpdateStep)
I1110 22:22:37.452509  2593 solver.cpp:310]     Train net output #0: loss = 0.842252 (* 1 = 0.842252 loss)
I1110 22:22:37.452533  2593 sgd_solver.cpp:106] Iteration 345, lr = 0.001
I1110 22:22:39.990738  2593 solver.cpp:295] Iteration 346 (no loss supplied for SingleUpdateStep)
I1110 22:22:39.990839  2593 solver.cpp:310]     Train net output #0: loss = 0.844927 (* 1 = 0.844927 loss)
I1110 22:22:39.990860  2593 sgd_solver.cpp:106] Iteration 346, lr = 0.001
I1110 22:22:42.775660  2593 solver.cpp:295] Iteration 347 (no loss supplied for SingleUpdateStep)
I1110 22:22:42.775786  2593 solver.cpp:310]     Train net output #0: loss = 0.828709 (* 1 = 0.828709 loss)
I1110 22:22:42.775810  2593 sgd_solver.cpp:106] Iteration 347, lr = 0.001
I1110 22:22:45.556022  2593 solver.cpp:295] Iteration 348 (no loss supplied for SingleUpdateStep)
I1110 22:22:45.556095  2593 solver.cpp:310]     Train net output #0: loss = 0.85086 (* 1 = 0.85086 loss)
I1110 22:22:45.556115  2593 sgd_solver.cpp:106] Iteration 348, lr = 0.001
I1110 22:22:48.478997  2593 solver.cpp:295] Iteration 349 (no loss supplied for SingleUpdateStep)
I1110 22:22:48.479099  2593 solver.cpp:310]     Train net output #0: loss = 0.909408 (* 1 = 0.909408 loss)
I1110 22:22:48.479121  2593 sgd_solver.cpp:106] Iteration 349, lr = 0.001
I1110 22:22:50.862009  2593 solver.cpp:295] Iteration 350 (no loss supplied for SingleUpdateStep)
I1110 22:22:50.862085  2593 solver.cpp:310]     Train net output #0: loss = 0.807427 (* 1 = 0.807427 loss)
I1110 22:22:50.862105  2593 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I1110 22:22:53.388504  2593 solver.cpp:295] Iteration 351 (no loss supplied for SingleUpdateStep)
I1110 22:22:53.388581  2593 solver.cpp:310]     Train net output #0: loss = 0.851257 (* 1 = 0.851257 loss)
I1110 22:22:53.388602  2593 sgd_solver.cpp:106] Iteration 351, lr = 0.001
I1110 22:22:56.314847  2593 solver.cpp:295] Iteration 352 (no loss supplied for SingleUpdateStep)
I1110 22:22:56.314975  2593 solver.cpp:310]     Train net output #0: loss = 0.845038 (* 1 = 0.845038 loss)
I1110 22:22:56.314999  2593 sgd_solver.cpp:106] Iteration 352, lr = 0.001
I1110 22:22:58.809188  2593 solver.cpp:295] Iteration 353 (no loss supplied for SingleUpdateStep)
I1110 22:22:58.809269  2593 solver.cpp:310]     Train net output #0: loss = 0.836665 (* 1 = 0.836665 loss)
I1110 22:22:58.809293  2593 sgd_solver.cpp:106] Iteration 353, lr = 0.001
I1110 22:23:01.704462  2593 solver.cpp:295] Iteration 354 (no loss supplied for SingleUpdateStep)
I1110 22:23:01.704555  2593 solver.cpp:310]     Train net output #0: loss = 0.895487 (* 1 = 0.895487 loss)
I1110 22:23:01.704577  2593 sgd_solver.cpp:106] Iteration 354, lr = 0.001
I1110 22:23:04.561331  2593 solver.cpp:295] Iteration 355 (no loss supplied for SingleUpdateStep)
I1110 22:23:04.561390  2593 solver.cpp:310]     Train net output #0: loss = 0.769118 (* 1 = 0.769118 loss)
I1110 22:23:04.561410  2593 sgd_solver.cpp:106] Iteration 355, lr = 0.001
I1110 22:23:07.532667  2593 solver.cpp:295] Iteration 356 (no loss supplied for SingleUpdateStep)
I1110 22:23:07.532800  2593 solver.cpp:310]     Train net output #0: loss = 0.844526 (* 1 = 0.844526 loss)
I1110 22:23:07.532824  2593 sgd_solver.cpp:106] Iteration 356, lr = 0.001
I1110 22:23:10.051276  2593 solver.cpp:295] Iteration 357 (no loss supplied for SingleUpdateStep)
I1110 22:23:10.051373  2593 solver.cpp:310]     Train net output #0: loss = 0.82442 (* 1 = 0.82442 loss)
I1110 22:23:10.051393  2593 sgd_solver.cpp:106] Iteration 357, lr = 0.001
I1110 22:23:12.710175  2593 solver.cpp:295] Iteration 358 (no loss supplied for SingleUpdateStep)
I1110 22:23:12.710307  2593 solver.cpp:310]     Train net output #0: loss = 0.885393 (* 1 = 0.885393 loss)
I1110 22:23:12.710330  2593 sgd_solver.cpp:106] Iteration 358, lr = 0.001
I1110 22:23:15.550429  2593 solver.cpp:295] Iteration 359 (no loss supplied for SingleUpdateStep)
I1110 22:23:15.550529  2593 solver.cpp:310]     Train net output #0: loss = 0.792588 (* 1 = 0.792588 loss)
I1110 22:23:15.550554  2593 sgd_solver.cpp:106] Iteration 359, lr = 0.001
I1110 22:23:17.834570  2593 solver.cpp:295] Iteration 360 (no loss supplied for SingleUpdateStep)
I1110 22:23:17.834645  2593 solver.cpp:310]     Train net output #0: loss = 0.865409 (* 1 = 0.865409 loss)
I1110 22:23:17.834666  2593 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I1110 22:23:20.508488  2593 solver.cpp:295] Iteration 361 (no loss supplied for SingleUpdateStep)
I1110 22:23:20.508570  2593 solver.cpp:310]     Train net output #0: loss = 0.849987 (* 1 = 0.849987 loss)
I1110 22:23:20.508592  2593 sgd_solver.cpp:106] Iteration 361, lr = 0.001
I1110 22:23:22.976582  2593 solver.cpp:295] Iteration 362 (no loss supplied for SingleUpdateStep)
I1110 22:23:22.976677  2593 solver.cpp:310]     Train net output #0: loss = 0.834585 (* 1 = 0.834585 loss)
I1110 22:23:22.976701  2593 sgd_solver.cpp:106] Iteration 362, lr = 0.001
I1110 22:23:25.373268  2593 solver.cpp:295] Iteration 363 (no loss supplied for SingleUpdateStep)
I1110 22:23:25.373396  2593 solver.cpp:310]     Train net output #0: loss = 0.842973 (* 1 = 0.842973 loss)
I1110 22:23:25.373422  2593 sgd_solver.cpp:106] Iteration 363, lr = 0.001
I1110 22:23:27.690230  2593 solver.cpp:295] Iteration 364 (no loss supplied for SingleUpdateStep)
I1110 22:23:27.690325  2593 solver.cpp:310]     Train net output #0: loss = 0.770825 (* 1 = 0.770825 loss)
I1110 22:23:27.690346  2593 sgd_solver.cpp:106] Iteration 364, lr = 0.001
I1110 22:23:30.208209  2593 solver.cpp:295] Iteration 365 (no loss supplied for SingleUpdateStep)
I1110 22:23:30.208310  2593 solver.cpp:310]     Train net output #0: loss = 0.79836 (* 1 = 0.79836 loss)
I1110 22:23:30.208333  2593 sgd_solver.cpp:106] Iteration 365, lr = 0.001
I1110 22:23:33.281647  2593 solver.cpp:295] Iteration 366 (no loss supplied for SingleUpdateStep)
I1110 22:23:33.281740  2593 solver.cpp:310]     Train net output #0: loss = 0.830127 (* 1 = 0.830127 loss)
I1110 22:23:33.281762  2593 sgd_solver.cpp:106] Iteration 366, lr = 0.001
I1110 22:23:36.019490  2593 solver.cpp:295] Iteration 367 (no loss supplied for SingleUpdateStep)
I1110 22:23:36.019589  2593 solver.cpp:310]     Train net output #0: loss = 0.827086 (* 1 = 0.827086 loss)
I1110 22:23:36.019613  2593 sgd_solver.cpp:106] Iteration 367, lr = 0.001
I1110 22:23:38.438047  2593 solver.cpp:295] Iteration 368 (no loss supplied for SingleUpdateStep)
I1110 22:23:38.438164  2593 solver.cpp:310]     Train net output #0: loss = 0.829207 (* 1 = 0.829207 loss)
I1110 22:23:38.438187  2593 sgd_solver.cpp:106] Iteration 368, lr = 0.001
I1110 22:23:41.207885  2593 solver.cpp:295] Iteration 369 (no loss supplied for SingleUpdateStep)
I1110 22:23:41.208082  2593 solver.cpp:310]     Train net output #0: loss = 0.877446 (* 1 = 0.877446 loss)
I1110 22:23:41.208107  2593 sgd_solver.cpp:106] Iteration 369, lr = 0.001
I1110 22:23:43.644845  2593 solver.cpp:295] Iteration 370 (no loss supplied for SingleUpdateStep)
I1110 22:23:43.644958  2593 solver.cpp:310]     Train net output #0: loss = 0.808768 (* 1 = 0.808768 loss)
I1110 22:23:43.644979  2593 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I1110 22:23:46.101479  2593 solver.cpp:295] Iteration 371 (no loss supplied for SingleUpdateStep)
I1110 22:23:46.101578  2593 solver.cpp:310]     Train net output #0: loss = 0.867629 (* 1 = 0.867629 loss)
I1110 22:23:46.101599  2593 sgd_solver.cpp:106] Iteration 371, lr = 0.001
I1110 22:23:48.397313  2593 solver.cpp:295] Iteration 372 (no loss supplied for SingleUpdateStep)
I1110 22:23:48.397379  2593 solver.cpp:310]     Train net output #0: loss = 0.791498 (* 1 = 0.791498 loss)
I1110 22:23:48.397400  2593 sgd_solver.cpp:106] Iteration 372, lr = 0.001
I1110 22:23:50.907524  2593 solver.cpp:295] Iteration 373 (no loss supplied for SingleUpdateStep)
I1110 22:23:50.907588  2593 solver.cpp:310]     Train net output #0: loss = 0.855976 (* 1 = 0.855976 loss)
I1110 22:23:50.907608  2593 sgd_solver.cpp:106] Iteration 373, lr = 0.001
I1110 22:23:53.444794  2593 solver.cpp:295] Iteration 374 (no loss supplied for SingleUpdateStep)
I1110 22:23:53.444959  2593 solver.cpp:310]     Train net output #0: loss = 0.871262 (* 1 = 0.871262 loss)
I1110 22:23:53.444983  2593 sgd_solver.cpp:106] Iteration 374, lr = 0.001
I1110 22:23:56.120975  2593 solver.cpp:295] Iteration 375 (no loss supplied for SingleUpdateStep)
I1110 22:23:56.121129  2593 solver.cpp:310]     Train net output #0: loss = 0.814683 (* 1 = 0.814683 loss)
I1110 22:23:56.121160  2593 sgd_solver.cpp:106] Iteration 375, lr = 0.001
I1110 22:23:58.577049  2593 solver.cpp:295] Iteration 376 (no loss supplied for SingleUpdateStep)
I1110 22:23:58.577139  2593 solver.cpp:310]     Train net output #0: loss = 0.756938 (* 1 = 0.756938 loss)
I1110 22:23:58.577159  2593 sgd_solver.cpp:106] Iteration 376, lr = 0.001
I1110 22:24:01.304169  2593 solver.cpp:295] Iteration 377 (no loss supplied for SingleUpdateStep)
I1110 22:24:01.304229  2593 solver.cpp:310]     Train net output #0: loss = 0.798188 (* 1 = 0.798188 loss)
I1110 22:24:01.304250  2593 sgd_solver.cpp:106] Iteration 377, lr = 0.001
I1110 22:24:03.819710  2593 solver.cpp:295] Iteration 378 (no loss supplied for SingleUpdateStep)
I1110 22:24:03.819809  2593 solver.cpp:310]     Train net output #0: loss = 0.783371 (* 1 = 0.783371 loss)
I1110 22:24:03.819830  2593 sgd_solver.cpp:106] Iteration 378, lr = 0.001
I1110 22:24:06.113634  2593 solver.cpp:295] Iteration 379 (no loss supplied for SingleUpdateStep)
I1110 22:24:06.113740  2593 solver.cpp:310]     Train net output #0: loss = 0.804878 (* 1 = 0.804878 loss)
I1110 22:24:06.113764  2593 sgd_solver.cpp:106] Iteration 379, lr = 0.001
I1110 22:24:08.484287  2593 solver.cpp:295] Iteration 380 (no loss supplied for SingleUpdateStep)
I1110 22:24:08.484412  2593 solver.cpp:310]     Train net output #0: loss = 0.806467 (* 1 = 0.806467 loss)
I1110 22:24:08.484443  2593 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I1110 22:24:10.775871  2593 solver.cpp:295] Iteration 381 (no loss supplied for SingleUpdateStep)
I1110 22:24:10.775955  2593 solver.cpp:310]     Train net output #0: loss = 0.789804 (* 1 = 0.789804 loss)
I1110 22:24:10.775977  2593 sgd_solver.cpp:106] Iteration 381, lr = 0.001
I1110 22:24:13.014953  2593 solver.cpp:295] Iteration 382 (no loss supplied for SingleUpdateStep)
I1110 22:24:13.015079  2593 solver.cpp:310]     Train net output #0: loss = 0.732696 (* 1 = 0.732696 loss)
I1110 22:24:13.015108  2593 sgd_solver.cpp:106] Iteration 382, lr = 0.001
I1110 22:24:16.126008  2593 solver.cpp:295] Iteration 383 (no loss supplied for SingleUpdateStep)
I1110 22:24:16.126060  2593 solver.cpp:310]     Train net output #0: loss = 0.723374 (* 1 = 0.723374 loss)
I1110 22:24:16.126078  2593 sgd_solver.cpp:106] Iteration 383, lr = 0.001
I1110 22:24:18.886484  2593 solver.cpp:295] Iteration 384 (no loss supplied for SingleUpdateStep)
I1110 22:24:18.886556  2593 solver.cpp:310]     Train net output #0: loss = 0.819228 (* 1 = 0.819228 loss)
I1110 22:24:18.886576  2593 sgd_solver.cpp:106] Iteration 384, lr = 0.001
I1110 22:24:22.203512  2593 solver.cpp:295] Iteration 385 (no loss supplied for SingleUpdateStep)
I1110 22:24:22.203583  2593 solver.cpp:310]     Train net output #0: loss = 0.760527 (* 1 = 0.760527 loss)
I1110 22:24:22.203603  2593 sgd_solver.cpp:106] Iteration 385, lr = 0.001
I1110 22:24:25.931690  2593 solver.cpp:295] Iteration 386 (no loss supplied for SingleUpdateStep)
I1110 22:24:25.931740  2593 solver.cpp:310]     Train net output #0: loss = 0.707695 (* 1 = 0.707695 loss)
I1110 22:24:25.931758  2593 sgd_solver.cpp:106] Iteration 386, lr = 0.001
I1110 22:24:28.566398  2593 solver.cpp:295] Iteration 387 (no loss supplied for SingleUpdateStep)
I1110 22:24:28.566560  2593 solver.cpp:310]     Train net output #0: loss = 0.77019 (* 1 = 0.77019 loss)
I1110 22:24:28.566587  2593 sgd_solver.cpp:106] Iteration 387, lr = 0.001
I1110 22:24:30.981408  2593 solver.cpp:295] Iteration 388 (no loss supplied for SingleUpdateStep)
I1110 22:24:30.981524  2593 solver.cpp:310]     Train net output #0: loss = 0.795004 (* 1 = 0.795004 loss)
I1110 22:24:30.981549  2593 sgd_solver.cpp:106] Iteration 388, lr = 0.001
I1110 22:24:34.425425  2593 solver.cpp:295] Iteration 389 (no loss supplied for SingleUpdateStep)
I1110 22:24:34.425500  2593 solver.cpp:310]     Train net output #0: loss = 0.788987 (* 1 = 0.788987 loss)
I1110 22:24:34.425521  2593 sgd_solver.cpp:106] Iteration 389, lr = 0.001
I1110 22:24:37.848409  2593 solver.cpp:295] Iteration 390 (no loss supplied for SingleUpdateStep)
I1110 22:24:37.848567  2593 solver.cpp:310]     Train net output #0: loss = 0.787748 (* 1 = 0.787748 loss)
I1110 22:24:37.848594  2593 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I1110 22:24:41.853016  2593 solver.cpp:295] Iteration 391 (no loss supplied for SingleUpdateStep)
I1110 22:24:41.853085  2593 solver.cpp:310]     Train net output #0: loss = 0.783409 (* 1 = 0.783409 loss)
I1110 22:24:41.853106  2593 sgd_solver.cpp:106] Iteration 391, lr = 0.001
I1110 22:24:45.143638  2593 solver.cpp:295] Iteration 392 (no loss supplied for SingleUpdateStep)
I1110 22:24:45.143726  2593 solver.cpp:310]     Train net output #0: loss = 0.704147 (* 1 = 0.704147 loss)
I1110 22:24:45.143751  2593 sgd_solver.cpp:106] Iteration 392, lr = 0.001
I1110 22:24:48.144287  2593 solver.cpp:295] Iteration 393 (no loss supplied for SingleUpdateStep)
I1110 22:24:48.144338  2593 solver.cpp:310]     Train net output #0: loss = 0.840195 (* 1 = 0.840195 loss)
I1110 22:24:48.144357  2593 sgd_solver.cpp:106] Iteration 393, lr = 0.001
I1110 22:24:51.252265  2593 solver.cpp:295] Iteration 394 (no loss supplied for SingleUpdateStep)
I1110 22:24:51.252323  2593 solver.cpp:310]     Train net output #0: loss = 0.773732 (* 1 = 0.773732 loss)
I1110 22:24:51.252342  2593 sgd_solver.cpp:106] Iteration 394, lr = 0.001
I1110 22:24:54.172082  2593 solver.cpp:295] Iteration 395 (no loss supplied for SingleUpdateStep)
I1110 22:24:54.172154  2593 solver.cpp:310]     Train net output #0: loss = 0.844 (* 1 = 0.844 loss)
I1110 22:24:54.172173  2593 sgd_solver.cpp:106] Iteration 395, lr = 0.001
I1110 22:24:56.730983  2593 solver.cpp:295] Iteration 396 (no loss supplied for SingleUpdateStep)
I1110 22:24:56.731093  2593 solver.cpp:310]     Train net output #0: loss = 0.7349 (* 1 = 0.7349 loss)
I1110 22:24:56.731117  2593 sgd_solver.cpp:106] Iteration 396, lr = 0.001
I1110 22:25:00.026276  2593 solver.cpp:295] Iteration 397 (no loss supplied for SingleUpdateStep)
I1110 22:25:00.026371  2593 solver.cpp:310]     Train net output #0: loss = 0.818123 (* 1 = 0.818123 loss)
I1110 22:25:00.026392  2593 sgd_solver.cpp:106] Iteration 397, lr = 0.001
I1110 22:25:02.921149  2593 solver.cpp:295] Iteration 398 (no loss supplied for SingleUpdateStep)
I1110 22:25:02.921202  2593 solver.cpp:310]     Train net output #0: loss = 0.796475 (* 1 = 0.796475 loss)
I1110 22:25:02.921221  2593 sgd_solver.cpp:106] Iteration 398, lr = 0.001
I1110 22:25:06.254804  2593 solver.cpp:295] Iteration 399 (no loss supplied for SingleUpdateStep)
I1110 22:25:06.254859  2593 solver.cpp:310]     Train net output #0: loss = 0.834536 (* 1 = 0.834536 loss)
I1110 22:25:06.254878  2593 sgd_solver.cpp:106] Iteration 399, lr = 0.001
I1110 22:25:11.281672  2593 solver.cpp:295] Iteration 400 (no loss supplied for SingleUpdateStep)
I1110 22:25:11.281733  2593 solver.cpp:310]     Train net output #0: loss = 0.838951 (* 1 = 0.838951 loss)
I1110 22:25:11.281752  2593 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I1110 22:25:13.963465  2593 solver.cpp:295] Iteration 401 (no loss supplied for SingleUpdateStep)
I1110 22:25:13.963534  2593 solver.cpp:310]     Train net output #0: loss = 0.812696 (* 1 = 0.812696 loss)
I1110 22:25:13.963554  2593 sgd_solver.cpp:106] Iteration 401, lr = 0.001
I1110 22:25:17.571993  2593 solver.cpp:295] Iteration 402 (no loss supplied for SingleUpdateStep)
I1110 22:25:17.572079  2593 solver.cpp:310]     Train net output #0: loss = 0.82681 (* 1 = 0.82681 loss)
I1110 22:25:17.572101  2593 sgd_solver.cpp:106] Iteration 402, lr = 0.001
I1110 22:25:21.025476  2593 solver.cpp:295] Iteration 403 (no loss supplied for SingleUpdateStep)
I1110 22:25:21.025528  2593 solver.cpp:310]     Train net output #0: loss = 0.795546 (* 1 = 0.795546 loss)
I1110 22:25:21.025547  2593 sgd_solver.cpp:106] Iteration 403, lr = 0.001
I1110 22:25:24.586508  2593 solver.cpp:295] Iteration 404 (no loss supplied for SingleUpdateStep)
I1110 22:25:24.586577  2593 solver.cpp:310]     Train net output #0: loss = 0.807954 (* 1 = 0.807954 loss)
I1110 22:25:24.586599  2593 sgd_solver.cpp:106] Iteration 404, lr = 0.001
I1110 22:25:28.023646  2593 solver.cpp:295] Iteration 405 (no loss supplied for SingleUpdateStep)
I1110 22:25:28.023742  2593 solver.cpp:310]     Train net output #0: loss = 0.787133 (* 1 = 0.787133 loss)
I1110 22:25:28.023762  2593 sgd_solver.cpp:106] Iteration 405, lr = 0.001
I1110 22:25:31.506263  2593 solver.cpp:295] Iteration 406 (no loss supplied for SingleUpdateStep)
I1110 22:25:31.506347  2593 solver.cpp:310]     Train net output #0: loss = 0.85051 (* 1 = 0.85051 loss)
I1110 22:25:31.506366  2593 sgd_solver.cpp:106] Iteration 406, lr = 0.001
I1110 22:25:34.466845  2593 solver.cpp:295] Iteration 407 (no loss supplied for SingleUpdateStep)
I1110 22:25:34.466917  2593 solver.cpp:310]     Train net output #0: loss = 0.767071 (* 1 = 0.767071 loss)
I1110 22:25:34.466936  2593 sgd_solver.cpp:106] Iteration 407, lr = 0.001
I1110 22:25:37.145174  2593 solver.cpp:295] Iteration 408 (no loss supplied for SingleUpdateStep)
I1110 22:25:37.145292  2593 solver.cpp:310]     Train net output #0: loss = 0.786168 (* 1 = 0.786168 loss)
I1110 22:25:37.145313  2593 sgd_solver.cpp:106] Iteration 408, lr = 0.001
I1110 22:25:40.187716  2593 solver.cpp:295] Iteration 409 (no loss supplied for SingleUpdateStep)
I1110 22:25:40.187834  2593 solver.cpp:310]     Train net output #0: loss = 0.787497 (* 1 = 0.787497 loss)
I1110 22:25:40.187861  2593 sgd_solver.cpp:106] Iteration 409, lr = 0.001
I1110 22:25:43.780244  2593 solver.cpp:295] Iteration 410 (no loss supplied for SingleUpdateStep)
I1110 22:25:43.780350  2593 solver.cpp:310]     Train net output #0: loss = 0.851272 (* 1 = 0.851272 loss)
I1110 22:25:43.780372  2593 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I1110 22:25:47.051136  2593 solver.cpp:295] Iteration 411 (no loss supplied for SingleUpdateStep)
I1110 22:25:47.051233  2593 solver.cpp:310]     Train net output #0: loss = 0.77186 (* 1 = 0.77186 loss)
I1110 22:25:47.051254  2593 sgd_solver.cpp:106] Iteration 411, lr = 0.001
I1110 22:25:50.432449  2593 solver.cpp:295] Iteration 412 (no loss supplied for SingleUpdateStep)
I1110 22:25:50.487239  2593 solver.cpp:310]     Train net output #0: loss = 0.730651 (* 1 = 0.730651 loss)
I1110 22:25:50.487287  2593 sgd_solver.cpp:106] Iteration 412, lr = 0.001
I1110 22:25:53.080217  2593 solver.cpp:295] Iteration 413 (no loss supplied for SingleUpdateStep)
I1110 22:25:53.080272  2593 solver.cpp:310]     Train net output #0: loss = 0.806585 (* 1 = 0.806585 loss)
I1110 22:25:53.080291  2593 sgd_solver.cpp:106] Iteration 413, lr = 0.001
I1110 22:25:56.397217  2593 solver.cpp:295] Iteration 414 (no loss supplied for SingleUpdateStep)
I1110 22:25:56.397336  2593 solver.cpp:310]     Train net output #0: loss = 0.858895 (* 1 = 0.858895 loss)
I1110 22:25:56.397361  2593 sgd_solver.cpp:106] Iteration 414, lr = 0.001
I1110 22:25:58.770308  2593 solver.cpp:295] Iteration 415 (no loss supplied for SingleUpdateStep)
I1110 22:25:58.770413  2593 solver.cpp:310]     Train net output #0: loss = 0.768596 (* 1 = 0.768596 loss)
I1110 22:25:58.770437  2593 sgd_solver.cpp:106] Iteration 415, lr = 0.001
I1110 22:26:01.225672  2593 solver.cpp:295] Iteration 416 (no loss supplied for SingleUpdateStep)
I1110 22:26:01.225764  2593 solver.cpp:310]     Train net output #0: loss = 0.759967 (* 1 = 0.759967 loss)
I1110 22:26:01.225783  2593 sgd_solver.cpp:106] Iteration 416, lr = 0.001
I1110 22:26:03.732913  2593 solver.cpp:295] Iteration 417 (no loss supplied for SingleUpdateStep)
I1110 22:26:03.733027  2593 solver.cpp:310]     Train net output #0: loss = 0.80445 (* 1 = 0.80445 loss)
I1110 22:26:03.733052  2593 sgd_solver.cpp:106] Iteration 417, lr = 0.001
I1110 22:26:06.153183  2593 solver.cpp:295] Iteration 418 (no loss supplied for SingleUpdateStep)
I1110 22:26:06.153321  2593 solver.cpp:310]     Train net output #0: loss = 0.806179 (* 1 = 0.806179 loss)
I1110 22:26:06.153344  2593 sgd_solver.cpp:106] Iteration 418, lr = 0.001
I1110 22:26:08.425272  2593 solver.cpp:295] Iteration 419 (no loss supplied for SingleUpdateStep)
I1110 22:26:08.425372  2593 solver.cpp:310]     Train net output #0: loss = 0.743778 (* 1 = 0.743778 loss)
I1110 22:26:08.425393  2593 sgd_solver.cpp:106] Iteration 419, lr = 0.001
I1110 22:26:10.737743  2593 solver.cpp:295] Iteration 420 (no loss supplied for SingleUpdateStep)
I1110 22:26:10.737821  2593 solver.cpp:310]     Train net output #0: loss = 0.829712 (* 1 = 0.829712 loss)
I1110 22:26:10.737843  2593 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I1110 22:26:13.082500  2593 solver.cpp:295] Iteration 421 (no loss supplied for SingleUpdateStep)
I1110 22:26:13.082590  2593 solver.cpp:310]     Train net output #0: loss = 0.790003 (* 1 = 0.790003 loss)
I1110 22:26:13.082613  2593 sgd_solver.cpp:106] Iteration 421, lr = 0.001
I1110 22:26:15.323730  2593 solver.cpp:295] Iteration 422 (no loss supplied for SingleUpdateStep)
I1110 22:26:15.323782  2593 solver.cpp:310]     Train net output #0: loss = 0.815718 (* 1 = 0.815718 loss)
I1110 22:26:15.323801  2593 sgd_solver.cpp:106] Iteration 422, lr = 0.001
I1110 22:26:17.857985  2593 solver.cpp:295] Iteration 423 (no loss supplied for SingleUpdateStep)
I1110 22:26:17.858043  2593 solver.cpp:310]     Train net output #0: loss = 0.78543 (* 1 = 0.78543 loss)
I1110 22:26:17.858062  2593 sgd_solver.cpp:106] Iteration 423, lr = 0.001
I1110 22:26:20.333262  2593 solver.cpp:295] Iteration 424 (no loss supplied for SingleUpdateStep)
I1110 22:26:20.333379  2593 solver.cpp:310]     Train net output #0: loss = 0.801398 (* 1 = 0.801398 loss)
I1110 22:26:20.333405  2593 sgd_solver.cpp:106] Iteration 424, lr = 0.001
I1110 22:26:22.654618  2593 solver.cpp:295] Iteration 425 (no loss supplied for SingleUpdateStep)
I1110 22:26:22.654713  2593 solver.cpp:310]     Train net output #0: loss = 0.773929 (* 1 = 0.773929 loss)
I1110 22:26:22.654734  2593 sgd_solver.cpp:106] Iteration 425, lr = 0.001
I1110 22:26:25.013183  2593 solver.cpp:295] Iteration 426 (no loss supplied for SingleUpdateStep)
I1110 22:26:25.013371  2593 solver.cpp:310]     Train net output #0: loss = 0.814899 (* 1 = 0.814899 loss)
I1110 22:26:25.013408  2593 sgd_solver.cpp:106] Iteration 426, lr = 0.001
I1110 22:26:27.392472  2593 solver.cpp:295] Iteration 427 (no loss supplied for SingleUpdateStep)
I1110 22:26:27.392590  2593 solver.cpp:310]     Train net output #0: loss = 0.779269 (* 1 = 0.779269 loss)
I1110 22:26:27.392611  2593 sgd_solver.cpp:106] Iteration 427, lr = 0.001
I1110 22:26:29.641069  2593 solver.cpp:295] Iteration 428 (no loss supplied for SingleUpdateStep)
I1110 22:26:29.641161  2593 solver.cpp:310]     Train net output #0: loss = 0.823292 (* 1 = 0.823292 loss)
I1110 22:26:29.641181  2593 sgd_solver.cpp:106] Iteration 428, lr = 0.001
I1110 22:26:31.960578  2593 solver.cpp:295] Iteration 429 (no loss supplied for SingleUpdateStep)
I1110 22:26:31.960727  2593 solver.cpp:310]     Train net output #0: loss = 0.840247 (* 1 = 0.840247 loss)
I1110 22:26:31.960764  2593 sgd_solver.cpp:106] Iteration 429, lr = 0.001
I1110 22:26:34.356307  2593 solver.cpp:295] Iteration 430 (no loss supplied for SingleUpdateStep)
I1110 22:26:34.356446  2593 solver.cpp:310]     Train net output #0: loss = 0.781854 (* 1 = 0.781854 loss)
I1110 22:26:34.356478  2593 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I1110 22:26:36.787607  2593 solver.cpp:295] Iteration 431 (no loss supplied for SingleUpdateStep)
I1110 22:26:36.787662  2593 solver.cpp:310]     Train net output #0: loss = 0.841747 (* 1 = 0.841747 loss)
I1110 22:26:36.787683  2593 sgd_solver.cpp:106] Iteration 431, lr = 0.001
I1110 22:26:38.750566  2593 solver.cpp:295] Iteration 432 (no loss supplied for SingleUpdateStep)
I1110 22:26:38.750672  2593 solver.cpp:310]     Train net output #0: loss = 0.812576 (* 1 = 0.812576 loss)
I1110 22:26:38.750700  2593 sgd_solver.cpp:106] Iteration 432, lr = 0.001
I1110 22:26:40.508122  2593 solver.cpp:295] Iteration 433 (no loss supplied for SingleUpdateStep)
I1110 22:26:40.508222  2593 solver.cpp:310]     Train net output #0: loss = 0.764033 (* 1 = 0.764033 loss)
I1110 22:26:40.508244  2593 sgd_solver.cpp:106] Iteration 433, lr = 0.001
I1110 22:26:42.220908  2593 solver.cpp:295] Iteration 434 (no loss supplied for SingleUpdateStep)
I1110 22:26:42.221050  2593 solver.cpp:310]     Train net output #0: loss = 0.745183 (* 1 = 0.745183 loss)
I1110 22:26:42.221076  2593 sgd_solver.cpp:106] Iteration 434, lr = 0.001
I1110 22:26:44.127290  2593 solver.cpp:295] Iteration 435 (no loss supplied for SingleUpdateStep)
I1110 22:26:44.127405  2593 solver.cpp:310]     Train net output #0: loss = 0.767442 (* 1 = 0.767442 loss)
I1110 22:26:44.127430  2593 sgd_solver.cpp:106] Iteration 435, lr = 0.001
I1110 22:26:46.065155  2593 solver.cpp:295] Iteration 436 (no loss supplied for SingleUpdateStep)
I1110 22:26:46.065246  2593 solver.cpp:310]     Train net output #0: loss = 0.805175 (* 1 = 0.805175 loss)
I1110 22:26:46.065268  2593 sgd_solver.cpp:106] Iteration 436, lr = 0.001
I1110 22:26:47.870714  2593 solver.cpp:295] Iteration 437 (no loss supplied for SingleUpdateStep)
I1110 22:26:47.870818  2593 solver.cpp:310]     Train net output #0: loss = 0.750466 (* 1 = 0.750466 loss)
I1110 22:26:47.870838  2593 sgd_solver.cpp:106] Iteration 437, lr = 0.001
I1110 22:26:49.956593  2593 solver.cpp:295] Iteration 438 (no loss supplied for SingleUpdateStep)
I1110 22:26:49.956686  2593 solver.cpp:310]     Train net output #0: loss = 0.725176 (* 1 = 0.725176 loss)
I1110 22:26:49.956706  2593 sgd_solver.cpp:106] Iteration 438, lr = 0.001
I1110 22:26:51.778913  2593 solver.cpp:295] Iteration 439 (no loss supplied for SingleUpdateStep)
I1110 22:26:51.779011  2593 solver.cpp:310]     Train net output #0: loss = 0.810315 (* 1 = 0.810315 loss)
I1110 22:26:51.779032  2593 sgd_solver.cpp:106] Iteration 439, lr = 0.001
I1110 22:26:53.652604  2593 solver.cpp:295] Iteration 440 (no loss supplied for SingleUpdateStep)
I1110 22:26:53.652681  2593 solver.cpp:310]     Train net output #0: loss = 0.762755 (* 1 = 0.762755 loss)
I1110 22:26:53.652704  2593 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I1110 22:26:55.492648  2593 solver.cpp:295] Iteration 441 (no loss supplied for SingleUpdateStep)
I1110 22:26:55.492748  2593 solver.cpp:310]     Train net output #0: loss = 0.723135 (* 1 = 0.723135 loss)
I1110 22:26:55.492770  2593 sgd_solver.cpp:106] Iteration 441, lr = 0.001
I1110 22:26:57.380110  2593 solver.cpp:295] Iteration 442 (no loss supplied for SingleUpdateStep)
I1110 22:26:57.380165  2593 solver.cpp:310]     Train net output #0: loss = 0.805755 (* 1 = 0.805755 loss)
I1110 22:26:57.380185  2593 sgd_solver.cpp:106] Iteration 442, lr = 0.001
I1110 22:26:59.223542  2593 solver.cpp:295] Iteration 443 (no loss supplied for SingleUpdateStep)
I1110 22:26:59.223727  2593 solver.cpp:310]     Train net output #0: loss = 0.775982 (* 1 = 0.775982 loss)
I1110 22:26:59.223753  2593 sgd_solver.cpp:106] Iteration 443, lr = 0.001
I1110 22:27:01.047469  2593 solver.cpp:295] Iteration 444 (no loss supplied for SingleUpdateStep)
I1110 22:27:01.047591  2593 solver.cpp:310]     Train net output #0: loss = 0.79248 (* 1 = 0.79248 loss)
I1110 22:27:01.047616  2593 sgd_solver.cpp:106] Iteration 444, lr = 0.001
I1110 22:27:02.752611  2593 solver.cpp:295] Iteration 445 (no loss supplied for SingleUpdateStep)
I1110 22:27:02.752733  2593 solver.cpp:310]     Train net output #0: loss = 0.814207 (* 1 = 0.814207 loss)
I1110 22:27:02.752759  2593 sgd_solver.cpp:106] Iteration 445, lr = 0.001
I1110 22:27:04.758288  2593 solver.cpp:295] Iteration 446 (no loss supplied for SingleUpdateStep)
I1110 22:27:04.758357  2593 solver.cpp:310]     Train net output #0: loss = 0.763481 (* 1 = 0.763481 loss)
I1110 22:27:04.758378  2593 sgd_solver.cpp:106] Iteration 446, lr = 0.001
I1110 22:27:07.401854  2593 solver.cpp:295] Iteration 447 (no loss supplied for SingleUpdateStep)
I1110 22:27:07.401995  2593 solver.cpp:310]     Train net output #0: loss = 0.781901 (* 1 = 0.781901 loss)
I1110 22:27:07.402020  2593 sgd_solver.cpp:106] Iteration 447, lr = 0.001
I1110 22:27:09.377990  2593 solver.cpp:295] Iteration 448 (no loss supplied for SingleUpdateStep)
I1110 22:27:09.378116  2593 solver.cpp:310]     Train net output #0: loss = 0.79953 (* 1 = 0.79953 loss)
I1110 22:27:09.378146  2593 sgd_solver.cpp:106] Iteration 448, lr = 0.001
I1110 22:27:11.232254  2593 solver.cpp:295] Iteration 449 (no loss supplied for SingleUpdateStep)
I1110 22:27:11.232327  2593 solver.cpp:310]     Train net output #0: loss = 0.819665 (* 1 = 0.819665 loss)
I1110 22:27:11.232349  2593 sgd_solver.cpp:106] Iteration 449, lr = 0.001
I1110 22:27:13.060466  2593 solver.cpp:295] Iteration 450 (no loss supplied for SingleUpdateStep)
I1110 22:27:13.060600  2593 solver.cpp:310]     Train net output #0: loss = 0.758522 (* 1 = 0.758522 loss)
I1110 22:27:13.060645  2593 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I1110 22:27:14.948303  2593 solver.cpp:295] Iteration 451 (no loss supplied for SingleUpdateStep)
I1110 22:27:14.948381  2593 solver.cpp:310]     Train net output #0: loss = 0.820315 (* 1 = 0.820315 loss)
I1110 22:27:14.948402  2593 sgd_solver.cpp:106] Iteration 451, lr = 0.001
I1110 22:27:16.999338  2593 solver.cpp:295] Iteration 452 (no loss supplied for SingleUpdateStep)
I1110 22:27:16.999450  2593 solver.cpp:310]     Train net output #0: loss = 0.805476 (* 1 = 0.805476 loss)
I1110 22:27:16.999471  2593 sgd_solver.cpp:106] Iteration 452, lr = 0.001
I1110 22:27:18.874810  2593 solver.cpp:295] Iteration 453 (no loss supplied for SingleUpdateStep)
I1110 22:27:18.874915  2593 solver.cpp:310]     Train net output #0: loss = 0.772943 (* 1 = 0.772943 loss)
I1110 22:27:18.874943  2593 sgd_solver.cpp:106] Iteration 453, lr = 0.001
I1110 22:27:20.777678  2593 solver.cpp:295] Iteration 454 (no loss supplied for SingleUpdateStep)
I1110 22:27:20.777786  2593 solver.cpp:310]     Train net output #0: loss = 0.849533 (* 1 = 0.849533 loss)
I1110 22:27:20.777811  2593 sgd_solver.cpp:106] Iteration 454, lr = 0.001
I1110 22:27:22.870450  2593 solver.cpp:295] Iteration 455 (no loss supplied for SingleUpdateStep)
I1110 22:27:22.870579  2593 solver.cpp:310]     Train net output #0: loss = 0.805581 (* 1 = 0.805581 loss)
I1110 22:27:22.870601  2593 sgd_solver.cpp:106] Iteration 455, lr = 0.001
I1110 22:27:24.682494  2593 solver.cpp:295] Iteration 456 (no loss supplied for SingleUpdateStep)
I1110 22:27:24.682579  2593 solver.cpp:310]     Train net output #0: loss = 0.790321 (* 1 = 0.790321 loss)
I1110 22:27:24.682602  2593 sgd_solver.cpp:106] Iteration 456, lr = 0.001
I1110 22:27:26.674240  2593 solver.cpp:295] Iteration 457 (no loss supplied for SingleUpdateStep)
I1110 22:27:26.674332  2593 solver.cpp:310]     Train net output #0: loss = 0.78381 (* 1 = 0.78381 loss)
I1110 22:27:26.674355  2593 sgd_solver.cpp:106] Iteration 457, lr = 0.001
I1110 22:27:28.835232  2593 solver.cpp:295] Iteration 458 (no loss supplied for SingleUpdateStep)
I1110 22:27:28.835330  2593 solver.cpp:310]     Train net output #0: loss = 0.777453 (* 1 = 0.777453 loss)
I1110 22:27:28.835351  2593 sgd_solver.cpp:106] Iteration 458, lr = 0.001
I1110 22:27:30.854724  2593 solver.cpp:295] Iteration 459 (no loss supplied for SingleUpdateStep)
I1110 22:27:30.854804  2593 solver.cpp:310]     Train net output #0: loss = 0.826001 (* 1 = 0.826001 loss)
I1110 22:27:30.854825  2593 sgd_solver.cpp:106] Iteration 459, lr = 0.001
I1110 22:27:32.566561  2593 solver.cpp:295] Iteration 460 (no loss supplied for SingleUpdateStep)
I1110 22:27:32.566681  2593 solver.cpp:310]     Train net output #0: loss = 0.85815 (* 1 = 0.85815 loss)
I1110 22:27:32.566706  2593 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I1110 22:27:34.698751  2593 solver.cpp:295] Iteration 461 (no loss supplied for SingleUpdateStep)
I1110 22:27:34.698885  2593 solver.cpp:310]     Train net output #0: loss = 0.757576 (* 1 = 0.757576 loss)
I1110 22:27:34.698909  2593 sgd_solver.cpp:106] Iteration 461, lr = 0.001
I1110 22:27:36.554069  2593 solver.cpp:295] Iteration 462 (no loss supplied for SingleUpdateStep)
I1110 22:27:36.554168  2593 solver.cpp:310]     Train net output #0: loss = 0.764844 (* 1 = 0.764844 loss)
I1110 22:27:36.554190  2593 sgd_solver.cpp:106] Iteration 462, lr = 0.001
I1110 22:27:38.443821  2593 solver.cpp:295] Iteration 463 (no loss supplied for SingleUpdateStep)
I1110 22:27:38.443876  2593 solver.cpp:310]     Train net output #0: loss = 0.806242 (* 1 = 0.806242 loss)
I1110 22:27:38.443894  2593 sgd_solver.cpp:106] Iteration 463, lr = 0.001
I1110 22:27:40.581640  2593 solver.cpp:295] Iteration 464 (no loss supplied for SingleUpdateStep)
I1110 22:27:40.581728  2593 solver.cpp:310]     Train net output #0: loss = 0.80292 (* 1 = 0.80292 loss)
I1110 22:27:40.581751  2593 sgd_solver.cpp:106] Iteration 464, lr = 0.001
I1110 22:27:42.528702  2593 solver.cpp:295] Iteration 465 (no loss supplied for SingleUpdateStep)
I1110 22:27:42.528833  2593 solver.cpp:310]     Train net output #0: loss = 0.82086 (* 1 = 0.82086 loss)
I1110 22:27:42.528859  2593 sgd_solver.cpp:106] Iteration 465, lr = 0.001
I1110 22:27:44.512660  2593 solver.cpp:295] Iteration 466 (no loss supplied for SingleUpdateStep)
I1110 22:27:44.512732  2593 solver.cpp:310]     Train net output #0: loss = 0.761236 (* 1 = 0.761236 loss)
I1110 22:27:44.512750  2593 sgd_solver.cpp:106] Iteration 466, lr = 0.001
I1110 22:27:46.279407  2593 solver.cpp:295] Iteration 467 (no loss supplied for SingleUpdateStep)
I1110 22:27:46.279484  2593 solver.cpp:310]     Train net output #0: loss = 0.798986 (* 1 = 0.798986 loss)
I1110 22:27:46.279505  2593 sgd_solver.cpp:106] Iteration 467, lr = 0.001
I1110 22:27:48.258256  2593 solver.cpp:295] Iteration 468 (no loss supplied for SingleUpdateStep)
I1110 22:27:48.258316  2593 solver.cpp:310]     Train net output #0: loss = 0.788897 (* 1 = 0.788897 loss)
I1110 22:27:48.258334  2593 sgd_solver.cpp:106] Iteration 468, lr = 0.001
I1110 22:27:50.129423  2593 solver.cpp:295] Iteration 469 (no loss supplied for SingleUpdateStep)
I1110 22:27:50.129683  2593 solver.cpp:310]     Train net output #0: loss = 0.756719 (* 1 = 0.756719 loss)
I1110 22:27:50.129714  2593 sgd_solver.cpp:106] Iteration 469, lr = 0.001
I1110 22:27:52.065978  2593 solver.cpp:295] Iteration 470 (no loss supplied for SingleUpdateStep)
I1110 22:27:52.066047  2593 solver.cpp:310]     Train net output #0: loss = 0.8003 (* 1 = 0.8003 loss)
I1110 22:27:52.066067  2593 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I1110 22:27:53.921574  2593 solver.cpp:295] Iteration 471 (no loss supplied for SingleUpdateStep)
I1110 22:27:53.921694  2593 solver.cpp:310]     Train net output #0: loss = 0.785068 (* 1 = 0.785068 loss)
I1110 22:27:53.921718  2593 sgd_solver.cpp:106] Iteration 471, lr = 0.001
I1110 22:27:56.052021  2593 solver.cpp:295] Iteration 472 (no loss supplied for SingleUpdateStep)
I1110 22:27:56.052175  2593 solver.cpp:310]     Train net output #0: loss = 0.767684 (* 1 = 0.767684 loss)
I1110 22:27:56.052201  2593 sgd_solver.cpp:106] Iteration 472, lr = 0.001
I1110 22:27:58.265197  2593 solver.cpp:295] Iteration 473 (no loss supplied for SingleUpdateStep)
I1110 22:27:58.265357  2593 solver.cpp:310]     Train net output #0: loss = 0.737598 (* 1 = 0.737598 loss)
I1110 22:27:58.265393  2593 sgd_solver.cpp:106] Iteration 473, lr = 0.001
I1110 22:28:00.242357  2593 solver.cpp:295] Iteration 474 (no loss supplied for SingleUpdateStep)
I1110 22:28:00.242427  2593 solver.cpp:310]     Train net output #0: loss = 0.721122 (* 1 = 0.721122 loss)
I1110 22:28:00.242447  2593 sgd_solver.cpp:106] Iteration 474, lr = 0.001
I1110 22:28:02.067571  2593 solver.cpp:295] Iteration 475 (no loss supplied for SingleUpdateStep)
I1110 22:28:02.067683  2593 solver.cpp:310]     Train net output #0: loss = 0.732777 (* 1 = 0.732777 loss)
I1110 22:28:02.067708  2593 sgd_solver.cpp:106] Iteration 475, lr = 0.001
I1110 22:28:03.917069  2593 solver.cpp:295] Iteration 476 (no loss supplied for SingleUpdateStep)
I1110 22:28:03.917140  2593 solver.cpp:310]     Train net output #0: loss = 0.765439 (* 1 = 0.765439 loss)
I1110 22:28:03.917160  2593 sgd_solver.cpp:106] Iteration 476, lr = 0.001
I1110 22:28:05.744810  2593 solver.cpp:295] Iteration 477 (no loss supplied for SingleUpdateStep)
I1110 22:28:05.744868  2593 solver.cpp:310]     Train net output #0: loss = 0.736704 (* 1 = 0.736704 loss)
I1110 22:28:05.744889  2593 sgd_solver.cpp:106] Iteration 477, lr = 0.001
I1110 22:28:07.513563  2593 solver.cpp:295] Iteration 478 (no loss supplied for SingleUpdateStep)
I1110 22:28:07.513663  2593 solver.cpp:310]     Train net output #0: loss = 0.747472 (* 1 = 0.747472 loss)
I1110 22:28:07.513684  2593 sgd_solver.cpp:106] Iteration 478, lr = 0.001
I1110 22:28:09.437989  2593 solver.cpp:295] Iteration 479 (no loss supplied for SingleUpdateStep)
I1110 22:28:09.438119  2593 solver.cpp:310]     Train net output #0: loss = 0.780702 (* 1 = 0.780702 loss)
I1110 22:28:09.438141  2593 sgd_solver.cpp:106] Iteration 479, lr = 0.001
I1110 22:28:11.199434  2593 solver.cpp:295] Iteration 480 (no loss supplied for SingleUpdateStep)
I1110 22:28:11.199494  2593 solver.cpp:310]     Train net output #0: loss = 0.730907 (* 1 = 0.730907 loss)
I1110 22:28:11.199515  2593 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I1110 22:28:13.120028  2593 solver.cpp:295] Iteration 481 (no loss supplied for SingleUpdateStep)
I1110 22:28:13.120131  2593 solver.cpp:310]     Train net output #0: loss = 0.729596 (* 1 = 0.729596 loss)
I1110 22:28:13.120152  2593 sgd_solver.cpp:106] Iteration 481, lr = 0.001
I1110 22:28:15.059183  2593 solver.cpp:295] Iteration 482 (no loss supplied for SingleUpdateStep)
I1110 22:28:15.059263  2593 solver.cpp:310]     Train net output #0: loss = 0.782136 (* 1 = 0.782136 loss)
I1110 22:28:15.059284  2593 sgd_solver.cpp:106] Iteration 482, lr = 0.001
I1110 22:28:16.902336  2593 solver.cpp:295] Iteration 483 (no loss supplied for SingleUpdateStep)
I1110 22:28:16.902425  2593 solver.cpp:310]     Train net output #0: loss = 0.723995 (* 1 = 0.723995 loss)
I1110 22:28:16.902449  2593 sgd_solver.cpp:106] Iteration 483, lr = 0.001
I1110 22:28:18.658015  2593 solver.cpp:295] Iteration 484 (no loss supplied for SingleUpdateStep)
I1110 22:28:18.658082  2593 solver.cpp:310]     Train net output #0: loss = 0.766012 (* 1 = 0.766012 loss)
I1110 22:28:18.658100  2593 sgd_solver.cpp:106] Iteration 484, lr = 0.001
I1110 22:28:20.489147  2593 solver.cpp:295] Iteration 485 (no loss supplied for SingleUpdateStep)
I1110 22:28:20.489197  2593 solver.cpp:310]     Train net output #0: loss = 0.7274 (* 1 = 0.7274 loss)
I1110 22:28:20.489215  2593 sgd_solver.cpp:106] Iteration 485, lr = 0.001
I1110 22:28:22.108043  2593 solver.cpp:295] Iteration 486 (no loss supplied for SingleUpdateStep)
I1110 22:28:22.108144  2593 solver.cpp:310]     Train net output #0: loss = 0.749407 (* 1 = 0.749407 loss)
I1110 22:28:22.108166  2593 sgd_solver.cpp:106] Iteration 486, lr = 0.001
I1110 22:28:23.848124  2593 solver.cpp:295] Iteration 487 (no loss supplied for SingleUpdateStep)
I1110 22:28:23.848201  2593 solver.cpp:310]     Train net output #0: loss = 0.750391 (* 1 = 0.750391 loss)
I1110 22:28:23.848222  2593 sgd_solver.cpp:106] Iteration 487, lr = 0.001
I1110 22:28:25.754184  2593 solver.cpp:295] Iteration 488 (no loss supplied for SingleUpdateStep)
I1110 22:28:25.754324  2593 solver.cpp:310]     Train net output #0: loss = 0.765603 (* 1 = 0.765603 loss)
I1110 22:28:25.754348  2593 sgd_solver.cpp:106] Iteration 488, lr = 0.001
I1110 22:28:27.657371  2593 solver.cpp:295] Iteration 489 (no loss supplied for SingleUpdateStep)
I1110 22:28:27.657480  2593 solver.cpp:310]     Train net output #0: loss = 0.735759 (* 1 = 0.735759 loss)
I1110 22:28:27.657505  2593 sgd_solver.cpp:106] Iteration 489, lr = 0.001
I1110 22:28:29.447546  2593 solver.cpp:295] Iteration 490 (no loss supplied for SingleUpdateStep)
I1110 22:28:29.447649  2593 solver.cpp:310]     Train net output #0: loss = 0.731543 (* 1 = 0.731543 loss)
I1110 22:28:29.447675  2593 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I1110 22:28:31.201994  2593 solver.cpp:295] Iteration 491 (no loss supplied for SingleUpdateStep)
I1110 22:28:31.202100  2593 solver.cpp:310]     Train net output #0: loss = 0.753599 (* 1 = 0.753599 loss)
I1110 22:28:31.202121  2593 sgd_solver.cpp:106] Iteration 491, lr = 0.001
I1110 22:28:32.982197  2593 solver.cpp:295] Iteration 492 (no loss supplied for SingleUpdateStep)
I1110 22:28:32.982311  2593 solver.cpp:310]     Train net output #0: loss = 0.671113 (* 1 = 0.671113 loss)
I1110 22:28:32.982332  2593 sgd_solver.cpp:106] Iteration 492, lr = 0.001
I1110 22:28:34.715194  2593 solver.cpp:295] Iteration 493 (no loss supplied for SingleUpdateStep)
I1110 22:28:34.715304  2593 solver.cpp:310]     Train net output #0: loss = 0.742236 (* 1 = 0.742236 loss)
I1110 22:28:34.715325  2593 sgd_solver.cpp:106] Iteration 493, lr = 0.001
I1110 22:28:36.616502  2593 solver.cpp:295] Iteration 494 (no loss supplied for SingleUpdateStep)
I1110 22:28:36.616647  2593 solver.cpp:310]     Train net output #0: loss = 0.769318 (* 1 = 0.769318 loss)
I1110 22:28:36.616672  2593 sgd_solver.cpp:106] Iteration 494, lr = 0.001
I1110 22:28:38.611111  2593 solver.cpp:295] Iteration 495 (no loss supplied for SingleUpdateStep)
I1110 22:28:38.611189  2593 solver.cpp:310]     Train net output #0: loss = 0.792503 (* 1 = 0.792503 loss)
I1110 22:28:38.611210  2593 sgd_solver.cpp:106] Iteration 495, lr = 0.001
I1110 22:28:40.378844  2593 solver.cpp:295] Iteration 496 (no loss supplied for SingleUpdateStep)
I1110 22:28:40.378919  2593 solver.cpp:310]     Train net output #0: loss = 0.696193 (* 1 = 0.696193 loss)
I1110 22:28:40.378942  2593 sgd_solver.cpp:106] Iteration 496, lr = 0.001
I1110 22:28:42.119035  2593 solver.cpp:295] Iteration 497 (no loss supplied for SingleUpdateStep)
I1110 22:28:42.119177  2593 solver.cpp:310]     Train net output #0: loss = 0.762961 (* 1 = 0.762961 loss)
I1110 22:28:42.119209  2593 sgd_solver.cpp:106] Iteration 497, lr = 0.001
I1110 22:28:44.414885  2593 solver.cpp:295] Iteration 498 (no loss supplied for SingleUpdateStep)
I1110 22:28:44.414981  2593 solver.cpp:310]     Train net output #0: loss = 0.73373 (* 1 = 0.73373 loss)
I1110 22:28:44.415005  2593 sgd_solver.cpp:106] Iteration 498, lr = 0.001
I1110 22:28:47.388890  2593 solver.cpp:295] Iteration 499 (no loss supplied for SingleUpdateStep)
I1110 22:28:47.388994  2593 solver.cpp:310]     Train net output #0: loss = 0.73525 (* 1 = 0.73525 loss)
I1110 22:28:47.389019  2593 sgd_solver.cpp:106] Iteration 499, lr = 0.001
I1110 22:28:50.438372  2593 solver.cpp:295] Iteration 500 (no loss supplied for SingleUpdateStep)
I1110 22:28:50.438493  2593 solver.cpp:310]     Train net output #0: loss = 0.717063 (* 1 = 0.717063 loss)
I1110 22:28:50.438521  2593 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I1110 22:28:52.988524  2593 solver.cpp:295] Iteration 501 (no loss supplied for SingleUpdateStep)
I1110 22:28:52.988652  2593 solver.cpp:310]     Train net output #0: loss = 0.699779 (* 1 = 0.699779 loss)
I1110 22:28:52.988685  2593 sgd_solver.cpp:106] Iteration 501, lr = 0.001
I1110 22:28:55.698581  2593 solver.cpp:295] Iteration 502 (no loss supplied for SingleUpdateStep)
I1110 22:28:55.698720  2593 solver.cpp:310]     Train net output #0: loss = 0.759819 (* 1 = 0.759819 loss)
I1110 22:28:55.698745  2593 sgd_solver.cpp:106] Iteration 502, lr = 0.001
I1110 22:28:58.481127  2593 solver.cpp:295] Iteration 503 (no loss supplied for SingleUpdateStep)
I1110 22:28:58.481240  2593 solver.cpp:310]     Train net output #0: loss = 0.731769 (* 1 = 0.731769 loss)
I1110 22:28:58.481262  2593 sgd_solver.cpp:106] Iteration 503, lr = 0.001
I1110 22:29:00.845549  2593 solver.cpp:295] Iteration 504 (no loss supplied for SingleUpdateStep)
I1110 22:29:00.845633  2593 solver.cpp:310]     Train net output #0: loss = 0.760633 (* 1 = 0.760633 loss)
I1110 22:29:00.845654  2593 sgd_solver.cpp:106] Iteration 504, lr = 0.001
I1110 22:29:03.202785  2593 solver.cpp:295] Iteration 505 (no loss supplied for SingleUpdateStep)
I1110 22:29:03.202880  2593 solver.cpp:310]     Train net output #0: loss = 0.745615 (* 1 = 0.745615 loss)
I1110 22:29:03.202901  2593 sgd_solver.cpp:106] Iteration 505, lr = 0.001
I1110 22:29:05.786958  2593 solver.cpp:295] Iteration 506 (no loss supplied for SingleUpdateStep)
I1110 22:29:05.787091  2593 solver.cpp:310]     Train net output #0: loss = 0.685344 (* 1 = 0.685344 loss)
I1110 22:29:05.787116  2593 sgd_solver.cpp:106] Iteration 506, lr = 0.001
I1110 22:29:08.121958  2593 solver.cpp:295] Iteration 507 (no loss supplied for SingleUpdateStep)
I1110 22:29:08.122057  2593 solver.cpp:310]     Train net output #0: loss = 0.662136 (* 1 = 0.662136 loss)
I1110 22:29:08.122081  2593 sgd_solver.cpp:106] Iteration 507, lr = 0.001
I1110 22:29:10.499027  2593 solver.cpp:295] Iteration 508 (no loss supplied for SingleUpdateStep)
I1110 22:29:10.499197  2593 solver.cpp:310]     Train net output #0: loss = 0.699154 (* 1 = 0.699154 loss)
I1110 22:29:10.499228  2593 sgd_solver.cpp:106] Iteration 508, lr = 0.001
I1110 22:29:12.855315  2593 solver.cpp:295] Iteration 509 (no loss supplied for SingleUpdateStep)
I1110 22:29:12.855393  2593 solver.cpp:310]     Train net output #0: loss = 0.75198 (* 1 = 0.75198 loss)
I1110 22:29:12.855413  2593 sgd_solver.cpp:106] Iteration 509, lr = 0.001
I1110 22:29:15.069293  2593 solver.cpp:295] Iteration 510 (no loss supplied for SingleUpdateStep)
I1110 22:29:15.069402  2593 solver.cpp:310]     Train net output #0: loss = 0.703063 (* 1 = 0.703063 loss)
I1110 22:29:15.069424  2593 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I1110 22:29:17.375548  2593 solver.cpp:295] Iteration 511 (no loss supplied for SingleUpdateStep)
I1110 22:29:17.375638  2593 solver.cpp:310]     Train net output #0: loss = 0.759048 (* 1 = 0.759048 loss)
I1110 22:29:17.375659  2593 sgd_solver.cpp:106] Iteration 511, lr = 0.001
I1110 22:29:19.741338  2593 solver.cpp:295] Iteration 512 (no loss supplied for SingleUpdateStep)
I1110 22:29:19.741412  2593 solver.cpp:310]     Train net output #0: loss = 0.745307 (* 1 = 0.745307 loss)
I1110 22:29:19.741432  2593 sgd_solver.cpp:106] Iteration 512, lr = 0.001
I1110 22:29:21.928779  2593 solver.cpp:295] Iteration 513 (no loss supplied for SingleUpdateStep)
I1110 22:29:21.928935  2593 solver.cpp:310]     Train net output #0: loss = 0.707138 (* 1 = 0.707138 loss)
I1110 22:29:21.928966  2593 sgd_solver.cpp:106] Iteration 513, lr = 0.001
I1110 22:29:24.291733  2593 solver.cpp:295] Iteration 514 (no loss supplied for SingleUpdateStep)
I1110 22:29:24.291852  2593 solver.cpp:310]     Train net output #0: loss = 0.728771 (* 1 = 0.728771 loss)
I1110 22:29:24.291877  2593 sgd_solver.cpp:106] Iteration 514, lr = 0.001
I1110 22:29:26.741716  2593 solver.cpp:295] Iteration 515 (no loss supplied for SingleUpdateStep)
I1110 22:29:26.741875  2593 solver.cpp:310]     Train net output #0: loss = 0.702303 (* 1 = 0.702303 loss)
I1110 22:29:26.741904  2593 sgd_solver.cpp:106] Iteration 515, lr = 0.001
I1110 22:29:29.217780  2593 solver.cpp:295] Iteration 516 (no loss supplied for SingleUpdateStep)
I1110 22:29:29.217875  2593 solver.cpp:310]     Train net output #0: loss = 0.752571 (* 1 = 0.752571 loss)
I1110 22:29:29.217897  2593 sgd_solver.cpp:106] Iteration 516, lr = 0.001
I1110 22:29:31.813271  2593 solver.cpp:295] Iteration 517 (no loss supplied for SingleUpdateStep)
I1110 22:29:31.813379  2593 solver.cpp:310]     Train net output #0: loss = 0.770054 (* 1 = 0.770054 loss)
I1110 22:29:31.813402  2593 sgd_solver.cpp:106] Iteration 517, lr = 0.001
I1110 22:29:34.726737  2593 solver.cpp:295] Iteration 518 (no loss supplied for SingleUpdateStep)
I1110 22:29:34.726863  2593 solver.cpp:310]     Train net output #0: loss = 0.729245 (* 1 = 0.729245 loss)
I1110 22:29:34.726886  2593 sgd_solver.cpp:106] Iteration 518, lr = 0.001
I1110 22:29:36.999986  2593 solver.cpp:295] Iteration 519 (no loss supplied for SingleUpdateStep)
I1110 22:29:37.000121  2593 solver.cpp:310]     Train net output #0: loss = 0.83043 (* 1 = 0.83043 loss)
I1110 22:29:37.000146  2593 sgd_solver.cpp:106] Iteration 519, lr = 0.001
I1110 22:29:39.332571  2593 solver.cpp:295] Iteration 520 (no loss supplied for SingleUpdateStep)
I1110 22:29:39.332674  2593 solver.cpp:310]     Train net output #0: loss = 0.747261 (* 1 = 0.747261 loss)
I1110 22:29:39.332697  2593 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I1110 22:29:41.881247  2593 solver.cpp:295] Iteration 521 (no loss supplied for SingleUpdateStep)
I1110 22:29:41.881361  2593 solver.cpp:310]     Train net output #0: loss = 0.73034 (* 1 = 0.73034 loss)
I1110 22:29:41.881386  2593 sgd_solver.cpp:106] Iteration 521, lr = 0.001
I1110 22:29:44.145577  2593 solver.cpp:295] Iteration 522 (no loss supplied for SingleUpdateStep)
I1110 22:29:44.145637  2593 solver.cpp:310]     Train net output #0: loss = 0.692076 (* 1 = 0.692076 loss)
I1110 22:29:44.145656  2593 sgd_solver.cpp:106] Iteration 522, lr = 0.001
I1110 22:29:46.338330  2593 solver.cpp:295] Iteration 523 (no loss supplied for SingleUpdateStep)
I1110 22:29:46.364398  2593 solver.cpp:310]     Train net output #0: loss = 0.678132 (* 1 = 0.678132 loss)
I1110 22:29:46.364436  2593 sgd_solver.cpp:106] Iteration 523, lr = 0.001
I1110 22:29:48.079857  2593 solver.cpp:295] Iteration 524 (no loss supplied for SingleUpdateStep)
I1110 22:29:48.079958  2593 solver.cpp:310]     Train net output #0: loss = 0.687885 (* 1 = 0.687885 loss)
I1110 22:29:48.079989  2593 sgd_solver.cpp:106] Iteration 524, lr = 0.001
I1110 22:29:49.905774  2593 solver.cpp:295] Iteration 525 (no loss supplied for SingleUpdateStep)
I1110 22:29:49.905874  2593 solver.cpp:310]     Train net output #0: loss = 0.718099 (* 1 = 0.718099 loss)
I1110 22:29:49.905897  2593 sgd_solver.cpp:106] Iteration 525, lr = 0.001
I1110 22:29:51.759627  2593 solver.cpp:295] Iteration 526 (no loss supplied for SingleUpdateStep)
I1110 22:29:51.759796  2593 solver.cpp:310]     Train net output #0: loss = 0.725069 (* 1 = 0.725069 loss)
I1110 22:29:51.759829  2593 sgd_solver.cpp:106] Iteration 526, lr = 0.001
I1110 22:29:53.564832  2593 solver.cpp:295] Iteration 527 (no loss supplied for SingleUpdateStep)
I1110 22:29:53.564909  2593 solver.cpp:310]     Train net output #0: loss = 0.676671 (* 1 = 0.676671 loss)
I1110 22:29:53.564932  2593 sgd_solver.cpp:106] Iteration 527, lr = 0.001
I1110 22:29:55.364344  2593 solver.cpp:295] Iteration 528 (no loss supplied for SingleUpdateStep)
I1110 22:29:55.364406  2593 solver.cpp:310]     Train net output #0: loss = 0.695525 (* 1 = 0.695525 loss)
I1110 22:29:55.364428  2593 sgd_solver.cpp:106] Iteration 528, lr = 0.001
I1110 22:29:57.443115  2593 solver.cpp:295] Iteration 529 (no loss supplied for SingleUpdateStep)
I1110 22:29:57.443243  2593 solver.cpp:310]     Train net output #0: loss = 0.726108 (* 1 = 0.726108 loss)
I1110 22:29:57.443269  2593 sgd_solver.cpp:106] Iteration 529, lr = 0.001
I1110 22:29:59.161840  2593 solver.cpp:295] Iteration 530 (no loss supplied for SingleUpdateStep)
I1110 22:29:59.161947  2593 solver.cpp:310]     Train net output #0: loss = 0.746289 (* 1 = 0.746289 loss)
I1110 22:29:59.161970  2593 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I1110 22:30:00.960984  2593 solver.cpp:295] Iteration 531 (no loss supplied for SingleUpdateStep)
I1110 22:30:00.961099  2593 solver.cpp:310]     Train net output #0: loss = 0.721053 (* 1 = 0.721053 loss)
I1110 22:30:00.961122  2593 sgd_solver.cpp:106] Iteration 531, lr = 0.001
I1110 22:30:02.842492  2593 solver.cpp:295] Iteration 532 (no loss supplied for SingleUpdateStep)
I1110 22:30:02.842587  2593 solver.cpp:310]     Train net output #0: loss = 0.660719 (* 1 = 0.660719 loss)
I1110 22:30:02.842608  2593 sgd_solver.cpp:106] Iteration 532, lr = 0.001
I1110 22:30:04.601702  2593 solver.cpp:295] Iteration 533 (no loss supplied for SingleUpdateStep)
I1110 22:30:04.601796  2593 solver.cpp:310]     Train net output #0: loss = 0.787737 (* 1 = 0.787737 loss)
I1110 22:30:04.601821  2593 sgd_solver.cpp:106] Iteration 533, lr = 0.001
I1110 22:30:06.338474  2593 solver.cpp:295] Iteration 534 (no loss supplied for SingleUpdateStep)
I1110 22:30:06.338623  2593 solver.cpp:310]     Train net output #0: loss = 0.742334 (* 1 = 0.742334 loss)
I1110 22:30:06.338651  2593 sgd_solver.cpp:106] Iteration 534, lr = 0.001
I1110 22:30:08.198281  2593 solver.cpp:295] Iteration 535 (no loss supplied for SingleUpdateStep)
I1110 22:30:08.198421  2593 solver.cpp:310]     Train net output #0: loss = 0.723668 (* 1 = 0.723668 loss)
I1110 22:30:08.198449  2593 sgd_solver.cpp:106] Iteration 535, lr = 0.001
I1110 22:30:10.047319  2593 solver.cpp:295] Iteration 536 (no loss supplied for SingleUpdateStep)
I1110 22:30:10.047451  2593 solver.cpp:310]     Train net output #0: loss = 0.704152 (* 1 = 0.704152 loss)
I1110 22:30:10.047482  2593 sgd_solver.cpp:106] Iteration 536, lr = 0.001
I1110 22:30:11.835486  2593 solver.cpp:295] Iteration 537 (no loss supplied for SingleUpdateStep)
I1110 22:30:11.835599  2593 solver.cpp:310]     Train net output #0: loss = 0.743109 (* 1 = 0.743109 loss)
I1110 22:30:11.835625  2593 sgd_solver.cpp:106] Iteration 537, lr = 0.001
I1110 22:30:13.722785  2593 solver.cpp:295] Iteration 538 (no loss supplied for SingleUpdateStep)
I1110 22:30:13.722862  2593 solver.cpp:310]     Train net output #0: loss = 0.726648 (* 1 = 0.726648 loss)
I1110 22:30:13.722882  2593 sgd_solver.cpp:106] Iteration 538, lr = 0.001
I1110 22:30:15.547415  2593 solver.cpp:295] Iteration 539 (no loss supplied for SingleUpdateStep)
I1110 22:30:15.547562  2593 solver.cpp:310]     Train net output #0: loss = 0.701868 (* 1 = 0.701868 loss)
I1110 22:30:15.547598  2593 sgd_solver.cpp:106] Iteration 539, lr = 0.001
I1110 22:30:17.267755  2593 solver.cpp:295] Iteration 540 (no loss supplied for SingleUpdateStep)
I1110 22:30:17.267853  2593 solver.cpp:310]     Train net output #0: loss = 0.711326 (* 1 = 0.711326 loss)
I1110 22:30:17.267874  2593 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I1110 22:30:19.162073  2593 solver.cpp:295] Iteration 541 (no loss supplied for SingleUpdateStep)
I1110 22:30:19.162161  2593 solver.cpp:310]     Train net output #0: loss = 0.730555 (* 1 = 0.730555 loss)
I1110 22:30:19.162181  2593 sgd_solver.cpp:106] Iteration 541, lr = 0.001
I1110 22:30:21.308975  2593 solver.cpp:295] Iteration 542 (no loss supplied for SingleUpdateStep)
I1110 22:30:21.309074  2593 solver.cpp:310]     Train net output #0: loss = 0.686667 (* 1 = 0.686667 loss)
I1110 22:30:21.309098  2593 sgd_solver.cpp:106] Iteration 542, lr = 0.001
I1110 22:30:23.754957  2593 solver.cpp:295] Iteration 543 (no loss supplied for SingleUpdateStep)
I1110 22:30:23.755019  2593 solver.cpp:310]     Train net output #0: loss = 0.715687 (* 1 = 0.715687 loss)
I1110 22:30:23.755039  2593 sgd_solver.cpp:106] Iteration 543, lr = 0.001
I1110 22:30:26.473265  2593 solver.cpp:295] Iteration 544 (no loss supplied for SingleUpdateStep)
I1110 22:30:26.473366  2593 solver.cpp:310]     Train net output #0: loss = 0.736548 (* 1 = 0.736548 loss)
I1110 22:30:26.473387  2593 sgd_solver.cpp:106] Iteration 544, lr = 0.001
I1110 22:30:30.175849  2593 solver.cpp:295] Iteration 545 (no loss supplied for SingleUpdateStep)
I1110 22:30:30.175912  2593 solver.cpp:310]     Train net output #0: loss = 0.700091 (* 1 = 0.700091 loss)
I1110 22:30:30.175932  2593 sgd_solver.cpp:106] Iteration 545, lr = 0.001
I1110 22:30:33.261764  2593 solver.cpp:295] Iteration 546 (no loss supplied for SingleUpdateStep)
I1110 22:30:33.261850  2593 solver.cpp:310]     Train net output #0: loss = 0.704553 (* 1 = 0.704553 loss)
I1110 22:30:33.261872  2593 sgd_solver.cpp:106] Iteration 546, lr = 0.001
I1110 22:30:35.619858  2593 solver.cpp:295] Iteration 547 (no loss supplied for SingleUpdateStep)
I1110 22:30:35.619933  2593 solver.cpp:310]     Train net output #0: loss = 0.725972 (* 1 = 0.725972 loss)
I1110 22:30:35.619953  2593 sgd_solver.cpp:106] Iteration 547, lr = 0.001
I1110 22:30:38.084708  2593 solver.cpp:295] Iteration 548 (no loss supplied for SingleUpdateStep)
I1110 22:30:38.084822  2593 solver.cpp:310]     Train net output #0: loss = 0.741324 (* 1 = 0.741324 loss)
I1110 22:30:38.084848  2593 sgd_solver.cpp:106] Iteration 548, lr = 0.001
I1110 22:30:40.736266  2593 solver.cpp:295] Iteration 549 (no loss supplied for SingleUpdateStep)
I1110 22:30:40.736364  2593 solver.cpp:310]     Train net output #0: loss = 0.75234 (* 1 = 0.75234 loss)
I1110 22:30:40.736393  2593 sgd_solver.cpp:106] Iteration 549, lr = 0.001
I1110 22:30:43.475049  2593 solver.cpp:295] Iteration 550 (no loss supplied for SingleUpdateStep)
I1110 22:30:43.475111  2593 solver.cpp:310]     Train net output #0: loss = 0.774127 (* 1 = 0.774127 loss)
I1110 22:30:43.475131  2593 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I1110 22:30:45.790992  2593 solver.cpp:295] Iteration 551 (no loss supplied for SingleUpdateStep)
I1110 22:30:45.791121  2593 solver.cpp:310]     Train net output #0: loss = 0.731591 (* 1 = 0.731591 loss)
I1110 22:30:45.791143  2593 sgd_solver.cpp:106] Iteration 551, lr = 0.001
I1110 22:30:47.942721  2593 solver.cpp:295] Iteration 552 (no loss supplied for SingleUpdateStep)
I1110 22:30:47.942899  2593 solver.cpp:310]     Train net output #0: loss = 0.781502 (* 1 = 0.781502 loss)
I1110 22:30:47.942932  2593 sgd_solver.cpp:106] Iteration 552, lr = 0.001
I1110 22:30:50.205394  2593 solver.cpp:295] Iteration 553 (no loss supplied for SingleUpdateStep)
I1110 22:30:50.205519  2593 solver.cpp:310]     Train net output #0: loss = 0.702523 (* 1 = 0.702523 loss)
I1110 22:30:50.205549  2593 sgd_solver.cpp:106] Iteration 553, lr = 0.001
I1110 22:30:52.430109  2593 solver.cpp:295] Iteration 554 (no loss supplied for SingleUpdateStep)
I1110 22:30:52.430156  2593 solver.cpp:310]     Train net output #0: loss = 0.719625 (* 1 = 0.719625 loss)
I1110 22:30:52.430176  2593 sgd_solver.cpp:106] Iteration 554, lr = 0.001
I1110 22:30:54.587895  2593 solver.cpp:295] Iteration 555 (no loss supplied for SingleUpdateStep)
I1110 22:30:54.587996  2593 solver.cpp:310]     Train net output #0: loss = 0.68753 (* 1 = 0.68753 loss)
I1110 22:30:54.588018  2593 sgd_solver.cpp:106] Iteration 555, lr = 0.001
I1110 22:30:56.748896  2593 solver.cpp:295] Iteration 556 (no loss supplied for SingleUpdateStep)
I1110 22:30:56.748998  2593 solver.cpp:310]     Train net output #0: loss = 0.765869 (* 1 = 0.765869 loss)
I1110 22:30:56.749021  2593 sgd_solver.cpp:106] Iteration 556, lr = 0.001
I1110 22:30:58.964835  2593 solver.cpp:295] Iteration 557 (no loss supplied for SingleUpdateStep)
I1110 22:30:58.964992  2593 solver.cpp:310]     Train net output #0: loss = 0.692959 (* 1 = 0.692959 loss)
I1110 22:30:58.965025  2593 sgd_solver.cpp:106] Iteration 557, lr = 0.001
I1110 22:31:01.447443  2593 solver.cpp:295] Iteration 558 (no loss supplied for SingleUpdateStep)
I1110 22:31:01.447492  2593 solver.cpp:310]     Train net output #0: loss = 0.76342 (* 1 = 0.76342 loss)
I1110 22:31:01.447510  2593 sgd_solver.cpp:106] Iteration 558, lr = 0.001
I1110 22:31:03.608991  2593 solver.cpp:295] Iteration 559 (no loss supplied for SingleUpdateStep)
I1110 22:31:03.609102  2593 solver.cpp:310]     Train net output #0: loss = 0.790574 (* 1 = 0.790574 loss)
I1110 22:31:03.609125  2593 sgd_solver.cpp:106] Iteration 559, lr = 0.001
I1110 22:31:05.882048  2593 solver.cpp:295] Iteration 560 (no loss supplied for SingleUpdateStep)
I1110 22:31:05.882186  2593 solver.cpp:310]     Train net output #0: loss = 0.75566 (* 1 = 0.75566 loss)
I1110 22:31:05.882211  2593 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I1110 22:31:08.203600  2593 solver.cpp:295] Iteration 561 (no loss supplied for SingleUpdateStep)
I1110 22:31:08.203692  2593 solver.cpp:310]     Train net output #0: loss = 0.661644 (* 1 = 0.661644 loss)
I1110 22:31:08.203712  2593 sgd_solver.cpp:106] Iteration 561, lr = 0.001
I1110 22:31:10.506592  2593 solver.cpp:295] Iteration 562 (no loss supplied for SingleUpdateStep)
I1110 22:31:10.506671  2593 solver.cpp:310]     Train net output #0: loss = 0.752736 (* 1 = 0.752736 loss)
I1110 22:31:10.506691  2593 sgd_solver.cpp:106] Iteration 562, lr = 0.001
I1110 22:31:12.841753  2593 solver.cpp:295] Iteration 563 (no loss supplied for SingleUpdateStep)
I1110 22:31:12.841855  2593 solver.cpp:310]     Train net output #0: loss = 0.689104 (* 1 = 0.689104 loss)
I1110 22:31:12.841878  2593 sgd_solver.cpp:106] Iteration 563, lr = 0.001
I1110 22:31:15.053064  2593 solver.cpp:295] Iteration 564 (no loss supplied for SingleUpdateStep)
I1110 22:31:15.053153  2593 solver.cpp:310]     Train net output #0: loss = 0.726401 (* 1 = 0.726401 loss)
I1110 22:31:15.053174  2593 sgd_solver.cpp:106] Iteration 564, lr = 0.001
I1110 22:31:17.354339  2593 solver.cpp:295] Iteration 565 (no loss supplied for SingleUpdateStep)
I1110 22:31:17.354444  2593 solver.cpp:310]     Train net output #0: loss = 0.704563 (* 1 = 0.704563 loss)
I1110 22:31:17.354468  2593 sgd_solver.cpp:106] Iteration 565, lr = 0.001
I1110 22:31:19.677256  2593 solver.cpp:295] Iteration 566 (no loss supplied for SingleUpdateStep)
I1110 22:31:19.677372  2593 solver.cpp:310]     Train net output #0: loss = 0.703753 (* 1 = 0.703753 loss)
I1110 22:31:19.677394  2593 sgd_solver.cpp:106] Iteration 566, lr = 0.001
I1110 22:31:21.900894  2593 solver.cpp:295] Iteration 567 (no loss supplied for SingleUpdateStep)
I1110 22:31:21.900991  2593 solver.cpp:310]     Train net output #0: loss = 0.649548 (* 1 = 0.649548 loss)
I1110 22:31:21.901013  2593 sgd_solver.cpp:106] Iteration 567, lr = 0.001
I1110 22:31:23.996603  2593 solver.cpp:295] Iteration 568 (no loss supplied for SingleUpdateStep)
I1110 22:31:23.996758  2593 solver.cpp:310]     Train net output #0: loss = 0.705876 (* 1 = 0.705876 loss)
I1110 22:31:23.996783  2593 sgd_solver.cpp:106] Iteration 568, lr = 0.001
I1110 22:31:26.264495  2593 solver.cpp:295] Iteration 569 (no loss supplied for SingleUpdateStep)
I1110 22:31:26.264598  2593 solver.cpp:310]     Train net output #0: loss = 0.719628 (* 1 = 0.719628 loss)
I1110 22:31:26.264621  2593 sgd_solver.cpp:106] Iteration 569, lr = 0.001
I1110 22:31:28.536895  2593 solver.cpp:295] Iteration 570 (no loss supplied for SingleUpdateStep)
I1110 22:31:28.537027  2593 solver.cpp:310]     Train net output #0: loss = 0.682841 (* 1 = 0.682841 loss)
I1110 22:31:28.537051  2593 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I1110 22:31:30.702170  2593 solver.cpp:295] Iteration 571 (no loss supplied for SingleUpdateStep)
I1110 22:31:30.702252  2593 solver.cpp:310]     Train net output #0: loss = 0.738663 (* 1 = 0.738663 loss)
I1110 22:31:30.702273  2593 sgd_solver.cpp:106] Iteration 571, lr = 0.001
I1110 22:31:32.963754  2593 solver.cpp:295] Iteration 572 (no loss supplied for SingleUpdateStep)
I1110 22:31:32.963867  2593 solver.cpp:310]     Train net output #0: loss = 0.734644 (* 1 = 0.734644 loss)
I1110 22:31:32.963889  2593 sgd_solver.cpp:106] Iteration 572, lr = 0.001
I1110 22:31:35.055059  2593 solver.cpp:295] Iteration 573 (no loss supplied for SingleUpdateStep)
I1110 22:31:35.055138  2593 solver.cpp:310]     Train net output #0: loss = 0.72462 (* 1 = 0.72462 loss)
I1110 22:31:35.055158  2593 sgd_solver.cpp:106] Iteration 573, lr = 0.001
I1110 22:31:37.107050  2593 solver.cpp:295] Iteration 574 (no loss supplied for SingleUpdateStep)
I1110 22:31:37.107167  2593 solver.cpp:310]     Train net output #0: loss = 0.741729 (* 1 = 0.741729 loss)
I1110 22:31:37.107189  2593 sgd_solver.cpp:106] Iteration 574, lr = 0.001
I1110 22:31:39.277278  2593 solver.cpp:295] Iteration 575 (no loss supplied for SingleUpdateStep)
I1110 22:31:39.277387  2593 solver.cpp:310]     Train net output #0: loss = 0.747375 (* 1 = 0.747375 loss)
I1110 22:31:39.277408  2593 sgd_solver.cpp:106] Iteration 575, lr = 0.001
I1110 22:31:41.563498  2593 solver.cpp:295] Iteration 576 (no loss supplied for SingleUpdateStep)
I1110 22:31:41.563575  2593 solver.cpp:310]     Train net output #0: loss = 0.674702 (* 1 = 0.674702 loss)
I1110 22:31:41.563594  2593 sgd_solver.cpp:106] Iteration 576, lr = 0.001
I1110 22:31:43.654938  2593 solver.cpp:295] Iteration 577 (no loss supplied for SingleUpdateStep)
I1110 22:31:43.655030  2593 solver.cpp:310]     Train net output #0: loss = 0.704326 (* 1 = 0.704326 loss)
I1110 22:31:43.655050  2593 sgd_solver.cpp:106] Iteration 577, lr = 0.001
I1110 22:31:45.896966  2593 solver.cpp:295] Iteration 578 (no loss supplied for SingleUpdateStep)
I1110 22:31:45.897066  2593 solver.cpp:310]     Train net output #0: loss = 0.709221 (* 1 = 0.709221 loss)
I1110 22:31:45.897090  2593 sgd_solver.cpp:106] Iteration 578, lr = 0.001
I1110 22:31:48.030315  2593 solver.cpp:295] Iteration 579 (no loss supplied for SingleUpdateStep)
I1110 22:31:48.030423  2593 solver.cpp:310]     Train net output #0: loss = 0.707752 (* 1 = 0.707752 loss)
I1110 22:31:48.030447  2593 sgd_solver.cpp:106] Iteration 579, lr = 0.001
I1110 22:31:50.318990  2593 solver.cpp:295] Iteration 580 (no loss supplied for SingleUpdateStep)
I1110 22:31:50.319125  2593 solver.cpp:310]     Train net output #0: loss = 0.704356 (* 1 = 0.704356 loss)
I1110 22:31:50.319149  2593 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I1110 22:31:52.701638  2593 solver.cpp:295] Iteration 581 (no loss supplied for SingleUpdateStep)
I1110 22:31:52.701725  2593 solver.cpp:310]     Train net output #0: loss = 0.693476 (* 1 = 0.693476 loss)
I1110 22:31:52.701745  2593 sgd_solver.cpp:106] Iteration 581, lr = 0.001
I1110 22:31:54.880990  2593 solver.cpp:295] Iteration 582 (no loss supplied for SingleUpdateStep)
I1110 22:31:54.881041  2593 solver.cpp:310]     Train net output #0: loss = 0.657792 (* 1 = 0.657792 loss)
I1110 22:31:54.881059  2593 sgd_solver.cpp:106] Iteration 582, lr = 0.001
I1110 22:31:57.313930  2593 solver.cpp:295] Iteration 583 (no loss supplied for SingleUpdateStep)
I1110 22:31:57.314059  2593 solver.cpp:310]     Train net output #0: loss = 0.702947 (* 1 = 0.702947 loss)
I1110 22:31:57.314080  2593 sgd_solver.cpp:106] Iteration 583, lr = 0.001
I1110 22:31:59.773447  2593 solver.cpp:295] Iteration 584 (no loss supplied for SingleUpdateStep)
I1110 22:31:59.773561  2593 solver.cpp:310]     Train net output #0: loss = 0.657064 (* 1 = 0.657064 loss)
I1110 22:31:59.773584  2593 sgd_solver.cpp:106] Iteration 584, lr = 0.001
I1110 22:32:02.439748  2593 solver.cpp:295] Iteration 585 (no loss supplied for SingleUpdateStep)
I1110 22:32:02.439857  2593 solver.cpp:310]     Train net output #0: loss = 0.709891 (* 1 = 0.709891 loss)
I1110 22:32:02.439879  2593 sgd_solver.cpp:106] Iteration 585, lr = 0.001
I1110 22:32:04.957451  2593 solver.cpp:295] Iteration 586 (no loss supplied for SingleUpdateStep)
I1110 22:32:04.957577  2593 solver.cpp:310]     Train net output #0: loss = 0.801492 (* 1 = 0.801492 loss)
I1110 22:32:04.957602  2593 sgd_solver.cpp:106] Iteration 586, lr = 0.001
I1110 22:32:07.443611  2593 solver.cpp:295] Iteration 587 (no loss supplied for SingleUpdateStep)
I1110 22:32:07.443718  2593 solver.cpp:310]     Train net output #0: loss = 0.751261 (* 1 = 0.751261 loss)
I1110 22:32:07.443738  2593 sgd_solver.cpp:106] Iteration 587, lr = 0.001
I1110 22:32:10.246881  2593 solver.cpp:295] Iteration 588 (no loss supplied for SingleUpdateStep)
I1110 22:32:10.246958  2593 solver.cpp:310]     Train net output #0: loss = 0.683727 (* 1 = 0.683727 loss)
I1110 22:32:10.246979  2593 sgd_solver.cpp:106] Iteration 588, lr = 0.001
I1110 22:32:13.397371  2593 solver.cpp:295] Iteration 589 (no loss supplied for SingleUpdateStep)
I1110 22:32:13.397460  2593 solver.cpp:310]     Train net output #0: loss = 0.659093 (* 1 = 0.659093 loss)
I1110 22:32:13.397481  2593 sgd_solver.cpp:106] Iteration 589, lr = 0.001
I1110 22:32:15.706007  2593 solver.cpp:295] Iteration 590 (no loss supplied for SingleUpdateStep)
I1110 22:32:15.706125  2593 solver.cpp:310]     Train net output #0: loss = 0.752502 (* 1 = 0.752502 loss)
I1110 22:32:15.706149  2593 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I1110 22:32:18.065124  2593 solver.cpp:295] Iteration 591 (no loss supplied for SingleUpdateStep)
I1110 22:32:18.065242  2593 solver.cpp:310]     Train net output #0: loss = 0.71366 (* 1 = 0.71366 loss)
I1110 22:32:18.065268  2593 sgd_solver.cpp:106] Iteration 591, lr = 0.001
I1110 22:32:20.374076  2593 solver.cpp:295] Iteration 592 (no loss supplied for SingleUpdateStep)
I1110 22:32:20.374177  2593 solver.cpp:310]     Train net output #0: loss = 0.665665 (* 1 = 0.665665 loss)
I1110 22:32:20.374202  2593 sgd_solver.cpp:106] Iteration 592, lr = 0.001
I1110 22:32:22.881479  2593 solver.cpp:295] Iteration 593 (no loss supplied for SingleUpdateStep)
I1110 22:32:22.881585  2593 solver.cpp:310]     Train net output #0: loss = 0.702447 (* 1 = 0.702447 loss)
I1110 22:32:22.881608  2593 sgd_solver.cpp:106] Iteration 593, lr = 0.001
I1110 22:32:25.177427  2593 solver.cpp:295] Iteration 594 (no loss supplied for SingleUpdateStep)
I1110 22:32:25.177533  2593 solver.cpp:310]     Train net output #0: loss = 0.742336 (* 1 = 0.742336 loss)
I1110 22:32:25.177553  2593 sgd_solver.cpp:106] Iteration 594, lr = 0.001
I1110 22:32:27.378650  2593 solver.cpp:295] Iteration 595 (no loss supplied for SingleUpdateStep)
I1110 22:32:27.378747  2593 solver.cpp:310]     Train net output #0: loss = 0.753871 (* 1 = 0.753871 loss)
I1110 22:32:27.378769  2593 sgd_solver.cpp:106] Iteration 595, lr = 0.001
I1110 22:32:29.546857  2593 solver.cpp:295] Iteration 596 (no loss supplied for SingleUpdateStep)
I1110 22:32:29.546988  2593 solver.cpp:310]     Train net output #0: loss = 0.697832 (* 1 = 0.697832 loss)
I1110 22:32:29.547015  2593 sgd_solver.cpp:106] Iteration 596, lr = 0.001
I1110 22:32:32.066373  2593 solver.cpp:295] Iteration 597 (no loss supplied for SingleUpdateStep)
I1110 22:32:32.066481  2593 solver.cpp:310]     Train net output #0: loss = 0.658987 (* 1 = 0.658987 loss)
I1110 22:32:32.066505  2593 sgd_solver.cpp:106] Iteration 597, lr = 0.001
I1110 22:32:34.584825  2593 solver.cpp:295] Iteration 598 (no loss supplied for SingleUpdateStep)
I1110 22:32:34.584894  2593 solver.cpp:310]     Train net output #0: loss = 0.712904 (* 1 = 0.712904 loss)
I1110 22:32:34.584913  2593 sgd_solver.cpp:106] Iteration 598, lr = 0.001
I1110 22:32:37.501453  2593 solver.cpp:295] Iteration 599 (no loss supplied for SingleUpdateStep)
I1110 22:32:37.501559  2593 solver.cpp:310]     Train net output #0: loss = 0.724892 (* 1 = 0.724892 loss)
I1110 22:32:37.501587  2593 sgd_solver.cpp:106] Iteration 599, lr = 0.001
I1110 22:32:39.763312  2593 solver.cpp:295] Iteration 600 (no loss supplied for SingleUpdateStep)
I1110 22:32:39.763422  2593 solver.cpp:310]     Train net output #0: loss = 0.654998 (* 1 = 0.654998 loss)
I1110 22:32:39.763447  2593 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I1110 22:32:42.621479  2593 solver.cpp:295] Iteration 601 (no loss supplied for SingleUpdateStep)
I1110 22:32:42.621600  2593 solver.cpp:310]     Train net output #0: loss = 0.740704 (* 1 = 0.740704 loss)
I1110 22:32:42.621631  2593 sgd_solver.cpp:106] Iteration 601, lr = 0.001
I1110 22:32:45.515437  2593 solver.cpp:295] Iteration 602 (no loss supplied for SingleUpdateStep)
I1110 22:32:45.515486  2593 solver.cpp:310]     Train net output #0: loss = 0.695663 (* 1 = 0.695663 loss)
I1110 22:32:45.515504  2593 sgd_solver.cpp:106] Iteration 602, lr = 0.001
I1110 22:32:48.898119  2593 solver.cpp:295] Iteration 603 (no loss supplied for SingleUpdateStep)
I1110 22:32:48.898207  2593 solver.cpp:310]     Train net output #0: loss = 0.737518 (* 1 = 0.737518 loss)
I1110 22:32:48.898229  2593 sgd_solver.cpp:106] Iteration 603, lr = 0.001
I1110 22:32:51.272536  2593 solver.cpp:295] Iteration 604 (no loss supplied for SingleUpdateStep)
I1110 22:32:51.272641  2593 solver.cpp:310]     Train net output #0: loss = 0.717298 (* 1 = 0.717298 loss)
I1110 22:32:51.272663  2593 sgd_solver.cpp:106] Iteration 604, lr = 0.001
I1110 22:32:53.752215  2593 solver.cpp:295] Iteration 605 (no loss supplied for SingleUpdateStep)
I1110 22:32:53.752320  2593 solver.cpp:310]     Train net output #0: loss = 0.713169 (* 1 = 0.713169 loss)
I1110 22:32:53.752339  2593 sgd_solver.cpp:106] Iteration 605, lr = 0.001
I1110 22:32:56.258316  2593 solver.cpp:295] Iteration 606 (no loss supplied for SingleUpdateStep)
I1110 22:32:56.258396  2593 solver.cpp:310]     Train net output #0: loss = 0.734859 (* 1 = 0.734859 loss)
I1110 22:32:56.258419  2593 sgd_solver.cpp:106] Iteration 606, lr = 0.001
I1110 22:32:58.760680  2593 solver.cpp:295] Iteration 607 (no loss supplied for SingleUpdateStep)
I1110 22:32:58.760746  2593 solver.cpp:310]     Train net output #0: loss = 0.780484 (* 1 = 0.780484 loss)
I1110 22:32:58.760766  2593 sgd_solver.cpp:106] Iteration 607, lr = 0.001
I1110 22:33:01.166431  2593 solver.cpp:295] Iteration 608 (no loss supplied for SingleUpdateStep)
I1110 22:33:01.166503  2593 solver.cpp:310]     Train net output #0: loss = 0.697722 (* 1 = 0.697722 loss)
I1110 22:33:01.166523  2593 sgd_solver.cpp:106] Iteration 608, lr = 0.001
I1110 22:33:03.391255  2593 solver.cpp:295] Iteration 609 (no loss supplied for SingleUpdateStep)
I1110 22:33:03.391389  2593 solver.cpp:310]     Train net output #0: loss = 0.74047 (* 1 = 0.74047 loss)
I1110 22:33:03.391412  2593 sgd_solver.cpp:106] Iteration 609, lr = 0.001
I1110 22:33:05.609779  2593 solver.cpp:295] Iteration 610 (no loss supplied for SingleUpdateStep)
I1110 22:33:05.609915  2593 solver.cpp:310]     Train net output #0: loss = 0.686172 (* 1 = 0.686172 loss)
I1110 22:33:05.609938  2593 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I1110 22:33:07.835672  2593 solver.cpp:295] Iteration 611 (no loss supplied for SingleUpdateStep)
I1110 22:33:07.835744  2593 solver.cpp:310]     Train net output #0: loss = 0.711883 (* 1 = 0.711883 loss)
I1110 22:33:07.835765  2593 sgd_solver.cpp:106] Iteration 611, lr = 0.001
I1110 22:33:10.255591  2593 solver.cpp:295] Iteration 612 (no loss supplied for SingleUpdateStep)
I1110 22:33:10.255689  2593 solver.cpp:310]     Train net output #0: loss = 0.655623 (* 1 = 0.655623 loss)
I1110 22:33:10.255712  2593 sgd_solver.cpp:106] Iteration 612, lr = 0.001
I1110 22:33:12.397955  2593 solver.cpp:295] Iteration 613 (no loss supplied for SingleUpdateStep)
I1110 22:33:12.398039  2593 solver.cpp:310]     Train net output #0: loss = 0.761074 (* 1 = 0.761074 loss)
I1110 22:33:12.398061  2593 sgd_solver.cpp:106] Iteration 613, lr = 0.001
I1110 22:33:14.514433  2593 solver.cpp:295] Iteration 614 (no loss supplied for SingleUpdateStep)
I1110 22:33:14.514518  2593 solver.cpp:310]     Train net output #0: loss = 0.682811 (* 1 = 0.682811 loss)
I1110 22:33:14.514539  2593 sgd_solver.cpp:106] Iteration 614, lr = 0.001
I1110 22:33:16.764704  2593 solver.cpp:295] Iteration 615 (no loss supplied for SingleUpdateStep)
I1110 22:33:16.764798  2593 solver.cpp:310]     Train net output #0: loss = 0.689171 (* 1 = 0.689171 loss)
I1110 22:33:16.764817  2593 sgd_solver.cpp:106] Iteration 615, lr = 0.001
I1110 22:33:18.930568  2593 solver.cpp:295] Iteration 616 (no loss supplied for SingleUpdateStep)
I1110 22:33:18.930692  2593 solver.cpp:310]     Train net output #0: loss = 0.728867 (* 1 = 0.728867 loss)
I1110 22:33:18.930717  2593 sgd_solver.cpp:106] Iteration 616, lr = 0.001
I1110 22:33:21.140570  2593 solver.cpp:295] Iteration 617 (no loss supplied for SingleUpdateStep)
I1110 22:33:21.140684  2593 solver.cpp:310]     Train net output #0: loss = 0.73332 (* 1 = 0.73332 loss)
I1110 22:33:21.140707  2593 sgd_solver.cpp:106] Iteration 617, lr = 0.001
I1110 22:33:23.434751  2593 solver.cpp:295] Iteration 618 (no loss supplied for SingleUpdateStep)
I1110 22:33:23.434864  2593 solver.cpp:310]     Train net output #0: loss = 0.713969 (* 1 = 0.713969 loss)
I1110 22:33:23.434887  2593 sgd_solver.cpp:106] Iteration 618, lr = 0.001
I1110 22:33:25.697373  2593 solver.cpp:295] Iteration 619 (no loss supplied for SingleUpdateStep)
I1110 22:33:25.697497  2593 solver.cpp:310]     Train net output #0: loss = 0.705539 (* 1 = 0.705539 loss)
I1110 22:33:25.697520  2593 sgd_solver.cpp:106] Iteration 619, lr = 0.001
I1110 22:33:27.965971  2593 solver.cpp:295] Iteration 620 (no loss supplied for SingleUpdateStep)
I1110 22:33:27.966056  2593 solver.cpp:310]     Train net output #0: loss = 0.655611 (* 1 = 0.655611 loss)
I1110 22:33:27.966078  2593 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I1110 22:33:30.186390  2593 solver.cpp:295] Iteration 621 (no loss supplied for SingleUpdateStep)
I1110 22:33:30.186455  2593 solver.cpp:310]     Train net output #0: loss = 0.646479 (* 1 = 0.646479 loss)
I1110 22:33:30.186475  2593 sgd_solver.cpp:106] Iteration 621, lr = 0.001
I1110 22:33:32.257450  2593 solver.cpp:295] Iteration 622 (no loss supplied for SingleUpdateStep)
I1110 22:33:32.257567  2593 solver.cpp:310]     Train net output #0: loss = 0.694463 (* 1 = 0.694463 loss)
I1110 22:33:32.257596  2593 sgd_solver.cpp:106] Iteration 622, lr = 0.001
I1110 22:33:34.553649  2593 solver.cpp:295] Iteration 623 (no loss supplied for SingleUpdateStep)
I1110 22:33:34.553805  2593 solver.cpp:310]     Train net output #0: loss = 0.703789 (* 1 = 0.703789 loss)
I1110 22:33:34.553831  2593 sgd_solver.cpp:106] Iteration 623, lr = 0.001
I1110 22:33:36.842922  2593 solver.cpp:295] Iteration 624 (no loss supplied for SingleUpdateStep)
I1110 22:33:36.843019  2593 solver.cpp:310]     Train net output #0: loss = 0.688596 (* 1 = 0.688596 loss)
I1110 22:33:36.843041  2593 sgd_solver.cpp:106] Iteration 624, lr = 0.001
I1110 22:33:39.148684  2593 solver.cpp:295] Iteration 625 (no loss supplied for SingleUpdateStep)
I1110 22:33:39.148797  2593 solver.cpp:310]     Train net output #0: loss = 0.729812 (* 1 = 0.729812 loss)
I1110 22:33:39.148821  2593 sgd_solver.cpp:106] Iteration 625, lr = 0.001
I1110 22:33:41.551043  2593 solver.cpp:295] Iteration 626 (no loss supplied for SingleUpdateStep)
I1110 22:33:41.551141  2593 solver.cpp:310]     Train net output #0: loss = 0.766852 (* 1 = 0.766852 loss)
I1110 22:33:41.551163  2593 sgd_solver.cpp:106] Iteration 626, lr = 0.001
I1110 22:33:43.889408  2593 solver.cpp:295] Iteration 627 (no loss supplied for SingleUpdateStep)
I1110 22:33:43.889526  2593 solver.cpp:310]     Train net output #0: loss = 0.685675 (* 1 = 0.685675 loss)
I1110 22:33:43.889551  2593 sgd_solver.cpp:106] Iteration 627, lr = 0.001
I1110 22:33:46.320680  2593 solver.cpp:295] Iteration 628 (no loss supplied for SingleUpdateStep)
I1110 22:33:46.320786  2593 solver.cpp:310]     Train net output #0: loss = 0.702495 (* 1 = 0.702495 loss)
I1110 22:33:46.320808  2593 sgd_solver.cpp:106] Iteration 628, lr = 0.001
I1110 22:33:48.584967  2593 solver.cpp:295] Iteration 629 (no loss supplied for SingleUpdateStep)
I1110 22:33:48.585073  2593 solver.cpp:310]     Train net output #0: loss = 0.76793 (* 1 = 0.76793 loss)
I1110 22:33:48.585096  2593 sgd_solver.cpp:106] Iteration 629, lr = 0.001
I1110 22:33:50.854893  2593 solver.cpp:295] Iteration 630 (no loss supplied for SingleUpdateStep)
I1110 22:33:50.855006  2593 solver.cpp:310]     Train net output #0: loss = 0.722459 (* 1 = 0.722459 loss)
I1110 22:33:50.855028  2593 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I1110 22:33:53.473558  2593 solver.cpp:295] Iteration 631 (no loss supplied for SingleUpdateStep)
I1110 22:33:53.473620  2593 solver.cpp:310]     Train net output #0: loss = 0.72078 (* 1 = 0.72078 loss)
I1110 22:33:53.473644  2593 sgd_solver.cpp:106] Iteration 631, lr = 0.001
I1110 22:33:56.104742  2593 solver.cpp:295] Iteration 632 (no loss supplied for SingleUpdateStep)
I1110 22:33:56.104830  2593 solver.cpp:310]     Train net output #0: loss = 0.670631 (* 1 = 0.670631 loss)
I1110 22:33:56.104851  2593 sgd_solver.cpp:106] Iteration 632, lr = 0.001
I1110 22:33:58.982080  2593 solver.cpp:295] Iteration 633 (no loss supplied for SingleUpdateStep)
I1110 22:33:58.982161  2593 solver.cpp:310]     Train net output #0: loss = 0.717533 (* 1 = 0.717533 loss)
I1110 22:33:58.982182  2593 sgd_solver.cpp:106] Iteration 633, lr = 0.001
I1110 22:34:01.599995  2593 solver.cpp:295] Iteration 634 (no loss supplied for SingleUpdateStep)
I1110 22:34:01.600076  2593 solver.cpp:310]     Train net output #0: loss = 0.676926 (* 1 = 0.676926 loss)
I1110 22:34:01.600098  2593 sgd_solver.cpp:106] Iteration 634, lr = 0.001
I1110 22:34:03.819337  2593 solver.cpp:295] Iteration 635 (no loss supplied for SingleUpdateStep)
I1110 22:34:03.819485  2593 solver.cpp:310]     Train net output #0: loss = 0.686992 (* 1 = 0.686992 loss)
I1110 22:34:03.819511  2593 sgd_solver.cpp:106] Iteration 635, lr = 0.001
I1110 22:34:05.857151  2593 solver.cpp:295] Iteration 636 (no loss supplied for SingleUpdateStep)
I1110 22:34:05.857266  2593 solver.cpp:310]     Train net output #0: loss = 0.727683 (* 1 = 0.727683 loss)
I1110 22:34:05.857290  2593 sgd_solver.cpp:106] Iteration 636, lr = 0.001
I1110 22:34:08.131974  2593 solver.cpp:295] Iteration 637 (no loss supplied for SingleUpdateStep)
I1110 22:34:08.132108  2593 solver.cpp:310]     Train net output #0: loss = 0.698542 (* 1 = 0.698542 loss)
I1110 22:34:08.132134  2593 sgd_solver.cpp:106] Iteration 637, lr = 0.001
I1110 22:34:10.273084  2593 solver.cpp:295] Iteration 638 (no loss supplied for SingleUpdateStep)
I1110 22:34:10.273135  2593 solver.cpp:310]     Train net output #0: loss = 0.717937 (* 1 = 0.717937 loss)
I1110 22:34:10.273154  2593 sgd_solver.cpp:106] Iteration 638, lr = 0.001
I1110 22:34:12.497454  2593 solver.cpp:295] Iteration 639 (no loss supplied for SingleUpdateStep)
I1110 22:34:12.497510  2593 solver.cpp:310]     Train net output #0: loss = 0.67786 (* 1 = 0.67786 loss)
I1110 22:34:12.497530  2593 sgd_solver.cpp:106] Iteration 639, lr = 0.001
I1110 22:34:14.578660  2593 solver.cpp:295] Iteration 640 (no loss supplied for SingleUpdateStep)
I1110 22:34:14.578745  2593 solver.cpp:310]     Train net output #0: loss = 0.705175 (* 1 = 0.705175 loss)
I1110 22:34:14.578765  2593 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I1110 22:34:16.779199  2593 solver.cpp:295] Iteration 641 (no loss supplied for SingleUpdateStep)
I1110 22:34:16.779351  2593 solver.cpp:310]     Train net output #0: loss = 0.676314 (* 1 = 0.676314 loss)
I1110 22:34:16.779377  2593 sgd_solver.cpp:106] Iteration 641, lr = 0.001
I1110 22:34:18.958168  2593 solver.cpp:295] Iteration 642 (no loss supplied for SingleUpdateStep)
I1110 22:34:18.958305  2593 solver.cpp:310]     Train net output #0: loss = 0.64163 (* 1 = 0.64163 loss)
I1110 22:34:18.958331  2593 sgd_solver.cpp:106] Iteration 642, lr = 0.001
I1110 22:34:21.230207  2593 solver.cpp:295] Iteration 643 (no loss supplied for SingleUpdateStep)
I1110 22:34:21.230298  2593 solver.cpp:310]     Train net output #0: loss = 0.653052 (* 1 = 0.653052 loss)
I1110 22:34:21.230320  2593 sgd_solver.cpp:106] Iteration 643, lr = 0.001
I1110 22:34:23.465071  2593 solver.cpp:295] Iteration 644 (no loss supplied for SingleUpdateStep)
I1110 22:34:23.465183  2593 solver.cpp:310]     Train net output #0: loss = 0.676164 (* 1 = 0.676164 loss)
I1110 22:34:23.465204  2593 sgd_solver.cpp:106] Iteration 644, lr = 0.001
I1110 22:34:25.912236  2593 solver.cpp:295] Iteration 645 (no loss supplied for SingleUpdateStep)
I1110 22:34:25.912374  2593 solver.cpp:310]     Train net output #0: loss = 0.715365 (* 1 = 0.715365 loss)
I1110 22:34:25.912402  2593 sgd_solver.cpp:106] Iteration 645, lr = 0.001
I1110 22:34:28.104200  2593 solver.cpp:295] Iteration 646 (no loss supplied for SingleUpdateStep)
I1110 22:34:28.104269  2593 solver.cpp:310]     Train net output #0: loss = 0.683568 (* 1 = 0.683568 loss)
I1110 22:34:28.104290  2593 sgd_solver.cpp:106] Iteration 646, lr = 0.001
I1110 22:34:30.398905  2593 solver.cpp:295] Iteration 647 (no loss supplied for SingleUpdateStep)
I1110 22:34:30.399055  2593 solver.cpp:310]     Train net output #0: loss = 0.700151 (* 1 = 0.700151 loss)
I1110 22:34:30.399080  2593 sgd_solver.cpp:106] Iteration 647, lr = 0.001
I1110 22:34:32.797859  2593 solver.cpp:295] Iteration 648 (no loss supplied for SingleUpdateStep)
I1110 22:34:32.797969  2593 solver.cpp:310]     Train net output #0: loss = 0.663629 (* 1 = 0.663629 loss)
I1110 22:34:32.797996  2593 sgd_solver.cpp:106] Iteration 648, lr = 0.001
I1110 22:34:35.185006  2593 solver.cpp:295] Iteration 649 (no loss supplied for SingleUpdateStep)
I1110 22:34:35.185101  2593 solver.cpp:310]     Train net output #0: loss = 0.673654 (* 1 = 0.673654 loss)
I1110 22:34:35.185123  2593 sgd_solver.cpp:106] Iteration 649, lr = 0.001
I1110 22:34:38.126034  2593 solver.cpp:295] Iteration 650 (no loss supplied for SingleUpdateStep)
I1110 22:34:38.126132  2593 solver.cpp:310]     Train net output #0: loss = 0.665439 (* 1 = 0.665439 loss)
I1110 22:34:38.126158  2593 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I1110 22:34:40.781184  2593 solver.cpp:295] Iteration 651 (no loss supplied for SingleUpdateStep)
I1110 22:34:40.781239  2593 solver.cpp:310]     Train net output #0: loss = 0.705476 (* 1 = 0.705476 loss)
I1110 22:34:40.781257  2593 sgd_solver.cpp:106] Iteration 651, lr = 0.001
I1110 22:34:43.791528  2593 solver.cpp:295] Iteration 652 (no loss supplied for SingleUpdateStep)
I1110 22:34:43.791693  2593 solver.cpp:310]     Train net output #0: loss = 0.664896 (* 1 = 0.664896 loss)
I1110 22:34:43.791721  2593 sgd_solver.cpp:106] Iteration 652, lr = 0.001
I1110 22:34:46.886703  2593 solver.cpp:295] Iteration 653 (no loss supplied for SingleUpdateStep)
I1110 22:34:46.886809  2593 solver.cpp:310]     Train net output #0: loss = 0.600908 (* 1 = 0.600908 loss)
I1110 22:34:46.886837  2593 sgd_solver.cpp:106] Iteration 653, lr = 0.001
I1110 22:34:49.147828  2593 solver.cpp:295] Iteration 654 (no loss supplied for SingleUpdateStep)
I1110 22:34:49.147907  2593 solver.cpp:310]     Train net output #0: loss = 0.716904 (* 1 = 0.716904 loss)
I1110 22:34:49.147927  2593 sgd_solver.cpp:106] Iteration 654, lr = 0.001
I1110 22:34:51.426718  2593 solver.cpp:295] Iteration 655 (no loss supplied for SingleUpdateStep)
I1110 22:34:51.426805  2593 solver.cpp:310]     Train net output #0: loss = 0.714486 (* 1 = 0.714486 loss)
I1110 22:34:51.426827  2593 sgd_solver.cpp:106] Iteration 655, lr = 0.001
I1110 22:34:53.955622  2593 solver.cpp:295] Iteration 656 (no loss supplied for SingleUpdateStep)
I1110 22:34:53.955709  2593 solver.cpp:310]     Train net output #0: loss = 0.664027 (* 1 = 0.664027 loss)
I1110 22:34:53.955732  2593 sgd_solver.cpp:106] Iteration 656, lr = 0.001
I1110 22:34:56.429847  2593 solver.cpp:295] Iteration 657 (no loss supplied for SingleUpdateStep)
I1110 22:34:56.429944  2593 solver.cpp:310]     Train net output #0: loss = 0.713923 (* 1 = 0.713923 loss)
I1110 22:34:56.429965  2593 sgd_solver.cpp:106] Iteration 657, lr = 0.001
I1110 22:34:59.112130  2593 solver.cpp:295] Iteration 658 (no loss supplied for SingleUpdateStep)
I1110 22:34:59.112234  2593 solver.cpp:310]     Train net output #0: loss = 0.679426 (* 1 = 0.679426 loss)
I1110 22:34:59.112257  2593 sgd_solver.cpp:106] Iteration 658, lr = 0.001
I1110 22:35:01.456864  2593 solver.cpp:295] Iteration 659 (no loss supplied for SingleUpdateStep)
I1110 22:35:01.457062  2593 solver.cpp:310]     Train net output #0: loss = 0.673263 (* 1 = 0.673263 loss)
I1110 22:35:01.457092  2593 sgd_solver.cpp:106] Iteration 659, lr = 0.001
I1110 22:35:03.880599  2593 solver.cpp:295] Iteration 660 (no loss supplied for SingleUpdateStep)
I1110 22:35:03.880712  2593 solver.cpp:310]     Train net output #0: loss = 0.646148 (* 1 = 0.646148 loss)
I1110 22:35:03.880733  2593 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I1110 22:35:06.244060  2593 solver.cpp:295] Iteration 661 (no loss supplied for SingleUpdateStep)
I1110 22:35:06.244149  2593 solver.cpp:310]     Train net output #0: loss = 0.656507 (* 1 = 0.656507 loss)
I1110 22:35:06.244169  2593 sgd_solver.cpp:106] Iteration 661, lr = 0.001
I1110 22:35:08.867184  2593 solver.cpp:295] Iteration 662 (no loss supplied for SingleUpdateStep)
I1110 22:35:08.867288  2593 solver.cpp:310]     Train net output #0: loss = 0.658691 (* 1 = 0.658691 loss)
I1110 22:35:08.867312  2593 sgd_solver.cpp:106] Iteration 662, lr = 0.001
I1110 22:35:11.495772  2593 solver.cpp:295] Iteration 663 (no loss supplied for SingleUpdateStep)
I1110 22:35:11.495821  2593 solver.cpp:310]     Train net output #0: loss = 0.70319 (* 1 = 0.70319 loss)
I1110 22:35:11.495839  2593 sgd_solver.cpp:106] Iteration 663, lr = 0.001
I1110 22:35:14.092329  2593 solver.cpp:295] Iteration 664 (no loss supplied for SingleUpdateStep)
I1110 22:35:14.092423  2593 solver.cpp:310]     Train net output #0: loss = 0.724265 (* 1 = 0.724265 loss)
I1110 22:35:14.092445  2593 sgd_solver.cpp:106] Iteration 664, lr = 0.001
I1110 22:35:16.576547  2593 solver.cpp:295] Iteration 665 (no loss supplied for SingleUpdateStep)
I1110 22:35:16.576606  2593 solver.cpp:310]     Train net output #0: loss = 0.671462 (* 1 = 0.671462 loss)
I1110 22:35:16.576624  2593 sgd_solver.cpp:106] Iteration 665, lr = 0.001
I1110 22:35:19.059773  2593 solver.cpp:295] Iteration 666 (no loss supplied for SingleUpdateStep)
I1110 22:35:19.059881  2593 solver.cpp:310]     Train net output #0: loss = 0.674343 (* 1 = 0.674343 loss)
I1110 22:35:19.059903  2593 sgd_solver.cpp:106] Iteration 666, lr = 0.001
I1110 22:35:21.560564  2593 solver.cpp:295] Iteration 667 (no loss supplied for SingleUpdateStep)
I1110 22:35:21.560684  2593 solver.cpp:310]     Train net output #0: loss = 0.672121 (* 1 = 0.672121 loss)
I1110 22:35:21.560706  2593 sgd_solver.cpp:106] Iteration 667, lr = 0.001
I1110 22:35:23.967586  2593 solver.cpp:295] Iteration 668 (no loss supplied for SingleUpdateStep)
I1110 22:35:23.967643  2593 solver.cpp:310]     Train net output #0: loss = 0.643078 (* 1 = 0.643078 loss)
I1110 22:35:23.967661  2593 sgd_solver.cpp:106] Iteration 668, lr = 0.001
I1110 22:35:26.089184  2593 solver.cpp:295] Iteration 669 (no loss supplied for SingleUpdateStep)
I1110 22:35:26.089283  2593 solver.cpp:310]     Train net output #0: loss = 0.713989 (* 1 = 0.713989 loss)
I1110 22:35:26.089306  2593 sgd_solver.cpp:106] Iteration 669, lr = 0.001
I1110 22:35:28.388819  2593 solver.cpp:295] Iteration 670 (no loss supplied for SingleUpdateStep)
I1110 22:35:28.388908  2593 solver.cpp:310]     Train net output #0: loss = 0.698434 (* 1 = 0.698434 loss)
I1110 22:35:28.388929  2593 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I1110 22:35:30.780215  2593 solver.cpp:295] Iteration 671 (no loss supplied for SingleUpdateStep)
I1110 22:35:30.780309  2593 solver.cpp:310]     Train net output #0: loss = 0.606931 (* 1 = 0.606931 loss)
I1110 22:35:30.780331  2593 sgd_solver.cpp:106] Iteration 671, lr = 0.001
I1110 22:35:32.983712  2593 solver.cpp:295] Iteration 672 (no loss supplied for SingleUpdateStep)
I1110 22:35:32.983815  2593 solver.cpp:310]     Train net output #0: loss = 0.702964 (* 1 = 0.702964 loss)
I1110 22:35:32.983836  2593 sgd_solver.cpp:106] Iteration 672, lr = 0.001
I1110 22:35:35.301031  2593 solver.cpp:295] Iteration 673 (no loss supplied for SingleUpdateStep)
I1110 22:35:35.301136  2593 solver.cpp:310]     Train net output #0: loss = 0.635581 (* 1 = 0.635581 loss)
I1110 22:35:35.301158  2593 sgd_solver.cpp:106] Iteration 673, lr = 0.001
I1110 22:35:37.386322  2593 solver.cpp:295] Iteration 674 (no loss supplied for SingleUpdateStep)
I1110 22:35:37.386414  2593 solver.cpp:310]     Train net output #0: loss = 0.718595 (* 1 = 0.718595 loss)
I1110 22:35:37.386435  2593 sgd_solver.cpp:106] Iteration 674, lr = 0.001
I1110 22:35:39.599208  2593 solver.cpp:295] Iteration 675 (no loss supplied for SingleUpdateStep)
I1110 22:35:39.599326  2593 solver.cpp:310]     Train net output #0: loss = 0.640422 (* 1 = 0.640422 loss)
I1110 22:35:39.599359  2593 sgd_solver.cpp:106] Iteration 675, lr = 0.001
I1110 22:35:41.713346  2593 solver.cpp:295] Iteration 676 (no loss supplied for SingleUpdateStep)
I1110 22:35:41.713480  2593 solver.cpp:310]     Train net output #0: loss = 0.64296 (* 1 = 0.64296 loss)
I1110 22:35:41.713505  2593 sgd_solver.cpp:106] Iteration 676, lr = 0.001
I1110 22:35:44.007696  2593 solver.cpp:295] Iteration 677 (no loss supplied for SingleUpdateStep)
I1110 22:35:44.007814  2593 solver.cpp:310]     Train net output #0: loss = 0.712943 (* 1 = 0.712943 loss)
I1110 22:35:44.007836  2593 sgd_solver.cpp:106] Iteration 677, lr = 0.001
I1110 22:35:46.168408  2593 solver.cpp:295] Iteration 678 (no loss supplied for SingleUpdateStep)
I1110 22:35:46.168525  2593 solver.cpp:310]     Train net output #0: loss = 0.621782 (* 1 = 0.621782 loss)
I1110 22:35:46.168547  2593 sgd_solver.cpp:106] Iteration 678, lr = 0.001
I1110 22:35:48.308264  2593 solver.cpp:295] Iteration 679 (no loss supplied for SingleUpdateStep)
I1110 22:35:48.308352  2593 solver.cpp:310]     Train net output #0: loss = 0.702226 (* 1 = 0.702226 loss)
I1110 22:35:48.308374  2593 sgd_solver.cpp:106] Iteration 679, lr = 0.001
I1110 22:35:50.393833  2593 solver.cpp:295] Iteration 680 (no loss supplied for SingleUpdateStep)
I1110 22:35:50.393955  2593 solver.cpp:310]     Train net output #0: loss = 0.671526 (* 1 = 0.671526 loss)
I1110 22:35:50.393977  2593 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I1110 22:35:52.663099  2593 solver.cpp:295] Iteration 681 (no loss supplied for SingleUpdateStep)
I1110 22:35:52.663221  2593 solver.cpp:310]     Train net output #0: loss = 0.650324 (* 1 = 0.650324 loss)
I1110 22:35:52.663246  2593 sgd_solver.cpp:106] Iteration 681, lr = 0.001
I1110 22:35:54.965775  2593 solver.cpp:295] Iteration 682 (no loss supplied for SingleUpdateStep)
I1110 22:35:54.965883  2593 solver.cpp:310]     Train net output #0: loss = 0.674829 (* 1 = 0.674829 loss)
I1110 22:35:54.965906  2593 sgd_solver.cpp:106] Iteration 682, lr = 0.001
I1110 22:35:57.173225  2593 solver.cpp:295] Iteration 683 (no loss supplied for SingleUpdateStep)
I1110 22:35:57.173333  2593 solver.cpp:310]     Train net output #0: loss = 0.638164 (* 1 = 0.638164 loss)
I1110 22:35:57.173358  2593 sgd_solver.cpp:106] Iteration 683, lr = 0.001
I1110 22:35:59.513629  2593 solver.cpp:295] Iteration 684 (no loss supplied for SingleUpdateStep)
I1110 22:35:59.513772  2593 solver.cpp:310]     Train net output #0: loss = 0.680904 (* 1 = 0.680904 loss)
I1110 22:35:59.513798  2593 sgd_solver.cpp:106] Iteration 684, lr = 0.001
I1110 22:36:01.614132  2593 solver.cpp:295] Iteration 685 (no loss supplied for SingleUpdateStep)
I1110 22:36:01.614228  2593 solver.cpp:310]     Train net output #0: loss = 0.649532 (* 1 = 0.649532 loss)
I1110 22:36:01.614251  2593 sgd_solver.cpp:106] Iteration 685, lr = 0.001
I1110 22:36:03.805018  2593 solver.cpp:295] Iteration 686 (no loss supplied for SingleUpdateStep)
I1110 22:36:03.805130  2593 solver.cpp:310]     Train net output #0: loss = 0.698596 (* 1 = 0.698596 loss)
I1110 22:36:03.805155  2593 sgd_solver.cpp:106] Iteration 686, lr = 0.001
I1110 22:36:05.956825  2593 solver.cpp:295] Iteration 687 (no loss supplied for SingleUpdateStep)
I1110 22:36:05.956923  2593 solver.cpp:310]     Train net output #0: loss = 0.684145 (* 1 = 0.684145 loss)
I1110 22:36:05.956944  2593 sgd_solver.cpp:106] Iteration 687, lr = 0.001
I1110 22:36:08.111186  2593 solver.cpp:295] Iteration 688 (no loss supplied for SingleUpdateStep)
I1110 22:36:08.111254  2593 solver.cpp:310]     Train net output #0: loss = 0.661435 (* 1 = 0.661435 loss)
I1110 22:36:08.111275  2593 sgd_solver.cpp:106] Iteration 688, lr = 0.001
I1110 22:36:10.410790  2593 solver.cpp:295] Iteration 689 (no loss supplied for SingleUpdateStep)
I1110 22:36:10.410915  2593 solver.cpp:310]     Train net output #0: loss = 0.682612 (* 1 = 0.682612 loss)
I1110 22:36:10.410938  2593 sgd_solver.cpp:106] Iteration 689, lr = 0.001
I1110 22:36:12.600296  2593 solver.cpp:295] Iteration 690 (no loss supplied for SingleUpdateStep)
I1110 22:36:12.600388  2593 solver.cpp:310]     Train net output #0: loss = 0.674778 (* 1 = 0.674778 loss)
I1110 22:36:12.600407  2593 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I1110 22:36:15.414454  2593 solver.cpp:295] Iteration 691 (no loss supplied for SingleUpdateStep)
I1110 22:36:15.414543  2593 solver.cpp:310]     Train net output #0: loss = 0.632522 (* 1 = 0.632522 loss)
I1110 22:36:15.414564  2593 sgd_solver.cpp:106] Iteration 691, lr = 0.001
I1110 22:36:18.257850  2593 solver.cpp:295] Iteration 692 (no loss supplied for SingleUpdateStep)
I1110 22:36:18.257921  2593 solver.cpp:310]     Train net output #0: loss = 0.665195 (* 1 = 0.665195 loss)
I1110 22:36:18.257942  2593 sgd_solver.cpp:106] Iteration 692, lr = 0.001
I1110 22:36:21.016808  2593 solver.cpp:295] Iteration 693 (no loss supplied for SingleUpdateStep)
I1110 22:36:21.016881  2593 solver.cpp:310]     Train net output #0: loss = 0.636036 (* 1 = 0.636036 loss)
I1110 22:36:21.016902  2593 sgd_solver.cpp:106] Iteration 693, lr = 0.001
I1110 22:36:23.501232  2593 solver.cpp:295] Iteration 694 (no loss supplied for SingleUpdateStep)
I1110 22:36:23.501307  2593 solver.cpp:310]     Train net output #0: loss = 0.605716 (* 1 = 0.605716 loss)
I1110 22:36:23.501327  2593 sgd_solver.cpp:106] Iteration 694, lr = 0.001
I1110 22:36:25.815389  2593 solver.cpp:295] Iteration 695 (no loss supplied for SingleUpdateStep)
I1110 22:36:25.815485  2593 solver.cpp:310]     Train net output #0: loss = 0.696008 (* 1 = 0.696008 loss)
I1110 22:36:25.815505  2593 sgd_solver.cpp:106] Iteration 695, lr = 0.001
I1110 22:36:28.224035  2593 solver.cpp:295] Iteration 696 (no loss supplied for SingleUpdateStep)
I1110 22:36:28.224177  2593 solver.cpp:310]     Train net output #0: loss = 0.666029 (* 1 = 0.666029 loss)
I1110 22:36:28.224201  2593 sgd_solver.cpp:106] Iteration 696, lr = 0.001
I1110 22:36:30.412919  2593 solver.cpp:295] Iteration 697 (no loss supplied for SingleUpdateStep)
I1110 22:36:30.413019  2593 solver.cpp:310]     Train net output #0: loss = 0.651265 (* 1 = 0.651265 loss)
I1110 22:36:30.413041  2593 sgd_solver.cpp:106] Iteration 697, lr = 0.001
I1110 22:36:32.717589  2593 solver.cpp:295] Iteration 698 (no loss supplied for SingleUpdateStep)
I1110 22:36:32.717667  2593 solver.cpp:310]     Train net output #0: loss = 0.676252 (* 1 = 0.676252 loss)
I1110 22:36:32.717689  2593 sgd_solver.cpp:106] Iteration 698, lr = 0.001
I1110 22:36:34.951287  2593 solver.cpp:295] Iteration 699 (no loss supplied for SingleUpdateStep)
I1110 22:36:34.951407  2593 solver.cpp:310]     Train net output #0: loss = 0.602391 (* 1 = 0.602391 loss)
I1110 22:36:34.951431  2593 sgd_solver.cpp:106] Iteration 699, lr = 0.001
I1110 22:36:37.165599  2593 solver.cpp:295] Iteration 700 (no loss supplied for SingleUpdateStep)
I1110 22:36:37.165735  2593 solver.cpp:310]     Train net output #0: loss = 0.684718 (* 1 = 0.684718 loss)
I1110 22:36:37.165761  2593 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I1110 22:36:39.287499  2593 solver.cpp:295] Iteration 701 (no loss supplied for SingleUpdateStep)
I1110 22:36:39.287597  2593 solver.cpp:310]     Train net output #0: loss = 0.654762 (* 1 = 0.654762 loss)
I1110 22:36:39.287621  2593 sgd_solver.cpp:106] Iteration 701, lr = 0.001
I1110 22:36:41.552700  2593 solver.cpp:295] Iteration 702 (no loss supplied for SingleUpdateStep)
I1110 22:36:41.552780  2593 solver.cpp:310]     Train net output #0: loss = 0.685647 (* 1 = 0.685647 loss)
I1110 22:36:41.552800  2593 sgd_solver.cpp:106] Iteration 702, lr = 0.001
I1110 22:36:43.761759  2593 solver.cpp:295] Iteration 703 (no loss supplied for SingleUpdateStep)
I1110 22:36:43.761864  2593 solver.cpp:310]     Train net output #0: loss = 0.594646 (* 1 = 0.594646 loss)
I1110 22:36:43.761888  2593 sgd_solver.cpp:106] Iteration 703, lr = 0.001
I1110 22:36:45.950789  2593 solver.cpp:295] Iteration 704 (no loss supplied for SingleUpdateStep)
I1110 22:36:45.950901  2593 solver.cpp:310]     Train net output #0: loss = 0.654488 (* 1 = 0.654488 loss)
I1110 22:36:45.950922  2593 sgd_solver.cpp:106] Iteration 704, lr = 0.001
I1110 22:36:48.238436  2593 solver.cpp:295] Iteration 705 (no loss supplied for SingleUpdateStep)
I1110 22:36:48.238556  2593 solver.cpp:310]     Train net output #0: loss = 0.651634 (* 1 = 0.651634 loss)
I1110 22:36:48.238580  2593 sgd_solver.cpp:106] Iteration 705, lr = 0.001
I1110 22:36:50.718972  2593 solver.cpp:295] Iteration 706 (no loss supplied for SingleUpdateStep)
I1110 22:36:50.719106  2593 solver.cpp:310]     Train net output #0: loss = 0.696361 (* 1 = 0.696361 loss)
I1110 22:36:50.719132  2593 sgd_solver.cpp:106] Iteration 706, lr = 0.001
I1110 22:36:53.198367  2593 solver.cpp:295] Iteration 707 (no loss supplied for SingleUpdateStep)
I1110 22:36:53.198468  2593 solver.cpp:310]     Train net output #0: loss = 0.624454 (* 1 = 0.624454 loss)
I1110 22:36:53.198490  2593 sgd_solver.cpp:106] Iteration 707, lr = 0.001
I1110 22:36:56.013659  2593 solver.cpp:295] Iteration 708 (no loss supplied for SingleUpdateStep)
I1110 22:36:56.013736  2593 solver.cpp:310]     Train net output #0: loss = 0.640225 (* 1 = 0.640225 loss)
I1110 22:36:56.013757  2593 sgd_solver.cpp:106] Iteration 708, lr = 0.001
I1110 22:36:58.853620  2593 solver.cpp:295] Iteration 709 (no loss supplied for SingleUpdateStep)
I1110 22:36:58.853775  2593 solver.cpp:310]     Train net output #0: loss = 0.676648 (* 1 = 0.676648 loss)
I1110 22:36:58.853799  2593 sgd_solver.cpp:106] Iteration 709, lr = 0.001
I1110 22:37:01.179684  2593 solver.cpp:295] Iteration 710 (no loss supplied for SingleUpdateStep)
I1110 22:37:01.179757  2593 solver.cpp:310]     Train net output #0: loss = 0.632943 (* 1 = 0.632943 loss)
I1110 22:37:01.179776  2593 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I1110 22:37:03.524230  2593 solver.cpp:295] Iteration 711 (no loss supplied for SingleUpdateStep)
I1110 22:37:03.524322  2593 solver.cpp:310]     Train net output #0: loss = 0.70569 (* 1 = 0.70569 loss)
I1110 22:37:03.524343  2593 sgd_solver.cpp:106] Iteration 711, lr = 0.001
I1110 22:37:05.803158  2593 solver.cpp:295] Iteration 712 (no loss supplied for SingleUpdateStep)
I1110 22:37:05.803267  2593 solver.cpp:310]     Train net output #0: loss = 0.638341 (* 1 = 0.638341 loss)
I1110 22:37:05.803287  2593 sgd_solver.cpp:106] Iteration 712, lr = 0.001
I1110 22:37:08.100093  2593 solver.cpp:295] Iteration 713 (no loss supplied for SingleUpdateStep)
I1110 22:37:08.100241  2593 solver.cpp:310]     Train net output #0: loss = 0.610172 (* 1 = 0.610172 loss)
I1110 22:37:08.100267  2593 sgd_solver.cpp:106] Iteration 713, lr = 0.001
I1110 22:37:10.405406  2593 solver.cpp:295] Iteration 714 (no loss supplied for SingleUpdateStep)
I1110 22:37:10.405460  2593 solver.cpp:310]     Train net output #0: loss = 0.577614 (* 1 = 0.577614 loss)
I1110 22:37:10.405478  2593 sgd_solver.cpp:106] Iteration 714, lr = 0.001
I1110 22:37:12.652554  2593 solver.cpp:295] Iteration 715 (no loss supplied for SingleUpdateStep)
I1110 22:37:12.652653  2593 solver.cpp:310]     Train net output #0: loss = 0.660915 (* 1 = 0.660915 loss)
I1110 22:37:12.652674  2593 sgd_solver.cpp:106] Iteration 715, lr = 0.001
I1110 22:37:14.992034  2593 solver.cpp:295] Iteration 716 (no loss supplied for SingleUpdateStep)
I1110 22:37:14.992136  2593 solver.cpp:310]     Train net output #0: loss = 0.678114 (* 1 = 0.678114 loss)
I1110 22:37:14.992157  2593 sgd_solver.cpp:106] Iteration 716, lr = 0.001
I1110 22:37:17.255107  2593 solver.cpp:295] Iteration 717 (no loss supplied for SingleUpdateStep)
I1110 22:37:17.255215  2593 solver.cpp:310]     Train net output #0: loss = 0.61148 (* 1 = 0.61148 loss)
I1110 22:37:17.255242  2593 sgd_solver.cpp:106] Iteration 717, lr = 0.001
I1110 22:37:19.464773  2593 solver.cpp:295] Iteration 718 (no loss supplied for SingleUpdateStep)
I1110 22:37:19.464890  2593 solver.cpp:310]     Train net output #0: loss = 0.637399 (* 1 = 0.637399 loss)
I1110 22:37:19.464911  2593 sgd_solver.cpp:106] Iteration 718, lr = 0.001
I1110 22:37:21.793020  2593 solver.cpp:295] Iteration 719 (no loss supplied for SingleUpdateStep)
I1110 22:37:21.793128  2593 solver.cpp:310]     Train net output #0: loss = 0.702819 (* 1 = 0.702819 loss)
I1110 22:37:21.793149  2593 sgd_solver.cpp:106] Iteration 719, lr = 0.001
I1110 22:37:24.056099  2593 solver.cpp:295] Iteration 720 (no loss supplied for SingleUpdateStep)
I1110 22:37:24.056205  2593 solver.cpp:310]     Train net output #0: loss = 0.650992 (* 1 = 0.650992 loss)
I1110 22:37:24.056228  2593 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I1110 22:37:26.332728  2593 solver.cpp:295] Iteration 721 (no loss supplied for SingleUpdateStep)
I1110 22:37:26.332792  2593 solver.cpp:310]     Train net output #0: loss = 0.688082 (* 1 = 0.688082 loss)
I1110 22:37:26.332811  2593 sgd_solver.cpp:106] Iteration 721, lr = 0.001
I1110 22:37:28.488495  2593 solver.cpp:295] Iteration 722 (no loss supplied for SingleUpdateStep)
I1110 22:37:28.488633  2593 solver.cpp:310]     Train net output #0: loss = 0.672421 (* 1 = 0.672421 loss)
I1110 22:37:28.488657  2593 sgd_solver.cpp:106] Iteration 722, lr = 0.001
I1110 22:37:30.852464  2593 solver.cpp:295] Iteration 723 (no loss supplied for SingleUpdateStep)
I1110 22:37:30.852525  2593 solver.cpp:310]     Train net output #0: loss = 0.708604 (* 1 = 0.708604 loss)
I1110 22:37:30.852545  2593 sgd_solver.cpp:106] Iteration 723, lr = 0.001
I1110 22:37:33.033372  2593 solver.cpp:295] Iteration 724 (no loss supplied for SingleUpdateStep)
I1110 22:37:33.033479  2593 solver.cpp:310]     Train net output #0: loss = 0.650137 (* 1 = 0.650137 loss)
I1110 22:37:33.033500  2593 sgd_solver.cpp:106] Iteration 724, lr = 0.001
I1110 22:37:35.409881  2593 solver.cpp:295] Iteration 725 (no loss supplied for SingleUpdateStep)
I1110 22:37:35.409991  2593 solver.cpp:310]     Train net output #0: loss = 0.616384 (* 1 = 0.616384 loss)
I1110 22:37:35.410012  2593 sgd_solver.cpp:106] Iteration 725, lr = 0.001
I1110 22:37:38.004127  2593 solver.cpp:295] Iteration 726 (no loss supplied for SingleUpdateStep)
I1110 22:37:38.004190  2593 solver.cpp:310]     Train net output #0: loss = 0.65421 (* 1 = 0.65421 loss)
I1110 22:37:38.004211  2593 sgd_solver.cpp:106] Iteration 726, lr = 0.001
I1110 22:37:40.465875  2593 solver.cpp:295] Iteration 727 (no loss supplied for SingleUpdateStep)
I1110 22:37:40.465957  2593 solver.cpp:310]     Train net output #0: loss = 0.676171 (* 1 = 0.676171 loss)
I1110 22:37:40.465976  2593 sgd_solver.cpp:106] Iteration 727, lr = 0.001
I1110 22:37:42.769665  2593 solver.cpp:295] Iteration 728 (no loss supplied for SingleUpdateStep)
I1110 22:37:42.769734  2593 solver.cpp:310]     Train net output #0: loss = 0.61643 (* 1 = 0.61643 loss)
I1110 22:37:42.769757  2593 sgd_solver.cpp:106] Iteration 728, lr = 0.001
I1110 22:37:45.116299  2593 solver.cpp:295] Iteration 729 (no loss supplied for SingleUpdateStep)
I1110 22:37:45.116410  2593 solver.cpp:310]     Train net output #0: loss = 0.665347 (* 1 = 0.665347 loss)
I1110 22:37:45.116431  2593 sgd_solver.cpp:106] Iteration 729, lr = 0.001
I1110 22:37:47.798923  2593 solver.cpp:295] Iteration 730 (no loss supplied for SingleUpdateStep)
I1110 22:37:47.798981  2593 solver.cpp:310]     Train net output #0: loss = 0.629945 (* 1 = 0.629945 loss)
I1110 22:37:47.799000  2593 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I1110 22:37:50.513247  2593 solver.cpp:295] Iteration 731 (no loss supplied for SingleUpdateStep)
I1110 22:37:50.513403  2593 solver.cpp:310]     Train net output #0: loss = 0.631345 (* 1 = 0.631345 loss)
I1110 22:37:50.513437  2593 sgd_solver.cpp:106] Iteration 731, lr = 0.001
I1110 22:37:53.046041  2593 solver.cpp:295] Iteration 732 (no loss supplied for SingleUpdateStep)
I1110 22:37:53.046152  2593 solver.cpp:310]     Train net output #0: loss = 0.668871 (* 1 = 0.668871 loss)
I1110 22:37:53.046180  2593 sgd_solver.cpp:106] Iteration 732, lr = 0.001
I1110 22:37:55.399718  2593 solver.cpp:295] Iteration 733 (no loss supplied for SingleUpdateStep)
I1110 22:37:55.399868  2593 solver.cpp:310]     Train net output #0: loss = 0.635949 (* 1 = 0.635949 loss)
I1110 22:37:55.399898  2593 sgd_solver.cpp:106] Iteration 733, lr = 0.001
I1110 22:37:57.992130  2593 solver.cpp:295] Iteration 734 (no loss supplied for SingleUpdateStep)
I1110 22:37:57.992226  2593 solver.cpp:310]     Train net output #0: loss = 0.671539 (* 1 = 0.671539 loss)
I1110 22:37:57.992249  2593 sgd_solver.cpp:106] Iteration 734, lr = 0.001
I1110 22:38:00.323792  2593 solver.cpp:295] Iteration 735 (no loss supplied for SingleUpdateStep)
I1110 22:38:00.323904  2593 solver.cpp:310]     Train net output #0: loss = 0.689701 (* 1 = 0.689701 loss)
I1110 22:38:00.323925  2593 sgd_solver.cpp:106] Iteration 735, lr = 0.001
I1110 22:38:02.614961  2593 solver.cpp:295] Iteration 736 (no loss supplied for SingleUpdateStep)
I1110 22:38:02.615075  2593 solver.cpp:310]     Train net output #0: loss = 0.663041 (* 1 = 0.663041 loss)
I1110 22:38:02.615102  2593 sgd_solver.cpp:106] Iteration 736, lr = 0.001
I1110 22:38:05.208303  2593 solver.cpp:295] Iteration 737 (no loss supplied for SingleUpdateStep)
I1110 22:38:05.208446  2593 solver.cpp:310]     Train net output #0: loss = 0.637011 (* 1 = 0.637011 loss)
I1110 22:38:05.208472  2593 sgd_solver.cpp:106] Iteration 737, lr = 0.001
I1110 22:38:07.698302  2593 solver.cpp:295] Iteration 738 (no loss supplied for SingleUpdateStep)
I1110 22:38:07.698410  2593 solver.cpp:310]     Train net output #0: loss = 0.592249 (* 1 = 0.592249 loss)
I1110 22:38:07.698432  2593 sgd_solver.cpp:106] Iteration 738, lr = 0.001
I1110 22:38:10.321709  2593 solver.cpp:295] Iteration 739 (no loss supplied for SingleUpdateStep)
I1110 22:38:10.321813  2593 solver.cpp:310]     Train net output #0: loss = 0.647273 (* 1 = 0.647273 loss)
I1110 22:38:10.321835  2593 sgd_solver.cpp:106] Iteration 739, lr = 0.001
I1110 22:38:13.018590  2593 solver.cpp:295] Iteration 740 (no loss supplied for SingleUpdateStep)
I1110 22:38:13.018687  2593 solver.cpp:310]     Train net output #0: loss = 0.660492 (* 1 = 0.660492 loss)
I1110 22:38:13.018709  2593 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I1110 22:38:15.501605  2593 solver.cpp:295] Iteration 741 (no loss supplied for SingleUpdateStep)
I1110 22:38:15.501729  2593 solver.cpp:310]     Train net output #0: loss = 0.639587 (* 1 = 0.639587 loss)
I1110 22:38:15.501752  2593 sgd_solver.cpp:106] Iteration 741, lr = 0.001
I1110 22:38:17.820487  2593 solver.cpp:295] Iteration 742 (no loss supplied for SingleUpdateStep)
I1110 22:38:17.820588  2593 solver.cpp:310]     Train net output #0: loss = 0.607716 (* 1 = 0.607716 loss)
I1110 22:38:17.820610  2593 sgd_solver.cpp:106] Iteration 742, lr = 0.001
I1110 22:38:19.914666  2593 solver.cpp:295] Iteration 743 (no loss supplied for SingleUpdateStep)
I1110 22:38:19.914738  2593 solver.cpp:310]     Train net output #0: loss = 0.666119 (* 1 = 0.666119 loss)
I1110 22:38:19.914757  2593 sgd_solver.cpp:106] Iteration 743, lr = 0.001
I1110 22:38:22.278738  2593 solver.cpp:295] Iteration 744 (no loss supplied for SingleUpdateStep)
I1110 22:38:22.278837  2593 solver.cpp:310]     Train net output #0: loss = 0.652599 (* 1 = 0.652599 loss)
I1110 22:38:22.278859  2593 sgd_solver.cpp:106] Iteration 744, lr = 0.001
I1110 22:38:24.708474  2593 solver.cpp:295] Iteration 745 (no loss supplied for SingleUpdateStep)
I1110 22:38:24.708607  2593 solver.cpp:310]     Train net output #0: loss = 0.676711 (* 1 = 0.676711 loss)
I1110 22:38:24.708631  2593 sgd_solver.cpp:106] Iteration 745, lr = 0.001
I1110 22:38:26.761320  2593 solver.cpp:295] Iteration 746 (no loss supplied for SingleUpdateStep)
I1110 22:38:26.761415  2593 solver.cpp:310]     Train net output #0: loss = 0.569722 (* 1 = 0.569722 loss)
I1110 22:38:26.761435  2593 sgd_solver.cpp:106] Iteration 746, lr = 0.001
I1110 22:38:28.975764  2593 solver.cpp:295] Iteration 747 (no loss supplied for SingleUpdateStep)
I1110 22:38:28.975817  2593 solver.cpp:310]     Train net output #0: loss = 0.653879 (* 1 = 0.653879 loss)
I1110 22:38:28.975836  2593 sgd_solver.cpp:106] Iteration 747, lr = 0.001
I1110 22:38:31.179724  2593 solver.cpp:295] Iteration 748 (no loss supplied for SingleUpdateStep)
I1110 22:38:31.179844  2593 solver.cpp:310]     Train net output #0: loss = 0.616038 (* 1 = 0.616038 loss)
I1110 22:38:31.179870  2593 sgd_solver.cpp:106] Iteration 748, lr = 0.001
I1110 22:38:33.490484  2593 solver.cpp:295] Iteration 749 (no loss supplied for SingleUpdateStep)
I1110 22:38:33.490547  2593 solver.cpp:310]     Train net output #0: loss = 0.678815 (* 1 = 0.678815 loss)
I1110 22:38:33.490567  2593 sgd_solver.cpp:106] Iteration 749, lr = 0.001
I1110 22:38:35.749006  2593 solver.cpp:295] Iteration 750 (no loss supplied for SingleUpdateStep)
I1110 22:38:35.749053  2593 solver.cpp:310]     Train net output #0: loss = 0.681414 (* 1 = 0.681414 loss)
I1110 22:38:35.749070  2593 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I1110 22:38:38.002531  2593 solver.cpp:295] Iteration 751 (no loss supplied for SingleUpdateStep)
I1110 22:38:38.002651  2593 solver.cpp:310]     Train net output #0: loss = 0.652315 (* 1 = 0.652315 loss)
I1110 22:38:38.002674  2593 sgd_solver.cpp:106] Iteration 751, lr = 0.001
I1110 22:38:40.327343  2593 solver.cpp:295] Iteration 752 (no loss supplied for SingleUpdateStep)
I1110 22:38:40.327435  2593 solver.cpp:310]     Train net output #0: loss = 0.605104 (* 1 = 0.605104 loss)
I1110 22:38:40.327455  2593 sgd_solver.cpp:106] Iteration 752, lr = 0.001
I1110 22:38:42.637449  2593 solver.cpp:295] Iteration 753 (no loss supplied for SingleUpdateStep)
I1110 22:38:42.637555  2593 solver.cpp:310]     Train net output #0: loss = 0.621445 (* 1 = 0.621445 loss)
I1110 22:38:42.637578  2593 sgd_solver.cpp:106] Iteration 753, lr = 0.001
I1110 22:38:44.859649  2593 solver.cpp:295] Iteration 754 (no loss supplied for SingleUpdateStep)
I1110 22:38:44.859745  2593 solver.cpp:310]     Train net output #0: loss = 0.62062 (* 1 = 0.62062 loss)
I1110 22:38:44.859767  2593 sgd_solver.cpp:106] Iteration 754, lr = 0.001
I1110 22:38:47.504518  2593 solver.cpp:295] Iteration 755 (no loss supplied for SingleUpdateStep)
I1110 22:38:47.504652  2593 solver.cpp:310]     Train net output #0: loss = 0.653942 (* 1 = 0.653942 loss)
I1110 22:38:47.504676  2593 sgd_solver.cpp:106] Iteration 755, lr = 0.001
I1110 22:38:49.711136  2593 solver.cpp:295] Iteration 756 (no loss supplied for SingleUpdateStep)
I1110 22:38:49.711266  2593 solver.cpp:310]     Train net output #0: loss = 0.644106 (* 1 = 0.644106 loss)
I1110 22:38:49.711290  2593 sgd_solver.cpp:106] Iteration 756, lr = 0.001
I1110 22:38:52.029424  2593 solver.cpp:295] Iteration 757 (no loss supplied for SingleUpdateStep)
I1110 22:38:52.029563  2593 solver.cpp:310]     Train net output #0: loss = 0.646718 (* 1 = 0.646718 loss)
I1110 22:38:52.029602  2593 sgd_solver.cpp:106] Iteration 757, lr = 0.001
I1110 22:38:54.218469  2593 solver.cpp:295] Iteration 758 (no loss supplied for SingleUpdateStep)
I1110 22:38:54.218660  2593 solver.cpp:310]     Train net output #0: loss = 0.686233 (* 1 = 0.686233 loss)
I1110 22:38:54.218693  2593 sgd_solver.cpp:106] Iteration 758, lr = 0.001
I1110 22:38:56.472178  2593 solver.cpp:295] Iteration 759 (no loss supplied for SingleUpdateStep)
I1110 22:38:56.472282  2593 solver.cpp:310]     Train net output #0: loss = 0.638365 (* 1 = 0.638365 loss)
I1110 22:38:56.472303  2593 sgd_solver.cpp:106] Iteration 759, lr = 0.001
I1110 22:38:58.708415  2593 solver.cpp:295] Iteration 760 (no loss supplied for SingleUpdateStep)
I1110 22:38:58.708518  2593 solver.cpp:310]     Train net output #0: loss = 0.631558 (* 1 = 0.631558 loss)
I1110 22:38:58.708539  2593 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I1110 22:39:00.969059  2593 solver.cpp:295] Iteration 761 (no loss supplied for SingleUpdateStep)
I1110 22:39:00.969141  2593 solver.cpp:310]     Train net output #0: loss = 0.653868 (* 1 = 0.653868 loss)
I1110 22:39:00.969161  2593 sgd_solver.cpp:106] Iteration 761, lr = 0.001
I1110 22:39:03.212790  2593 solver.cpp:295] Iteration 762 (no loss supplied for SingleUpdateStep)
I1110 22:39:03.212878  2593 solver.cpp:310]     Train net output #0: loss = 0.60043 (* 1 = 0.60043 loss)
I1110 22:39:03.212904  2593 sgd_solver.cpp:106] Iteration 762, lr = 0.001
I1110 22:39:05.470248  2593 solver.cpp:295] Iteration 763 (no loss supplied for SingleUpdateStep)
I1110 22:39:05.470299  2593 solver.cpp:310]     Train net output #0: loss = 0.626294 (* 1 = 0.626294 loss)
I1110 22:39:05.470317  2593 sgd_solver.cpp:106] Iteration 763, lr = 0.001
I1110 22:39:07.810672  2593 solver.cpp:295] Iteration 764 (no loss supplied for SingleUpdateStep)
I1110 22:39:07.810731  2593 solver.cpp:310]     Train net output #0: loss = 0.633586 (* 1 = 0.633586 loss)
I1110 22:39:07.810751  2593 sgd_solver.cpp:106] Iteration 764, lr = 0.001
I1110 22:39:10.090934  2593 solver.cpp:295] Iteration 765 (no loss supplied for SingleUpdateStep)
I1110 22:39:10.091018  2593 solver.cpp:310]     Train net output #0: loss = 0.620873 (* 1 = 0.620873 loss)
I1110 22:39:10.091038  2593 sgd_solver.cpp:106] Iteration 765, lr = 0.001
I1110 22:39:12.545588  2593 solver.cpp:295] Iteration 766 (no loss supplied for SingleUpdateStep)
I1110 22:39:12.545692  2593 solver.cpp:310]     Train net output #0: loss = 0.619197 (* 1 = 0.619197 loss)
I1110 22:39:12.545717  2593 sgd_solver.cpp:106] Iteration 766, lr = 0.001
I1110 22:39:15.025264  2593 solver.cpp:295] Iteration 767 (no loss supplied for SingleUpdateStep)
I1110 22:39:15.025368  2593 solver.cpp:310]     Train net output #0: loss = 0.671794 (* 1 = 0.671794 loss)
I1110 22:39:15.025388  2593 sgd_solver.cpp:106] Iteration 767, lr = 0.001
I1110 22:39:17.418175  2593 solver.cpp:295] Iteration 768 (no loss supplied for SingleUpdateStep)
I1110 22:39:17.418233  2593 solver.cpp:310]     Train net output #0: loss = 0.634624 (* 1 = 0.634624 loss)
I1110 22:39:17.418251  2593 sgd_solver.cpp:106] Iteration 768, lr = 0.001
I1110 22:39:19.823312  2593 solver.cpp:295] Iteration 769 (no loss supplied for SingleUpdateStep)
I1110 22:39:19.823446  2593 solver.cpp:310]     Train net output #0: loss = 0.67539 (* 1 = 0.67539 loss)
I1110 22:39:19.823472  2593 sgd_solver.cpp:106] Iteration 769, lr = 0.001
I1110 22:39:22.004402  2593 solver.cpp:295] Iteration 770 (no loss supplied for SingleUpdateStep)
I1110 22:39:22.004536  2593 solver.cpp:310]     Train net output #0: loss = 0.623638 (* 1 = 0.623638 loss)
I1110 22:39:22.004560  2593 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I1110 22:39:24.434216  2593 solver.cpp:295] Iteration 771 (no loss supplied for SingleUpdateStep)
I1110 22:39:24.434352  2593 solver.cpp:310]     Train net output #0: loss = 0.630261 (* 1 = 0.630261 loss)
I1110 22:39:24.434388  2593 sgd_solver.cpp:106] Iteration 771, lr = 0.001
I1110 22:39:26.702143  2593 solver.cpp:295] Iteration 772 (no loss supplied for SingleUpdateStep)
I1110 22:39:26.702242  2593 solver.cpp:310]     Train net output #0: loss = 0.655455 (* 1 = 0.655455 loss)
I1110 22:39:26.702267  2593 sgd_solver.cpp:106] Iteration 772, lr = 0.001
I1110 22:39:29.093191  2593 solver.cpp:295] Iteration 773 (no loss supplied for SingleUpdateStep)
I1110 22:39:29.093314  2593 solver.cpp:310]     Train net output #0: loss = 0.665436 (* 1 = 0.665436 loss)
I1110 22:39:29.093339  2593 sgd_solver.cpp:106] Iteration 773, lr = 0.001
I1110 22:39:31.468426  2593 solver.cpp:295] Iteration 774 (no loss supplied for SingleUpdateStep)
I1110 22:39:31.468570  2593 solver.cpp:310]     Train net output #0: loss = 0.599679 (* 1 = 0.599679 loss)
I1110 22:39:31.468595  2593 sgd_solver.cpp:106] Iteration 774, lr = 0.001
I1110 22:39:33.860146  2593 solver.cpp:295] Iteration 775 (no loss supplied for SingleUpdateStep)
I1110 22:39:33.860324  2593 solver.cpp:310]     Train net output #0: loss = 0.625 (* 1 = 0.625 loss)
I1110 22:39:33.860352  2593 sgd_solver.cpp:106] Iteration 775, lr = 0.001
I1110 22:39:36.197626  2593 solver.cpp:295] Iteration 776 (no loss supplied for SingleUpdateStep)
I1110 22:39:36.197770  2593 solver.cpp:310]     Train net output #0: loss = 0.617165 (* 1 = 0.617165 loss)
I1110 22:39:36.197803  2593 sgd_solver.cpp:106] Iteration 776, lr = 0.001
I1110 22:39:38.423730  2593 solver.cpp:295] Iteration 777 (no loss supplied for SingleUpdateStep)
I1110 22:39:38.423873  2593 solver.cpp:310]     Train net output #0: loss = 0.614937 (* 1 = 0.614937 loss)
I1110 22:39:38.423897  2593 sgd_solver.cpp:106] Iteration 777, lr = 0.001
I1110 22:39:41.216467  2593 solver.cpp:295] Iteration 778 (no loss supplied for SingleUpdateStep)
I1110 22:39:41.216599  2593 solver.cpp:310]     Train net output #0: loss = 0.62351 (* 1 = 0.62351 loss)
I1110 22:39:41.216631  2593 sgd_solver.cpp:106] Iteration 778, lr = 0.001
I1110 22:39:43.903540  2593 solver.cpp:295] Iteration 779 (no loss supplied for SingleUpdateStep)
I1110 22:39:43.903640  2593 solver.cpp:310]     Train net output #0: loss = 0.619562 (* 1 = 0.619562 loss)
I1110 22:39:43.903666  2593 sgd_solver.cpp:106] Iteration 779, lr = 0.001
I1110 22:39:46.679304  2593 solver.cpp:295] Iteration 780 (no loss supplied for SingleUpdateStep)
I1110 22:39:46.679417  2593 solver.cpp:310]     Train net output #0: loss = 0.650497 (* 1 = 0.650497 loss)
I1110 22:39:46.679440  2593 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I1110 22:39:49.144244  2593 solver.cpp:295] Iteration 781 (no loss supplied for SingleUpdateStep)
I1110 22:39:49.144358  2593 solver.cpp:310]     Train net output #0: loss = 0.611872 (* 1 = 0.611872 loss)
I1110 22:39:49.144387  2593 sgd_solver.cpp:106] Iteration 781, lr = 0.001
I1110 22:39:51.437156  2593 solver.cpp:295] Iteration 782 (no loss supplied for SingleUpdateStep)
I1110 22:39:51.437245  2593 solver.cpp:310]     Train net output #0: loss = 0.642177 (* 1 = 0.642177 loss)
I1110 22:39:51.437266  2593 sgd_solver.cpp:106] Iteration 782, lr = 0.001
I1110 22:39:53.971498  2593 solver.cpp:295] Iteration 783 (no loss supplied for SingleUpdateStep)
I1110 22:39:53.971652  2593 solver.cpp:310]     Train net output #0: loss = 0.654339 (* 1 = 0.654339 loss)
I1110 22:39:53.971679  2593 sgd_solver.cpp:106] Iteration 783, lr = 0.001
I1110 22:39:56.313029  2593 solver.cpp:295] Iteration 784 (no loss supplied for SingleUpdateStep)
I1110 22:39:56.313267  2593 solver.cpp:310]     Train net output #0: loss = 0.662129 (* 1 = 0.662129 loss)
I1110 22:39:56.313323  2593 sgd_solver.cpp:106] Iteration 784, lr = 0.001
I1110 22:39:58.667352  2593 solver.cpp:295] Iteration 785 (no loss supplied for SingleUpdateStep)
I1110 22:39:58.667449  2593 solver.cpp:310]     Train net output #0: loss = 0.657862 (* 1 = 0.657862 loss)
I1110 22:39:58.667469  2593 sgd_solver.cpp:106] Iteration 785, lr = 0.001
I1110 22:40:00.848816  2593 solver.cpp:295] Iteration 786 (no loss supplied for SingleUpdateStep)
I1110 22:40:00.848871  2593 solver.cpp:310]     Train net output #0: loss = 0.654575 (* 1 = 0.654575 loss)
I1110 22:40:00.848891  2593 sgd_solver.cpp:106] Iteration 786, lr = 0.001
I1110 22:40:03.374933  2593 solver.cpp:295] Iteration 787 (no loss supplied for SingleUpdateStep)
I1110 22:40:03.375051  2593 solver.cpp:310]     Train net output #0: loss = 0.672632 (* 1 = 0.672632 loss)
I1110 22:40:03.375077  2593 sgd_solver.cpp:106] Iteration 787, lr = 0.001
I1110 22:40:06.440596  2593 solver.cpp:295] Iteration 788 (no loss supplied for SingleUpdateStep)
I1110 22:40:06.440678  2593 solver.cpp:310]     Train net output #0: loss = 0.643552 (* 1 = 0.643552 loss)
I1110 22:40:06.440698  2593 sgd_solver.cpp:106] Iteration 788, lr = 0.001
I1110 22:40:10.010562  2593 solver.cpp:295] Iteration 789 (no loss supplied for SingleUpdateStep)
I1110 22:40:10.010653  2593 solver.cpp:310]     Train net output #0: loss = 0.642784 (* 1 = 0.642784 loss)
I1110 22:40:10.010674  2593 sgd_solver.cpp:106] Iteration 789, lr = 0.001
I1110 22:40:12.571269  2593 solver.cpp:295] Iteration 790 (no loss supplied for SingleUpdateStep)
I1110 22:40:12.571344  2593 solver.cpp:310]     Train net output #0: loss = 0.63816 (* 1 = 0.63816 loss)
I1110 22:40:12.571364  2593 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I1110 22:40:14.946822  2593 solver.cpp:295] Iteration 791 (no loss supplied for SingleUpdateStep)
I1110 22:40:14.946965  2593 solver.cpp:310]     Train net output #0: loss = 0.627337 (* 1 = 0.627337 loss)
I1110 22:40:14.946996  2593 sgd_solver.cpp:106] Iteration 791, lr = 0.001
I1110 22:40:17.403344  2593 solver.cpp:295] Iteration 792 (no loss supplied for SingleUpdateStep)
I1110 22:40:17.403424  2593 solver.cpp:310]     Train net output #0: loss = 0.675331 (* 1 = 0.675331 loss)
I1110 22:40:17.403442  2593 sgd_solver.cpp:106] Iteration 792, lr = 0.001
I1110 22:40:19.558611  2593 solver.cpp:295] Iteration 793 (no loss supplied for SingleUpdateStep)
I1110 22:40:19.558665  2593 solver.cpp:310]     Train net output #0: loss = 0.611508 (* 1 = 0.611508 loss)
I1110 22:40:19.558682  2593 sgd_solver.cpp:106] Iteration 793, lr = 0.001
I1110 22:40:21.944249  2593 solver.cpp:295] Iteration 794 (no loss supplied for SingleUpdateStep)
I1110 22:40:21.944315  2593 solver.cpp:310]     Train net output #0: loss = 0.636554 (* 1 = 0.636554 loss)
I1110 22:40:21.944335  2593 sgd_solver.cpp:106] Iteration 794, lr = 0.001
I1110 22:40:24.427022  2593 solver.cpp:295] Iteration 795 (no loss supplied for SingleUpdateStep)
I1110 22:40:24.427084  2593 solver.cpp:310]     Train net output #0: loss = 0.643583 (* 1 = 0.643583 loss)
I1110 22:40:24.427105  2593 sgd_solver.cpp:106] Iteration 795, lr = 0.001
I1110 22:40:26.776235  2593 solver.cpp:295] Iteration 796 (no loss supplied for SingleUpdateStep)
I1110 22:40:26.776348  2593 solver.cpp:310]     Train net output #0: loss = 0.669111 (* 1 = 0.669111 loss)
I1110 22:40:26.776373  2593 sgd_solver.cpp:106] Iteration 796, lr = 0.001
I1110 22:40:29.124600  2593 solver.cpp:295] Iteration 797 (no loss supplied for SingleUpdateStep)
I1110 22:40:29.124706  2593 solver.cpp:310]     Train net output #0: loss = 0.60139 (* 1 = 0.60139 loss)
I1110 22:40:29.124727  2593 sgd_solver.cpp:106] Iteration 797, lr = 0.001
I1110 22:40:32.050858  2593 solver.cpp:295] Iteration 798 (no loss supplied for SingleUpdateStep)
I1110 22:40:32.050968  2593 solver.cpp:310]     Train net output #0: loss = 0.668117 (* 1 = 0.668117 loss)
I1110 22:40:32.050990  2593 sgd_solver.cpp:106] Iteration 798, lr = 0.001
I1110 22:40:39.137984  2593 solver.cpp:295] Iteration 799 (no loss supplied for SingleUpdateStep)
I1110 22:40:39.138147  2593 solver.cpp:310]     Train net output #0: loss = 0.648077 (* 1 = 0.648077 loss)
I1110 22:40:39.138185  2593 sgd_solver.cpp:106] Iteration 799, lr = 0.001
I1110 22:40:44.183442  2593 solver.cpp:295] Iteration 800 (no loss supplied for SingleUpdateStep)
I1110 22:40:44.183526  2593 solver.cpp:310]     Train net output #0: loss = 0.628267 (* 1 = 0.628267 loss)
I1110 22:40:44.183547  2593 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I1110 22:40:48.201557  2593 solver.cpp:295] Iteration 801 (no loss supplied for SingleUpdateStep)
I1110 22:40:48.201690  2593 solver.cpp:310]     Train net output #0: loss = 0.660035 (* 1 = 0.660035 loss)
I1110 22:40:48.201714  2593 sgd_solver.cpp:106] Iteration 801, lr = 0.001
I1110 22:40:51.749933  2593 solver.cpp:295] Iteration 802 (no loss supplied for SingleUpdateStep)
I1110 22:40:51.750052  2593 solver.cpp:310]     Train net output #0: loss = 0.632648 (* 1 = 0.632648 loss)
I1110 22:40:51.750080  2593 sgd_solver.cpp:106] Iteration 802, lr = 0.001
I1110 22:40:56.277154  2593 solver.cpp:295] Iteration 803 (no loss supplied for SingleUpdateStep)
I1110 22:40:56.277230  2593 solver.cpp:310]     Train net output #0: loss = 0.58743 (* 1 = 0.58743 loss)
I1110 22:40:56.277251  2593 sgd_solver.cpp:106] Iteration 803, lr = 0.001
I1110 22:40:59.501919  2593 solver.cpp:295] Iteration 804 (no loss supplied for SingleUpdateStep)
I1110 22:40:59.502019  2593 solver.cpp:310]     Train net output #0: loss = 0.645042 (* 1 = 0.645042 loss)
I1110 22:40:59.502038  2593 sgd_solver.cpp:106] Iteration 804, lr = 0.001
I1110 22:41:01.966518  2593 solver.cpp:295] Iteration 805 (no loss supplied for SingleUpdateStep)
I1110 22:41:01.966627  2593 solver.cpp:310]     Train net output #0: loss = 0.630218 (* 1 = 0.630218 loss)
I1110 22:41:01.966650  2593 sgd_solver.cpp:106] Iteration 805, lr = 0.001
I1110 22:41:04.512634  2593 solver.cpp:295] Iteration 806 (no loss supplied for SingleUpdateStep)
I1110 22:41:04.512691  2593 solver.cpp:310]     Train net output #0: loss = 0.634671 (* 1 = 0.634671 loss)
I1110 22:41:04.512711  2593 sgd_solver.cpp:106] Iteration 806, lr = 0.001
I1110 22:41:07.328215  2593 solver.cpp:295] Iteration 807 (no loss supplied for SingleUpdateStep)
I1110 22:41:07.328297  2593 solver.cpp:310]     Train net output #0: loss = 0.589198 (* 1 = 0.589198 loss)
I1110 22:41:07.328317  2593 sgd_solver.cpp:106] Iteration 807, lr = 0.001
I1110 22:41:09.659589  2593 solver.cpp:295] Iteration 808 (no loss supplied for SingleUpdateStep)
I1110 22:41:09.659665  2593 solver.cpp:310]     Train net output #0: loss = 0.637859 (* 1 = 0.637859 loss)
I1110 22:41:09.659687  2593 sgd_solver.cpp:106] Iteration 808, lr = 0.001
I1110 22:41:13.057523  2593 solver.cpp:295] Iteration 809 (no loss supplied for SingleUpdateStep)
I1110 22:41:13.057611  2593 solver.cpp:310]     Train net output #0: loss = 0.635924 (* 1 = 0.635924 loss)
I1110 22:41:13.057632  2593 sgd_solver.cpp:106] Iteration 809, lr = 0.001
I1110 22:41:16.344172  2593 solver.cpp:295] Iteration 810 (no loss supplied for SingleUpdateStep)
I1110 22:41:16.344367  2593 solver.cpp:310]     Train net output #0: loss = 0.629596 (* 1 = 0.629596 loss)
I1110 22:41:16.344393  2593 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I1110 22:41:19.200076  2593 solver.cpp:295] Iteration 811 (no loss supplied for SingleUpdateStep)
I1110 22:41:19.200187  2593 solver.cpp:310]     Train net output #0: loss = 0.658219 (* 1 = 0.658219 loss)
I1110 22:41:19.200212  2593 sgd_solver.cpp:106] Iteration 811, lr = 0.001
I1110 22:41:22.295300  2593 solver.cpp:295] Iteration 812 (no loss supplied for SingleUpdateStep)
I1110 22:41:22.295351  2593 solver.cpp:310]     Train net output #0: loss = 0.656076 (* 1 = 0.656076 loss)
I1110 22:41:22.295368  2593 sgd_solver.cpp:106] Iteration 812, lr = 0.001
I1110 22:41:24.885059  2593 solver.cpp:295] Iteration 813 (no loss supplied for SingleUpdateStep)
I1110 22:41:24.885154  2593 solver.cpp:310]     Train net output #0: loss = 0.57595 (* 1 = 0.57595 loss)
I1110 22:41:24.885175  2593 sgd_solver.cpp:106] Iteration 813, lr = 0.001
I1110 22:41:27.877735  2593 solver.cpp:295] Iteration 814 (no loss supplied for SingleUpdateStep)
I1110 22:41:27.877837  2593 solver.cpp:310]     Train net output #0: loss = 0.599325 (* 1 = 0.599325 loss)
I1110 22:41:27.877858  2593 sgd_solver.cpp:106] Iteration 814, lr = 0.001
I1110 22:41:30.400671  2593 solver.cpp:295] Iteration 815 (no loss supplied for SingleUpdateStep)
I1110 22:41:30.400765  2593 solver.cpp:310]     Train net output #0: loss = 0.620751 (* 1 = 0.620751 loss)
I1110 22:41:30.400786  2593 sgd_solver.cpp:106] Iteration 815, lr = 0.001
I1110 22:41:32.976449  2593 solver.cpp:295] Iteration 816 (no loss supplied for SingleUpdateStep)
I1110 22:41:32.976522  2593 solver.cpp:310]     Train net output #0: loss = 0.597485 (* 1 = 0.597485 loss)
I1110 22:41:32.976541  2593 sgd_solver.cpp:106] Iteration 816, lr = 0.001
I1110 22:41:35.986991  2593 solver.cpp:295] Iteration 817 (no loss supplied for SingleUpdateStep)
I1110 22:41:35.987046  2593 solver.cpp:310]     Train net output #0: loss = 0.626924 (* 1 = 0.626924 loss)
I1110 22:41:35.987063  2593 sgd_solver.cpp:106] Iteration 817, lr = 0.001
I1110 22:41:38.588058  2593 solver.cpp:295] Iteration 818 (no loss supplied for SingleUpdateStep)
I1110 22:41:38.588137  2593 solver.cpp:310]     Train net output #0: loss = 0.62948 (* 1 = 0.62948 loss)
I1110 22:41:38.588158  2593 sgd_solver.cpp:106] Iteration 818, lr = 0.001
I1110 22:41:41.294594  2593 solver.cpp:295] Iteration 819 (no loss supplied for SingleUpdateStep)
I1110 22:41:41.294704  2593 solver.cpp:310]     Train net output #0: loss = 0.628576 (* 1 = 0.628576 loss)
I1110 22:41:41.294728  2593 sgd_solver.cpp:106] Iteration 819, lr = 0.001
I1110 22:41:44.308293  2593 solver.cpp:295] Iteration 820 (no loss supplied for SingleUpdateStep)
I1110 22:41:44.308351  2593 solver.cpp:310]     Train net output #0: loss = 0.616355 (* 1 = 0.616355 loss)
I1110 22:41:44.308374  2593 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I1110 22:41:47.113878  2593 solver.cpp:295] Iteration 821 (no loss supplied for SingleUpdateStep)
I1110 22:41:47.113991  2593 solver.cpp:310]     Train net output #0: loss = 0.613272 (* 1 = 0.613272 loss)
I1110 22:41:47.114013  2593 sgd_solver.cpp:106] Iteration 821, lr = 0.001
I1110 22:41:49.891041  2593 solver.cpp:295] Iteration 822 (no loss supplied for SingleUpdateStep)
I1110 22:41:49.891121  2593 solver.cpp:310]     Train net output #0: loss = 0.574817 (* 1 = 0.574817 loss)
I1110 22:41:49.891144  2593 sgd_solver.cpp:106] Iteration 822, lr = 0.001
I1110 22:41:53.433070  2593 solver.cpp:295] Iteration 823 (no loss supplied for SingleUpdateStep)
I1110 22:41:53.433172  2593 solver.cpp:310]     Train net output #0: loss = 0.640633 (* 1 = 0.640633 loss)
I1110 22:41:53.433194  2593 sgd_solver.cpp:106] Iteration 823, lr = 0.001
I1110 22:41:55.785079  2593 solver.cpp:295] Iteration 824 (no loss supplied for SingleUpdateStep)
I1110 22:41:55.785166  2593 solver.cpp:310]     Train net output #0: loss = 0.628954 (* 1 = 0.628954 loss)
I1110 22:41:55.785187  2593 sgd_solver.cpp:106] Iteration 824, lr = 0.001
I1110 22:41:58.206652  2593 solver.cpp:295] Iteration 825 (no loss supplied for SingleUpdateStep)
I1110 22:41:58.206787  2593 solver.cpp:310]     Train net output #0: loss = 0.611062 (* 1 = 0.611062 loss)
I1110 22:41:58.206811  2593 sgd_solver.cpp:106] Iteration 825, lr = 0.001
I1110 22:42:00.579958  2593 solver.cpp:295] Iteration 826 (no loss supplied for SingleUpdateStep)
I1110 22:42:00.580158  2593 solver.cpp:310]     Train net output #0: loss = 0.649374 (* 1 = 0.649374 loss)
I1110 22:42:00.580196  2593 sgd_solver.cpp:106] Iteration 826, lr = 0.001
I1110 22:42:02.969575  2593 solver.cpp:295] Iteration 827 (no loss supplied for SingleUpdateStep)
I1110 22:42:02.969684  2593 solver.cpp:310]     Train net output #0: loss = 0.65333 (* 1 = 0.65333 loss)
I1110 22:42:02.969705  2593 sgd_solver.cpp:106] Iteration 827, lr = 0.001
I1110 22:42:05.173398  2593 solver.cpp:295] Iteration 828 (no loss supplied for SingleUpdateStep)
I1110 22:42:05.173498  2593 solver.cpp:310]     Train net output #0: loss = 0.597356 (* 1 = 0.597356 loss)
I1110 22:42:05.173529  2593 sgd_solver.cpp:106] Iteration 828, lr = 0.001
I1110 22:42:07.440204  2593 solver.cpp:295] Iteration 829 (no loss supplied for SingleUpdateStep)
I1110 22:42:07.440343  2593 solver.cpp:310]     Train net output #0: loss = 0.641985 (* 1 = 0.641985 loss)
I1110 22:42:07.440367  2593 sgd_solver.cpp:106] Iteration 829, lr = 0.001
I1110 22:42:10.001178  2593 solver.cpp:295] Iteration 830 (no loss supplied for SingleUpdateStep)
I1110 22:42:10.001257  2593 solver.cpp:310]     Train net output #0: loss = 0.642786 (* 1 = 0.642786 loss)
I1110 22:42:10.001278  2593 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I1110 22:42:12.186727  2593 solver.cpp:295] Iteration 831 (no loss supplied for SingleUpdateStep)
I1110 22:42:12.186787  2593 solver.cpp:310]     Train net output #0: loss = 0.643975 (* 1 = 0.643975 loss)
I1110 22:42:12.186806  2593 sgd_solver.cpp:106] Iteration 831, lr = 0.001
I1110 22:42:14.680809  2593 solver.cpp:295] Iteration 832 (no loss supplied for SingleUpdateStep)
I1110 22:42:14.680932  2593 solver.cpp:310]     Train net output #0: loss = 0.64011 (* 1 = 0.64011 loss)
I1110 22:42:14.680954  2593 sgd_solver.cpp:106] Iteration 832, lr = 0.001
I1110 22:42:17.440853  2593 solver.cpp:295] Iteration 833 (no loss supplied for SingleUpdateStep)
I1110 22:42:17.440943  2593 solver.cpp:310]     Train net output #0: loss = 0.623331 (* 1 = 0.623331 loss)
I1110 22:42:17.440964  2593 sgd_solver.cpp:106] Iteration 833, lr = 0.001
I1110 22:42:20.133299  2593 solver.cpp:295] Iteration 834 (no loss supplied for SingleUpdateStep)
I1110 22:42:20.133416  2593 solver.cpp:310]     Train net output #0: loss = 0.648481 (* 1 = 0.648481 loss)
I1110 22:42:20.133440  2593 sgd_solver.cpp:106] Iteration 834, lr = 0.001
I1110 22:42:23.890590  2593 solver.cpp:295] Iteration 835 (no loss supplied for SingleUpdateStep)
I1110 22:42:23.890702  2593 solver.cpp:310]     Train net output #0: loss = 0.646343 (* 1 = 0.646343 loss)
I1110 22:42:23.890723  2593 sgd_solver.cpp:106] Iteration 835, lr = 0.001
I1110 22:42:26.371477  2593 solver.cpp:295] Iteration 836 (no loss supplied for SingleUpdateStep)
I1110 22:42:26.371587  2593 solver.cpp:310]     Train net output #0: loss = 0.670371 (* 1 = 0.670371 loss)
I1110 22:42:26.371613  2593 sgd_solver.cpp:106] Iteration 836, lr = 0.001
I1110 22:42:28.592660  2593 solver.cpp:295] Iteration 837 (no loss supplied for SingleUpdateStep)
I1110 22:42:28.592723  2593 solver.cpp:310]     Train net output #0: loss = 0.578389 (* 1 = 0.578389 loss)
I1110 22:42:28.592743  2593 sgd_solver.cpp:106] Iteration 837, lr = 0.001
I1110 22:42:30.960810  2593 solver.cpp:295] Iteration 838 (no loss supplied for SingleUpdateStep)
I1110 22:42:30.960945  2593 solver.cpp:310]     Train net output #0: loss = 0.607949 (* 1 = 0.607949 loss)
I1110 22:42:30.960970  2593 sgd_solver.cpp:106] Iteration 838, lr = 0.001
I1110 22:42:33.230523  2593 solver.cpp:295] Iteration 839 (no loss supplied for SingleUpdateStep)
I1110 22:42:33.230617  2593 solver.cpp:310]     Train net output #0: loss = 0.594343 (* 1 = 0.594343 loss)
I1110 22:42:33.230638  2593 sgd_solver.cpp:106] Iteration 839, lr = 0.001
I1110 22:42:35.482123  2593 solver.cpp:295] Iteration 840 (no loss supplied for SingleUpdateStep)
I1110 22:42:35.482197  2593 solver.cpp:310]     Train net output #0: loss = 0.591394 (* 1 = 0.591394 loss)
I1110 22:42:35.482218  2593 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I1110 22:42:37.783244  2593 solver.cpp:295] Iteration 841 (no loss supplied for SingleUpdateStep)
I1110 22:42:37.783345  2593 solver.cpp:310]     Train net output #0: loss = 0.668289 (* 1 = 0.668289 loss)
I1110 22:42:37.783367  2593 sgd_solver.cpp:106] Iteration 841, lr = 0.001
I1110 22:42:39.959810  2593 solver.cpp:295] Iteration 842 (no loss supplied for SingleUpdateStep)
I1110 22:42:39.959918  2593 solver.cpp:310]     Train net output #0: loss = 0.664696 (* 1 = 0.664696 loss)
I1110 22:42:39.959939  2593 sgd_solver.cpp:106] Iteration 842, lr = 0.001
I1110 22:42:42.398303  2593 solver.cpp:295] Iteration 843 (no loss supplied for SingleUpdateStep)
I1110 22:42:42.398406  2593 solver.cpp:310]     Train net output #0: loss = 0.702889 (* 1 = 0.702889 loss)
I1110 22:42:42.398427  2593 sgd_solver.cpp:106] Iteration 843, lr = 0.001
I1110 22:42:44.793087  2593 solver.cpp:295] Iteration 844 (no loss supplied for SingleUpdateStep)
I1110 22:42:44.793190  2593 solver.cpp:310]     Train net output #0: loss = 0.655869 (* 1 = 0.655869 loss)
I1110 22:42:44.793212  2593 sgd_solver.cpp:106] Iteration 844, lr = 0.001
I1110 22:42:47.284298  2593 solver.cpp:295] Iteration 845 (no loss supplied for SingleUpdateStep)
I1110 22:42:47.284399  2593 solver.cpp:310]     Train net output #0: loss = 0.651632 (* 1 = 0.651632 loss)
I1110 22:42:47.284420  2593 sgd_solver.cpp:106] Iteration 845, lr = 0.001
I1110 22:42:49.596009  2593 solver.cpp:295] Iteration 846 (no loss supplied for SingleUpdateStep)
I1110 22:42:49.596112  2593 solver.cpp:310]     Train net output #0: loss = 0.6321 (* 1 = 0.6321 loss)
I1110 22:42:49.596133  2593 sgd_solver.cpp:106] Iteration 846, lr = 0.001
I1110 22:42:51.878458  2593 solver.cpp:295] Iteration 847 (no loss supplied for SingleUpdateStep)
I1110 22:42:51.878648  2593 solver.cpp:310]     Train net output #0: loss = 0.601307 (* 1 = 0.601307 loss)
I1110 22:42:51.878697  2593 sgd_solver.cpp:106] Iteration 847, lr = 0.001
I1110 22:42:54.110169  2593 solver.cpp:295] Iteration 848 (no loss supplied for SingleUpdateStep)
I1110 22:42:54.110286  2593 solver.cpp:310]     Train net output #0: loss = 0.62046 (* 1 = 0.62046 loss)
I1110 22:42:54.110311  2593 sgd_solver.cpp:106] Iteration 848, lr = 0.001
I1110 22:42:56.509227  2593 solver.cpp:295] Iteration 849 (no loss supplied for SingleUpdateStep)
I1110 22:42:56.509359  2593 solver.cpp:310]     Train net output #0: loss = 0.630983 (* 1 = 0.630983 loss)
I1110 22:42:56.509382  2593 sgd_solver.cpp:106] Iteration 849, lr = 0.001
I1110 22:42:58.730999  2593 solver.cpp:295] Iteration 850 (no loss supplied for SingleUpdateStep)
I1110 22:42:58.731103  2593 solver.cpp:310]     Train net output #0: loss = 0.572893 (* 1 = 0.572893 loss)
I1110 22:42:58.731130  2593 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I1110 22:43:01.305167  2593 solver.cpp:295] Iteration 851 (no loss supplied for SingleUpdateStep)
I1110 22:43:01.305238  2593 solver.cpp:310]     Train net output #0: loss = 0.603106 (* 1 = 0.603106 loss)
I1110 22:43:01.305260  2593 sgd_solver.cpp:106] Iteration 851, lr = 0.001
I1110 22:43:03.737668  2593 solver.cpp:295] Iteration 852 (no loss supplied for SingleUpdateStep)
I1110 22:43:03.737785  2593 solver.cpp:310]     Train net output #0: loss = 0.664847 (* 1 = 0.664847 loss)
I1110 22:43:03.737808  2593 sgd_solver.cpp:106] Iteration 852, lr = 0.001
I1110 22:43:05.968638  2593 solver.cpp:295] Iteration 853 (no loss supplied for SingleUpdateStep)
I1110 22:43:05.968698  2593 solver.cpp:310]     Train net output #0: loss = 0.644961 (* 1 = 0.644961 loss)
I1110 22:43:05.968719  2593 sgd_solver.cpp:106] Iteration 853, lr = 0.001
I1110 22:43:08.365239  2593 solver.cpp:295] Iteration 854 (no loss supplied for SingleUpdateStep)
I1110 22:43:08.365367  2593 solver.cpp:310]     Train net output #0: loss = 0.637303 (* 1 = 0.637303 loss)
I1110 22:43:08.365396  2593 sgd_solver.cpp:106] Iteration 854, lr = 0.001
I1110 22:43:10.866098  2593 solver.cpp:295] Iteration 855 (no loss supplied for SingleUpdateStep)
I1110 22:43:10.866158  2593 solver.cpp:310]     Train net output #0: loss = 0.605821 (* 1 = 0.605821 loss)
I1110 22:43:10.866175  2593 sgd_solver.cpp:106] Iteration 855, lr = 0.001
I1110 22:43:13.344404  2593 solver.cpp:295] Iteration 856 (no loss supplied for SingleUpdateStep)
I1110 22:43:13.344518  2593 solver.cpp:310]     Train net output #0: loss = 0.63812 (* 1 = 0.63812 loss)
I1110 22:43:13.344540  2593 sgd_solver.cpp:106] Iteration 856, lr = 0.001
I1110 22:43:15.756026  2593 solver.cpp:295] Iteration 857 (no loss supplied for SingleUpdateStep)
I1110 22:43:15.756103  2593 solver.cpp:310]     Train net output #0: loss = 0.581262 (* 1 = 0.581262 loss)
I1110 22:43:15.756124  2593 sgd_solver.cpp:106] Iteration 857, lr = 0.001
I1110 22:43:18.248668  2593 solver.cpp:295] Iteration 858 (no loss supplied for SingleUpdateStep)
I1110 22:43:18.248816  2593 solver.cpp:310]     Train net output #0: loss = 0.617529 (* 1 = 0.617529 loss)
I1110 22:43:18.248841  2593 sgd_solver.cpp:106] Iteration 858, lr = 0.001
I1110 22:43:20.856225  2593 solver.cpp:295] Iteration 859 (no loss supplied for SingleUpdateStep)
I1110 22:43:20.856303  2593 solver.cpp:310]     Train net output #0: loss = 0.645113 (* 1 = 0.645113 loss)
I1110 22:43:20.856324  2593 sgd_solver.cpp:106] Iteration 859, lr = 0.001
I1110 22:43:23.425063  2593 solver.cpp:295] Iteration 860 (no loss supplied for SingleUpdateStep)
I1110 22:43:23.425165  2593 solver.cpp:310]     Train net output #0: loss = 0.639912 (* 1 = 0.639912 loss)
I1110 22:43:23.425187  2593 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I1110 22:43:26.028966  2593 solver.cpp:295] Iteration 861 (no loss supplied for SingleUpdateStep)
I1110 22:43:26.029068  2593 solver.cpp:310]     Train net output #0: loss = 0.61274 (* 1 = 0.61274 loss)
I1110 22:43:26.029094  2593 sgd_solver.cpp:106] Iteration 861, lr = 0.001
I1110 22:43:28.543543  2593 solver.cpp:295] Iteration 862 (no loss supplied for SingleUpdateStep)
I1110 22:43:28.543660  2593 solver.cpp:310]     Train net output #0: loss = 0.615256 (* 1 = 0.615256 loss)
I1110 22:43:28.543684  2593 sgd_solver.cpp:106] Iteration 862, lr = 0.001
I1110 22:43:30.857393  2593 solver.cpp:295] Iteration 863 (no loss supplied for SingleUpdateStep)
I1110 22:43:30.857476  2593 solver.cpp:310]     Train net output #0: loss = 0.604918 (* 1 = 0.604918 loss)
I1110 22:43:30.857498  2593 sgd_solver.cpp:106] Iteration 863, lr = 0.001
I1110 22:43:33.092805  2593 solver.cpp:295] Iteration 864 (no loss supplied for SingleUpdateStep)
I1110 22:43:33.092895  2593 solver.cpp:310]     Train net output #0: loss = 0.627243 (* 1 = 0.627243 loss)
I1110 22:43:33.092916  2593 sgd_solver.cpp:106] Iteration 864, lr = 0.001
I1110 22:43:35.332191  2593 solver.cpp:295] Iteration 865 (no loss supplied for SingleUpdateStep)
I1110 22:43:35.332267  2593 solver.cpp:310]     Train net output #0: loss = 0.619114 (* 1 = 0.619114 loss)
I1110 22:43:35.332286  2593 sgd_solver.cpp:106] Iteration 865, lr = 0.001
I1110 22:43:37.635437  2593 solver.cpp:295] Iteration 866 (no loss supplied for SingleUpdateStep)
I1110 22:43:37.635498  2593 solver.cpp:310]     Train net output #0: loss = 0.631272 (* 1 = 0.631272 loss)
I1110 22:43:37.635517  2593 sgd_solver.cpp:106] Iteration 866, lr = 0.001
I1110 22:43:40.081737  2593 solver.cpp:295] Iteration 867 (no loss supplied for SingleUpdateStep)
I1110 22:43:40.081871  2593 solver.cpp:310]     Train net output #0: loss = 0.675782 (* 1 = 0.675782 loss)
I1110 22:43:40.081897  2593 sgd_solver.cpp:106] Iteration 867, lr = 0.001
I1110 22:43:42.371049  2593 solver.cpp:295] Iteration 868 (no loss supplied for SingleUpdateStep)
I1110 22:43:42.371160  2593 solver.cpp:310]     Train net output #0: loss = 0.67464 (* 1 = 0.67464 loss)
I1110 22:43:42.371183  2593 sgd_solver.cpp:106] Iteration 868, lr = 0.001
I1110 22:43:44.691828  2593 solver.cpp:295] Iteration 869 (no loss supplied for SingleUpdateStep)
I1110 22:43:44.691936  2593 solver.cpp:310]     Train net output #0: loss = 0.608589 (* 1 = 0.608589 loss)
I1110 22:43:44.691963  2593 sgd_solver.cpp:106] Iteration 869, lr = 0.001
I1110 22:43:46.824105  2593 solver.cpp:295] Iteration 870 (no loss supplied for SingleUpdateStep)
I1110 22:43:46.824247  2593 solver.cpp:310]     Train net output #0: loss = 0.650068 (* 1 = 0.650068 loss)
I1110 22:43:46.824271  2593 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I1110 22:43:49.026657  2593 solver.cpp:295] Iteration 871 (no loss supplied for SingleUpdateStep)
I1110 22:43:49.026767  2593 solver.cpp:310]     Train net output #0: loss = 0.641907 (* 1 = 0.641907 loss)
I1110 22:43:49.026787  2593 sgd_solver.cpp:106] Iteration 871, lr = 0.001
I1110 22:43:51.492102  2593 solver.cpp:295] Iteration 872 (no loss supplied for SingleUpdateStep)
I1110 22:43:51.492156  2593 solver.cpp:310]     Train net output #0: loss = 0.642531 (* 1 = 0.642531 loss)
I1110 22:43:51.492174  2593 sgd_solver.cpp:106] Iteration 872, lr = 0.001
I1110 22:43:53.897243  2593 solver.cpp:295] Iteration 873 (no loss supplied for SingleUpdateStep)
I1110 22:43:53.897361  2593 solver.cpp:310]     Train net output #0: loss = 0.621575 (* 1 = 0.621575 loss)
I1110 22:43:53.897383  2593 sgd_solver.cpp:106] Iteration 873, lr = 0.001
I1110 22:43:56.267989  2593 solver.cpp:295] Iteration 874 (no loss supplied for SingleUpdateStep)
I1110 22:43:56.268157  2593 solver.cpp:310]     Train net output #0: loss = 0.583232 (* 1 = 0.583232 loss)
I1110 22:43:56.268192  2593 sgd_solver.cpp:106] Iteration 874, lr = 0.001
I1110 22:43:58.500560  2593 solver.cpp:295] Iteration 875 (no loss supplied for SingleUpdateStep)
I1110 22:43:58.500685  2593 solver.cpp:310]     Train net output #0: loss = 0.63965 (* 1 = 0.63965 loss)
I1110 22:43:58.500710  2593 sgd_solver.cpp:106] Iteration 875, lr = 0.001
I1110 22:44:00.830754  2593 solver.cpp:295] Iteration 876 (no loss supplied for SingleUpdateStep)
I1110 22:44:00.830899  2593 solver.cpp:310]     Train net output #0: loss = 0.615052 (* 1 = 0.615052 loss)
I1110 22:44:00.830922  2593 sgd_solver.cpp:106] Iteration 876, lr = 0.001
I1110 22:44:03.454135  2593 solver.cpp:295] Iteration 877 (no loss supplied for SingleUpdateStep)
I1110 22:44:03.454191  2593 solver.cpp:310]     Train net output #0: loss = 0.602435 (* 1 = 0.602435 loss)
I1110 22:44:03.454210  2593 sgd_solver.cpp:106] Iteration 877, lr = 0.001
I1110 22:44:05.854176  2593 solver.cpp:295] Iteration 878 (no loss supplied for SingleUpdateStep)
I1110 22:44:05.854290  2593 solver.cpp:310]     Train net output #0: loss = 0.672887 (* 1 = 0.672887 loss)
I1110 22:44:05.854311  2593 sgd_solver.cpp:106] Iteration 878, lr = 0.001
I1110 22:44:08.070018  2593 solver.cpp:295] Iteration 879 (no loss supplied for SingleUpdateStep)
I1110 22:44:08.070101  2593 solver.cpp:310]     Train net output #0: loss = 0.587232 (* 1 = 0.587232 loss)
I1110 22:44:08.070122  2593 sgd_solver.cpp:106] Iteration 879, lr = 0.001
I1110 22:44:10.566864  2593 solver.cpp:295] Iteration 880 (no loss supplied for SingleUpdateStep)
I1110 22:44:10.566916  2593 solver.cpp:310]     Train net output #0: loss = 0.63799 (* 1 = 0.63799 loss)
I1110 22:44:10.566936  2593 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I1110 22:44:12.837153  2593 solver.cpp:295] Iteration 881 (no loss supplied for SingleUpdateStep)
I1110 22:44:12.837291  2593 solver.cpp:310]     Train net output #0: loss = 0.683127 (* 1 = 0.683127 loss)
I1110 22:44:12.837321  2593 sgd_solver.cpp:106] Iteration 881, lr = 0.001
I1110 22:44:15.172523  2593 solver.cpp:295] Iteration 882 (no loss supplied for SingleUpdateStep)
I1110 22:44:15.172607  2593 solver.cpp:310]     Train net output #0: loss = 0.590255 (* 1 = 0.590255 loss)
I1110 22:44:15.172628  2593 sgd_solver.cpp:106] Iteration 882, lr = 0.001
I1110 22:44:17.565721  2593 solver.cpp:295] Iteration 883 (no loss supplied for SingleUpdateStep)
I1110 22:44:17.565845  2593 solver.cpp:310]     Train net output #0: loss = 0.646978 (* 1 = 0.646978 loss)
I1110 22:44:17.565868  2593 sgd_solver.cpp:106] Iteration 883, lr = 0.001
I1110 22:44:19.902015  2593 solver.cpp:295] Iteration 884 (no loss supplied for SingleUpdateStep)
I1110 22:44:19.902144  2593 solver.cpp:310]     Train net output #0: loss = 0.619904 (* 1 = 0.619904 loss)
I1110 22:44:19.902168  2593 sgd_solver.cpp:106] Iteration 884, lr = 0.001
I1110 22:44:22.462458  2593 solver.cpp:295] Iteration 885 (no loss supplied for SingleUpdateStep)
I1110 22:44:22.462554  2593 solver.cpp:310]     Train net output #0: loss = 0.628349 (* 1 = 0.628349 loss)
I1110 22:44:22.462576  2593 sgd_solver.cpp:106] Iteration 885, lr = 0.001
I1110 22:44:24.777575  2593 solver.cpp:295] Iteration 886 (no loss supplied for SingleUpdateStep)
I1110 22:44:24.777665  2593 solver.cpp:310]     Train net output #0: loss = 0.655819 (* 1 = 0.655819 loss)
I1110 22:44:24.777688  2593 sgd_solver.cpp:106] Iteration 886, lr = 0.001
I1110 22:44:27.122145  2593 solver.cpp:295] Iteration 887 (no loss supplied for SingleUpdateStep)
I1110 22:44:27.122253  2593 solver.cpp:310]     Train net output #0: loss = 0.624409 (* 1 = 0.624409 loss)
I1110 22:44:27.122277  2593 sgd_solver.cpp:106] Iteration 887, lr = 0.001
I1110 22:44:30.011632  2593 solver.cpp:295] Iteration 888 (no loss supplied for SingleUpdateStep)
I1110 22:44:30.011728  2593 solver.cpp:310]     Train net output #0: loss = 0.617892 (* 1 = 0.617892 loss)
I1110 22:44:30.011749  2593 sgd_solver.cpp:106] Iteration 888, lr = 0.001
I1110 22:44:32.395218  2593 solver.cpp:295] Iteration 889 (no loss supplied for SingleUpdateStep)
I1110 22:44:32.395355  2593 solver.cpp:310]     Train net output #0: loss = 0.610643 (* 1 = 0.610643 loss)
I1110 22:44:32.395388  2593 sgd_solver.cpp:106] Iteration 889, lr = 0.001
I1110 22:44:35.024885  2593 solver.cpp:295] Iteration 890 (no loss supplied for SingleUpdateStep)
I1110 22:44:35.025029  2593 solver.cpp:310]     Train net output #0: loss = 0.604375 (* 1 = 0.604375 loss)
I1110 22:44:35.025053  2593 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I1110 22:44:37.301574  2593 solver.cpp:295] Iteration 891 (no loss supplied for SingleUpdateStep)
I1110 22:44:37.301738  2593 solver.cpp:310]     Train net output #0: loss = 0.604702 (* 1 = 0.604702 loss)
I1110 22:44:37.301769  2593 sgd_solver.cpp:106] Iteration 891, lr = 0.001
I1110 22:44:39.712294  2593 solver.cpp:295] Iteration 892 (no loss supplied for SingleUpdateStep)
I1110 22:44:39.712402  2593 solver.cpp:310]     Train net output #0: loss = 0.706822 (* 1 = 0.706822 loss)
I1110 22:44:39.712427  2593 sgd_solver.cpp:106] Iteration 892, lr = 0.001
I1110 22:44:42.361400  2593 solver.cpp:295] Iteration 893 (no loss supplied for SingleUpdateStep)
I1110 22:44:42.361466  2593 solver.cpp:310]     Train net output #0: loss = 0.570653 (* 1 = 0.570653 loss)
I1110 22:44:42.361485  2593 sgd_solver.cpp:106] Iteration 893, lr = 0.001
I1110 22:44:44.975224  2593 solver.cpp:295] Iteration 894 (no loss supplied for SingleUpdateStep)
I1110 22:44:44.975365  2593 solver.cpp:310]     Train net output #0: loss = 0.633726 (* 1 = 0.633726 loss)
I1110 22:44:44.975400  2593 sgd_solver.cpp:106] Iteration 894, lr = 0.001
I1110 22:44:47.447798  2593 solver.cpp:295] Iteration 895 (no loss supplied for SingleUpdateStep)
I1110 22:44:47.447912  2593 solver.cpp:310]     Train net output #0: loss = 0.628877 (* 1 = 0.628877 loss)
I1110 22:44:47.447932  2593 sgd_solver.cpp:106] Iteration 895, lr = 0.001
I1110 22:44:49.839522  2593 solver.cpp:295] Iteration 896 (no loss supplied for SingleUpdateStep)
I1110 22:44:49.839615  2593 solver.cpp:310]     Train net output #0: loss = 0.627694 (* 1 = 0.627694 loss)
I1110 22:44:49.839635  2593 sgd_solver.cpp:106] Iteration 896, lr = 0.001
I1110 22:44:52.382551  2593 solver.cpp:295] Iteration 897 (no loss supplied for SingleUpdateStep)
I1110 22:44:52.382612  2593 solver.cpp:310]     Train net output #0: loss = 0.592116 (* 1 = 0.592116 loss)
I1110 22:44:52.382632  2593 sgd_solver.cpp:106] Iteration 897, lr = 0.001
I1110 22:44:55.093747  2593 solver.cpp:295] Iteration 898 (no loss supplied for SingleUpdateStep)
I1110 22:44:55.093848  2593 solver.cpp:310]     Train net output #0: loss = 0.638162 (* 1 = 0.638162 loss)
I1110 22:44:55.093871  2593 sgd_solver.cpp:106] Iteration 898, lr = 0.001
I1110 22:44:57.819604  2593 solver.cpp:295] Iteration 899 (no loss supplied for SingleUpdateStep)
I1110 22:44:57.819720  2593 solver.cpp:310]     Train net output #0: loss = 0.651508 (* 1 = 0.651508 loss)
I1110 22:44:57.819746  2593 sgd_solver.cpp:106] Iteration 899, lr = 0.001
I1110 22:45:00.526358  2593 solver.cpp:295] Iteration 900 (no loss supplied for SingleUpdateStep)
I1110 22:45:00.526454  2593 solver.cpp:310]     Train net output #0: loss = 0.643857 (* 1 = 0.643857 loss)
I1110 22:45:00.526474  2593 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I1110 22:45:02.999006  2593 solver.cpp:295] Iteration 901 (no loss supplied for SingleUpdateStep)
I1110 22:45:02.999114  2593 solver.cpp:310]     Train net output #0: loss = 0.594602 (* 1 = 0.594602 loss)
I1110 22:45:02.999136  2593 sgd_solver.cpp:106] Iteration 901, lr = 0.001
I1110 22:45:05.450840  2593 solver.cpp:295] Iteration 902 (no loss supplied for SingleUpdateStep)
I1110 22:45:05.450964  2593 solver.cpp:310]     Train net output #0: loss = 0.642833 (* 1 = 0.642833 loss)
I1110 22:45:05.450995  2593 sgd_solver.cpp:106] Iteration 902, lr = 0.001
I1110 22:45:07.589442  2593 solver.cpp:295] Iteration 903 (no loss supplied for SingleUpdateStep)
I1110 22:45:07.589570  2593 solver.cpp:310]     Train net output #0: loss = 0.611047 (* 1 = 0.611047 loss)
I1110 22:45:07.589592  2593 sgd_solver.cpp:106] Iteration 903, lr = 0.001
I1110 22:45:09.965608  2593 solver.cpp:295] Iteration 904 (no loss supplied for SingleUpdateStep)
I1110 22:45:09.965708  2593 solver.cpp:310]     Train net output #0: loss = 0.580994 (* 1 = 0.580994 loss)
I1110 22:45:09.965729  2593 sgd_solver.cpp:106] Iteration 904, lr = 0.001
I1110 22:45:12.715898  2593 solver.cpp:295] Iteration 905 (no loss supplied for SingleUpdateStep)
I1110 22:45:12.716032  2593 solver.cpp:310]     Train net output #0: loss = 0.57743 (* 1 = 0.57743 loss)
I1110 22:45:12.716054  2593 sgd_solver.cpp:106] Iteration 905, lr = 0.001
I1110 22:45:15.256119  2593 solver.cpp:295] Iteration 906 (no loss supplied for SingleUpdateStep)
I1110 22:45:15.256175  2593 solver.cpp:310]     Train net output #0: loss = 0.648117 (* 1 = 0.648117 loss)
I1110 22:45:15.256196  2593 sgd_solver.cpp:106] Iteration 906, lr = 0.001
I1110 22:45:18.637912  2593 solver.cpp:295] Iteration 907 (no loss supplied for SingleUpdateStep)
I1110 22:45:18.638061  2593 solver.cpp:310]     Train net output #0: loss = 0.603774 (* 1 = 0.603774 loss)
I1110 22:45:18.638084  2593 sgd_solver.cpp:106] Iteration 907, lr = 0.001
I1110 22:45:21.905555  2593 solver.cpp:295] Iteration 908 (no loss supplied for SingleUpdateStep)
I1110 22:45:21.944093  2593 solver.cpp:310]     Train net output #0: loss = 0.58139 (* 1 = 0.58139 loss)
I1110 22:45:21.944135  2593 sgd_solver.cpp:106] Iteration 908, lr = 0.001
I1110 22:45:24.171144  2593 solver.cpp:295] Iteration 909 (no loss supplied for SingleUpdateStep)
I1110 22:45:24.171200  2593 solver.cpp:310]     Train net output #0: loss = 0.628159 (* 1 = 0.628159 loss)
I1110 22:45:24.171221  2593 sgd_solver.cpp:106] Iteration 909, lr = 0.001
I1110 22:45:26.571171  2593 solver.cpp:295] Iteration 910 (no loss supplied for SingleUpdateStep)
I1110 22:45:26.571250  2593 solver.cpp:310]     Train net output #0: loss = 0.627548 (* 1 = 0.627548 loss)
I1110 22:45:26.571274  2593 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I1110 22:45:28.983681  2593 solver.cpp:295] Iteration 911 (no loss supplied for SingleUpdateStep)
I1110 22:45:28.983770  2593 solver.cpp:310]     Train net output #0: loss = 0.611859 (* 1 = 0.611859 loss)
I1110 22:45:28.983793  2593 sgd_solver.cpp:106] Iteration 911, lr = 0.001
I1110 22:45:31.567090  2593 solver.cpp:295] Iteration 912 (no loss supplied for SingleUpdateStep)
I1110 22:45:31.567270  2593 solver.cpp:310]     Train net output #0: loss = 0.608624 (* 1 = 0.608624 loss)
I1110 22:45:31.567297  2593 sgd_solver.cpp:106] Iteration 912, lr = 0.001
I1110 22:45:33.972226  2593 solver.cpp:295] Iteration 913 (no loss supplied for SingleUpdateStep)
I1110 22:45:33.972282  2593 solver.cpp:310]     Train net output #0: loss = 0.576232 (* 1 = 0.576232 loss)
I1110 22:45:33.972301  2593 sgd_solver.cpp:106] Iteration 913, lr = 0.001
I1110 22:45:36.322335  2593 solver.cpp:295] Iteration 914 (no loss supplied for SingleUpdateStep)
I1110 22:45:36.322444  2593 solver.cpp:310]     Train net output #0: loss = 0.622139 (* 1 = 0.622139 loss)
I1110 22:45:36.322468  2593 sgd_solver.cpp:106] Iteration 914, lr = 0.001
I1110 22:45:38.517045  2593 solver.cpp:295] Iteration 915 (no loss supplied for SingleUpdateStep)
I1110 22:45:38.517104  2593 solver.cpp:310]     Train net output #0: loss = 0.622284 (* 1 = 0.622284 loss)
I1110 22:45:38.517123  2593 sgd_solver.cpp:106] Iteration 915, lr = 0.001
I1110 22:45:42.062548  2593 solver.cpp:295] Iteration 916 (no loss supplied for SingleUpdateStep)
I1110 22:45:42.062644  2593 solver.cpp:310]     Train net output #0: loss = 0.597061 (* 1 = 0.597061 loss)
I1110 22:45:42.062667  2593 sgd_solver.cpp:106] Iteration 916, lr = 0.001
I1110 22:45:45.663432  2593 solver.cpp:295] Iteration 917 (no loss supplied for SingleUpdateStep)
I1110 22:45:45.663501  2593 solver.cpp:310]     Train net output #0: loss = 0.599466 (* 1 = 0.599466 loss)
I1110 22:45:45.663521  2593 sgd_solver.cpp:106] Iteration 917, lr = 0.001
I1110 22:45:48.386234  2593 solver.cpp:295] Iteration 918 (no loss supplied for SingleUpdateStep)
I1110 22:45:48.386337  2593 solver.cpp:310]     Train net output #0: loss = 0.608837 (* 1 = 0.608837 loss)
I1110 22:45:48.386358  2593 sgd_solver.cpp:106] Iteration 918, lr = 0.001
I1110 22:45:52.384228  2593 solver.cpp:295] Iteration 919 (no loss supplied for SingleUpdateStep)
I1110 22:45:52.384300  2593 solver.cpp:310]     Train net output #0: loss = 0.64705 (* 1 = 0.64705 loss)
I1110 22:45:52.384320  2593 sgd_solver.cpp:106] Iteration 919, lr = 0.001
I1110 22:45:55.419447  2593 solver.cpp:295] Iteration 920 (no loss supplied for SingleUpdateStep)
I1110 22:45:55.419517  2593 solver.cpp:310]     Train net output #0: loss = 0.598002 (* 1 = 0.598002 loss)
I1110 22:45:55.419535  2593 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I1110 22:45:59.119462  2593 solver.cpp:295] Iteration 921 (no loss supplied for SingleUpdateStep)
I1110 22:45:59.119514  2593 solver.cpp:310]     Train net output #0: loss = 0.652374 (* 1 = 0.652374 loss)
I1110 22:45:59.119532  2593 sgd_solver.cpp:106] Iteration 921, lr = 0.001
I1110 22:46:03.133733  2593 solver.cpp:295] Iteration 922 (no loss supplied for SingleUpdateStep)
I1110 22:46:03.133808  2593 solver.cpp:310]     Train net output #0: loss = 0.60105 (* 1 = 0.60105 loss)
I1110 22:46:03.133828  2593 sgd_solver.cpp:106] Iteration 922, lr = 0.001
I1110 22:46:06.566700  2593 solver.cpp:295] Iteration 923 (no loss supplied for SingleUpdateStep)
I1110 22:46:06.566803  2593 solver.cpp:310]     Train net output #0: loss = 0.625196 (* 1 = 0.625196 loss)
I1110 22:46:06.566823  2593 sgd_solver.cpp:106] Iteration 923, lr = 0.001
I1110 22:46:09.572525  2593 solver.cpp:295] Iteration 924 (no loss supplied for SingleUpdateStep)
I1110 22:46:09.572636  2593 solver.cpp:310]     Train net output #0: loss = 0.639008 (* 1 = 0.639008 loss)
I1110 22:46:09.572657  2593 sgd_solver.cpp:106] Iteration 924, lr = 0.001
I1110 22:46:13.143220  2593 solver.cpp:295] Iteration 925 (no loss supplied for SingleUpdateStep)
I1110 22:46:13.143311  2593 solver.cpp:310]     Train net output #0: loss = 0.581134 (* 1 = 0.581134 loss)
I1110 22:46:13.143331  2593 sgd_solver.cpp:106] Iteration 925, lr = 0.001
I1110 22:46:17.067836  2593 solver.cpp:295] Iteration 926 (no loss supplied for SingleUpdateStep)
I1110 22:46:17.067941  2593 solver.cpp:310]     Train net output #0: loss = 0.601479 (* 1 = 0.601479 loss)
I1110 22:46:17.067965  2593 sgd_solver.cpp:106] Iteration 926, lr = 0.001
I1110 22:46:19.722471  2593 solver.cpp:295] Iteration 927 (no loss supplied for SingleUpdateStep)
I1110 22:46:19.722568  2593 solver.cpp:310]     Train net output #0: loss = 0.596185 (* 1 = 0.596185 loss)
I1110 22:46:19.722589  2593 sgd_solver.cpp:106] Iteration 927, lr = 0.001
I1110 22:46:22.061363  2593 solver.cpp:295] Iteration 928 (no loss supplied for SingleUpdateStep)
I1110 22:46:22.061481  2593 solver.cpp:310]     Train net output #0: loss = 0.644575 (* 1 = 0.644575 loss)
I1110 22:46:22.061511  2593 sgd_solver.cpp:106] Iteration 928, lr = 0.001
I1110 22:46:24.782094  2593 solver.cpp:295] Iteration 929 (no loss supplied for SingleUpdateStep)
I1110 22:46:24.782156  2593 solver.cpp:310]     Train net output #0: loss = 0.585921 (* 1 = 0.585921 loss)
I1110 22:46:24.782174  2593 sgd_solver.cpp:106] Iteration 929, lr = 0.001
I1110 22:46:27.860625  2593 solver.cpp:295] Iteration 930 (no loss supplied for SingleUpdateStep)
I1110 22:46:27.860733  2593 solver.cpp:310]     Train net output #0: loss = 0.635184 (* 1 = 0.635184 loss)
I1110 22:46:27.860756  2593 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I1110 22:46:31.749490  2593 solver.cpp:295] Iteration 931 (no loss supplied for SingleUpdateStep)
I1110 22:46:31.749598  2593 solver.cpp:310]     Train net output #0: loss = 0.586687 (* 1 = 0.586687 loss)
I1110 22:46:31.749640  2593 sgd_solver.cpp:106] Iteration 931, lr = 0.001
I1110 22:46:34.758306  2593 solver.cpp:295] Iteration 932 (no loss supplied for SingleUpdateStep)
I1110 22:46:34.758373  2593 solver.cpp:310]     Train net output #0: loss = 0.590029 (* 1 = 0.590029 loss)
I1110 22:46:34.758394  2593 sgd_solver.cpp:106] Iteration 932, lr = 0.001
I1110 22:46:37.582775  2593 solver.cpp:295] Iteration 933 (no loss supplied for SingleUpdateStep)
I1110 22:46:37.582859  2593 solver.cpp:310]     Train net output #0: loss = 0.595311 (* 1 = 0.595311 loss)
I1110 22:46:37.582880  2593 sgd_solver.cpp:106] Iteration 933, lr = 0.001
I1110 22:46:40.031359  2593 solver.cpp:295] Iteration 934 (no loss supplied for SingleUpdateStep)
I1110 22:46:40.031476  2593 solver.cpp:310]     Train net output #0: loss = 0.557328 (* 1 = 0.557328 loss)
I1110 22:46:40.031505  2593 sgd_solver.cpp:106] Iteration 934, lr = 0.001
I1110 22:46:42.421231  2593 solver.cpp:295] Iteration 935 (no loss supplied for SingleUpdateStep)
I1110 22:46:42.421357  2593 solver.cpp:310]     Train net output #0: loss = 0.598986 (* 1 = 0.598986 loss)
I1110 22:46:42.421381  2593 sgd_solver.cpp:106] Iteration 935, lr = 0.001
I1110 22:46:47.574137  2593 solver.cpp:295] Iteration 936 (no loss supplied for SingleUpdateStep)
I1110 22:46:47.574260  2593 solver.cpp:310]     Train net output #0: loss = 0.617941 (* 1 = 0.617941 loss)
I1110 22:46:47.574285  2593 sgd_solver.cpp:106] Iteration 936, lr = 0.001
I1110 22:46:50.267835  2593 solver.cpp:295] Iteration 937 (no loss supplied for SingleUpdateStep)
I1110 22:46:50.267915  2593 solver.cpp:310]     Train net output #0: loss = 0.56323 (* 1 = 0.56323 loss)
I1110 22:46:50.267937  2593 sgd_solver.cpp:106] Iteration 937, lr = 0.001
I1110 22:46:52.674401  2593 solver.cpp:295] Iteration 938 (no loss supplied for SingleUpdateStep)
I1110 22:46:52.674501  2593 solver.cpp:310]     Train net output #0: loss = 0.560037 (* 1 = 0.560037 loss)
I1110 22:46:52.674525  2593 sgd_solver.cpp:106] Iteration 938, lr = 0.001
I1110 22:46:55.057214  2593 solver.cpp:295] Iteration 939 (no loss supplied for SingleUpdateStep)
I1110 22:46:55.057291  2593 solver.cpp:310]     Train net output #0: loss = 0.626567 (* 1 = 0.626567 loss)
I1110 22:46:55.057313  2593 sgd_solver.cpp:106] Iteration 939, lr = 0.001
I1110 22:46:57.580473  2593 solver.cpp:295] Iteration 940 (no loss supplied for SingleUpdateStep)
I1110 22:46:57.580586  2593 solver.cpp:310]     Train net output #0: loss = 0.605224 (* 1 = 0.605224 loss)
I1110 22:46:57.580607  2593 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I1110 22:46:59.754189  2593 solver.cpp:295] Iteration 941 (no loss supplied for SingleUpdateStep)
I1110 22:46:59.754288  2593 solver.cpp:310]     Train net output #0: loss = 0.562015 (* 1 = 0.562015 loss)
I1110 22:46:59.754310  2593 sgd_solver.cpp:106] Iteration 941, lr = 0.001
I1110 22:47:02.112730  2593 solver.cpp:295] Iteration 942 (no loss supplied for SingleUpdateStep)
I1110 22:47:02.112823  2593 solver.cpp:310]     Train net output #0: loss = 0.573242 (* 1 = 0.573242 loss)
I1110 22:47:02.112845  2593 sgd_solver.cpp:106] Iteration 942, lr = 0.001
I1110 22:47:04.611320  2593 solver.cpp:295] Iteration 943 (no loss supplied for SingleUpdateStep)
I1110 22:47:04.611373  2593 solver.cpp:310]     Train net output #0: loss = 0.600742 (* 1 = 0.600742 loss)
I1110 22:47:04.611392  2593 sgd_solver.cpp:106] Iteration 943, lr = 0.001
I1110 22:47:07.222929  2593 solver.cpp:295] Iteration 944 (no loss supplied for SingleUpdateStep)
I1110 22:47:07.223057  2593 solver.cpp:310]     Train net output #0: loss = 0.54356 (* 1 = 0.54356 loss)
I1110 22:47:07.223081  2593 sgd_solver.cpp:106] Iteration 944, lr = 0.001
I1110 22:47:09.747588  2593 solver.cpp:295] Iteration 945 (no loss supplied for SingleUpdateStep)
I1110 22:47:09.747740  2593 solver.cpp:310]     Train net output #0: loss = 0.648276 (* 1 = 0.648276 loss)
I1110 22:47:09.747766  2593 sgd_solver.cpp:106] Iteration 945, lr = 0.001
I1110 22:47:11.968965  2593 solver.cpp:295] Iteration 946 (no loss supplied for SingleUpdateStep)
I1110 22:47:11.969122  2593 solver.cpp:310]     Train net output #0: loss = 0.596069 (* 1 = 0.596069 loss)
I1110 22:47:11.969153  2593 sgd_solver.cpp:106] Iteration 946, lr = 0.001
I1110 22:47:14.327577  2593 solver.cpp:295] Iteration 947 (no loss supplied for SingleUpdateStep)
I1110 22:47:14.327682  2593 solver.cpp:310]     Train net output #0: loss = 0.596695 (* 1 = 0.596695 loss)
I1110 22:47:14.327703  2593 sgd_solver.cpp:106] Iteration 947, lr = 0.001
I1110 22:47:16.664232  2593 solver.cpp:295] Iteration 948 (no loss supplied for SingleUpdateStep)
I1110 22:47:16.664302  2593 solver.cpp:310]     Train net output #0: loss = 0.573717 (* 1 = 0.573717 loss)
I1110 22:47:16.664324  2593 sgd_solver.cpp:106] Iteration 948, lr = 0.001
I1110 22:47:18.975031  2593 solver.cpp:295] Iteration 949 (no loss supplied for SingleUpdateStep)
I1110 22:47:18.975085  2593 solver.cpp:310]     Train net output #0: loss = 0.603304 (* 1 = 0.603304 loss)
I1110 22:47:18.975102  2593 sgd_solver.cpp:106] Iteration 949, lr = 0.001
I1110 22:47:21.335196  2593 solver.cpp:295] Iteration 950 (no loss supplied for SingleUpdateStep)
I1110 22:47:21.335255  2593 solver.cpp:310]     Train net output #0: loss = 0.603265 (* 1 = 0.603265 loss)
I1110 22:47:21.335274  2593 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I1110 22:47:23.642802  2593 solver.cpp:295] Iteration 951 (no loss supplied for SingleUpdateStep)
I1110 22:47:23.642899  2593 solver.cpp:310]     Train net output #0: loss = 0.60025 (* 1 = 0.60025 loss)
I1110 22:47:23.642923  2593 sgd_solver.cpp:106] Iteration 951, lr = 0.001
I1110 22:47:25.963562  2593 solver.cpp:295] Iteration 952 (no loss supplied for SingleUpdateStep)
I1110 22:47:25.963630  2593 solver.cpp:310]     Train net output #0: loss = 0.62142 (* 1 = 0.62142 loss)
I1110 22:47:25.963650  2593 sgd_solver.cpp:106] Iteration 952, lr = 0.001
I1110 22:47:28.512919  2593 solver.cpp:295] Iteration 953 (no loss supplied for SingleUpdateStep)
I1110 22:47:28.513008  2593 solver.cpp:310]     Train net output #0: loss = 0.558823 (* 1 = 0.558823 loss)
I1110 22:47:28.513031  2593 sgd_solver.cpp:106] Iteration 953, lr = 0.001
I1110 22:47:30.789870  2593 solver.cpp:295] Iteration 954 (no loss supplied for SingleUpdateStep)
I1110 22:47:30.789991  2593 solver.cpp:310]     Train net output #0: loss = 0.599265 (* 1 = 0.599265 loss)
I1110 22:47:30.790014  2593 sgd_solver.cpp:106] Iteration 954, lr = 0.001
I1110 22:47:33.268625  2593 solver.cpp:295] Iteration 955 (no loss supplied for SingleUpdateStep)
I1110 22:47:33.268707  2593 solver.cpp:310]     Train net output #0: loss = 0.582581 (* 1 = 0.582581 loss)
I1110 22:47:33.268728  2593 sgd_solver.cpp:106] Iteration 955, lr = 0.001
I1110 22:47:35.746001  2593 solver.cpp:295] Iteration 956 (no loss supplied for SingleUpdateStep)
I1110 22:47:35.746078  2593 solver.cpp:310]     Train net output #0: loss = 0.58051 (* 1 = 0.58051 loss)
I1110 22:47:35.746099  2593 sgd_solver.cpp:106] Iteration 956, lr = 0.001
I1110 22:47:38.218323  2593 solver.cpp:295] Iteration 957 (no loss supplied for SingleUpdateStep)
I1110 22:47:38.218421  2593 solver.cpp:310]     Train net output #0: loss = 0.588074 (* 1 = 0.588074 loss)
I1110 22:47:38.218442  2593 sgd_solver.cpp:106] Iteration 957, lr = 0.001
I1110 22:47:40.778496  2593 solver.cpp:295] Iteration 958 (no loss supplied for SingleUpdateStep)
I1110 22:47:40.778648  2593 solver.cpp:310]     Train net output #0: loss = 0.576947 (* 1 = 0.576947 loss)
I1110 22:47:40.778676  2593 sgd_solver.cpp:106] Iteration 958, lr = 0.001
I1110 22:47:43.190948  2593 solver.cpp:295] Iteration 959 (no loss supplied for SingleUpdateStep)
I1110 22:47:43.191082  2593 solver.cpp:310]     Train net output #0: loss = 0.625484 (* 1 = 0.625484 loss)
I1110 22:47:43.191105  2593 sgd_solver.cpp:106] Iteration 959, lr = 0.001
I1110 22:47:45.751711  2593 solver.cpp:295] Iteration 960 (no loss supplied for SingleUpdateStep)
I1110 22:47:45.751821  2593 solver.cpp:310]     Train net output #0: loss = 0.598198 (* 1 = 0.598198 loss)
I1110 22:47:45.751842  2593 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I1110 22:47:48.133822  2593 solver.cpp:295] Iteration 961 (no loss supplied for SingleUpdateStep)
I1110 22:47:48.133929  2593 solver.cpp:310]     Train net output #0: loss = 0.601693 (* 1 = 0.601693 loss)
I1110 22:47:48.133949  2593 sgd_solver.cpp:106] Iteration 961, lr = 0.001
I1110 22:47:50.714799  2593 solver.cpp:295] Iteration 962 (no loss supplied for SingleUpdateStep)
I1110 22:47:50.714853  2593 solver.cpp:310]     Train net output #0: loss = 0.558939 (* 1 = 0.558939 loss)
I1110 22:47:50.714871  2593 sgd_solver.cpp:106] Iteration 962, lr = 0.001
I1110 22:47:53.227571  2593 solver.cpp:295] Iteration 963 (no loss supplied for SingleUpdateStep)
I1110 22:47:53.227690  2593 solver.cpp:310]     Train net output #0: loss = 0.613249 (* 1 = 0.613249 loss)
I1110 22:47:53.227715  2593 sgd_solver.cpp:106] Iteration 963, lr = 0.001
I1110 22:47:55.437067  2593 solver.cpp:295] Iteration 964 (no loss supplied for SingleUpdateStep)
I1110 22:47:55.437129  2593 solver.cpp:310]     Train net output #0: loss = 0.589457 (* 1 = 0.589457 loss)
I1110 22:47:55.437150  2593 sgd_solver.cpp:106] Iteration 964, lr = 0.001
I1110 22:47:57.728626  2593 solver.cpp:295] Iteration 965 (no loss supplied for SingleUpdateStep)
I1110 22:47:57.728715  2593 solver.cpp:310]     Train net output #0: loss = 0.622167 (* 1 = 0.622167 loss)
I1110 22:47:57.728740  2593 sgd_solver.cpp:106] Iteration 965, lr = 0.001
I1110 22:48:00.154811  2593 solver.cpp:295] Iteration 966 (no loss supplied for SingleUpdateStep)
I1110 22:48:00.154873  2593 solver.cpp:310]     Train net output #0: loss = 0.584608 (* 1 = 0.584608 loss)
I1110 22:48:00.154893  2593 sgd_solver.cpp:106] Iteration 966, lr = 0.001
I1110 22:48:03.098033  2593 solver.cpp:295] Iteration 967 (no loss supplied for SingleUpdateStep)
I1110 22:48:03.098083  2593 solver.cpp:310]     Train net output #0: loss = 0.589062 (* 1 = 0.589062 loss)
I1110 22:48:03.098101  2593 sgd_solver.cpp:106] Iteration 967, lr = 0.001
I1110 22:48:05.530647  2593 solver.cpp:295] Iteration 968 (no loss supplied for SingleUpdateStep)
I1110 22:48:05.530762  2593 solver.cpp:310]     Train net output #0: loss = 0.608797 (* 1 = 0.608797 loss)
I1110 22:48:05.530786  2593 sgd_solver.cpp:106] Iteration 968, lr = 0.001
I1110 22:48:08.909970  2593 solver.cpp:295] Iteration 969 (no loss supplied for SingleUpdateStep)
I1110 22:48:08.910074  2593 solver.cpp:310]     Train net output #0: loss = 0.589466 (* 1 = 0.589466 loss)
I1110 22:48:08.910099  2593 sgd_solver.cpp:106] Iteration 969, lr = 0.001
I1110 22:48:11.251811  2593 solver.cpp:295] Iteration 970 (no loss supplied for SingleUpdateStep)
I1110 22:48:11.251935  2593 solver.cpp:310]     Train net output #0: loss = 0.607977 (* 1 = 0.607977 loss)
I1110 22:48:11.251958  2593 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I1110 22:48:13.988546  2593 solver.cpp:295] Iteration 971 (no loss supplied for SingleUpdateStep)
I1110 22:48:13.988708  2593 solver.cpp:310]     Train net output #0: loss = 0.590055 (* 1 = 0.590055 loss)
I1110 22:48:13.988740  2593 sgd_solver.cpp:106] Iteration 971, lr = 0.001
I1110 22:48:16.775352  2593 solver.cpp:295] Iteration 972 (no loss supplied for SingleUpdateStep)
I1110 22:48:16.775504  2593 solver.cpp:310]     Train net output #0: loss = 0.574664 (* 1 = 0.574664 loss)
I1110 22:48:16.775532  2593 sgd_solver.cpp:106] Iteration 972, lr = 0.001
I1110 22:48:19.488066  2593 solver.cpp:295] Iteration 973 (no loss supplied for SingleUpdateStep)
I1110 22:48:19.488198  2593 solver.cpp:310]     Train net output #0: loss = 0.591985 (* 1 = 0.591985 loss)
I1110 22:48:19.488224  2593 sgd_solver.cpp:106] Iteration 973, lr = 0.001
I1110 22:48:22.171152  2593 solver.cpp:295] Iteration 974 (no loss supplied for SingleUpdateStep)
I1110 22:48:22.171277  2593 solver.cpp:310]     Train net output #0: loss = 0.625352 (* 1 = 0.625352 loss)
I1110 22:48:22.171303  2593 sgd_solver.cpp:106] Iteration 974, lr = 0.001
I1110 22:48:26.180186  2593 solver.cpp:295] Iteration 975 (no loss supplied for SingleUpdateStep)
I1110 22:48:26.180246  2593 solver.cpp:310]     Train net output #0: loss = 0.649548 (* 1 = 0.649548 loss)
I1110 22:48:26.180264  2593 sgd_solver.cpp:106] Iteration 975, lr = 0.001
I1110 22:48:29.284714  2593 solver.cpp:295] Iteration 976 (no loss supplied for SingleUpdateStep)
I1110 22:48:29.284780  2593 solver.cpp:310]     Train net output #0: loss = 0.557322 (* 1 = 0.557322 loss)
I1110 22:48:29.284801  2593 sgd_solver.cpp:106] Iteration 976, lr = 0.001
I1110 22:48:31.643589  2593 solver.cpp:295] Iteration 977 (no loss supplied for SingleUpdateStep)
I1110 22:48:31.643705  2593 solver.cpp:310]     Train net output #0: loss = 0.609522 (* 1 = 0.609522 loss)
I1110 22:48:31.643728  2593 sgd_solver.cpp:106] Iteration 977, lr = 0.001
I1110 22:48:34.696677  2593 solver.cpp:295] Iteration 978 (no loss supplied for SingleUpdateStep)
I1110 22:48:34.696746  2593 solver.cpp:310]     Train net output #0: loss = 0.52934 (* 1 = 0.52934 loss)
I1110 22:48:34.696766  2593 sgd_solver.cpp:106] Iteration 978, lr = 0.001
I1110 22:48:37.804582  2593 solver.cpp:295] Iteration 979 (no loss supplied for SingleUpdateStep)
I1110 22:48:37.804678  2593 solver.cpp:310]     Train net output #0: loss = 0.575764 (* 1 = 0.575764 loss)
I1110 22:48:37.804699  2593 sgd_solver.cpp:106] Iteration 979, lr = 0.001
I1110 22:48:40.694568  2593 solver.cpp:295] Iteration 980 (no loss supplied for SingleUpdateStep)
I1110 22:48:40.694656  2593 solver.cpp:310]     Train net output #0: loss = 0.592443 (* 1 = 0.592443 loss)
I1110 22:48:40.694679  2593 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I1110 22:48:43.649623  2593 solver.cpp:295] Iteration 981 (no loss supplied for SingleUpdateStep)
I1110 22:48:43.649706  2593 solver.cpp:310]     Train net output #0: loss = 0.5576 (* 1 = 0.5576 loss)
I1110 22:48:43.649727  2593 sgd_solver.cpp:106] Iteration 981, lr = 0.001
I1110 22:48:46.237061  2593 solver.cpp:295] Iteration 982 (no loss supplied for SingleUpdateStep)
I1110 22:48:46.237159  2593 solver.cpp:310]     Train net output #0: loss = 0.649236 (* 1 = 0.649236 loss)
I1110 22:48:46.237179  2593 sgd_solver.cpp:106] Iteration 982, lr = 0.001
I1110 22:48:48.713680  2593 solver.cpp:295] Iteration 983 (no loss supplied for SingleUpdateStep)
I1110 22:48:48.713740  2593 solver.cpp:310]     Train net output #0: loss = 0.590897 (* 1 = 0.590897 loss)
I1110 22:48:48.713760  2593 sgd_solver.cpp:106] Iteration 983, lr = 0.001
I1110 22:48:51.088389  2593 solver.cpp:295] Iteration 984 (no loss supplied for SingleUpdateStep)
I1110 22:48:51.088495  2593 solver.cpp:310]     Train net output #0: loss = 0.592849 (* 1 = 0.592849 loss)
I1110 22:48:51.088516  2593 sgd_solver.cpp:106] Iteration 984, lr = 0.001
I1110 22:48:53.481062  2593 solver.cpp:295] Iteration 985 (no loss supplied for SingleUpdateStep)
I1110 22:48:53.481196  2593 solver.cpp:310]     Train net output #0: loss = 0.543328 (* 1 = 0.543328 loss)
I1110 22:48:53.481220  2593 sgd_solver.cpp:106] Iteration 985, lr = 0.001
I1110 22:48:56.217182  2593 solver.cpp:295] Iteration 986 (no loss supplied for SingleUpdateStep)
I1110 22:48:56.217303  2593 solver.cpp:310]     Train net output #0: loss = 0.596572 (* 1 = 0.596572 loss)
I1110 22:48:56.217326  2593 sgd_solver.cpp:106] Iteration 986, lr = 0.001
I1110 22:48:58.905426  2593 solver.cpp:295] Iteration 987 (no loss supplied for SingleUpdateStep)
I1110 22:48:58.905591  2593 solver.cpp:310]     Train net output #0: loss = 0.575604 (* 1 = 0.575604 loss)
I1110 22:48:58.905617  2593 sgd_solver.cpp:106] Iteration 987, lr = 0.001
I1110 22:49:01.336691  2593 solver.cpp:295] Iteration 988 (no loss supplied for SingleUpdateStep)
I1110 22:49:01.336765  2593 solver.cpp:310]     Train net output #0: loss = 0.606379 (* 1 = 0.606379 loss)
I1110 22:49:01.336784  2593 sgd_solver.cpp:106] Iteration 988, lr = 0.001
I1110 22:49:03.547025  2593 solver.cpp:295] Iteration 989 (no loss supplied for SingleUpdateStep)
I1110 22:49:03.547086  2593 solver.cpp:310]     Train net output #0: loss = 0.593862 (* 1 = 0.593862 loss)
I1110 22:49:03.547111  2593 sgd_solver.cpp:106] Iteration 989, lr = 0.001
I1110 22:49:06.021177  2593 solver.cpp:295] Iteration 990 (no loss supplied for SingleUpdateStep)
I1110 22:49:06.021280  2593 solver.cpp:310]     Train net output #0: loss = 0.570443 (* 1 = 0.570443 loss)
I1110 22:49:06.021302  2593 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I1110 22:49:08.626329  2593 solver.cpp:295] Iteration 991 (no loss supplied for SingleUpdateStep)
I1110 22:49:08.626494  2593 solver.cpp:310]     Train net output #0: loss = 0.620306 (* 1 = 0.620306 loss)
I1110 22:49:08.626521  2593 sgd_solver.cpp:106] Iteration 991, lr = 0.001
I1110 22:49:11.158308  2593 solver.cpp:295] Iteration 992 (no loss supplied for SingleUpdateStep)
I1110 22:49:11.158444  2593 solver.cpp:310]     Train net output #0: loss = 0.59963 (* 1 = 0.59963 loss)
I1110 22:49:11.158470  2593 sgd_solver.cpp:106] Iteration 992, lr = 0.001
I1110 22:49:14.022712  2593 solver.cpp:295] Iteration 993 (no loss supplied for SingleUpdateStep)
I1110 22:49:14.022814  2593 solver.cpp:310]     Train net output #0: loss = 0.526481 (* 1 = 0.526481 loss)
I1110 22:49:14.022837  2593 sgd_solver.cpp:106] Iteration 993, lr = 0.001
I1110 22:49:16.592985  2593 solver.cpp:295] Iteration 994 (no loss supplied for SingleUpdateStep)
I1110 22:49:16.593142  2593 solver.cpp:310]     Train net output #0: loss = 0.596123 (* 1 = 0.596123 loss)
I1110 22:49:16.593168  2593 sgd_solver.cpp:106] Iteration 994, lr = 0.001
I1110 22:49:19.017307  2593 solver.cpp:295] Iteration 995 (no loss supplied for SingleUpdateStep)
I1110 22:49:19.017408  2593 solver.cpp:310]     Train net output #0: loss = 0.577285 (* 1 = 0.577285 loss)
I1110 22:49:19.017431  2593 sgd_solver.cpp:106] Iteration 995, lr = 0.001
I1110 22:49:21.650841  2593 solver.cpp:295] Iteration 996 (no loss supplied for SingleUpdateStep)
I1110 22:49:21.650915  2593 solver.cpp:310]     Train net output #0: loss = 0.562613 (* 1 = 0.562613 loss)
I1110 22:49:21.650934  2593 sgd_solver.cpp:106] Iteration 996, lr = 0.001
I1110 22:49:24.698454  2593 solver.cpp:295] Iteration 997 (no loss supplied for SingleUpdateStep)
I1110 22:49:24.698626  2593 solver.cpp:310]     Train net output #0: loss = 0.580024 (* 1 = 0.580024 loss)
I1110 22:49:24.698667  2593 sgd_solver.cpp:106] Iteration 997, lr = 0.001
I1110 22:49:27.580797  2593 solver.cpp:295] Iteration 998 (no loss supplied for SingleUpdateStep)
I1110 22:49:27.580916  2593 solver.cpp:310]     Train net output #0: loss = 0.580295 (* 1 = 0.580295 loss)
I1110 22:49:27.580940  2593 sgd_solver.cpp:106] Iteration 998, lr = 0.001
I1110 22:49:30.702335  2593 solver.cpp:295] Iteration 999 (no loss supplied for SingleUpdateStep)
I1110 22:49:30.702389  2593 solver.cpp:310]     Train net output #0: loss = 0.545946 (* 1 = 0.545946 loss)
I1110 22:49:30.702406  2593 sgd_solver.cpp:106] Iteration 999, lr = 0.001
I1110 22:49:30.702512  2593 solver.cpp:534] Snapshotting to binary proto file stitch_iter_1000.caffemodel
I1110 22:49:30.702536  2593 net.cpp:1022] Serializing 2 layers
I1110 22:49:30.752876  2593 sgd_solver.cpp:269] Snapshotting solver state to binary proto file stitch_iter_1000.solverstate
I1110 22:49:33.714957  2593 solver.cpp:295] Iteration 1000 (no loss supplied for SingleUpdateStep)
I1110 22:49:33.715029  2593 solver.cpp:310]     Train net output #0: loss = 0.560815 (* 1 = 0.560815 loss)
I1110 22:49:33.715049  2593 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I1110 22:49:37.564445  2593 solver.cpp:295] Iteration 1001 (no loss supplied for SingleUpdateStep)
I1110 22:49:37.564569  2593 solver.cpp:310]     Train net output #0: loss = 0.56589 (* 1 = 0.56589 loss)
I1110 22:49:37.564594  2593 sgd_solver.cpp:106] Iteration 1001, lr = 0.001
I1110 22:49:40.784442  2593 solver.cpp:295] Iteration 1002 (no loss supplied for SingleUpdateStep)
I1110 22:49:40.784560  2593 solver.cpp:310]     Train net output #0: loss = 0.562856 (* 1 = 0.562856 loss)
I1110 22:49:40.784584  2593 sgd_solver.cpp:106] Iteration 1002, lr = 0.001
I1110 22:49:43.188401  2593 solver.cpp:295] Iteration 1003 (no loss supplied for SingleUpdateStep)
I1110 22:49:43.188532  2593 solver.cpp:310]     Train net output #0: loss = 0.573472 (* 1 = 0.573472 loss)
I1110 22:49:43.188557  2593 sgd_solver.cpp:106] Iteration 1003, lr = 0.001
I1110 22:49:45.511765  2593 solver.cpp:295] Iteration 1004 (no loss supplied for SingleUpdateStep)
I1110 22:49:45.511868  2593 solver.cpp:310]     Train net output #0: loss = 0.583042 (* 1 = 0.583042 loss)
I1110 22:49:45.511891  2593 sgd_solver.cpp:106] Iteration 1004, lr = 0.001
I1110 22:49:47.890100  2593 solver.cpp:295] Iteration 1005 (no loss supplied for SingleUpdateStep)
I1110 22:49:47.890195  2593 solver.cpp:310]     Train net output #0: loss = 0.574387 (* 1 = 0.574387 loss)
I1110 22:49:47.890216  2593 sgd_solver.cpp:106] Iteration 1005, lr = 0.001
I1110 22:49:50.533807  2593 solver.cpp:295] Iteration 1006 (no loss supplied for SingleUpdateStep)
I1110 22:49:50.533939  2593 solver.cpp:310]     Train net output #0: loss = 0.599989 (* 1 = 0.599989 loss)
I1110 22:49:50.533967  2593 sgd_solver.cpp:106] Iteration 1006, lr = 0.001
I1110 22:49:52.964853  2593 solver.cpp:295] Iteration 1007 (no loss supplied for SingleUpdateStep)
I1110 22:49:52.964980  2593 solver.cpp:310]     Train net output #0: loss = 0.639332 (* 1 = 0.639332 loss)
I1110 22:49:52.965003  2593 sgd_solver.cpp:106] Iteration 1007, lr = 0.001
I1110 22:49:55.280446  2593 solver.cpp:295] Iteration 1008 (no loss supplied for SingleUpdateStep)
I1110 22:49:55.280542  2593 solver.cpp:310]     Train net output #0: loss = 0.609584 (* 1 = 0.609584 loss)
I1110 22:49:55.280565  2593 sgd_solver.cpp:106] Iteration 1008, lr = 0.001
I1110 22:49:58.036306  2593 solver.cpp:295] Iteration 1009 (no loss supplied for SingleUpdateStep)
I1110 22:49:58.036406  2593 solver.cpp:310]     Train net output #0: loss = 0.602621 (* 1 = 0.602621 loss)
I1110 22:49:58.036428  2593 sgd_solver.cpp:106] Iteration 1009, lr = 0.001
I1110 22:50:00.518059  2593 solver.cpp:295] Iteration 1010 (no loss supplied for SingleUpdateStep)
I1110 22:50:00.518167  2593 solver.cpp:310]     Train net output #0: loss = 0.576944 (* 1 = 0.576944 loss)
I1110 22:50:00.518193  2593 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I1110 22:50:03.270793  2593 solver.cpp:295] Iteration 1011 (no loss supplied for SingleUpdateStep)
I1110 22:50:03.270905  2593 solver.cpp:310]     Train net output #0: loss = 0.607257 (* 1 = 0.607257 loss)
I1110 22:50:03.270927  2593 sgd_solver.cpp:106] Iteration 1011, lr = 0.001
I1110 22:50:05.727229  2593 solver.cpp:295] Iteration 1012 (no loss supplied for SingleUpdateStep)
I1110 22:50:05.727327  2593 solver.cpp:310]     Train net output #0: loss = 0.586711 (* 1 = 0.586711 loss)
I1110 22:50:05.727349  2593 sgd_solver.cpp:106] Iteration 1012, lr = 0.001
I1110 22:50:07.963264  2593 solver.cpp:295] Iteration 1013 (no loss supplied for SingleUpdateStep)
I1110 22:50:07.963398  2593 solver.cpp:310]     Train net output #0: loss = 0.570129 (* 1 = 0.570129 loss)
I1110 22:50:07.963423  2593 sgd_solver.cpp:106] Iteration 1013, lr = 0.001
I1110 22:50:10.341863  2593 solver.cpp:295] Iteration 1014 (no loss supplied for SingleUpdateStep)
I1110 22:50:10.341945  2593 solver.cpp:310]     Train net output #0: loss = 0.569065 (* 1 = 0.569065 loss)
I1110 22:50:10.341969  2593 sgd_solver.cpp:106] Iteration 1014, lr = 0.001
I1110 22:50:13.023540  2593 solver.cpp:295] Iteration 1015 (no loss supplied for SingleUpdateStep)
I1110 22:50:13.023639  2593 solver.cpp:310]     Train net output #0: loss = 0.556878 (* 1 = 0.556878 loss)
I1110 22:50:13.023659  2593 sgd_solver.cpp:106] Iteration 1015, lr = 0.001
I1110 22:50:15.483521  2593 solver.cpp:295] Iteration 1016 (no loss supplied for SingleUpdateStep)
I1110 22:50:15.483606  2593 solver.cpp:310]     Train net output #0: loss = 0.57158 (* 1 = 0.57158 loss)
I1110 22:50:15.483625  2593 sgd_solver.cpp:106] Iteration 1016, lr = 0.001
I1110 22:50:17.937899  2593 solver.cpp:295] Iteration 1017 (no loss supplied for SingleUpdateStep)
I1110 22:50:17.938019  2593 solver.cpp:310]     Train net output #0: loss = 0.593421 (* 1 = 0.593421 loss)
I1110 22:50:17.938041  2593 sgd_solver.cpp:106] Iteration 1017, lr = 0.001
I1110 22:50:20.363219  2593 solver.cpp:295] Iteration 1018 (no loss supplied for SingleUpdateStep)
I1110 22:50:20.363335  2593 solver.cpp:310]     Train net output #0: loss = 0.63762 (* 1 = 0.63762 loss)
I1110 22:50:20.363374  2593 sgd_solver.cpp:106] Iteration 1018, lr = 0.001
I1110 22:50:22.812719  2593 solver.cpp:295] Iteration 1019 (no loss supplied for SingleUpdateStep)
I1110 22:50:22.812810  2593 solver.cpp:310]     Train net output #0: loss = 0.550394 (* 1 = 0.550394 loss)
I1110 22:50:22.812831  2593 sgd_solver.cpp:106] Iteration 1019, lr = 0.001
I1110 22:50:25.167841  2593 solver.cpp:295] Iteration 1020 (no loss supplied for SingleUpdateStep)
I1110 22:50:25.167948  2593 solver.cpp:310]     Train net output #0: loss = 0.568703 (* 1 = 0.568703 loss)
I1110 22:50:25.167992  2593 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I1110 22:50:27.470985  2593 solver.cpp:295] Iteration 1021 (no loss supplied for SingleUpdateStep)
I1110 22:50:27.471063  2593 solver.cpp:310]     Train net output #0: loss = 0.562753 (* 1 = 0.562753 loss)
I1110 22:50:27.471086  2593 sgd_solver.cpp:106] Iteration 1021, lr = 0.001
I1110 22:50:29.897265  2593 solver.cpp:295] Iteration 1022 (no loss supplied for SingleUpdateStep)
I1110 22:50:29.897336  2593 solver.cpp:310]     Train net output #0: loss = 0.563776 (* 1 = 0.563776 loss)
I1110 22:50:29.897354  2593 sgd_solver.cpp:106] Iteration 1022, lr = 0.001
I1110 22:50:32.159339  2593 solver.cpp:295] Iteration 1023 (no loss supplied for SingleUpdateStep)
I1110 22:50:32.159445  2593 solver.cpp:310]     Train net output #0: loss = 0.604636 (* 1 = 0.604636 loss)
I1110 22:50:32.159467  2593 sgd_solver.cpp:106] Iteration 1023, lr = 0.001
I1110 22:50:34.317401  2593 solver.cpp:295] Iteration 1024 (no loss supplied for SingleUpdateStep)
I1110 22:50:34.317507  2593 solver.cpp:310]     Train net output #0: loss = 0.566362 (* 1 = 0.566362 loss)
I1110 22:50:34.317536  2593 sgd_solver.cpp:106] Iteration 1024, lr = 0.001
I1110 22:50:36.723280  2593 solver.cpp:295] Iteration 1025 (no loss supplied for SingleUpdateStep)
I1110 22:50:36.723363  2593 solver.cpp:310]     Train net output #0: loss = 0.601052 (* 1 = 0.601052 loss)
I1110 22:50:36.723386  2593 sgd_solver.cpp:106] Iteration 1025, lr = 0.001
I1110 22:50:39.422102  2593 solver.cpp:295] Iteration 1026 (no loss supplied for SingleUpdateStep)
I1110 22:50:39.422188  2593 solver.cpp:310]     Train net output #0: loss = 0.616412 (* 1 = 0.616412 loss)
I1110 22:50:39.422209  2593 sgd_solver.cpp:106] Iteration 1026, lr = 0.001
I1110 22:50:41.696411  2593 solver.cpp:295] Iteration 1027 (no loss supplied for SingleUpdateStep)
I1110 22:50:41.696498  2593 solver.cpp:310]     Train net output #0: loss = 0.537429 (* 1 = 0.537429 loss)
I1110 22:50:41.696521  2593 sgd_solver.cpp:106] Iteration 1027, lr = 0.001
I1110 22:50:44.070565  2593 solver.cpp:295] Iteration 1028 (no loss supplied for SingleUpdateStep)
I1110 22:50:44.070679  2593 solver.cpp:310]     Train net output #0: loss = 0.582768 (* 1 = 0.582768 loss)
I1110 22:50:44.070705  2593 sgd_solver.cpp:106] Iteration 1028, lr = 0.001
I1110 22:50:46.839154  2593 solver.cpp:295] Iteration 1029 (no loss supplied for SingleUpdateStep)
I1110 22:50:46.839228  2593 solver.cpp:310]     Train net output #0: loss = 0.562431 (* 1 = 0.562431 loss)
I1110 22:50:46.839251  2593 sgd_solver.cpp:106] Iteration 1029, lr = 0.001
I1110 22:50:49.180377  2593 solver.cpp:295] Iteration 1030 (no loss supplied for SingleUpdateStep)
I1110 22:50:49.180454  2593 solver.cpp:310]     Train net output #0: loss = 0.569552 (* 1 = 0.569552 loss)
I1110 22:50:49.180475  2593 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I1110 22:50:51.617043  2593 solver.cpp:295] Iteration 1031 (no loss supplied for SingleUpdateStep)
I1110 22:50:51.617148  2593 solver.cpp:310]     Train net output #0: loss = 0.598697 (* 1 = 0.598697 loss)
I1110 22:50:51.617172  2593 sgd_solver.cpp:106] Iteration 1031, lr = 0.001
I1110 22:50:53.854300  2593 solver.cpp:295] Iteration 1032 (no loss supplied for SingleUpdateStep)
I1110 22:50:53.854416  2593 solver.cpp:310]     Train net output #0: loss = 0.572134 (* 1 = 0.572134 loss)
I1110 22:50:53.854446  2593 sgd_solver.cpp:106] Iteration 1032, lr = 0.001
I1110 22:50:56.224171  2593 solver.cpp:295] Iteration 1033 (no loss supplied for SingleUpdateStep)
I1110 22:50:56.224280  2593 solver.cpp:310]     Train net output #0: loss = 0.587237 (* 1 = 0.587237 loss)
I1110 22:50:56.224305  2593 sgd_solver.cpp:106] Iteration 1033, lr = 0.001
I1110 22:50:58.679148  2593 solver.cpp:295] Iteration 1034 (no loss supplied for SingleUpdateStep)
I1110 22:50:58.679215  2593 solver.cpp:310]     Train net output #0: loss = 0.547884 (* 1 = 0.547884 loss)
I1110 22:50:58.679235  2593 sgd_solver.cpp:106] Iteration 1034, lr = 0.001
I1110 22:51:00.939777  2593 solver.cpp:295] Iteration 1035 (no loss supplied for SingleUpdateStep)
I1110 22:51:00.939889  2593 solver.cpp:310]     Train net output #0: loss = 0.589949 (* 1 = 0.589949 loss)
I1110 22:51:00.939911  2593 sgd_solver.cpp:106] Iteration 1035, lr = 0.001
I1110 22:51:03.343564  2593 solver.cpp:295] Iteration 1036 (no loss supplied for SingleUpdateStep)
I1110 22:51:03.343675  2593 solver.cpp:310]     Train net output #0: loss = 0.593027 (* 1 = 0.593027 loss)
I1110 22:51:03.343698  2593 sgd_solver.cpp:106] Iteration 1036, lr = 0.001
I1110 22:51:05.661026  2593 solver.cpp:295] Iteration 1037 (no loss supplied for SingleUpdateStep)
I1110 22:51:05.661131  2593 solver.cpp:310]     Train net output #0: loss = 0.552347 (* 1 = 0.552347 loss)
I1110 22:51:05.661154  2593 sgd_solver.cpp:106] Iteration 1037, lr = 0.001
I1110 22:51:07.782217  2593 solver.cpp:295] Iteration 1038 (no loss supplied for SingleUpdateStep)
I1110 22:51:07.782299  2593 solver.cpp:310]     Train net output #0: loss = 0.571535 (* 1 = 0.571535 loss)
I1110 22:51:07.782318  2593 sgd_solver.cpp:106] Iteration 1038, lr = 0.001
I1110 22:51:09.984896  2593 solver.cpp:295] Iteration 1039 (no loss supplied for SingleUpdateStep)
I1110 22:51:09.984976  2593 solver.cpp:310]     Train net output #0: loss = 0.591149 (* 1 = 0.591149 loss)
I1110 22:51:09.984997  2593 sgd_solver.cpp:106] Iteration 1039, lr = 0.001
I1110 22:51:12.258688  2593 solver.cpp:295] Iteration 1040 (no loss supplied for SingleUpdateStep)
I1110 22:51:12.258793  2593 solver.cpp:310]     Train net output #0: loss = 0.582845 (* 1 = 0.582845 loss)
I1110 22:51:12.258816  2593 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I1110 22:51:14.497097  2593 solver.cpp:295] Iteration 1041 (no loss supplied for SingleUpdateStep)
I1110 22:51:14.497154  2593 solver.cpp:310]     Train net output #0: loss = 0.561451 (* 1 = 0.561451 loss)
I1110 22:51:14.497174  2593 sgd_solver.cpp:106] Iteration 1041, lr = 0.001
I1110 22:51:16.991241  2593 solver.cpp:295] Iteration 1042 (no loss supplied for SingleUpdateStep)
I1110 22:51:16.991364  2593 solver.cpp:310]     Train net output #0: loss = 0.562459 (* 1 = 0.562459 loss)
I1110 22:51:16.991386  2593 sgd_solver.cpp:106] Iteration 1042, lr = 0.001
I1110 22:51:19.170019  2593 solver.cpp:295] Iteration 1043 (no loss supplied for SingleUpdateStep)
I1110 22:51:19.170089  2593 solver.cpp:310]     Train net output #0: loss = 0.607651 (* 1 = 0.607651 loss)
I1110 22:51:19.170109  2593 sgd_solver.cpp:106] Iteration 1043, lr = 0.001
I1110 22:51:21.520694  2593 solver.cpp:295] Iteration 1044 (no loss supplied for SingleUpdateStep)
I1110 22:51:21.520812  2593 solver.cpp:310]     Train net output #0: loss = 0.613761 (* 1 = 0.613761 loss)
I1110 22:51:21.520836  2593 sgd_solver.cpp:106] Iteration 1044, lr = 0.001
I1110 22:51:23.762048  2593 solver.cpp:295] Iteration 1045 (no loss supplied for SingleUpdateStep)
I1110 22:51:23.762159  2593 solver.cpp:310]     Train net output #0: loss = 0.566994 (* 1 = 0.566994 loss)
I1110 22:51:23.762181  2593 sgd_solver.cpp:106] Iteration 1045, lr = 0.001
I1110 22:51:27.013128  2593 solver.cpp:295] Iteration 1046 (no loss supplied for SingleUpdateStep)
I1110 22:51:27.013250  2593 solver.cpp:310]     Train net output #0: loss = 0.582619 (* 1 = 0.582619 loss)
I1110 22:51:27.013275  2593 sgd_solver.cpp:106] Iteration 1046, lr = 0.001
I1110 22:51:30.590824  2593 solver.cpp:295] Iteration 1047 (no loss supplied for SingleUpdateStep)
I1110 22:51:30.590915  2593 solver.cpp:310]     Train net output #0: loss = 0.58234 (* 1 = 0.58234 loss)
I1110 22:51:30.590937  2593 sgd_solver.cpp:106] Iteration 1047, lr = 0.001
I1110 22:51:32.881361  2593 solver.cpp:295] Iteration 1048 (no loss supplied for SingleUpdateStep)
I1110 22:51:32.881510  2593 solver.cpp:310]     Train net output #0: loss = 0.580361 (* 1 = 0.580361 loss)
I1110 22:51:32.881543  2593 sgd_solver.cpp:106] Iteration 1048, lr = 0.001
I1110 22:51:35.260933  2593 solver.cpp:295] Iteration 1049 (no loss supplied for SingleUpdateStep)
I1110 22:51:35.261085  2593 solver.cpp:310]     Train net output #0: loss = 0.612138 (* 1 = 0.612138 loss)
I1110 22:51:35.261114  2593 sgd_solver.cpp:106] Iteration 1049, lr = 0.001
I1110 22:51:37.896764  2593 solver.cpp:295] Iteration 1050 (no loss supplied for SingleUpdateStep)
I1110 22:51:37.896847  2593 solver.cpp:310]     Train net output #0: loss = 0.556422 (* 1 = 0.556422 loss)
I1110 22:51:37.896868  2593 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I1110 22:51:40.279253  2593 solver.cpp:295] Iteration 1051 (no loss supplied for SingleUpdateStep)
I1110 22:51:40.279352  2593 solver.cpp:310]     Train net output #0: loss = 0.582198 (* 1 = 0.582198 loss)
I1110 22:51:40.279376  2593 sgd_solver.cpp:106] Iteration 1051, lr = 0.001
I1110 22:51:43.001471  2593 solver.cpp:295] Iteration 1052 (no loss supplied for SingleUpdateStep)
I1110 22:51:43.001577  2593 solver.cpp:310]     Train net output #0: loss = 0.548069 (* 1 = 0.548069 loss)
I1110 22:51:43.001600  2593 sgd_solver.cpp:106] Iteration 1052, lr = 0.001
I1110 22:51:45.646523  2593 solver.cpp:295] Iteration 1053 (no loss supplied for SingleUpdateStep)
I1110 22:51:45.646615  2593 solver.cpp:310]     Train net output #0: loss = 0.575755 (* 1 = 0.575755 loss)
I1110 22:51:45.646636  2593 sgd_solver.cpp:106] Iteration 1053, lr = 0.001
I1110 22:51:48.265316  2593 solver.cpp:295] Iteration 1054 (no loss supplied for SingleUpdateStep)
I1110 22:51:48.265382  2593 solver.cpp:310]     Train net output #0: loss = 0.56258 (* 1 = 0.56258 loss)
I1110 22:51:48.265404  2593 sgd_solver.cpp:106] Iteration 1054, lr = 0.001
I1110 22:51:50.512104  2593 solver.cpp:295] Iteration 1055 (no loss supplied for SingleUpdateStep)
I1110 22:51:50.512166  2593 solver.cpp:310]     Train net output #0: loss = 0.588148 (* 1 = 0.588148 loss)
I1110 22:51:50.512186  2593 sgd_solver.cpp:106] Iteration 1055, lr = 0.001
I1110 22:51:52.896700  2593 solver.cpp:295] Iteration 1056 (no loss supplied for SingleUpdateStep)
I1110 22:51:52.896805  2593 solver.cpp:310]     Train net output #0: loss = 0.534403 (* 1 = 0.534403 loss)
I1110 22:51:52.896826  2593 sgd_solver.cpp:106] Iteration 1056, lr = 0.001
I1110 22:51:55.456455  2593 solver.cpp:295] Iteration 1057 (no loss supplied for SingleUpdateStep)
I1110 22:51:55.456595  2593 solver.cpp:310]     Train net output #0: loss = 0.57762 (* 1 = 0.57762 loss)
I1110 22:51:55.456622  2593 sgd_solver.cpp:106] Iteration 1057, lr = 0.001
I1110 22:51:58.510424  2593 solver.cpp:295] Iteration 1058 (no loss supplied for SingleUpdateStep)
I1110 22:51:58.510543  2593 solver.cpp:310]     Train net output #0: loss = 0.577733 (* 1 = 0.577733 loss)
I1110 22:51:58.510567  2593 sgd_solver.cpp:106] Iteration 1058, lr = 0.001
I1110 22:52:01.021572  2593 solver.cpp:295] Iteration 1059 (no loss supplied for SingleUpdateStep)
I1110 22:52:01.021646  2593 solver.cpp:310]     Train net output #0: loss = 0.605571 (* 1 = 0.605571 loss)
I1110 22:52:01.021667  2593 sgd_solver.cpp:106] Iteration 1059, lr = 0.001
I1110 22:52:03.475949  2593 solver.cpp:295] Iteration 1060 (no loss supplied for SingleUpdateStep)
I1110 22:52:03.476066  2593 solver.cpp:310]     Train net output #0: loss = 0.596892 (* 1 = 0.596892 loss)
I1110 22:52:03.476090  2593 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I1110 22:52:05.963121  2593 solver.cpp:295] Iteration 1061 (no loss supplied for SingleUpdateStep)
I1110 22:52:05.963263  2593 solver.cpp:310]     Train net output #0: loss = 0.566883 (* 1 = 0.566883 loss)
I1110 22:52:05.963289  2593 sgd_solver.cpp:106] Iteration 1061, lr = 0.001
I1110 22:52:08.334980  2593 solver.cpp:295] Iteration 1062 (no loss supplied for SingleUpdateStep)
I1110 22:52:08.335114  2593 solver.cpp:310]     Train net output #0: loss = 0.540159 (* 1 = 0.540159 loss)
I1110 22:52:08.335137  2593 sgd_solver.cpp:106] Iteration 1062, lr = 0.001
I1110 22:52:10.784718  2593 solver.cpp:295] Iteration 1063 (no loss supplied for SingleUpdateStep)
I1110 22:52:10.784824  2593 solver.cpp:310]     Train net output #0: loss = 0.609445 (* 1 = 0.609445 loss)
I1110 22:52:10.784847  2593 sgd_solver.cpp:106] Iteration 1063, lr = 0.001
I1110 22:52:13.000393  2593 solver.cpp:295] Iteration 1064 (no loss supplied for SingleUpdateStep)
I1110 22:52:13.000499  2593 solver.cpp:310]     Train net output #0: loss = 0.583041 (* 1 = 0.583041 loss)
I1110 22:52:13.000521  2593 sgd_solver.cpp:106] Iteration 1064, lr = 0.001
I1110 22:52:15.260108  2593 solver.cpp:295] Iteration 1065 (no loss supplied for SingleUpdateStep)
I1110 22:52:15.260226  2593 solver.cpp:310]     Train net output #0: loss = 0.565972 (* 1 = 0.565972 loss)
I1110 22:52:15.260247  2593 sgd_solver.cpp:106] Iteration 1065, lr = 0.001
I1110 22:52:17.534004  2593 solver.cpp:295] Iteration 1066 (no loss supplied for SingleUpdateStep)
I1110 22:52:17.534116  2593 solver.cpp:310]     Train net output #0: loss = 0.597313 (* 1 = 0.597313 loss)
I1110 22:52:17.534137  2593 sgd_solver.cpp:106] Iteration 1066, lr = 0.001
I1110 22:52:19.766304  2593 solver.cpp:295] Iteration 1067 (no loss supplied for SingleUpdateStep)
I1110 22:52:19.766388  2593 solver.cpp:310]     Train net output #0: loss = 0.601325 (* 1 = 0.601325 loss)
I1110 22:52:19.766409  2593 sgd_solver.cpp:106] Iteration 1067, lr = 0.001
I1110 22:52:21.976441  2593 solver.cpp:295] Iteration 1068 (no loss supplied for SingleUpdateStep)
I1110 22:52:21.976552  2593 solver.cpp:310]     Train net output #0: loss = 0.574742 (* 1 = 0.574742 loss)
I1110 22:52:21.976575  2593 sgd_solver.cpp:106] Iteration 1068, lr = 0.001
I1110 22:52:24.210093  2593 solver.cpp:295] Iteration 1069 (no loss supplied for SingleUpdateStep)
I1110 22:52:24.210183  2593 solver.cpp:310]     Train net output #0: loss = 0.538292 (* 1 = 0.538292 loss)
I1110 22:52:24.210208  2593 sgd_solver.cpp:106] Iteration 1069, lr = 0.001
I1110 22:52:26.383265  2593 solver.cpp:295] Iteration 1070 (no loss supplied for SingleUpdateStep)
I1110 22:52:26.383313  2593 solver.cpp:310]     Train net output #0: loss = 0.542466 (* 1 = 0.542466 loss)
I1110 22:52:26.383332  2593 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I1110 22:52:28.586478  2593 solver.cpp:295] Iteration 1071 (no loss supplied for SingleUpdateStep)
I1110 22:52:28.586611  2593 solver.cpp:310]     Train net output #0: loss = 0.543368 (* 1 = 0.543368 loss)
I1110 22:52:28.586633  2593 sgd_solver.cpp:106] Iteration 1071, lr = 0.001
I1110 22:52:30.823518  2593 solver.cpp:295] Iteration 1072 (no loss supplied for SingleUpdateStep)
I1110 22:52:30.823673  2593 solver.cpp:310]     Train net output #0: loss = 0.521591 (* 1 = 0.521591 loss)
I1110 22:52:30.823698  2593 sgd_solver.cpp:106] Iteration 1072, lr = 0.001
I1110 22:52:33.121939  2593 solver.cpp:295] Iteration 1073 (no loss supplied for SingleUpdateStep)
I1110 22:52:33.122001  2593 solver.cpp:310]     Train net output #0: loss = 0.57132 (* 1 = 0.57132 loss)
I1110 22:52:33.122021  2593 sgd_solver.cpp:106] Iteration 1073, lr = 0.001
I1110 22:52:35.309420  2593 solver.cpp:295] Iteration 1074 (no loss supplied for SingleUpdateStep)
I1110 22:52:35.309526  2593 solver.cpp:310]     Train net output #0: loss = 0.53901 (* 1 = 0.53901 loss)
I1110 22:52:35.309547  2593 sgd_solver.cpp:106] Iteration 1074, lr = 0.001
I1110 22:52:37.589646  2593 solver.cpp:295] Iteration 1075 (no loss supplied for SingleUpdateStep)
I1110 22:52:37.589789  2593 solver.cpp:310]     Train net output #0: loss = 0.615311 (* 1 = 0.615311 loss)
I1110 22:52:37.589812  2593 sgd_solver.cpp:106] Iteration 1075, lr = 0.001
I1110 22:52:39.929857  2593 solver.cpp:295] Iteration 1076 (no loss supplied for SingleUpdateStep)
I1110 22:52:39.929991  2593 solver.cpp:310]     Train net output #0: loss = 0.614313 (* 1 = 0.614313 loss)
I1110 22:52:39.930011  2593 sgd_solver.cpp:106] Iteration 1076, lr = 0.001
I1110 22:52:42.110014  2593 solver.cpp:295] Iteration 1077 (no loss supplied for SingleUpdateStep)
I1110 22:52:42.110131  2593 solver.cpp:310]     Train net output #0: loss = 0.588296 (* 1 = 0.588296 loss)
I1110 22:52:42.110152  2593 sgd_solver.cpp:106] Iteration 1077, lr = 0.001
I1110 22:52:44.288920  2593 solver.cpp:295] Iteration 1078 (no loss supplied for SingleUpdateStep)
I1110 22:52:44.288993  2593 solver.cpp:310]     Train net output #0: loss = 0.541429 (* 1 = 0.541429 loss)
I1110 22:52:44.289012  2593 sgd_solver.cpp:106] Iteration 1078, lr = 0.001
I1110 22:52:46.588954  2593 solver.cpp:295] Iteration 1079 (no loss supplied for SingleUpdateStep)
I1110 22:52:46.589073  2593 solver.cpp:310]     Train net output #0: loss = 0.50221 (* 1 = 0.50221 loss)
I1110 22:52:46.589100  2593 sgd_solver.cpp:106] Iteration 1079, lr = 0.001
I1110 22:52:48.887540  2593 solver.cpp:295] Iteration 1080 (no loss supplied for SingleUpdateStep)
I1110 22:52:48.887656  2593 solver.cpp:310]     Train net output #0: loss = 0.557994 (* 1 = 0.557994 loss)
I1110 22:52:48.887677  2593 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I1110 22:52:51.176508  2593 solver.cpp:295] Iteration 1081 (no loss supplied for SingleUpdateStep)
I1110 22:52:51.176625  2593 solver.cpp:310]     Train net output #0: loss = 0.581887 (* 1 = 0.581887 loss)
I1110 22:52:51.176651  2593 sgd_solver.cpp:106] Iteration 1081, lr = 0.001
I1110 22:52:53.442698  2593 solver.cpp:295] Iteration 1082 (no loss supplied for SingleUpdateStep)
I1110 22:52:53.442775  2593 solver.cpp:310]     Train net output #0: loss = 0.550256 (* 1 = 0.550256 loss)
I1110 22:52:53.442797  2593 sgd_solver.cpp:106] Iteration 1082, lr = 0.001
I1110 22:52:55.719806  2593 solver.cpp:295] Iteration 1083 (no loss supplied for SingleUpdateStep)
I1110 22:52:55.719867  2593 solver.cpp:310]     Train net output #0: loss = 0.555078 (* 1 = 0.555078 loss)
I1110 22:52:55.719887  2593 sgd_solver.cpp:106] Iteration 1083, lr = 0.001
I1110 22:52:57.972905  2593 solver.cpp:295] Iteration 1084 (no loss supplied for SingleUpdateStep)
I1110 22:52:57.973011  2593 solver.cpp:310]     Train net output #0: loss = 0.556769 (* 1 = 0.556769 loss)
I1110 22:52:57.973032  2593 sgd_solver.cpp:106] Iteration 1084, lr = 0.001
I1110 22:53:00.268582  2593 solver.cpp:295] Iteration 1085 (no loss supplied for SingleUpdateStep)
I1110 22:53:00.268740  2593 solver.cpp:310]     Train net output #0: loss = 0.523926 (* 1 = 0.523926 loss)
I1110 22:53:00.268779  2593 sgd_solver.cpp:106] Iteration 1085, lr = 0.001
I1110 22:53:02.517500  2593 solver.cpp:295] Iteration 1086 (no loss supplied for SingleUpdateStep)
I1110 22:53:02.517597  2593 solver.cpp:310]     Train net output #0: loss = 0.636335 (* 1 = 0.636335 loss)
I1110 22:53:02.517621  2593 sgd_solver.cpp:106] Iteration 1086, lr = 0.001
I1110 22:53:04.751575  2593 solver.cpp:295] Iteration 1087 (no loss supplied for SingleUpdateStep)
I1110 22:53:04.751682  2593 solver.cpp:310]     Train net output #0: loss = 0.579311 (* 1 = 0.579311 loss)
I1110 22:53:04.751704  2593 sgd_solver.cpp:106] Iteration 1087, lr = 0.001
I1110 22:53:07.082581  2593 solver.cpp:295] Iteration 1088 (no loss supplied for SingleUpdateStep)
I1110 22:53:07.082756  2593 solver.cpp:310]     Train net output #0: loss = 0.551414 (* 1 = 0.551414 loss)
I1110 22:53:07.082782  2593 sgd_solver.cpp:106] Iteration 1088, lr = 0.001
I1110 22:53:09.229774  2593 solver.cpp:295] Iteration 1089 (no loss supplied for SingleUpdateStep)
I1110 22:53:09.229894  2593 solver.cpp:310]     Train net output #0: loss = 0.577394 (* 1 = 0.577394 loss)
I1110 22:53:09.229919  2593 sgd_solver.cpp:106] Iteration 1089, lr = 0.001
I1110 22:53:11.550741  2593 solver.cpp:295] Iteration 1090 (no loss supplied for SingleUpdateStep)
I1110 22:53:11.550799  2593 solver.cpp:310]     Train net output #0: loss = 0.566439 (* 1 = 0.566439 loss)
I1110 22:53:11.550818  2593 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I1110 22:53:13.753764  2593 solver.cpp:295] Iteration 1091 (no loss supplied for SingleUpdateStep)
I1110 22:53:13.753826  2593 solver.cpp:310]     Train net output #0: loss = 0.593867 (* 1 = 0.593867 loss)
I1110 22:53:13.753847  2593 sgd_solver.cpp:106] Iteration 1091, lr = 0.001
I1110 22:53:15.862828  2593 solver.cpp:295] Iteration 1092 (no loss supplied for SingleUpdateStep)
I1110 22:53:15.862949  2593 solver.cpp:310]     Train net output #0: loss = 0.569978 (* 1 = 0.569978 loss)
I1110 22:53:15.862973  2593 sgd_solver.cpp:106] Iteration 1092, lr = 0.001
I1110 22:53:18.140488  2593 solver.cpp:295] Iteration 1093 (no loss supplied for SingleUpdateStep)
I1110 22:53:18.140573  2593 solver.cpp:310]     Train net output #0: loss = 0.628753 (* 1 = 0.628753 loss)
I1110 22:53:18.140594  2593 sgd_solver.cpp:106] Iteration 1093, lr = 0.001
I1110 22:53:20.219621  2593 solver.cpp:295] Iteration 1094 (no loss supplied for SingleUpdateStep)
I1110 22:53:20.219722  2593 solver.cpp:310]     Train net output #0: loss = 0.586638 (* 1 = 0.586638 loss)
I1110 22:53:20.219744  2593 sgd_solver.cpp:106] Iteration 1094, lr = 0.001
I1110 22:53:22.523075  2593 solver.cpp:295] Iteration 1095 (no loss supplied for SingleUpdateStep)
I1110 22:53:22.523185  2593 solver.cpp:310]     Train net output #0: loss = 0.538518 (* 1 = 0.538518 loss)
I1110 22:53:22.523208  2593 sgd_solver.cpp:106] Iteration 1095, lr = 0.001
I1110 22:53:25.032425  2593 solver.cpp:295] Iteration 1096 (no loss supplied for SingleUpdateStep)
I1110 22:53:25.032537  2593 solver.cpp:310]     Train net output #0: loss = 0.563861 (* 1 = 0.563861 loss)
I1110 22:53:25.032565  2593 sgd_solver.cpp:106] Iteration 1096, lr = 0.001
I1110 22:53:27.392846  2593 solver.cpp:295] Iteration 1097 (no loss supplied for SingleUpdateStep)
I1110 22:53:27.392946  2593 solver.cpp:310]     Train net output #0: loss = 0.563279 (* 1 = 0.563279 loss)
I1110 22:53:27.392966  2593 sgd_solver.cpp:106] Iteration 1097, lr = 0.001
I1110 22:53:29.721246  2593 solver.cpp:295] Iteration 1098 (no loss supplied for SingleUpdateStep)
I1110 22:53:29.721364  2593 solver.cpp:310]     Train net output #0: loss = 0.569363 (* 1 = 0.569363 loss)
I1110 22:53:29.721385  2593 sgd_solver.cpp:106] Iteration 1098, lr = 0.001
I1110 22:53:32.175568  2593 solver.cpp:295] Iteration 1099 (no loss supplied for SingleUpdateStep)
I1110 22:53:32.175638  2593 solver.cpp:310]     Train net output #0: loss = 0.577701 (* 1 = 0.577701 loss)
I1110 22:53:32.175659  2593 sgd_solver.cpp:106] Iteration 1099, lr = 0.001
I1110 22:53:35.106609  2593 solver.cpp:295] Iteration 1100 (no loss supplied for SingleUpdateStep)
I1110 22:53:35.106731  2593 solver.cpp:310]     Train net output #0: loss = 0.540038 (* 1 = 0.540038 loss)
I1110 22:53:35.106760  2593 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I1110 22:53:38.021812  2593 solver.cpp:295] Iteration 1101 (no loss supplied for SingleUpdateStep)
I1110 22:53:38.021914  2593 solver.cpp:310]     Train net output #0: loss = 0.558136 (* 1 = 0.558136 loss)
I1110 22:53:38.021935  2593 sgd_solver.cpp:106] Iteration 1101, lr = 0.001
I1110 22:53:41.511567  2593 solver.cpp:295] Iteration 1102 (no loss supplied for SingleUpdateStep)
I1110 22:53:41.511731  2593 solver.cpp:310]     Train net output #0: loss = 0.607099 (* 1 = 0.607099 loss)
I1110 22:53:41.511755  2593 sgd_solver.cpp:106] Iteration 1102, lr = 0.001
I1110 22:53:44.136595  2593 solver.cpp:295] Iteration 1103 (no loss supplied for SingleUpdateStep)
I1110 22:53:44.136657  2593 solver.cpp:310]     Train net output #0: loss = 0.563149 (* 1 = 0.563149 loss)
I1110 22:53:44.136677  2593 sgd_solver.cpp:106] Iteration 1103, lr = 0.001
I1110 22:53:46.376637  2593 solver.cpp:295] Iteration 1104 (no loss supplied for SingleUpdateStep)
I1110 22:53:46.376724  2593 solver.cpp:310]     Train net output #0: loss = 0.533575 (* 1 = 0.533575 loss)
I1110 22:53:46.376747  2593 sgd_solver.cpp:106] Iteration 1104, lr = 0.001
I1110 22:53:48.668097  2593 solver.cpp:295] Iteration 1105 (no loss supplied for SingleUpdateStep)
I1110 22:53:48.668198  2593 solver.cpp:310]     Train net output #0: loss = 0.536569 (* 1 = 0.536569 loss)
I1110 22:53:48.668222  2593 sgd_solver.cpp:106] Iteration 1105, lr = 0.001
I1110 22:53:50.952177  2593 solver.cpp:295] Iteration 1106 (no loss supplied for SingleUpdateStep)
I1110 22:53:50.952252  2593 solver.cpp:310]     Train net output #0: loss = 0.573238 (* 1 = 0.573238 loss)
I1110 22:53:50.952271  2593 sgd_solver.cpp:106] Iteration 1106, lr = 0.001
I1110 22:53:53.124023  2593 solver.cpp:295] Iteration 1107 (no loss supplied for SingleUpdateStep)
I1110 22:53:53.124158  2593 solver.cpp:310]     Train net output #0: loss = 0.514325 (* 1 = 0.514325 loss)
I1110 22:53:53.124182  2593 sgd_solver.cpp:106] Iteration 1107, lr = 0.001
I1110 22:53:55.434326  2593 solver.cpp:295] Iteration 1108 (no loss supplied for SingleUpdateStep)
I1110 22:53:55.434435  2593 solver.cpp:310]     Train net output #0: loss = 0.542069 (* 1 = 0.542069 loss)
I1110 22:53:55.434458  2593 sgd_solver.cpp:106] Iteration 1108, lr = 0.001
I1110 22:53:57.755822  2593 solver.cpp:295] Iteration 1109 (no loss supplied for SingleUpdateStep)
I1110 22:53:57.755972  2593 solver.cpp:310]     Train net output #0: loss = 0.506778 (* 1 = 0.506778 loss)
I1110 22:53:57.755998  2593 sgd_solver.cpp:106] Iteration 1109, lr = 0.001
I1110 22:53:59.966573  2593 solver.cpp:295] Iteration 1110 (no loss supplied for SingleUpdateStep)
I1110 22:53:59.966670  2593 solver.cpp:310]     Train net output #0: loss = 0.590474 (* 1 = 0.590474 loss)
I1110 22:53:59.966691  2593 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I1110 22:54:02.156237  2593 solver.cpp:295] Iteration 1111 (no loss supplied for SingleUpdateStep)
I1110 22:54:02.156363  2593 solver.cpp:310]     Train net output #0: loss = 0.567329 (* 1 = 0.567329 loss)
I1110 22:54:02.156388  2593 sgd_solver.cpp:106] Iteration 1111, lr = 0.001
I1110 22:54:04.331245  2593 solver.cpp:295] Iteration 1112 (no loss supplied for SingleUpdateStep)
I1110 22:54:04.331413  2593 solver.cpp:310]     Train net output #0: loss = 0.537845 (* 1 = 0.537845 loss)
I1110 22:54:04.331454  2593 sgd_solver.cpp:106] Iteration 1112, lr = 0.001
I1110 22:54:06.610765  2593 solver.cpp:295] Iteration 1113 (no loss supplied for SingleUpdateStep)
I1110 22:54:06.610852  2593 solver.cpp:310]     Train net output #0: loss = 0.530032 (* 1 = 0.530032 loss)
I1110 22:54:06.610873  2593 sgd_solver.cpp:106] Iteration 1113, lr = 0.001
I1110 22:54:08.836753  2593 solver.cpp:295] Iteration 1114 (no loss supplied for SingleUpdateStep)
I1110 22:54:08.836868  2593 solver.cpp:310]     Train net output #0: loss = 0.537225 (* 1 = 0.537225 loss)
I1110 22:54:08.836890  2593 sgd_solver.cpp:106] Iteration 1114, lr = 0.001
I1110 22:54:11.070271  2593 solver.cpp:295] Iteration 1115 (no loss supplied for SingleUpdateStep)
I1110 22:54:11.070392  2593 solver.cpp:310]     Train net output #0: loss = 0.545294 (* 1 = 0.545294 loss)
I1110 22:54:11.070415  2593 sgd_solver.cpp:106] Iteration 1115, lr = 0.001
I1110 22:54:13.377883  2593 solver.cpp:295] Iteration 1116 (no loss supplied for SingleUpdateStep)
I1110 22:54:13.378000  2593 solver.cpp:310]     Train net output #0: loss = 0.542831 (* 1 = 0.542831 loss)
I1110 22:54:13.378021  2593 sgd_solver.cpp:106] Iteration 1116, lr = 0.001
I1110 22:54:15.478832  2593 solver.cpp:295] Iteration 1117 (no loss supplied for SingleUpdateStep)
I1110 22:54:15.478955  2593 solver.cpp:310]     Train net output #0: loss = 0.554627 (* 1 = 0.554627 loss)
I1110 22:54:15.478982  2593 sgd_solver.cpp:106] Iteration 1117, lr = 0.001
I1110 22:54:17.872045  2593 solver.cpp:295] Iteration 1118 (no loss supplied for SingleUpdateStep)
I1110 22:54:17.872144  2593 solver.cpp:310]     Train net output #0: loss = 0.52598 (* 1 = 0.52598 loss)
I1110 22:54:17.872167  2593 sgd_solver.cpp:106] Iteration 1118, lr = 0.001
I1110 22:54:20.120914  2593 solver.cpp:295] Iteration 1119 (no loss supplied for SingleUpdateStep)
I1110 22:54:20.121018  2593 solver.cpp:310]     Train net output #0: loss = 0.541478 (* 1 = 0.541478 loss)
I1110 22:54:20.121039  2593 sgd_solver.cpp:106] Iteration 1119, lr = 0.001
I1110 22:54:22.194991  2593 solver.cpp:295] Iteration 1120 (no loss supplied for SingleUpdateStep)
I1110 22:54:22.195094  2593 solver.cpp:310]     Train net output #0: loss = 0.573859 (* 1 = 0.573859 loss)
I1110 22:54:22.195116  2593 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I1110 22:54:24.406939  2593 solver.cpp:295] Iteration 1121 (no loss supplied for SingleUpdateStep)
I1110 22:54:24.407043  2593 solver.cpp:310]     Train net output #0: loss = 0.53765 (* 1 = 0.53765 loss)
I1110 22:54:24.407065  2593 sgd_solver.cpp:106] Iteration 1121, lr = 0.001
I1110 22:54:27.237637  2593 solver.cpp:295] Iteration 1122 (no loss supplied for SingleUpdateStep)
I1110 22:54:27.237750  2593 solver.cpp:310]     Train net output #0: loss = 0.518611 (* 1 = 0.518611 loss)
I1110 22:54:27.237771  2593 sgd_solver.cpp:106] Iteration 1122, lr = 0.001
I1110 22:54:29.938990  2593 solver.cpp:295] Iteration 1123 (no loss supplied for SingleUpdateStep)
I1110 22:54:29.939132  2593 solver.cpp:310]     Train net output #0: loss = 0.535189 (* 1 = 0.535189 loss)
I1110 22:54:29.939155  2593 sgd_solver.cpp:106] Iteration 1123, lr = 0.001
I1110 22:54:32.981639  2593 solver.cpp:295] Iteration 1124 (no loss supplied for SingleUpdateStep)
I1110 22:54:32.981693  2593 solver.cpp:310]     Train net output #0: loss = 0.559034 (* 1 = 0.559034 loss)
I1110 22:54:32.981710  2593 sgd_solver.cpp:106] Iteration 1124, lr = 0.001
I1110 22:54:36.068284  2593 solver.cpp:295] Iteration 1125 (no loss supplied for SingleUpdateStep)
I1110 22:54:36.068356  2593 solver.cpp:310]     Train net output #0: loss = 0.577412 (* 1 = 0.577412 loss)
I1110 22:54:36.068377  2593 sgd_solver.cpp:106] Iteration 1125, lr = 0.001
I1110 22:54:38.623270  2593 solver.cpp:295] Iteration 1126 (no loss supplied for SingleUpdateStep)
I1110 22:54:38.623342  2593 solver.cpp:310]     Train net output #0: loss = 0.558356 (* 1 = 0.558356 loss)
I1110 22:54:38.623363  2593 sgd_solver.cpp:106] Iteration 1126, lr = 0.001
I1110 22:54:41.006695  2593 solver.cpp:295] Iteration 1127 (no loss supplied for SingleUpdateStep)
I1110 22:54:41.006793  2593 solver.cpp:310]     Train net output #0: loss = 0.571095 (* 1 = 0.571095 loss)
I1110 22:54:41.006815  2593 sgd_solver.cpp:106] Iteration 1127, lr = 0.001
I1110 22:54:43.770995  2593 solver.cpp:295] Iteration 1128 (no loss supplied for SingleUpdateStep)
I1110 22:54:43.771131  2593 solver.cpp:310]     Train net output #0: loss = 0.529564 (* 1 = 0.529564 loss)
I1110 22:54:43.771157  2593 sgd_solver.cpp:106] Iteration 1128, lr = 0.001
I1110 22:54:46.285604  2593 solver.cpp:295] Iteration 1129 (no loss supplied for SingleUpdateStep)
I1110 22:54:46.285711  2593 solver.cpp:310]     Train net output #0: loss = 0.579698 (* 1 = 0.579698 loss)
I1110 22:54:46.285732  2593 sgd_solver.cpp:106] Iteration 1129, lr = 0.001
I1110 22:54:48.680981  2593 solver.cpp:295] Iteration 1130 (no loss supplied for SingleUpdateStep)
I1110 22:54:48.681066  2593 solver.cpp:310]     Train net output #0: loss = 0.555968 (* 1 = 0.555968 loss)
I1110 22:54:48.681087  2593 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I1110 22:54:50.884333  2593 solver.cpp:295] Iteration 1131 (no loss supplied for SingleUpdateStep)
I1110 22:54:50.884410  2593 solver.cpp:310]     Train net output #0: loss = 0.556151 (* 1 = 0.556151 loss)
I1110 22:54:50.884430  2593 sgd_solver.cpp:106] Iteration 1131, lr = 0.001
I1110 22:54:53.202560  2593 solver.cpp:295] Iteration 1132 (no loss supplied for SingleUpdateStep)
I1110 22:54:53.202687  2593 solver.cpp:310]     Train net output #0: loss = 0.552213 (* 1 = 0.552213 loss)
I1110 22:54:53.202710  2593 sgd_solver.cpp:106] Iteration 1132, lr = 0.001
I1110 22:54:56.118971  2593 solver.cpp:295] Iteration 1133 (no loss supplied for SingleUpdateStep)
I1110 22:54:56.119070  2593 solver.cpp:310]     Train net output #0: loss = 0.562038 (* 1 = 0.562038 loss)
I1110 22:54:56.119092  2593 sgd_solver.cpp:106] Iteration 1133, lr = 0.001
I1110 22:54:58.796869  2593 solver.cpp:295] Iteration 1134 (no loss supplied for SingleUpdateStep)
I1110 22:54:58.796946  2593 solver.cpp:310]     Train net output #0: loss = 0.561435 (* 1 = 0.561435 loss)
I1110 22:54:58.796965  2593 sgd_solver.cpp:106] Iteration 1134, lr = 0.001
I1110 22:55:01.125648  2593 solver.cpp:295] Iteration 1135 (no loss supplied for SingleUpdateStep)
I1110 22:55:01.125740  2593 solver.cpp:310]     Train net output #0: loss = 0.57229 (* 1 = 0.57229 loss)
I1110 22:55:01.125761  2593 sgd_solver.cpp:106] Iteration 1135, lr = 0.001
I1110 22:55:03.588474  2593 solver.cpp:295] Iteration 1136 (no loss supplied for SingleUpdateStep)
I1110 22:55:03.588611  2593 solver.cpp:310]     Train net output #0: loss = 0.537681 (* 1 = 0.537681 loss)
I1110 22:55:03.588644  2593 sgd_solver.cpp:106] Iteration 1136, lr = 0.001
I1110 22:55:06.194402  2593 solver.cpp:295] Iteration 1137 (no loss supplied for SingleUpdateStep)
I1110 22:55:06.194521  2593 solver.cpp:310]     Train net output #0: loss = 0.543671 (* 1 = 0.543671 loss)
I1110 22:55:06.194546  2593 sgd_solver.cpp:106] Iteration 1137, lr = 0.001
I1110 22:55:08.612709  2593 solver.cpp:295] Iteration 1138 (no loss supplied for SingleUpdateStep)
I1110 22:55:08.612838  2593 solver.cpp:310]     Train net output #0: loss = 0.521582 (* 1 = 0.521582 loss)
I1110 22:55:08.612860  2593 sgd_solver.cpp:106] Iteration 1138, lr = 0.001
I1110 22:55:11.264595  2593 solver.cpp:295] Iteration 1139 (no loss supplied for SingleUpdateStep)
I1110 22:55:11.264700  2593 solver.cpp:310]     Train net output #0: loss = 0.519638 (* 1 = 0.519638 loss)
I1110 22:55:11.264724  2593 sgd_solver.cpp:106] Iteration 1139, lr = 0.001
I1110 22:55:13.748744  2593 solver.cpp:295] Iteration 1140 (no loss supplied for SingleUpdateStep)
I1110 22:55:13.748836  2593 solver.cpp:310]     Train net output #0: loss = 0.536933 (* 1 = 0.536933 loss)
I1110 22:55:13.748857  2593 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I1110 22:55:16.150346  2593 solver.cpp:295] Iteration 1141 (no loss supplied for SingleUpdateStep)
I1110 22:55:16.150446  2593 solver.cpp:310]     Train net output #0: loss = 0.570393 (* 1 = 0.570393 loss)
I1110 22:55:16.150466  2593 sgd_solver.cpp:106] Iteration 1141, lr = 0.001
I1110 22:55:18.339805  2593 solver.cpp:295] Iteration 1142 (no loss supplied for SingleUpdateStep)
I1110 22:55:18.339892  2593 solver.cpp:310]     Train net output #0: loss = 0.552686 (* 1 = 0.552686 loss)
I1110 22:55:18.339916  2593 sgd_solver.cpp:106] Iteration 1142, lr = 0.001
I1110 22:55:20.738458  2593 solver.cpp:295] Iteration 1143 (no loss supplied for SingleUpdateStep)
I1110 22:55:20.738598  2593 solver.cpp:310]     Train net output #0: loss = 0.504766 (* 1 = 0.504766 loss)
I1110 22:55:20.738631  2593 sgd_solver.cpp:106] Iteration 1143, lr = 0.001
I1110 22:55:22.953194  2593 solver.cpp:295] Iteration 1144 (no loss supplied for SingleUpdateStep)
I1110 22:55:22.953342  2593 solver.cpp:310]     Train net output #0: loss = 0.518952 (* 1 = 0.518952 loss)
I1110 22:55:22.953366  2593 sgd_solver.cpp:106] Iteration 1144, lr = 0.001
I1110 22:55:25.102578  2593 solver.cpp:295] Iteration 1145 (no loss supplied for SingleUpdateStep)
I1110 22:55:25.102746  2593 solver.cpp:310]     Train net output #0: loss = 0.540926 (* 1 = 0.540926 loss)
I1110 22:55:25.102772  2593 sgd_solver.cpp:106] Iteration 1145, lr = 0.001
I1110 22:55:27.205621  2593 solver.cpp:295] Iteration 1146 (no loss supplied for SingleUpdateStep)
I1110 22:55:27.205801  2593 solver.cpp:310]     Train net output #0: loss = 0.522524 (* 1 = 0.522524 loss)
I1110 22:55:27.205835  2593 sgd_solver.cpp:106] Iteration 1146, lr = 0.001
I1110 22:55:29.551544  2593 solver.cpp:295] Iteration 1147 (no loss supplied for SingleUpdateStep)
I1110 22:55:29.551654  2593 solver.cpp:310]     Train net output #0: loss = 0.542328 (* 1 = 0.542328 loss)
I1110 22:55:29.551676  2593 sgd_solver.cpp:106] Iteration 1147, lr = 0.001
I1110 22:55:31.596972  2593 solver.cpp:295] Iteration 1148 (no loss supplied for SingleUpdateStep)
I1110 22:55:31.597049  2593 solver.cpp:310]     Train net output #0: loss = 0.527352 (* 1 = 0.527352 loss)
I1110 22:55:31.597070  2593 sgd_solver.cpp:106] Iteration 1148, lr = 0.001
I1110 22:55:34.087208  2593 solver.cpp:295] Iteration 1149 (no loss supplied for SingleUpdateStep)
I1110 22:55:34.087301  2593 solver.cpp:310]     Train net output #0: loss = 0.52209 (* 1 = 0.52209 loss)
I1110 22:55:34.087324  2593 sgd_solver.cpp:106] Iteration 1149, lr = 0.001
I1110 22:55:36.433303  2593 solver.cpp:295] Iteration 1150 (no loss supplied for SingleUpdateStep)
I1110 22:55:36.433436  2593 solver.cpp:310]     Train net output #0: loss = 0.570081 (* 1 = 0.570081 loss)
I1110 22:55:36.433462  2593 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I1110 22:55:38.838795  2593 solver.cpp:295] Iteration 1151 (no loss supplied for SingleUpdateStep)
I1110 22:55:38.838871  2593 solver.cpp:310]     Train net output #0: loss = 0.546933 (* 1 = 0.546933 loss)
I1110 22:55:38.838891  2593 sgd_solver.cpp:106] Iteration 1151, lr = 0.001
I1110 22:55:41.890645  2593 solver.cpp:295] Iteration 1152 (no loss supplied for SingleUpdateStep)
I1110 22:55:41.890734  2593 solver.cpp:310]     Train net output #0: loss = 0.535969 (* 1 = 0.535969 loss)
I1110 22:55:41.890754  2593 sgd_solver.cpp:106] Iteration 1152, lr = 0.001
I1110 22:55:44.235266  2593 solver.cpp:295] Iteration 1153 (no loss supplied for SingleUpdateStep)
I1110 22:55:44.235374  2593 solver.cpp:310]     Train net output #0: loss = 0.541662 (* 1 = 0.541662 loss)
I1110 22:55:44.235396  2593 sgd_solver.cpp:106] Iteration 1153, lr = 0.001
I1110 22:55:46.388154  2593 solver.cpp:295] Iteration 1154 (no loss supplied for SingleUpdateStep)
I1110 22:55:46.388207  2593 solver.cpp:310]     Train net output #0: loss = 0.537585 (* 1 = 0.537585 loss)
I1110 22:55:46.388226  2593 sgd_solver.cpp:106] Iteration 1154, lr = 0.001
I1110 22:55:48.665601  2593 solver.cpp:295] Iteration 1155 (no loss supplied for SingleUpdateStep)
I1110 22:55:48.665705  2593 solver.cpp:310]     Train net output #0: loss = 0.547896 (* 1 = 0.547896 loss)
I1110 22:55:48.665727  2593 sgd_solver.cpp:106] Iteration 1155, lr = 0.001
I1110 22:55:50.829705  2593 solver.cpp:295] Iteration 1156 (no loss supplied for SingleUpdateStep)
I1110 22:55:50.829823  2593 solver.cpp:310]     Train net output #0: loss = 0.526379 (* 1 = 0.526379 loss)
I1110 22:55:50.829849  2593 sgd_solver.cpp:106] Iteration 1156, lr = 0.001
I1110 22:55:53.038118  2593 solver.cpp:295] Iteration 1157 (no loss supplied for SingleUpdateStep)
I1110 22:55:53.038174  2593 solver.cpp:310]     Train net output #0: loss = 0.573734 (* 1 = 0.573734 loss)
I1110 22:55:53.038192  2593 sgd_solver.cpp:106] Iteration 1157, lr = 0.001
I1110 22:55:55.204941  2593 solver.cpp:295] Iteration 1158 (no loss supplied for SingleUpdateStep)
I1110 22:55:55.204995  2593 solver.cpp:310]     Train net output #0: loss = 0.560696 (* 1 = 0.560696 loss)
I1110 22:55:55.205014  2593 sgd_solver.cpp:106] Iteration 1158, lr = 0.001
I1110 22:55:57.412077  2593 solver.cpp:295] Iteration 1159 (no loss supplied for SingleUpdateStep)
I1110 22:55:57.412137  2593 solver.cpp:310]     Train net output #0: loss = 0.543344 (* 1 = 0.543344 loss)
I1110 22:55:57.412155  2593 sgd_solver.cpp:106] Iteration 1159, lr = 0.001
I1110 22:55:59.722872  2593 solver.cpp:295] Iteration 1160 (no loss supplied for SingleUpdateStep)
I1110 22:55:59.723009  2593 solver.cpp:310]     Train net output #0: loss = 0.538525 (* 1 = 0.538525 loss)
I1110 22:55:59.723037  2593 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I1110 22:56:01.835326  2593 solver.cpp:295] Iteration 1161 (no loss supplied for SingleUpdateStep)
I1110 22:56:01.835397  2593 solver.cpp:310]     Train net output #0: loss = 0.595017 (* 1 = 0.595017 loss)
I1110 22:56:01.835417  2593 sgd_solver.cpp:106] Iteration 1161, lr = 0.001
I1110 22:56:03.935104  2593 solver.cpp:295] Iteration 1162 (no loss supplied for SingleUpdateStep)
I1110 22:56:03.935258  2593 solver.cpp:310]     Train net output #0: loss = 0.569251 (* 1 = 0.569251 loss)
I1110 22:56:03.935286  2593 sgd_solver.cpp:106] Iteration 1162, lr = 0.001
I1110 22:56:06.118482  2593 solver.cpp:295] Iteration 1163 (no loss supplied for SingleUpdateStep)
I1110 22:56:06.118626  2593 solver.cpp:310]     Train net output #0: loss = 0.519208 (* 1 = 0.519208 loss)
I1110 22:56:06.118657  2593 sgd_solver.cpp:106] Iteration 1163, lr = 0.001
I1110 22:56:08.326047  2593 solver.cpp:295] Iteration 1164 (no loss supplied for SingleUpdateStep)
I1110 22:56:08.326124  2593 solver.cpp:310]     Train net output #0: loss = 0.511386 (* 1 = 0.511386 loss)
I1110 22:56:08.326144  2593 sgd_solver.cpp:106] Iteration 1164, lr = 0.001
I1110 22:56:10.458670  2593 solver.cpp:295] Iteration 1165 (no loss supplied for SingleUpdateStep)
I1110 22:56:10.458762  2593 solver.cpp:310]     Train net output #0: loss = 0.539262 (* 1 = 0.539262 loss)
I1110 22:56:10.458786  2593 sgd_solver.cpp:106] Iteration 1165, lr = 0.001
I1110 22:56:12.512183  2593 solver.cpp:295] Iteration 1166 (no loss supplied for SingleUpdateStep)
I1110 22:56:12.512291  2593 solver.cpp:310]     Train net output #0: loss = 0.535298 (* 1 = 0.535298 loss)
I1110 22:56:12.512311  2593 sgd_solver.cpp:106] Iteration 1166, lr = 0.001
I1110 22:56:14.719640  2593 solver.cpp:295] Iteration 1167 (no loss supplied for SingleUpdateStep)
I1110 22:56:14.719758  2593 solver.cpp:310]     Train net output #0: loss = 0.541916 (* 1 = 0.541916 loss)
I1110 22:56:14.719784  2593 sgd_solver.cpp:106] Iteration 1167, lr = 0.001
I1110 22:56:16.923033  2593 solver.cpp:295] Iteration 1168 (no loss supplied for SingleUpdateStep)
I1110 22:56:16.923136  2593 solver.cpp:310]     Train net output #0: loss = 0.551803 (* 1 = 0.551803 loss)
I1110 22:56:16.923157  2593 sgd_solver.cpp:106] Iteration 1168, lr = 0.001
I1110 22:56:19.208955  2593 solver.cpp:295] Iteration 1169 (no loss supplied for SingleUpdateStep)
I1110 22:56:19.209064  2593 solver.cpp:310]     Train net output #0: loss = 0.549254 (* 1 = 0.549254 loss)
I1110 22:56:19.209084  2593 sgd_solver.cpp:106] Iteration 1169, lr = 0.001
I1110 22:56:21.575234  2593 solver.cpp:295] Iteration 1170 (no loss supplied for SingleUpdateStep)
I1110 22:56:21.575350  2593 solver.cpp:310]     Train net output #0: loss = 0.565786 (* 1 = 0.565786 loss)
I1110 22:56:21.575373  2593 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I1110 22:56:23.721974  2593 solver.cpp:295] Iteration 1171 (no loss supplied for SingleUpdateStep)
I1110 22:56:23.722071  2593 solver.cpp:310]     Train net output #0: loss = 0.557595 (* 1 = 0.557595 loss)
I1110 22:56:23.722092  2593 sgd_solver.cpp:106] Iteration 1171, lr = 0.001
I1110 22:56:25.823834  2593 solver.cpp:295] Iteration 1172 (no loss supplied for SingleUpdateStep)
I1110 22:56:25.823940  2593 solver.cpp:310]     Train net output #0: loss = 0.561989 (* 1 = 0.561989 loss)
I1110 22:56:25.823964  2593 sgd_solver.cpp:106] Iteration 1172, lr = 0.001
I1110 22:56:28.179958  2593 solver.cpp:295] Iteration 1173 (no loss supplied for SingleUpdateStep)
I1110 22:56:28.180068  2593 solver.cpp:310]     Train net output #0: loss = 0.543906 (* 1 = 0.543906 loss)
I1110 22:56:28.180091  2593 sgd_solver.cpp:106] Iteration 1173, lr = 0.001
I1110 22:56:30.425495  2593 solver.cpp:295] Iteration 1174 (no loss supplied for SingleUpdateStep)
I1110 22:56:30.425612  2593 solver.cpp:310]     Train net output #0: loss = 0.485797 (* 1 = 0.485797 loss)
I1110 22:56:30.425637  2593 sgd_solver.cpp:106] Iteration 1174, lr = 0.001
I1110 22:56:32.798861  2593 solver.cpp:295] Iteration 1175 (no loss supplied for SingleUpdateStep)
I1110 22:56:32.799021  2593 solver.cpp:310]     Train net output #0: loss = 0.510904 (* 1 = 0.510904 loss)
I1110 22:56:32.799059  2593 sgd_solver.cpp:106] Iteration 1175, lr = 0.001
I1110 22:56:35.270864  2593 solver.cpp:295] Iteration 1176 (no loss supplied for SingleUpdateStep)
I1110 22:56:35.271075  2593 solver.cpp:310]     Train net output #0: loss = 0.514018 (* 1 = 0.514018 loss)
I1110 22:56:35.271116  2593 sgd_solver.cpp:106] Iteration 1176, lr = 0.001
I1110 22:56:37.807808  2593 solver.cpp:295] Iteration 1177 (no loss supplied for SingleUpdateStep)
I1110 22:56:37.807982  2593 solver.cpp:310]     Train net output #0: loss = 0.549444 (* 1 = 0.549444 loss)
I1110 22:56:37.808009  2593 sgd_solver.cpp:106] Iteration 1177, lr = 0.001
I1110 22:56:40.223749  2593 solver.cpp:295] Iteration 1178 (no loss supplied for SingleUpdateStep)
I1110 22:56:40.223845  2593 solver.cpp:310]     Train net output #0: loss = 0.514125 (* 1 = 0.514125 loss)
I1110 22:56:40.223867  2593 sgd_solver.cpp:106] Iteration 1178, lr = 0.001
I1110 22:56:42.684945  2593 solver.cpp:295] Iteration 1179 (no loss supplied for SingleUpdateStep)
I1110 22:56:42.685073  2593 solver.cpp:310]     Train net output #0: loss = 0.519266 (* 1 = 0.519266 loss)
I1110 22:56:42.685098  2593 sgd_solver.cpp:106] Iteration 1179, lr = 0.001
I1110 22:56:45.084156  2593 solver.cpp:295] Iteration 1180 (no loss supplied for SingleUpdateStep)
I1110 22:56:45.084210  2593 solver.cpp:310]     Train net output #0: loss = 0.545581 (* 1 = 0.545581 loss)
I1110 22:56:45.084229  2593 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I1110 22:56:47.432272  2593 solver.cpp:295] Iteration 1181 (no loss supplied for SingleUpdateStep)
I1110 22:56:47.432361  2593 solver.cpp:310]     Train net output #0: loss = 0.562136 (* 1 = 0.562136 loss)
I1110 22:56:47.432381  2593 sgd_solver.cpp:106] Iteration 1181, lr = 0.001
I1110 22:56:49.665860  2593 solver.cpp:295] Iteration 1182 (no loss supplied for SingleUpdateStep)
I1110 22:56:49.665963  2593 solver.cpp:310]     Train net output #0: loss = 0.512895 (* 1 = 0.512895 loss)
I1110 22:56:49.665984  2593 sgd_solver.cpp:106] Iteration 1182, lr = 0.001
I1110 22:56:51.916124  2593 solver.cpp:295] Iteration 1183 (no loss supplied for SingleUpdateStep)
I1110 22:56:51.916201  2593 solver.cpp:310]     Train net output #0: loss = 0.535767 (* 1 = 0.535767 loss)
I1110 22:56:51.916223  2593 sgd_solver.cpp:106] Iteration 1183, lr = 0.001
I1110 22:56:54.138690  2593 solver.cpp:295] Iteration 1184 (no loss supplied for SingleUpdateStep)
I1110 22:56:54.138828  2593 solver.cpp:310]     Train net output #0: loss = 0.567191 (* 1 = 0.567191 loss)
I1110 22:56:54.138855  2593 sgd_solver.cpp:106] Iteration 1184, lr = 0.001
I1110 22:56:56.464419  2593 solver.cpp:295] Iteration 1185 (no loss supplied for SingleUpdateStep)
I1110 22:56:56.464529  2593 solver.cpp:310]     Train net output #0: loss = 0.529454 (* 1 = 0.529454 loss)
I1110 22:56:56.464551  2593 sgd_solver.cpp:106] Iteration 1185, lr = 0.001
I1110 22:56:58.618913  2593 solver.cpp:295] Iteration 1186 (no loss supplied for SingleUpdateStep)
I1110 22:56:58.618998  2593 solver.cpp:310]     Train net output #0: loss = 0.549507 (* 1 = 0.549507 loss)
I1110 22:56:58.619019  2593 sgd_solver.cpp:106] Iteration 1186, lr = 0.001
I1110 22:57:00.876580  2593 solver.cpp:295] Iteration 1187 (no loss supplied for SingleUpdateStep)
I1110 22:57:00.876652  2593 solver.cpp:310]     Train net output #0: loss = 0.524362 (* 1 = 0.524362 loss)
I1110 22:57:00.876672  2593 sgd_solver.cpp:106] Iteration 1187, lr = 0.001
I1110 22:57:02.925518  2593 solver.cpp:295] Iteration 1188 (no loss supplied for SingleUpdateStep)
I1110 22:57:02.925664  2593 solver.cpp:310]     Train net output #0: loss = 0.540595 (* 1 = 0.540595 loss)
I1110 22:57:02.925688  2593 sgd_solver.cpp:106] Iteration 1188, lr = 0.001
I1110 22:57:05.230234  2593 solver.cpp:295] Iteration 1189 (no loss supplied for SingleUpdateStep)
I1110 22:57:05.230321  2593 solver.cpp:310]     Train net output #0: loss = 0.525099 (* 1 = 0.525099 loss)
I1110 22:57:05.230341  2593 sgd_solver.cpp:106] Iteration 1189, lr = 0.001
I1110 22:57:07.363418  2593 solver.cpp:295] Iteration 1190 (no loss supplied for SingleUpdateStep)
I1110 22:57:07.363525  2593 solver.cpp:310]     Train net output #0: loss = 0.537392 (* 1 = 0.537392 loss)
I1110 22:57:07.363546  2593 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I1110 22:57:09.549149  2593 solver.cpp:295] Iteration 1191 (no loss supplied for SingleUpdateStep)
I1110 22:57:09.549275  2593 solver.cpp:310]     Train net output #0: loss = 0.515383 (* 1 = 0.515383 loss)
I1110 22:57:09.549299  2593 sgd_solver.cpp:106] Iteration 1191, lr = 0.001
I1110 22:57:11.721952  2593 solver.cpp:295] Iteration 1192 (no loss supplied for SingleUpdateStep)
I1110 22:57:11.722110  2593 solver.cpp:310]     Train net output #0: loss = 0.54378 (* 1 = 0.54378 loss)
I1110 22:57:11.722162  2593 sgd_solver.cpp:106] Iteration 1192, lr = 0.001
I1110 22:57:13.898411  2593 solver.cpp:295] Iteration 1193 (no loss supplied for SingleUpdateStep)
I1110 22:57:13.898540  2593 solver.cpp:310]     Train net output #0: loss = 0.544103 (* 1 = 0.544103 loss)
I1110 22:57:13.898562  2593 sgd_solver.cpp:106] Iteration 1193, lr = 0.001
I1110 22:57:16.077812  2593 solver.cpp:295] Iteration 1194 (no loss supplied for SingleUpdateStep)
I1110 22:57:16.077869  2593 solver.cpp:310]     Train net output #0: loss = 0.556459 (* 1 = 0.556459 loss)
I1110 22:57:16.077888  2593 sgd_solver.cpp:106] Iteration 1194, lr = 0.001
I1110 22:57:18.268643  2593 solver.cpp:295] Iteration 1195 (no loss supplied for SingleUpdateStep)
I1110 22:57:18.268754  2593 solver.cpp:310]     Train net output #0: loss = 0.564934 (* 1 = 0.564934 loss)
I1110 22:57:18.268776  2593 sgd_solver.cpp:106] Iteration 1195, lr = 0.001
I1110 22:57:20.662487  2593 solver.cpp:295] Iteration 1196 (no loss supplied for SingleUpdateStep)
I1110 22:57:20.662600  2593 solver.cpp:310]     Train net output #0: loss = 0.570388 (* 1 = 0.570388 loss)
I1110 22:57:20.662624  2593 sgd_solver.cpp:106] Iteration 1196, lr = 0.001
I1110 22:57:22.874375  2593 solver.cpp:295] Iteration 1197 (no loss supplied for SingleUpdateStep)
I1110 22:57:22.874485  2593 solver.cpp:310]     Train net output #0: loss = 0.524363 (* 1 = 0.524363 loss)
I1110 22:57:22.874510  2593 sgd_solver.cpp:106] Iteration 1197, lr = 0.001
I1110 22:57:25.169201  2593 solver.cpp:295] Iteration 1198 (no loss supplied for SingleUpdateStep)
I1110 22:57:25.169313  2593 solver.cpp:310]     Train net output #0: loss = 0.547671 (* 1 = 0.547671 loss)
I1110 22:57:25.169335  2593 sgd_solver.cpp:106] Iteration 1198, lr = 0.001
I1110 22:57:27.401319  2593 solver.cpp:295] Iteration 1199 (no loss supplied for SingleUpdateStep)
I1110 22:57:27.401449  2593 solver.cpp:310]     Train net output #0: loss = 0.48988 (* 1 = 0.48988 loss)
I1110 22:57:27.401470  2593 sgd_solver.cpp:106] Iteration 1199, lr = 0.001
I1110 22:57:29.564646  2593 solver.cpp:295] Iteration 1200 (no loss supplied for SingleUpdateStep)
I1110 22:57:29.564769  2593 solver.cpp:310]     Train net output #0: loss = 0.524549 (* 1 = 0.524549 loss)
I1110 22:57:29.564795  2593 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I1110 22:57:31.699990  2593 solver.cpp:295] Iteration 1201 (no loss supplied for SingleUpdateStep)
I1110 22:57:31.700060  2593 solver.cpp:310]     Train net output #0: loss = 0.55964 (* 1 = 0.55964 loss)
I1110 22:57:31.700080  2593 sgd_solver.cpp:106] Iteration 1201, lr = 0.001
I1110 22:57:34.350541  2593 solver.cpp:295] Iteration 1202 (no loss supplied for SingleUpdateStep)
I1110 22:57:34.350622  2593 solver.cpp:310]     Train net output #0: loss = 0.544344 (* 1 = 0.544344 loss)
I1110 22:57:34.350646  2593 sgd_solver.cpp:106] Iteration 1202, lr = 0.001
I1110 22:57:36.565214  2593 solver.cpp:295] Iteration 1203 (no loss supplied for SingleUpdateStep)
I1110 22:57:36.565311  2593 solver.cpp:310]     Train net output #0: loss = 0.524409 (* 1 = 0.524409 loss)
I1110 22:57:36.565333  2593 sgd_solver.cpp:106] Iteration 1203, lr = 0.001
I1110 22:57:39.208612  2593 solver.cpp:295] Iteration 1204 (no loss supplied for SingleUpdateStep)
I1110 22:57:39.208698  2593 solver.cpp:310]     Train net output #0: loss = 0.522407 (* 1 = 0.522407 loss)
I1110 22:57:39.208717  2593 sgd_solver.cpp:106] Iteration 1204, lr = 0.001
I1110 22:57:42.435696  2593 solver.cpp:295] Iteration 1205 (no loss supplied for SingleUpdateStep)
I1110 22:57:42.435777  2593 solver.cpp:310]     Train net output #0: loss = 0.555187 (* 1 = 0.555187 loss)
I1110 22:57:42.435799  2593 sgd_solver.cpp:106] Iteration 1205, lr = 0.001
I1110 22:57:45.730602  2593 solver.cpp:295] Iteration 1206 (no loss supplied for SingleUpdateStep)
I1110 22:57:45.730659  2593 solver.cpp:310]     Train net output #0: loss = 0.515881 (* 1 = 0.515881 loss)
I1110 22:57:45.730679  2593 sgd_solver.cpp:106] Iteration 1206, lr = 0.001
I1110 22:57:48.913664  2593 solver.cpp:295] Iteration 1207 (no loss supplied for SingleUpdateStep)
I1110 22:57:48.913820  2593 solver.cpp:310]     Train net output #0: loss = 0.496014 (* 1 = 0.496014 loss)
I1110 22:57:48.913846  2593 sgd_solver.cpp:106] Iteration 1207, lr = 0.001
I1110 22:57:51.575892  2593 solver.cpp:295] Iteration 1208 (no loss supplied for SingleUpdateStep)
I1110 22:57:51.575995  2593 solver.cpp:310]     Train net output #0: loss = 0.567518 (* 1 = 0.567518 loss)
I1110 22:57:51.576015  2593 sgd_solver.cpp:106] Iteration 1208, lr = 0.001
I1110 22:57:53.930083  2593 solver.cpp:295] Iteration 1209 (no loss supplied for SingleUpdateStep)
I1110 22:57:53.930169  2593 solver.cpp:310]     Train net output #0: loss = 0.519302 (* 1 = 0.519302 loss)
I1110 22:57:53.930188  2593 sgd_solver.cpp:106] Iteration 1209, lr = 0.001
I1110 22:57:56.388080  2593 solver.cpp:295] Iteration 1210 (no loss supplied for SingleUpdateStep)
I1110 22:57:56.388155  2593 solver.cpp:310]     Train net output #0: loss = 0.524969 (* 1 = 0.524969 loss)
I1110 22:57:56.388176  2593 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I1110 22:57:59.023675  2593 solver.cpp:295] Iteration 1211 (no loss supplied for SingleUpdateStep)
I1110 22:57:59.023804  2593 solver.cpp:310]     Train net output #0: loss = 0.550942 (* 1 = 0.550942 loss)
I1110 22:57:59.023828  2593 sgd_solver.cpp:106] Iteration 1211, lr = 0.001
I1110 22:58:01.167698  2593 solver.cpp:295] Iteration 1212 (no loss supplied for SingleUpdateStep)
I1110 22:58:01.167814  2593 solver.cpp:310]     Train net output #0: loss = 0.509341 (* 1 = 0.509341 loss)
I1110 22:58:01.167837  2593 sgd_solver.cpp:106] Iteration 1212, lr = 0.001
I1110 22:58:03.269419  2593 solver.cpp:295] Iteration 1213 (no loss supplied for SingleUpdateStep)
I1110 22:58:03.269505  2593 solver.cpp:310]     Train net output #0: loss = 0.558182 (* 1 = 0.558182 loss)
I1110 22:58:03.269527  2593 sgd_solver.cpp:106] Iteration 1213, lr = 0.001
I1110 22:58:05.522228  2593 solver.cpp:295] Iteration 1214 (no loss supplied for SingleUpdateStep)
I1110 22:58:05.522333  2593 solver.cpp:310]     Train net output #0: loss = 0.547378 (* 1 = 0.547378 loss)
I1110 22:58:05.522356  2593 sgd_solver.cpp:106] Iteration 1214, lr = 0.001
I1110 22:58:07.756402  2593 solver.cpp:295] Iteration 1215 (no loss supplied for SingleUpdateStep)
I1110 22:58:07.756512  2593 solver.cpp:310]     Train net output #0: loss = 0.566507 (* 1 = 0.566507 loss)
I1110 22:58:07.756537  2593 sgd_solver.cpp:106] Iteration 1215, lr = 0.001
I1110 22:58:09.944852  2593 solver.cpp:295] Iteration 1216 (no loss supplied for SingleUpdateStep)
I1110 22:58:09.944962  2593 solver.cpp:310]     Train net output #0: loss = 0.559149 (* 1 = 0.559149 loss)
I1110 22:58:09.944986  2593 sgd_solver.cpp:106] Iteration 1216, lr = 0.001
I1110 22:58:12.056602  2593 solver.cpp:295] Iteration 1217 (no loss supplied for SingleUpdateStep)
I1110 22:58:12.056665  2593 solver.cpp:310]     Train net output #0: loss = 0.559831 (* 1 = 0.559831 loss)
I1110 22:58:12.056686  2593 sgd_solver.cpp:106] Iteration 1217, lr = 0.001
I1110 22:58:14.297071  2593 solver.cpp:295] Iteration 1218 (no loss supplied for SingleUpdateStep)
I1110 22:58:14.297168  2593 solver.cpp:310]     Train net output #0: loss = 0.529077 (* 1 = 0.529077 loss)
I1110 22:58:14.297191  2593 sgd_solver.cpp:106] Iteration 1218, lr = 0.001
I1110 22:58:16.839383  2593 solver.cpp:295] Iteration 1219 (no loss supplied for SingleUpdateStep)
I1110 22:58:16.839493  2593 solver.cpp:310]     Train net output #0: loss = 0.563391 (* 1 = 0.563391 loss)
I1110 22:58:16.839516  2593 sgd_solver.cpp:106] Iteration 1219, lr = 0.001
I1110 22:58:19.048790  2593 solver.cpp:295] Iteration 1220 (no loss supplied for SingleUpdateStep)
I1110 22:58:19.048900  2593 solver.cpp:310]     Train net output #0: loss = 0.58517 (* 1 = 0.58517 loss)
I1110 22:58:19.048924  2593 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I1110 22:58:21.266952  2593 solver.cpp:295] Iteration 1221 (no loss supplied for SingleUpdateStep)
I1110 22:58:21.267072  2593 solver.cpp:310]     Train net output #0: loss = 0.553111 (* 1 = 0.553111 loss)
I1110 22:58:21.267096  2593 sgd_solver.cpp:106] Iteration 1221, lr = 0.001
I1110 22:58:23.581447  2593 solver.cpp:295] Iteration 1222 (no loss supplied for SingleUpdateStep)
I1110 22:58:23.581500  2593 solver.cpp:310]     Train net output #0: loss = 0.532671 (* 1 = 0.532671 loss)
I1110 22:58:23.581518  2593 sgd_solver.cpp:106] Iteration 1222, lr = 0.001
I1110 22:58:25.813707  2593 solver.cpp:295] Iteration 1223 (no loss supplied for SingleUpdateStep)
I1110 22:58:25.813779  2593 solver.cpp:310]     Train net output #0: loss = 0.573872 (* 1 = 0.573872 loss)
I1110 22:58:25.813802  2593 sgd_solver.cpp:106] Iteration 1223, lr = 0.001
I1110 22:58:28.142153  2593 solver.cpp:295] Iteration 1224 (no loss supplied for SingleUpdateStep)
I1110 22:58:28.142225  2593 solver.cpp:310]     Train net output #0: loss = 0.511351 (* 1 = 0.511351 loss)
I1110 22:58:28.142246  2593 sgd_solver.cpp:106] Iteration 1224, lr = 0.001
I1110 22:58:30.742629  2593 solver.cpp:295] Iteration 1225 (no loss supplied for SingleUpdateStep)
I1110 22:58:30.742686  2593 solver.cpp:310]     Train net output #0: loss = 0.549516 (* 1 = 0.549516 loss)
I1110 22:58:30.742705  2593 sgd_solver.cpp:106] Iteration 1225, lr = 0.001
I1110 22:58:33.010864  2593 solver.cpp:295] Iteration 1226 (no loss supplied for SingleUpdateStep)
I1110 22:58:33.010967  2593 solver.cpp:310]     Train net output #0: loss = 0.544771 (* 1 = 0.544771 loss)
I1110 22:58:33.010992  2593 sgd_solver.cpp:106] Iteration 1226, lr = 0.001
I1110 22:58:35.304245  2593 solver.cpp:295] Iteration 1227 (no loss supplied for SingleUpdateStep)
I1110 22:58:35.304393  2593 solver.cpp:310]     Train net output #0: loss = 0.580307 (* 1 = 0.580307 loss)
I1110 22:58:35.304416  2593 sgd_solver.cpp:106] Iteration 1227, lr = 0.001
I1110 22:58:37.419080  2593 solver.cpp:295] Iteration 1228 (no loss supplied for SingleUpdateStep)
I1110 22:58:37.419190  2593 solver.cpp:310]     Train net output #0: loss = 0.54733 (* 1 = 0.54733 loss)
I1110 22:58:37.419211  2593 sgd_solver.cpp:106] Iteration 1228, lr = 0.001
I1110 22:58:39.708067  2593 solver.cpp:295] Iteration 1229 (no loss supplied for SingleUpdateStep)
I1110 22:58:39.708163  2593 solver.cpp:310]     Train net output #0: loss = 0.528554 (* 1 = 0.528554 loss)
I1110 22:58:39.708185  2593 sgd_solver.cpp:106] Iteration 1229, lr = 0.001
I1110 22:58:42.338428  2593 solver.cpp:295] Iteration 1230 (no loss supplied for SingleUpdateStep)
I1110 22:58:42.338485  2593 solver.cpp:310]     Train net output #0: loss = 0.502312 (* 1 = 0.502312 loss)
I1110 22:58:42.338503  2593 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I1110 22:58:44.877287  2593 solver.cpp:295] Iteration 1231 (no loss supplied for SingleUpdateStep)
I1110 22:58:44.877374  2593 solver.cpp:310]     Train net output #0: loss = 0.547486 (* 1 = 0.547486 loss)
I1110 22:58:44.877394  2593 sgd_solver.cpp:106] Iteration 1231, lr = 0.001
I1110 22:58:47.805531  2593 solver.cpp:295] Iteration 1232 (no loss supplied for SingleUpdateStep)
I1110 22:58:47.805618  2593 solver.cpp:310]     Train net output #0: loss = 0.574986 (* 1 = 0.574986 loss)
I1110 22:58:47.805639  2593 sgd_solver.cpp:106] Iteration 1232, lr = 0.001
I1110 22:58:50.068284  2593 solver.cpp:295] Iteration 1233 (no loss supplied for SingleUpdateStep)
I1110 22:58:50.068342  2593 solver.cpp:310]     Train net output #0: loss = 0.502039 (* 1 = 0.502039 loss)
I1110 22:58:50.068367  2593 sgd_solver.cpp:106] Iteration 1233, lr = 0.001
I1110 22:58:52.319481  2593 solver.cpp:295] Iteration 1234 (no loss supplied for SingleUpdateStep)
I1110 22:58:52.319746  2593 solver.cpp:310]     Train net output #0: loss = 0.57828 (* 1 = 0.57828 loss)
I1110 22:58:52.319795  2593 sgd_solver.cpp:106] Iteration 1234, lr = 0.001
I1110 22:58:54.661473  2593 solver.cpp:295] Iteration 1235 (no loss supplied for SingleUpdateStep)
I1110 22:58:54.661574  2593 solver.cpp:310]     Train net output #0: loss = 0.513726 (* 1 = 0.513726 loss)
I1110 22:58:54.661595  2593 sgd_solver.cpp:106] Iteration 1235, lr = 0.001
I1110 22:58:56.956168  2593 solver.cpp:295] Iteration 1236 (no loss supplied for SingleUpdateStep)
I1110 22:58:56.956269  2593 solver.cpp:310]     Train net output #0: loss = 0.525593 (* 1 = 0.525593 loss)
I1110 22:58:56.956293  2593 sgd_solver.cpp:106] Iteration 1236, lr = 0.001
I1110 22:58:59.316949  2593 solver.cpp:295] Iteration 1237 (no loss supplied for SingleUpdateStep)
I1110 22:58:59.317006  2593 solver.cpp:310]     Train net output #0: loss = 0.509835 (* 1 = 0.509835 loss)
I1110 22:58:59.317025  2593 sgd_solver.cpp:106] Iteration 1237, lr = 0.001
I1110 22:59:01.512712  2593 solver.cpp:295] Iteration 1238 (no loss supplied for SingleUpdateStep)
I1110 22:59:01.512784  2593 solver.cpp:310]     Train net output #0: loss = 0.519411 (* 1 = 0.519411 loss)
I1110 22:59:01.512809  2593 sgd_solver.cpp:106] Iteration 1238, lr = 0.001
I1110 22:59:04.056648  2593 solver.cpp:295] Iteration 1239 (no loss supplied for SingleUpdateStep)
I1110 22:59:04.056788  2593 solver.cpp:310]     Train net output #0: loss = 0.536825 (* 1 = 0.536825 loss)
I1110 22:59:04.056819  2593 sgd_solver.cpp:106] Iteration 1239, lr = 0.001
I1110 22:59:06.434145  2593 solver.cpp:295] Iteration 1240 (no loss supplied for SingleUpdateStep)
I1110 22:59:06.434219  2593 solver.cpp:310]     Train net output #0: loss = 0.520096 (* 1 = 0.520096 loss)
I1110 22:59:06.434240  2593 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I1110 22:59:08.593909  2593 solver.cpp:295] Iteration 1241 (no loss supplied for SingleUpdateStep)
I1110 22:59:08.593994  2593 solver.cpp:310]     Train net output #0: loss = 0.564828 (* 1 = 0.564828 loss)
I1110 22:59:08.594014  2593 sgd_solver.cpp:106] Iteration 1241, lr = 0.001
I1110 22:59:10.452078  2593 solver.cpp:295] Iteration 1242 (no loss supplied for SingleUpdateStep)
I1110 22:59:10.452194  2593 solver.cpp:310]     Train net output #0: loss = 0.511815 (* 1 = 0.511815 loss)
I1110 22:59:10.452220  2593 sgd_solver.cpp:106] Iteration 1242, lr = 0.001
I1110 22:59:12.444190  2593 solver.cpp:295] Iteration 1243 (no loss supplied for SingleUpdateStep)
I1110 22:59:12.444270  2593 solver.cpp:310]     Train net output #0: loss = 0.493044 (* 1 = 0.493044 loss)
I1110 22:59:12.444294  2593 sgd_solver.cpp:106] Iteration 1243, lr = 0.001
I1110 22:59:14.451644  2593 solver.cpp:295] Iteration 1244 (no loss supplied for SingleUpdateStep)
I1110 22:59:14.451776  2593 solver.cpp:310]     Train net output #0: loss = 0.516457 (* 1 = 0.516457 loss)
I1110 22:59:14.451799  2593 sgd_solver.cpp:106] Iteration 1244, lr = 0.001
I1110 22:59:16.394181  2593 solver.cpp:295] Iteration 1245 (no loss supplied for SingleUpdateStep)
I1110 22:59:16.394263  2593 solver.cpp:310]     Train net output #0: loss = 0.503857 (* 1 = 0.503857 loss)
I1110 22:59:16.394282  2593 sgd_solver.cpp:106] Iteration 1245, lr = 0.001
I1110 22:59:18.579315  2593 solver.cpp:295] Iteration 1246 (no loss supplied for SingleUpdateStep)
I1110 22:59:18.579443  2593 solver.cpp:310]     Train net output #0: loss = 0.523084 (* 1 = 0.523084 loss)
I1110 22:59:18.579490  2593 sgd_solver.cpp:106] Iteration 1246, lr = 0.001
I1110 22:59:20.681695  2593 solver.cpp:295] Iteration 1247 (no loss supplied for SingleUpdateStep)
I1110 22:59:20.681788  2593 solver.cpp:310]     Train net output #0: loss = 0.521805 (* 1 = 0.521805 loss)
I1110 22:59:20.681809  2593 sgd_solver.cpp:106] Iteration 1247, lr = 0.001
I1110 22:59:22.654310  2593 solver.cpp:295] Iteration 1248 (no loss supplied for SingleUpdateStep)
I1110 22:59:22.654402  2593 solver.cpp:310]     Train net output #0: loss = 0.526868 (* 1 = 0.526868 loss)
I1110 22:59:22.654427  2593 sgd_solver.cpp:106] Iteration 1248, lr = 0.001
I1110 22:59:24.665330  2593 solver.cpp:295] Iteration 1249 (no loss supplied for SingleUpdateStep)
I1110 22:59:24.665452  2593 solver.cpp:310]     Train net output #0: loss = 0.540889 (* 1 = 0.540889 loss)
I1110 22:59:24.665477  2593 sgd_solver.cpp:106] Iteration 1249, lr = 0.001
I1110 22:59:26.653954  2593 solver.cpp:295] Iteration 1250 (no loss supplied for SingleUpdateStep)
I1110 22:59:26.654057  2593 solver.cpp:310]     Train net output #0: loss = 0.529445 (* 1 = 0.529445 loss)
I1110 22:59:26.654081  2593 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I1110 22:59:28.604198  2593 solver.cpp:295] Iteration 1251 (no loss supplied for SingleUpdateStep)
I1110 22:59:28.604324  2593 solver.cpp:310]     Train net output #0: loss = 0.515641 (* 1 = 0.515641 loss)
I1110 22:59:28.604349  2593 sgd_solver.cpp:106] Iteration 1251, lr = 0.001
I1110 22:59:30.709962  2593 solver.cpp:295] Iteration 1252 (no loss supplied for SingleUpdateStep)
I1110 22:59:30.710074  2593 solver.cpp:310]     Train net output #0: loss = 0.605659 (* 1 = 0.605659 loss)
I1110 22:59:30.710098  2593 sgd_solver.cpp:106] Iteration 1252, lr = 0.001
I1110 22:59:32.685247  2593 solver.cpp:295] Iteration 1253 (no loss supplied for SingleUpdateStep)
I1110 22:59:32.685304  2593 solver.cpp:310]     Train net output #0: loss = 0.53427 (* 1 = 0.53427 loss)
I1110 22:59:32.685323  2593 sgd_solver.cpp:106] Iteration 1253, lr = 0.001
I1110 22:59:34.984985  2593 solver.cpp:295] Iteration 1254 (no loss supplied for SingleUpdateStep)
I1110 22:59:34.985064  2593 solver.cpp:310]     Train net output #0: loss = 0.511261 (* 1 = 0.511261 loss)
I1110 22:59:34.985085  2593 sgd_solver.cpp:106] Iteration 1254, lr = 0.001
I1110 22:59:37.115005  2593 solver.cpp:295] Iteration 1255 (no loss supplied for SingleUpdateStep)
I1110 22:59:37.115120  2593 solver.cpp:310]     Train net output #0: loss = 0.524073 (* 1 = 0.524073 loss)
I1110 22:59:37.115144  2593 sgd_solver.cpp:106] Iteration 1255, lr = 0.001
I1110 22:59:39.234776  2593 solver.cpp:295] Iteration 1256 (no loss supplied for SingleUpdateStep)
I1110 22:59:39.234899  2593 solver.cpp:310]     Train net output #0: loss = 0.577467 (* 1 = 0.577467 loss)
I1110 22:59:39.234923  2593 sgd_solver.cpp:106] Iteration 1256, lr = 0.001
I1110 22:59:41.307970  2593 solver.cpp:295] Iteration 1257 (no loss supplied for SingleUpdateStep)
I1110 22:59:41.308092  2593 solver.cpp:310]     Train net output #0: loss = 0.497083 (* 1 = 0.497083 loss)
I1110 22:59:41.308116  2593 sgd_solver.cpp:106] Iteration 1257, lr = 0.001
I1110 22:59:43.364249  2593 solver.cpp:295] Iteration 1258 (no loss supplied for SingleUpdateStep)
I1110 22:59:43.364316  2593 solver.cpp:310]     Train net output #0: loss = 0.560226 (* 1 = 0.560226 loss)
I1110 22:59:43.364338  2593 sgd_solver.cpp:106] Iteration 1258, lr = 0.001
I1110 22:59:45.459084  2593 solver.cpp:295] Iteration 1259 (no loss supplied for SingleUpdateStep)
I1110 22:59:45.459210  2593 solver.cpp:310]     Train net output #0: loss = 0.508803 (* 1 = 0.508803 loss)
I1110 22:59:45.459239  2593 sgd_solver.cpp:106] Iteration 1259, lr = 0.001
I1110 22:59:47.402613  2593 solver.cpp:295] Iteration 1260 (no loss supplied for SingleUpdateStep)
I1110 22:59:47.402719  2593 solver.cpp:310]     Train net output #0: loss = 0.477148 (* 1 = 0.477148 loss)
I1110 22:59:47.402740  2593 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I1110 22:59:50.455680  2593 solver.cpp:295] Iteration 1261 (no loss supplied for SingleUpdateStep)
I1110 22:59:50.455777  2593 solver.cpp:310]     Train net output #0: loss = 0.491543 (* 1 = 0.491543 loss)
I1110 22:59:50.455799  2593 sgd_solver.cpp:106] Iteration 1261, lr = 0.001
I1110 22:59:53.110960  2593 solver.cpp:295] Iteration 1262 (no loss supplied for SingleUpdateStep)
I1110 22:59:53.111064  2593 solver.cpp:310]     Train net output #0: loss = 0.490782 (* 1 = 0.490782 loss)
I1110 22:59:53.111088  2593 sgd_solver.cpp:106] Iteration 1262, lr = 0.001
I1110 22:59:55.807852  2593 solver.cpp:295] Iteration 1263 (no loss supplied for SingleUpdateStep)
I1110 22:59:55.807934  2593 solver.cpp:310]     Train net output #0: loss = 0.559465 (* 1 = 0.559465 loss)
I1110 22:59:55.807953  2593 sgd_solver.cpp:106] Iteration 1263, lr = 0.001
I1110 22:59:58.164882  2593 solver.cpp:295] Iteration 1264 (no loss supplied for SingleUpdateStep)
I1110 22:59:58.164990  2593 solver.cpp:310]     Train net output #0: loss = 0.520671 (* 1 = 0.520671 loss)
I1110 22:59:58.165015  2593 sgd_solver.cpp:106] Iteration 1264, lr = 0.001
I1110 23:00:00.211894  2593 solver.cpp:295] Iteration 1265 (no loss supplied for SingleUpdateStep)
I1110 23:00:00.212018  2593 solver.cpp:310]     Train net output #0: loss = 0.560323 (* 1 = 0.560323 loss)
I1110 23:00:00.212043  2593 sgd_solver.cpp:106] Iteration 1265, lr = 0.001
I1110 23:00:02.153084  2593 solver.cpp:295] Iteration 1266 (no loss supplied for SingleUpdateStep)
I1110 23:00:02.153221  2593 solver.cpp:310]     Train net output #0: loss = 0.531416 (* 1 = 0.531416 loss)
I1110 23:00:02.153245  2593 sgd_solver.cpp:106] Iteration 1266, lr = 0.001
I1110 23:00:04.185392  2593 solver.cpp:295] Iteration 1267 (no loss supplied for SingleUpdateStep)
I1110 23:00:04.185490  2593 solver.cpp:310]     Train net output #0: loss = 0.529637 (* 1 = 0.529637 loss)
I1110 23:00:04.185511  2593 sgd_solver.cpp:106] Iteration 1267, lr = 0.001
I1110 23:00:06.327443  2593 solver.cpp:295] Iteration 1268 (no loss supplied for SingleUpdateStep)
I1110 23:00:06.327565  2593 solver.cpp:310]     Train net output #0: loss = 0.557298 (* 1 = 0.557298 loss)
I1110 23:00:06.327590  2593 sgd_solver.cpp:106] Iteration 1268, lr = 0.001
I1110 23:00:08.451077  2593 solver.cpp:295] Iteration 1269 (no loss supplied for SingleUpdateStep)
I1110 23:00:08.451189  2593 solver.cpp:310]     Train net output #0: loss = 0.540687 (* 1 = 0.540687 loss)
I1110 23:00:08.451212  2593 sgd_solver.cpp:106] Iteration 1269, lr = 0.001
I1110 23:00:10.524760  2593 solver.cpp:295] Iteration 1270 (no loss supplied for SingleUpdateStep)
I1110 23:00:10.524905  2593 solver.cpp:310]     Train net output #0: loss = 0.508828 (* 1 = 0.508828 loss)
I1110 23:00:10.524930  2593 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I1110 23:00:12.525436  2593 solver.cpp:295] Iteration 1271 (no loss supplied for SingleUpdateStep)
I1110 23:00:12.525545  2593 solver.cpp:310]     Train net output #0: loss = 0.535579 (* 1 = 0.535579 loss)
I1110 23:00:12.525568  2593 sgd_solver.cpp:106] Iteration 1271, lr = 0.001
I1110 23:00:14.717103  2593 solver.cpp:295] Iteration 1272 (no loss supplied for SingleUpdateStep)
I1110 23:00:14.717224  2593 solver.cpp:310]     Train net output #0: loss = 0.560872 (* 1 = 0.560872 loss)
I1110 23:00:14.717247  2593 sgd_solver.cpp:106] Iteration 1272, lr = 0.001
I1110 23:00:17.469434  2593 solver.cpp:295] Iteration 1273 (no loss supplied for SingleUpdateStep)
I1110 23:00:17.469485  2593 solver.cpp:310]     Train net output #0: loss = 0.515365 (* 1 = 0.515365 loss)
I1110 23:00:17.469503  2593 sgd_solver.cpp:106] Iteration 1273, lr = 0.001
I1110 23:00:20.526321  2593 solver.cpp:295] Iteration 1274 (no loss supplied for SingleUpdateStep)
I1110 23:00:20.526406  2593 solver.cpp:310]     Train net output #0: loss = 0.505438 (* 1 = 0.505438 loss)
I1110 23:00:20.526425  2593 sgd_solver.cpp:106] Iteration 1274, lr = 0.001
I1110 23:00:23.251255  2593 solver.cpp:295] Iteration 1275 (no loss supplied for SingleUpdateStep)
I1110 23:00:23.251343  2593 solver.cpp:310]     Train net output #0: loss = 0.512983 (* 1 = 0.512983 loss)
I1110 23:00:23.251366  2593 sgd_solver.cpp:106] Iteration 1275, lr = 0.001
I1110 23:00:25.910346  2593 solver.cpp:295] Iteration 1276 (no loss supplied for SingleUpdateStep)
I1110 23:00:25.910444  2593 solver.cpp:310]     Train net output #0: loss = 0.574744 (* 1 = 0.574744 loss)
I1110 23:00:25.910465  2593 sgd_solver.cpp:106] Iteration 1276, lr = 0.001
I1110 23:00:28.550719  2593 solver.cpp:295] Iteration 1277 (no loss supplied for SingleUpdateStep)
I1110 23:00:28.550832  2593 solver.cpp:310]     Train net output #0: loss = 0.559694 (* 1 = 0.559694 loss)
I1110 23:00:28.550854  2593 sgd_solver.cpp:106] Iteration 1277, lr = 0.001
I1110 23:00:31.914508  2593 solver.cpp:295] Iteration 1278 (no loss supplied for SingleUpdateStep)
I1110 23:00:31.914620  2593 solver.cpp:310]     Train net output #0: loss = 0.4985 (* 1 = 0.4985 loss)
I1110 23:00:31.914644  2593 sgd_solver.cpp:106] Iteration 1278, lr = 0.001
I1110 23:00:34.937129  2593 solver.cpp:295] Iteration 1279 (no loss supplied for SingleUpdateStep)
I1110 23:00:34.937295  2593 solver.cpp:310]     Train net output #0: loss = 0.511575 (* 1 = 0.511575 loss)
I1110 23:00:34.937333  2593 sgd_solver.cpp:106] Iteration 1279, lr = 0.001
I1110 23:00:37.379770  2593 solver.cpp:295] Iteration 1280 (no loss supplied for SingleUpdateStep)
I1110 23:00:37.379874  2593 solver.cpp:310]     Train net output #0: loss = 0.540412 (* 1 = 0.540412 loss)
I1110 23:00:37.379896  2593 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I1110 23:00:39.599663  2593 solver.cpp:295] Iteration 1281 (no loss supplied for SingleUpdateStep)
I1110 23:00:39.599723  2593 solver.cpp:310]     Train net output #0: loss = 0.536049 (* 1 = 0.536049 loss)
I1110 23:00:39.599742  2593 sgd_solver.cpp:106] Iteration 1281, lr = 0.001
I1110 23:00:41.905516  2593 solver.cpp:295] Iteration 1282 (no loss supplied for SingleUpdateStep)
I1110 23:00:41.905601  2593 solver.cpp:310]     Train net output #0: loss = 0.569711 (* 1 = 0.569711 loss)
I1110 23:00:41.905621  2593 sgd_solver.cpp:106] Iteration 1282, lr = 0.001
I1110 23:00:44.176373  2593 solver.cpp:295] Iteration 1283 (no loss supplied for SingleUpdateStep)
I1110 23:00:44.176482  2593 solver.cpp:310]     Train net output #0: loss = 0.513653 (* 1 = 0.513653 loss)
I1110 23:00:44.176506  2593 sgd_solver.cpp:106] Iteration 1283, lr = 0.001
I1110 23:00:46.122287  2593 solver.cpp:295] Iteration 1284 (no loss supplied for SingleUpdateStep)
I1110 23:00:46.122370  2593 solver.cpp:310]     Train net output #0: loss = 0.592117 (* 1 = 0.592117 loss)
I1110 23:00:46.122390  2593 sgd_solver.cpp:106] Iteration 1284, lr = 0.001
I1110 23:00:48.309243  2593 solver.cpp:295] Iteration 1285 (no loss supplied for SingleUpdateStep)
I1110 23:00:48.309379  2593 solver.cpp:310]     Train net output #0: loss = 0.542815 (* 1 = 0.542815 loss)
I1110 23:00:48.309439  2593 sgd_solver.cpp:106] Iteration 1285, lr = 0.001
I1110 23:00:50.949043  2593 solver.cpp:295] Iteration 1286 (no loss supplied for SingleUpdateStep)
I1110 23:00:50.949163  2593 solver.cpp:310]     Train net output #0: loss = 0.553505 (* 1 = 0.553505 loss)
I1110 23:00:50.949187  2593 sgd_solver.cpp:106] Iteration 1286, lr = 0.001
I1110 23:00:53.339339  2593 solver.cpp:295] Iteration 1287 (no loss supplied for SingleUpdateStep)
I1110 23:00:53.339460  2593 solver.cpp:310]     Train net output #0: loss = 0.508425 (* 1 = 0.508425 loss)
I1110 23:00:53.339488  2593 sgd_solver.cpp:106] Iteration 1287, lr = 0.001
I1110 23:00:55.890929  2593 solver.cpp:295] Iteration 1288 (no loss supplied for SingleUpdateStep)
I1110 23:00:55.891047  2593 solver.cpp:310]     Train net output #0: loss = 0.560324 (* 1 = 0.560324 loss)
I1110 23:00:55.891072  2593 sgd_solver.cpp:106] Iteration 1288, lr = 0.001
I1110 23:00:58.088307  2593 solver.cpp:295] Iteration 1289 (no loss supplied for SingleUpdateStep)
I1110 23:00:58.088425  2593 solver.cpp:310]     Train net output #0: loss = 0.513218 (* 1 = 0.513218 loss)
I1110 23:00:58.088449  2593 sgd_solver.cpp:106] Iteration 1289, lr = 0.001
I1110 23:01:00.193569  2593 solver.cpp:295] Iteration 1290 (no loss supplied for SingleUpdateStep)
I1110 23:01:00.193634  2593 solver.cpp:310]     Train net output #0: loss = 0.545843 (* 1 = 0.545843 loss)
I1110 23:01:00.193655  2593 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I1110 23:01:02.360420  2593 solver.cpp:295] Iteration 1291 (no loss supplied for SingleUpdateStep)
I1110 23:01:02.360584  2593 solver.cpp:310]     Train net output #0: loss = 0.5384 (* 1 = 0.5384 loss)
I1110 23:01:02.360618  2593 sgd_solver.cpp:106] Iteration 1291, lr = 0.001
I1110 23:01:04.321020  2593 solver.cpp:295] Iteration 1292 (no loss supplied for SingleUpdateStep)
I1110 23:01:04.321171  2593 solver.cpp:310]     Train net output #0: loss = 0.559426 (* 1 = 0.559426 loss)
I1110 23:01:04.321200  2593 sgd_solver.cpp:106] Iteration 1292, lr = 0.001
I1110 23:01:06.571135  2593 solver.cpp:295] Iteration 1293 (no loss supplied for SingleUpdateStep)
I1110 23:01:06.571286  2593 solver.cpp:310]     Train net output #0: loss = 0.530235 (* 1 = 0.530235 loss)
I1110 23:01:06.571316  2593 sgd_solver.cpp:106] Iteration 1293, lr = 0.001
I1110 23:01:08.652859  2593 solver.cpp:295] Iteration 1294 (no loss supplied for SingleUpdateStep)
I1110 23:01:08.652945  2593 solver.cpp:310]     Train net output #0: loss = 0.564496 (* 1 = 0.564496 loss)
I1110 23:01:08.652966  2593 sgd_solver.cpp:106] Iteration 1294, lr = 0.001
I1110 23:01:10.994799  2593 solver.cpp:295] Iteration 1295 (no loss supplied for SingleUpdateStep)
I1110 23:01:10.994851  2593 solver.cpp:310]     Train net output #0: loss = 0.549593 (* 1 = 0.549593 loss)
I1110 23:01:10.994869  2593 sgd_solver.cpp:106] Iteration 1295, lr = 0.001
I1110 23:01:13.195240  2593 solver.cpp:295] Iteration 1296 (no loss supplied for SingleUpdateStep)
I1110 23:01:13.195410  2593 solver.cpp:310]     Train net output #0: loss = 0.526662 (* 1 = 0.526662 loss)
I1110 23:01:13.195442  2593 sgd_solver.cpp:106] Iteration 1296, lr = 0.001
I1110 23:01:15.381813  2593 solver.cpp:295] Iteration 1297 (no loss supplied for SingleUpdateStep)
I1110 23:01:15.381878  2593 solver.cpp:310]     Train net output #0: loss = 0.545538 (* 1 = 0.545538 loss)
I1110 23:01:15.381897  2593 sgd_solver.cpp:106] Iteration 1297, lr = 0.001
I1110 23:01:17.353385  2593 solver.cpp:295] Iteration 1298 (no loss supplied for SingleUpdateStep)
I1110 23:01:17.353446  2593 solver.cpp:310]     Train net output #0: loss = 0.499753 (* 1 = 0.499753 loss)
I1110 23:01:17.353466  2593 sgd_solver.cpp:106] Iteration 1298, lr = 0.001
I1110 23:01:19.504144  2593 solver.cpp:295] Iteration 1299 (no loss supplied for SingleUpdateStep)
I1110 23:01:19.504221  2593 solver.cpp:310]     Train net output #0: loss = 0.504092 (* 1 = 0.504092 loss)
I1110 23:01:19.504243  2593 sgd_solver.cpp:106] Iteration 1299, lr = 0.001
I1110 23:01:21.562428  2593 solver.cpp:295] Iteration 1300 (no loss supplied for SingleUpdateStep)
I1110 23:01:21.562517  2593 solver.cpp:310]     Train net output #0: loss = 0.560915 (* 1 = 0.560915 loss)
I1110 23:01:21.562537  2593 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I1110 23:01:23.871716  2593 solver.cpp:295] Iteration 1301 (no loss supplied for SingleUpdateStep)
I1110 23:01:23.871773  2593 solver.cpp:310]     Train net output #0: loss = 0.525547 (* 1 = 0.525547 loss)
I1110 23:01:23.871793  2593 sgd_solver.cpp:106] Iteration 1301, lr = 0.001
I1110 23:01:25.936336  2593 solver.cpp:295] Iteration 1302 (no loss supplied for SingleUpdateStep)
I1110 23:01:25.936452  2593 solver.cpp:310]     Train net output #0: loss = 0.546086 (* 1 = 0.546086 loss)
I1110 23:01:25.936476  2593 sgd_solver.cpp:106] Iteration 1302, lr = 0.001
I1110 23:01:28.053774  2593 solver.cpp:295] Iteration 1303 (no loss supplied for SingleUpdateStep)
I1110 23:01:28.053874  2593 solver.cpp:310]     Train net output #0: loss = 0.539609 (* 1 = 0.539609 loss)
I1110 23:01:28.053895  2593 sgd_solver.cpp:106] Iteration 1303, lr = 0.001
I1110 23:01:29.968235  2593 solver.cpp:295] Iteration 1304 (no loss supplied for SingleUpdateStep)
I1110 23:01:29.968355  2593 solver.cpp:310]     Train net output #0: loss = 0.509531 (* 1 = 0.509531 loss)
I1110 23:01:29.968379  2593 sgd_solver.cpp:106] Iteration 1304, lr = 0.001
I1110 23:01:31.976572  2593 solver.cpp:295] Iteration 1305 (no loss supplied for SingleUpdateStep)
I1110 23:01:31.976649  2593 solver.cpp:310]     Train net output #0: loss = 0.549546 (* 1 = 0.549546 loss)
I1110 23:01:31.976670  2593 sgd_solver.cpp:106] Iteration 1305, lr = 0.001
I1110 23:01:33.766854  2593 solver.cpp:295] Iteration 1306 (no loss supplied for SingleUpdateStep)
I1110 23:01:33.767011  2593 solver.cpp:310]     Train net output #0: loss = 0.515888 (* 1 = 0.515888 loss)
I1110 23:01:33.767035  2593 sgd_solver.cpp:106] Iteration 1306, lr = 0.001
I1110 23:01:35.914898  2593 solver.cpp:295] Iteration 1307 (no loss supplied for SingleUpdateStep)
I1110 23:01:35.915009  2593 solver.cpp:310]     Train net output #0: loss = 0.5218 (* 1 = 0.5218 loss)
I1110 23:01:35.915032  2593 sgd_solver.cpp:106] Iteration 1307, lr = 0.001
I1110 23:01:37.869978  2593 solver.cpp:295] Iteration 1308 (no loss supplied for SingleUpdateStep)
I1110 23:01:37.870090  2593 solver.cpp:310]     Train net output #0: loss = 0.57886 (* 1 = 0.57886 loss)
I1110 23:01:37.870113  2593 sgd_solver.cpp:106] Iteration 1308, lr = 0.001
I1110 23:01:40.562789  2593 solver.cpp:295] Iteration 1309 (no loss supplied for SingleUpdateStep)
I1110 23:01:40.562844  2593 solver.cpp:310]     Train net output #0: loss = 0.529786 (* 1 = 0.529786 loss)
I1110 23:01:40.562862  2593 sgd_solver.cpp:106] Iteration 1309, lr = 0.001
I1110 23:01:43.284878  2593 solver.cpp:295] Iteration 1310 (no loss supplied for SingleUpdateStep)
I1110 23:01:43.285017  2593 solver.cpp:310]     Train net output #0: loss = 0.54465 (* 1 = 0.54465 loss)
I1110 23:01:43.285045  2593 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I1110 23:01:45.702180  2593 solver.cpp:295] Iteration 1311 (no loss supplied for SingleUpdateStep)
I1110 23:01:45.702291  2593 solver.cpp:310]     Train net output #0: loss = 0.509359 (* 1 = 0.509359 loss)
I1110 23:01:45.702313  2593 sgd_solver.cpp:106] Iteration 1311, lr = 0.001
I1110 23:01:48.017966  2593 solver.cpp:295] Iteration 1312 (no loss supplied for SingleUpdateStep)
I1110 23:01:48.018046  2593 solver.cpp:310]     Train net output #0: loss = 0.508 (* 1 = 0.508 loss)
I1110 23:01:48.018065  2593 sgd_solver.cpp:106] Iteration 1312, lr = 0.001
I1110 23:01:50.471879  2593 solver.cpp:295] Iteration 1313 (no loss supplied for SingleUpdateStep)
I1110 23:01:50.471961  2593 solver.cpp:310]     Train net output #0: loss = 0.535018 (* 1 = 0.535018 loss)
I1110 23:01:50.471983  2593 sgd_solver.cpp:106] Iteration 1313, lr = 0.001
I1110 23:01:52.613756  2593 solver.cpp:295] Iteration 1314 (no loss supplied for SingleUpdateStep)
I1110 23:01:52.613922  2593 solver.cpp:310]     Train net output #0: loss = 0.505902 (* 1 = 0.505902 loss)
I1110 23:01:52.613958  2593 sgd_solver.cpp:106] Iteration 1314, lr = 0.001
I1110 23:01:55.074473  2593 solver.cpp:295] Iteration 1315 (no loss supplied for SingleUpdateStep)
I1110 23:01:55.074578  2593 solver.cpp:310]     Train net output #0: loss = 0.546456 (* 1 = 0.546456 loss)
I1110 23:01:55.074599  2593 sgd_solver.cpp:106] Iteration 1315, lr = 0.001
I1110 23:01:57.256264  2593 solver.cpp:295] Iteration 1316 (no loss supplied for SingleUpdateStep)
I1110 23:01:57.256378  2593 solver.cpp:310]     Train net output #0: loss = 0.505417 (* 1 = 0.505417 loss)
I1110 23:01:57.256402  2593 sgd_solver.cpp:106] Iteration 1316, lr = 0.001
I1110 23:01:59.194777  2593 solver.cpp:295] Iteration 1317 (no loss supplied for SingleUpdateStep)
I1110 23:01:59.194864  2593 solver.cpp:310]     Train net output #0: loss = 0.535287 (* 1 = 0.535287 loss)
I1110 23:01:59.194906  2593 sgd_solver.cpp:106] Iteration 1317, lr = 0.001
I1110 23:02:01.167233  2593 solver.cpp:295] Iteration 1318 (no loss supplied for SingleUpdateStep)
I1110 23:02:01.167323  2593 solver.cpp:310]     Train net output #0: loss = 0.471438 (* 1 = 0.471438 loss)
I1110 23:02:01.167347  2593 sgd_solver.cpp:106] Iteration 1318, lr = 0.001
I1110 23:02:03.101367  2593 solver.cpp:295] Iteration 1319 (no loss supplied for SingleUpdateStep)
I1110 23:02:03.101541  2593 solver.cpp:310]     Train net output #0: loss = 0.550684 (* 1 = 0.550684 loss)
I1110 23:02:03.101574  2593 sgd_solver.cpp:106] Iteration 1319, lr = 0.001
I1110 23:02:05.240221  2593 solver.cpp:295] Iteration 1320 (no loss supplied for SingleUpdateStep)
I1110 23:02:05.240402  2593 solver.cpp:310]     Train net output #0: loss = 0.536539 (* 1 = 0.536539 loss)
I1110 23:02:05.240427  2593 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I1110 23:02:07.374651  2593 solver.cpp:295] Iteration 1321 (no loss supplied for SingleUpdateStep)
I1110 23:02:07.374719  2593 solver.cpp:310]     Train net output #0: loss = 0.535473 (* 1 = 0.535473 loss)
I1110 23:02:07.374744  2593 sgd_solver.cpp:106] Iteration 1321, lr = 0.001
I1110 23:02:09.594977  2593 solver.cpp:295] Iteration 1322 (no loss supplied for SingleUpdateStep)
I1110 23:02:09.595082  2593 solver.cpp:310]     Train net output #0: loss = 0.48936 (* 1 = 0.48936 loss)
I1110 23:02:09.595104  2593 sgd_solver.cpp:106] Iteration 1322, lr = 0.001
I1110 23:02:11.918126  2593 solver.cpp:295] Iteration 1323 (no loss supplied for SingleUpdateStep)
I1110 23:02:11.918197  2593 solver.cpp:310]     Train net output #0: loss = 0.533141 (* 1 = 0.533141 loss)
I1110 23:02:11.918217  2593 sgd_solver.cpp:106] Iteration 1323, lr = 0.001
I1110 23:02:14.113891  2593 solver.cpp:295] Iteration 1324 (no loss supplied for SingleUpdateStep)
I1110 23:02:14.114059  2593 solver.cpp:310]     Train net output #0: loss = 0.580692 (* 1 = 0.580692 loss)
I1110 23:02:14.114085  2593 sgd_solver.cpp:106] Iteration 1324, lr = 0.001
I1110 23:02:16.348031  2593 solver.cpp:295] Iteration 1325 (no loss supplied for SingleUpdateStep)
I1110 23:02:16.348129  2593 solver.cpp:310]     Train net output #0: loss = 0.543176 (* 1 = 0.543176 loss)
I1110 23:02:16.348151  2593 sgd_solver.cpp:106] Iteration 1325, lr = 0.001
I1110 23:02:18.457176  2593 solver.cpp:295] Iteration 1326 (no loss supplied for SingleUpdateStep)
I1110 23:02:18.457278  2593 solver.cpp:310]     Train net output #0: loss = 0.574845 (* 1 = 0.574845 loss)
I1110 23:02:18.457299  2593 sgd_solver.cpp:106] Iteration 1326, lr = 0.001
I1110 23:02:20.631094  2593 solver.cpp:295] Iteration 1327 (no loss supplied for SingleUpdateStep)
I1110 23:02:20.631234  2593 solver.cpp:310]     Train net output #0: loss = 0.515645 (* 1 = 0.515645 loss)
I1110 23:02:20.631258  2593 sgd_solver.cpp:106] Iteration 1327, lr = 0.001
I1110 23:02:23.137759  2593 solver.cpp:295] Iteration 1328 (no loss supplied for SingleUpdateStep)
I1110 23:02:23.137864  2593 solver.cpp:310]     Train net output #0: loss = 0.533456 (* 1 = 0.533456 loss)
I1110 23:02:23.137887  2593 sgd_solver.cpp:106] Iteration 1328, lr = 0.001
I1110 23:02:25.877877  2593 solver.cpp:295] Iteration 1329 (no loss supplied for SingleUpdateStep)
I1110 23:02:25.877943  2593 solver.cpp:310]     Train net output #0: loss = 0.517066 (* 1 = 0.517066 loss)
I1110 23:02:25.877962  2593 sgd_solver.cpp:106] Iteration 1329, lr = 0.001
I1110 23:02:28.525369  2593 solver.cpp:295] Iteration 1330 (no loss supplied for SingleUpdateStep)
I1110 23:02:28.525482  2593 solver.cpp:310]     Train net output #0: loss = 0.511752 (* 1 = 0.511752 loss)
I1110 23:02:28.525506  2593 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I1110 23:02:30.987114  2593 solver.cpp:295] Iteration 1331 (no loss supplied for SingleUpdateStep)
I1110 23:02:30.987259  2593 solver.cpp:310]     Train net output #0: loss = 0.580005 (* 1 = 0.580005 loss)
I1110 23:02:30.987292  2593 sgd_solver.cpp:106] Iteration 1331, lr = 0.001
I1110 23:02:34.314105  2593 solver.cpp:295] Iteration 1332 (no loss supplied for SingleUpdateStep)
I1110 23:02:34.314204  2593 solver.cpp:310]     Train net output #0: loss = 0.526952 (* 1 = 0.526952 loss)
I1110 23:02:34.314225  2593 sgd_solver.cpp:106] Iteration 1332, lr = 0.001
I1110 23:02:37.267946  2593 solver.cpp:295] Iteration 1333 (no loss supplied for SingleUpdateStep)
I1110 23:02:37.268031  2593 solver.cpp:310]     Train net output #0: loss = 0.51949 (* 1 = 0.51949 loss)
I1110 23:02:37.268054  2593 sgd_solver.cpp:106] Iteration 1333, lr = 0.001
I1110 23:02:40.124421  2593 solver.cpp:295] Iteration 1334 (no loss supplied for SingleUpdateStep)
I1110 23:02:40.124526  2593 solver.cpp:310]     Train net output #0: loss = 0.551818 (* 1 = 0.551818 loss)
I1110 23:02:40.124548  2593 sgd_solver.cpp:106] Iteration 1334, lr = 0.001
I1110 23:02:42.925037  2593 solver.cpp:295] Iteration 1335 (no loss supplied for SingleUpdateStep)
I1110 23:02:42.925155  2593 solver.cpp:310]     Train net output #0: loss = 0.509532 (* 1 = 0.509532 loss)
I1110 23:02:42.925182  2593 sgd_solver.cpp:106] Iteration 1335, lr = 0.001
I1110 23:02:45.733518  2593 solver.cpp:295] Iteration 1336 (no loss supplied for SingleUpdateStep)
I1110 23:02:45.733642  2593 solver.cpp:310]     Train net output #0: loss = 0.526184 (* 1 = 0.526184 loss)
I1110 23:02:45.733665  2593 sgd_solver.cpp:106] Iteration 1336, lr = 0.001
I1110 23:02:48.056033  2593 solver.cpp:295] Iteration 1337 (no loss supplied for SingleUpdateStep)
I1110 23:02:48.056134  2593 solver.cpp:310]     Train net output #0: loss = 0.496363 (* 1 = 0.496363 loss)
I1110 23:02:48.056161  2593 sgd_solver.cpp:106] Iteration 1337, lr = 0.001
I1110 23:02:50.563987  2593 solver.cpp:295] Iteration 1338 (no loss supplied for SingleUpdateStep)
I1110 23:02:50.564110  2593 solver.cpp:310]     Train net output #0: loss = 0.526058 (* 1 = 0.526058 loss)
I1110 23:02:50.564133  2593 sgd_solver.cpp:106] Iteration 1338, lr = 0.001
I1110 23:02:52.736896  2593 solver.cpp:295] Iteration 1339 (no loss supplied for SingleUpdateStep)
I1110 23:02:52.736989  2593 solver.cpp:310]     Train net output #0: loss = 0.526542 (* 1 = 0.526542 loss)
I1110 23:02:52.737010  2593 sgd_solver.cpp:106] Iteration 1339, lr = 0.001
I1110 23:02:55.043203  2593 solver.cpp:295] Iteration 1340 (no loss supplied for SingleUpdateStep)
I1110 23:02:55.043308  2593 solver.cpp:310]     Train net output #0: loss = 0.52944 (* 1 = 0.52944 loss)
I1110 23:02:55.043331  2593 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I1110 23:02:57.153967  2593 solver.cpp:295] Iteration 1341 (no loss supplied for SingleUpdateStep)
I1110 23:02:57.154068  2593 solver.cpp:310]     Train net output #0: loss = 0.505088 (* 1 = 0.505088 loss)
I1110 23:02:57.154091  2593 sgd_solver.cpp:106] Iteration 1341, lr = 0.001
I1110 23:02:59.368918  2593 solver.cpp:295] Iteration 1342 (no loss supplied for SingleUpdateStep)
I1110 23:02:59.368983  2593 solver.cpp:310]     Train net output #0: loss = 0.556041 (* 1 = 0.556041 loss)
I1110 23:02:59.369002  2593 sgd_solver.cpp:106] Iteration 1342, lr = 0.001
I1110 23:03:01.574585  2593 solver.cpp:295] Iteration 1343 (no loss supplied for SingleUpdateStep)
I1110 23:03:01.574690  2593 solver.cpp:310]     Train net output #0: loss = 0.548527 (* 1 = 0.548527 loss)
I1110 23:03:01.574712  2593 sgd_solver.cpp:106] Iteration 1343, lr = 0.001
I1110 23:03:03.695997  2593 solver.cpp:295] Iteration 1344 (no loss supplied for SingleUpdateStep)
I1110 23:03:03.696099  2593 solver.cpp:310]     Train net output #0: loss = 0.538112 (* 1 = 0.538112 loss)
I1110 23:03:03.696122  2593 sgd_solver.cpp:106] Iteration 1344, lr = 0.001
I1110 23:03:06.028353  2593 solver.cpp:295] Iteration 1345 (no loss supplied for SingleUpdateStep)
I1110 23:03:06.028409  2593 solver.cpp:310]     Train net output #0: loss = 0.521187 (* 1 = 0.521187 loss)
I1110 23:03:06.028427  2593 sgd_solver.cpp:106] Iteration 1345, lr = 0.001
I1110 23:03:08.436578  2593 solver.cpp:295] Iteration 1346 (no loss supplied for SingleUpdateStep)
I1110 23:03:08.436674  2593 solver.cpp:310]     Train net output #0: loss = 0.500171 (* 1 = 0.500171 loss)
I1110 23:03:08.436698  2593 sgd_solver.cpp:106] Iteration 1346, lr = 0.001
I1110 23:03:10.895671  2593 solver.cpp:295] Iteration 1347 (no loss supplied for SingleUpdateStep)
I1110 23:03:10.895781  2593 solver.cpp:310]     Train net output #0: loss = 0.555072 (* 1 = 0.555072 loss)
I1110 23:03:10.895807  2593 sgd_solver.cpp:106] Iteration 1347, lr = 0.001
I1110 23:03:13.229089  2593 solver.cpp:295] Iteration 1348 (no loss supplied for SingleUpdateStep)
I1110 23:03:13.229205  2593 solver.cpp:310]     Train net output #0: loss = 0.536433 (* 1 = 0.536433 loss)
I1110 23:03:13.229228  2593 sgd_solver.cpp:106] Iteration 1348, lr = 0.001
I1110 23:03:15.638357  2593 solver.cpp:295] Iteration 1349 (no loss supplied for SingleUpdateStep)
I1110 23:03:15.638489  2593 solver.cpp:310]     Train net output #0: loss = 0.521395 (* 1 = 0.521395 loss)
I1110 23:03:15.638512  2593 sgd_solver.cpp:106] Iteration 1349, lr = 0.001
I1110 23:03:17.857524  2593 solver.cpp:295] Iteration 1350 (no loss supplied for SingleUpdateStep)
I1110 23:03:17.857620  2593 solver.cpp:310]     Train net output #0: loss = 0.48929 (* 1 = 0.48929 loss)
I1110 23:03:17.857641  2593 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I1110 23:03:20.115730  2593 solver.cpp:295] Iteration 1351 (no loss supplied for SingleUpdateStep)
I1110 23:03:20.115942  2593 solver.cpp:310]     Train net output #0: loss = 0.556307 (* 1 = 0.556307 loss)
I1110 23:03:20.115972  2593 sgd_solver.cpp:106] Iteration 1351, lr = 0.001
I1110 23:03:22.493648  2593 solver.cpp:295] Iteration 1352 (no loss supplied for SingleUpdateStep)
I1110 23:03:22.493763  2593 solver.cpp:310]     Train net output #0: loss = 0.510914 (* 1 = 0.510914 loss)
I1110 23:03:22.493789  2593 sgd_solver.cpp:106] Iteration 1352, lr = 0.001
I1110 23:03:24.719218  2593 solver.cpp:295] Iteration 1353 (no loss supplied for SingleUpdateStep)
I1110 23:03:24.719280  2593 solver.cpp:310]     Train net output #0: loss = 0.495468 (* 1 = 0.495468 loss)
I1110 23:03:24.719300  2593 sgd_solver.cpp:106] Iteration 1353, lr = 0.001
I1110 23:03:26.995427  2593 solver.cpp:295] Iteration 1354 (no loss supplied for SingleUpdateStep)
I1110 23:03:26.995493  2593 solver.cpp:310]     Train net output #0: loss = 0.562437 (* 1 = 0.562437 loss)
I1110 23:03:26.995513  2593 sgd_solver.cpp:106] Iteration 1354, lr = 0.001
I1110 23:03:29.289468  2593 solver.cpp:295] Iteration 1355 (no loss supplied for SingleUpdateStep)
I1110 23:03:29.289556  2593 solver.cpp:310]     Train net output #0: loss = 0.543826 (* 1 = 0.543826 loss)
I1110 23:03:29.289577  2593 sgd_solver.cpp:106] Iteration 1355, lr = 0.001
I1110 23:03:31.503316  2593 solver.cpp:295] Iteration 1356 (no loss supplied for SingleUpdateStep)
I1110 23:03:31.503468  2593 solver.cpp:310]     Train net output #0: loss = 0.506947 (* 1 = 0.506947 loss)
I1110 23:03:31.503494  2593 sgd_solver.cpp:106] Iteration 1356, lr = 0.001
I1110 23:03:33.519373  2593 solver.cpp:295] Iteration 1357 (no loss supplied for SingleUpdateStep)
I1110 23:03:33.519493  2593 solver.cpp:310]     Train net output #0: loss = 0.536255 (* 1 = 0.536255 loss)
I1110 23:03:33.519525  2593 sgd_solver.cpp:106] Iteration 1357, lr = 0.001
I1110 23:03:35.718762  2593 solver.cpp:295] Iteration 1358 (no loss supplied for SingleUpdateStep)
I1110 23:03:35.718878  2593 solver.cpp:310]     Train net output #0: loss = 0.508112 (* 1 = 0.508112 loss)
I1110 23:03:35.718899  2593 sgd_solver.cpp:106] Iteration 1358, lr = 0.001
I1110 23:03:37.883383  2593 solver.cpp:295] Iteration 1359 (no loss supplied for SingleUpdateStep)
I1110 23:03:37.883436  2593 solver.cpp:310]     Train net output #0: loss = 0.50594 (* 1 = 0.50594 loss)
I1110 23:03:37.883455  2593 sgd_solver.cpp:106] Iteration 1359, lr = 0.001
I1110 23:03:39.945166  2593 solver.cpp:295] Iteration 1360 (no loss supplied for SingleUpdateStep)
I1110 23:03:39.945283  2593 solver.cpp:310]     Train net output #0: loss = 0.512507 (* 1 = 0.512507 loss)
I1110 23:03:39.945304  2593 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I1110 23:03:42.105020  2593 solver.cpp:295] Iteration 1361 (no loss supplied for SingleUpdateStep)
I1110 23:03:42.105186  2593 solver.cpp:310]     Train net output #0: loss = 0.533906 (* 1 = 0.533906 loss)
I1110 23:03:42.105211  2593 sgd_solver.cpp:106] Iteration 1361, lr = 0.001
I1110 23:03:44.248217  2593 solver.cpp:295] Iteration 1362 (no loss supplied for SingleUpdateStep)
I1110 23:03:44.248314  2593 solver.cpp:310]     Train net output #0: loss = 0.552544 (* 1 = 0.552544 loss)
I1110 23:03:44.248337  2593 sgd_solver.cpp:106] Iteration 1362, lr = 0.001
I1110 23:03:46.502728  2593 solver.cpp:295] Iteration 1363 (no loss supplied for SingleUpdateStep)
I1110 23:03:46.502836  2593 solver.cpp:310]     Train net output #0: loss = 0.512325 (* 1 = 0.512325 loss)
I1110 23:03:46.502859  2593 sgd_solver.cpp:106] Iteration 1363, lr = 0.001
I1110 23:03:48.687597  2593 solver.cpp:295] Iteration 1364 (no loss supplied for SingleUpdateStep)
I1110 23:03:48.687713  2593 solver.cpp:310]     Train net output #0: loss = 0.516249 (* 1 = 0.516249 loss)
I1110 23:03:48.687736  2593 sgd_solver.cpp:106] Iteration 1364, lr = 0.001
I1110 23:03:51.026927  2593 solver.cpp:295] Iteration 1365 (no loss supplied for SingleUpdateStep)
I1110 23:03:51.027022  2593 solver.cpp:310]     Train net output #0: loss = 0.56389 (* 1 = 0.56389 loss)
I1110 23:03:51.027043  2593 sgd_solver.cpp:106] Iteration 1365, lr = 0.001
I1110 23:03:53.114954  2593 solver.cpp:295] Iteration 1366 (no loss supplied for SingleUpdateStep)
I1110 23:03:53.115082  2593 solver.cpp:310]     Train net output #0: loss = 0.493249 (* 1 = 0.493249 loss)
I1110 23:03:53.115104  2593 sgd_solver.cpp:106] Iteration 1366, lr = 0.001
I1110 23:03:55.083848  2593 solver.cpp:295] Iteration 1367 (no loss supplied for SingleUpdateStep)
I1110 23:03:55.083946  2593 solver.cpp:310]     Train net output #0: loss = 0.505706 (* 1 = 0.505706 loss)
I1110 23:03:55.083969  2593 sgd_solver.cpp:106] Iteration 1367, lr = 0.001
I1110 23:03:57.106840  2593 solver.cpp:295] Iteration 1368 (no loss supplied for SingleUpdateStep)
I1110 23:03:57.106905  2593 solver.cpp:310]     Train net output #0: loss = 0.46715 (* 1 = 0.46715 loss)
I1110 23:03:57.106925  2593 sgd_solver.cpp:106] Iteration 1368, lr = 0.001
I1110 23:03:59.207432  2593 solver.cpp:295] Iteration 1369 (no loss supplied for SingleUpdateStep)
I1110 23:03:59.207576  2593 solver.cpp:310]     Train net output #0: loss = 0.493483 (* 1 = 0.493483 loss)
I1110 23:03:59.207600  2593 sgd_solver.cpp:106] Iteration 1369, lr = 0.001
I1110 23:04:01.095145  2593 solver.cpp:295] Iteration 1370 (no loss supplied for SingleUpdateStep)
I1110 23:04:01.095217  2593 solver.cpp:310]     Train net output #0: loss = 0.529939 (* 1 = 0.529939 loss)
I1110 23:04:01.095239  2593 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I1110 23:04:03.468890  2593 solver.cpp:295] Iteration 1371 (no loss supplied for SingleUpdateStep)
I1110 23:04:03.469012  2593 solver.cpp:310]     Train net output #0: loss = 0.501577 (* 1 = 0.501577 loss)
I1110 23:04:03.469035  2593 sgd_solver.cpp:106] Iteration 1371, lr = 0.001
I1110 23:04:06.153185  2593 solver.cpp:295] Iteration 1372 (no loss supplied for SingleUpdateStep)
I1110 23:04:06.153267  2593 solver.cpp:310]     Train net output #0: loss = 0.523934 (* 1 = 0.523934 loss)
I1110 23:04:06.153288  2593 sgd_solver.cpp:106] Iteration 1372, lr = 0.001
I1110 23:04:08.264292  2593 solver.cpp:295] Iteration 1373 (no loss supplied for SingleUpdateStep)
I1110 23:04:08.264385  2593 solver.cpp:310]     Train net output #0: loss = 0.555455 (* 1 = 0.555455 loss)
I1110 23:04:08.264406  2593 sgd_solver.cpp:106] Iteration 1373, lr = 0.001
I1110 23:04:10.573940  2593 solver.cpp:295] Iteration 1374 (no loss supplied for SingleUpdateStep)
I1110 23:04:10.574101  2593 solver.cpp:310]     Train net output #0: loss = 0.534772 (* 1 = 0.534772 loss)
I1110 23:04:10.574131  2593 sgd_solver.cpp:106] Iteration 1374, lr = 0.001
I1110 23:04:12.461390  2593 solver.cpp:295] Iteration 1375 (no loss supplied for SingleUpdateStep)
I1110 23:04:12.461513  2593 solver.cpp:310]     Train net output #0: loss = 0.521211 (* 1 = 0.521211 loss)
I1110 23:04:12.461535  2593 sgd_solver.cpp:106] Iteration 1375, lr = 0.001
I1110 23:04:14.471925  2593 solver.cpp:295] Iteration 1376 (no loss supplied for SingleUpdateStep)
I1110 23:04:14.472057  2593 solver.cpp:310]     Train net output #0: loss = 0.516723 (* 1 = 0.516723 loss)
I1110 23:04:14.472089  2593 sgd_solver.cpp:106] Iteration 1376, lr = 0.001
I1110 23:04:16.530562  2593 solver.cpp:295] Iteration 1377 (no loss supplied for SingleUpdateStep)
I1110 23:04:16.530611  2593 solver.cpp:310]     Train net output #0: loss = 0.541277 (* 1 = 0.541277 loss)
I1110 23:04:16.530629  2593 sgd_solver.cpp:106] Iteration 1377, lr = 0.001
I1110 23:04:18.548481  2593 solver.cpp:295] Iteration 1378 (no loss supplied for SingleUpdateStep)
I1110 23:04:18.548600  2593 solver.cpp:310]     Train net output #0: loss = 0.494847 (* 1 = 0.494847 loss)
I1110 23:04:18.548624  2593 sgd_solver.cpp:106] Iteration 1378, lr = 0.001
I1110 23:04:20.407619  2593 solver.cpp:295] Iteration 1379 (no loss supplied for SingleUpdateStep)
I1110 23:04:20.407688  2593 solver.cpp:310]     Train net output #0: loss = 0.517704 (* 1 = 0.517704 loss)
I1110 23:04:20.407708  2593 sgd_solver.cpp:106] Iteration 1379, lr = 0.001
I1110 23:04:22.302562  2593 solver.cpp:295] Iteration 1380 (no loss supplied for SingleUpdateStep)
I1110 23:04:22.302706  2593 solver.cpp:310]     Train net output #0: loss = 0.532202 (* 1 = 0.532202 loss)
I1110 23:04:22.302729  2593 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I1110 23:04:24.071849  2593 solver.cpp:295] Iteration 1381 (no loss supplied for SingleUpdateStep)
I1110 23:04:24.072008  2593 solver.cpp:310]     Train net output #0: loss = 0.517594 (* 1 = 0.517594 loss)
I1110 23:04:24.072044  2593 sgd_solver.cpp:106] Iteration 1381, lr = 0.001
I1110 23:04:26.132469  2593 solver.cpp:295] Iteration 1382 (no loss supplied for SingleUpdateStep)
I1110 23:04:26.132603  2593 solver.cpp:310]     Train net output #0: loss = 0.513202 (* 1 = 0.513202 loss)
I1110 23:04:26.132632  2593 sgd_solver.cpp:106] Iteration 1382, lr = 0.001
I1110 23:04:27.935122  2593 solver.cpp:295] Iteration 1383 (no loss supplied for SingleUpdateStep)
I1110 23:04:27.935205  2593 solver.cpp:310]     Train net output #0: loss = 0.513382 (* 1 = 0.513382 loss)
I1110 23:04:27.935226  2593 sgd_solver.cpp:106] Iteration 1383, lr = 0.001
I1110 23:04:29.709580  2593 solver.cpp:295] Iteration 1384 (no loss supplied for SingleUpdateStep)
I1110 23:04:29.709664  2593 solver.cpp:310]     Train net output #0: loss = 0.520156 (* 1 = 0.520156 loss)
I1110 23:04:29.709686  2593 sgd_solver.cpp:106] Iteration 1384, lr = 0.001
I1110 23:04:31.573324  2593 solver.cpp:295] Iteration 1385 (no loss supplied for SingleUpdateStep)
I1110 23:04:31.573434  2593 solver.cpp:310]     Train net output #0: loss = 0.526815 (* 1 = 0.526815 loss)
I1110 23:04:31.573458  2593 sgd_solver.cpp:106] Iteration 1385, lr = 0.001
I1110 23:04:33.444064  2593 solver.cpp:295] Iteration 1386 (no loss supplied for SingleUpdateStep)
I1110 23:04:33.444140  2593 solver.cpp:310]     Train net output #0: loss = 0.535665 (* 1 = 0.535665 loss)
I1110 23:04:33.444160  2593 sgd_solver.cpp:106] Iteration 1386, lr = 0.001
I1110 23:04:35.284379  2593 solver.cpp:295] Iteration 1387 (no loss supplied for SingleUpdateStep)
I1110 23:04:35.284494  2593 solver.cpp:310]     Train net output #0: loss = 0.517609 (* 1 = 0.517609 loss)
I1110 23:04:35.284523  2593 sgd_solver.cpp:106] Iteration 1387, lr = 0.001
I1110 23:04:37.123924  2593 solver.cpp:295] Iteration 1388 (no loss supplied for SingleUpdateStep)
I1110 23:04:37.124085  2593 solver.cpp:310]     Train net output #0: loss = 0.520659 (* 1 = 0.520659 loss)
I1110 23:04:37.124125  2593 sgd_solver.cpp:106] Iteration 1388, lr = 0.001
I1110 23:04:38.931133  2593 solver.cpp:295] Iteration 1389 (no loss supplied for SingleUpdateStep)
I1110 23:04:38.931231  2593 solver.cpp:310]     Train net output #0: loss = 0.518317 (* 1 = 0.518317 loss)
I1110 23:04:38.931254  2593 sgd_solver.cpp:106] Iteration 1389, lr = 0.001
I1110 23:04:40.682081  2593 solver.cpp:295] Iteration 1390 (no loss supplied for SingleUpdateStep)
I1110 23:04:40.682200  2593 solver.cpp:310]     Train net output #0: loss = 0.479542 (* 1 = 0.479542 loss)
I1110 23:04:40.682225  2593 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I1110 23:04:42.539572  2593 solver.cpp:295] Iteration 1391 (no loss supplied for SingleUpdateStep)
I1110 23:04:42.539680  2593 solver.cpp:310]     Train net output #0: loss = 0.503461 (* 1 = 0.503461 loss)
I1110 23:04:42.539700  2593 sgd_solver.cpp:106] Iteration 1391, lr = 0.001
I1110 23:04:44.359100  2593 solver.cpp:295] Iteration 1392 (no loss supplied for SingleUpdateStep)
I1110 23:04:44.359225  2593 solver.cpp:310]     Train net output #0: loss = 0.496381 (* 1 = 0.496381 loss)
I1110 23:04:44.359254  2593 sgd_solver.cpp:106] Iteration 1392, lr = 0.001
I1110 23:04:46.312166  2593 solver.cpp:295] Iteration 1393 (no loss supplied for SingleUpdateStep)
I1110 23:04:46.312259  2593 solver.cpp:310]     Train net output #0: loss = 0.498107 (* 1 = 0.498107 loss)
I1110 23:04:46.312280  2593 sgd_solver.cpp:106] Iteration 1393, lr = 0.001
I1110 23:04:48.168314  2593 solver.cpp:295] Iteration 1394 (no loss supplied for SingleUpdateStep)
I1110 23:04:48.168377  2593 solver.cpp:310]     Train net output #0: loss = 0.492082 (* 1 = 0.492082 loss)
I1110 23:04:48.168396  2593 sgd_solver.cpp:106] Iteration 1394, lr = 0.001
I1110 23:04:50.030364  2593 solver.cpp:295] Iteration 1395 (no loss supplied for SingleUpdateStep)
I1110 23:04:50.030488  2593 solver.cpp:310]     Train net output #0: loss = 0.462242 (* 1 = 0.462242 loss)
I1110 23:04:50.030511  2593 sgd_solver.cpp:106] Iteration 1395, lr = 0.001
I1110 23:04:51.828512  2593 solver.cpp:295] Iteration 1396 (no loss supplied for SingleUpdateStep)
I1110 23:04:51.828590  2593 solver.cpp:310]     Train net output #0: loss = 0.522401 (* 1 = 0.522401 loss)
I1110 23:04:51.828611  2593 sgd_solver.cpp:106] Iteration 1396, lr = 0.001
I1110 23:04:53.741777  2593 solver.cpp:295] Iteration 1397 (no loss supplied for SingleUpdateStep)
I1110 23:04:53.741919  2593 solver.cpp:310]     Train net output #0: loss = 0.504844 (* 1 = 0.504844 loss)
I1110 23:04:53.741942  2593 sgd_solver.cpp:106] Iteration 1397, lr = 0.001
I1110 23:04:55.563537  2593 solver.cpp:295] Iteration 1398 (no loss supplied for SingleUpdateStep)
I1110 23:04:55.563591  2593 solver.cpp:310]     Train net output #0: loss = 0.488239 (* 1 = 0.488239 loss)
I1110 23:04:55.563609  2593 sgd_solver.cpp:106] Iteration 1398, lr = 0.001
I1110 23:04:57.344236  2593 solver.cpp:295] Iteration 1399 (no loss supplied for SingleUpdateStep)
I1110 23:04:57.344359  2593 solver.cpp:310]     Train net output #0: loss = 0.516288 (* 1 = 0.516288 loss)
I1110 23:04:57.344388  2593 sgd_solver.cpp:106] Iteration 1399, lr = 0.001
I1110 23:04:58.957098  2593 solver.cpp:295] Iteration 1400 (no loss supplied for SingleUpdateStep)
I1110 23:04:58.957151  2593 solver.cpp:310]     Train net output #0: loss = 0.533058 (* 1 = 0.533058 loss)
I1110 23:04:58.957170  2593 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I1110 23:05:00.828711  2593 solver.cpp:295] Iteration 1401 (no loss supplied for SingleUpdateStep)
I1110 23:05:00.828894  2593 solver.cpp:310]     Train net output #0: loss = 0.528492 (* 1 = 0.528492 loss)
I1110 23:05:00.828935  2593 sgd_solver.cpp:106] Iteration 1401, lr = 0.001
I1110 23:05:02.639909  2593 solver.cpp:295] Iteration 1402 (no loss supplied for SingleUpdateStep)
I1110 23:05:02.640085  2593 solver.cpp:310]     Train net output #0: loss = 0.538473 (* 1 = 0.538473 loss)
I1110 23:05:02.640110  2593 sgd_solver.cpp:106] Iteration 1402, lr = 0.001
I1110 23:05:04.586464  2593 solver.cpp:295] Iteration 1403 (no loss supplied for SingleUpdateStep)
I1110 23:05:04.586537  2593 solver.cpp:310]     Train net output #0: loss = 0.521974 (* 1 = 0.521974 loss)
I1110 23:05:04.586558  2593 sgd_solver.cpp:106] Iteration 1403, lr = 0.001
I1110 23:05:06.385357  2593 solver.cpp:295] Iteration 1404 (no loss supplied for SingleUpdateStep)
I1110 23:05:06.385447  2593 solver.cpp:310]     Train net output #0: loss = 0.500828 (* 1 = 0.500828 loss)
I1110 23:05:06.385468  2593 sgd_solver.cpp:106] Iteration 1404, lr = 0.001
I1110 23:05:08.760746  2593 solver.cpp:295] Iteration 1405 (no loss supplied for SingleUpdateStep)
I1110 23:05:08.760848  2593 solver.cpp:310]     Train net output #0: loss = 0.520222 (* 1 = 0.520222 loss)
I1110 23:05:08.760869  2593 sgd_solver.cpp:106] Iteration 1405, lr = 0.001
I1110 23:05:10.575153  2593 solver.cpp:295] Iteration 1406 (no loss supplied for SingleUpdateStep)
I1110 23:05:10.575294  2593 solver.cpp:310]     Train net output #0: loss = 0.481352 (* 1 = 0.481352 loss)
I1110 23:05:10.575325  2593 sgd_solver.cpp:106] Iteration 1406, lr = 0.001
I1110 23:05:12.586488  2593 solver.cpp:295] Iteration 1407 (no loss supplied for SingleUpdateStep)
I1110 23:05:12.586621  2593 solver.cpp:310]     Train net output #0: loss = 0.508014 (* 1 = 0.508014 loss)
I1110 23:05:12.586644  2593 sgd_solver.cpp:106] Iteration 1407, lr = 0.001
I1110 23:05:15.035601  2593 solver.cpp:295] Iteration 1408 (no loss supplied for SingleUpdateStep)
I1110 23:05:15.035661  2593 solver.cpp:310]     Train net output #0: loss = 0.482584 (* 1 = 0.482584 loss)
I1110 23:05:15.035682  2593 sgd_solver.cpp:106] Iteration 1408, lr = 0.001
I1110 23:05:17.033941  2593 solver.cpp:295] Iteration 1409 (no loss supplied for SingleUpdateStep)
I1110 23:05:17.034049  2593 solver.cpp:310]     Train net output #0: loss = 0.489962 (* 1 = 0.489962 loss)
I1110 23:05:17.034073  2593 sgd_solver.cpp:106] Iteration 1409, lr = 0.001
I1110 23:05:19.148069  2593 solver.cpp:295] Iteration 1410 (no loss supplied for SingleUpdateStep)
I1110 23:05:19.148190  2593 solver.cpp:310]     Train net output #0: loss = 0.534593 (* 1 = 0.534593 loss)
I1110 23:05:19.148219  2593 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I1110 23:05:21.881203  2593 solver.cpp:295] Iteration 1411 (no loss supplied for SingleUpdateStep)
I1110 23:05:21.881294  2593 solver.cpp:310]     Train net output #0: loss = 0.496354 (* 1 = 0.496354 loss)
I1110 23:05:21.881314  2593 sgd_solver.cpp:106] Iteration 1411, lr = 0.001
I1110 23:05:24.484215  2593 solver.cpp:295] Iteration 1412 (no loss supplied for SingleUpdateStep)
I1110 23:05:24.484328  2593 solver.cpp:310]     Train net output #0: loss = 0.521488 (* 1 = 0.521488 loss)
I1110 23:05:24.484350  2593 sgd_solver.cpp:106] Iteration 1412, lr = 0.001
I1110 23:05:27.222515  2593 solver.cpp:295] Iteration 1413 (no loss supplied for SingleUpdateStep)
I1110 23:05:27.222576  2593 solver.cpp:310]     Train net output #0: loss = 0.518206 (* 1 = 0.518206 loss)
I1110 23:05:27.222595  2593 sgd_solver.cpp:106] Iteration 1413, lr = 0.001
I1110 23:05:29.885917  2593 solver.cpp:295] Iteration 1414 (no loss supplied for SingleUpdateStep)
I1110 23:05:29.886018  2593 solver.cpp:310]     Train net output #0: loss = 0.561431 (* 1 = 0.561431 loss)
I1110 23:05:29.886039  2593 sgd_solver.cpp:106] Iteration 1414, lr = 0.001
I1110 23:05:32.842464  2593 solver.cpp:295] Iteration 1415 (no loss supplied for SingleUpdateStep)
I1110 23:05:32.842598  2593 solver.cpp:310]     Train net output #0: loss = 0.542566 (* 1 = 0.542566 loss)
I1110 23:05:32.842628  2593 sgd_solver.cpp:106] Iteration 1415, lr = 0.001
I1110 23:05:35.220016  2593 solver.cpp:295] Iteration 1416 (no loss supplied for SingleUpdateStep)
I1110 23:05:35.220139  2593 solver.cpp:310]     Train net output #0: loss = 0.492982 (* 1 = 0.492982 loss)
I1110 23:05:35.220163  2593 sgd_solver.cpp:106] Iteration 1416, lr = 0.001
I1110 23:05:37.402829  2593 solver.cpp:295] Iteration 1417 (no loss supplied for SingleUpdateStep)
I1110 23:05:37.402912  2593 solver.cpp:310]     Train net output #0: loss = 0.558089 (* 1 = 0.558089 loss)
I1110 23:05:37.402935  2593 sgd_solver.cpp:106] Iteration 1417, lr = 0.001
I1110 23:05:39.377857  2593 solver.cpp:295] Iteration 1418 (no loss supplied for SingleUpdateStep)
I1110 23:05:39.377946  2593 solver.cpp:310]     Train net output #0: loss = 0.534422 (* 1 = 0.534422 loss)
I1110 23:05:39.377969  2593 sgd_solver.cpp:106] Iteration 1418, lr = 0.001
I1110 23:05:41.710181  2593 solver.cpp:295] Iteration 1419 (no loss supplied for SingleUpdateStep)
I1110 23:05:41.710278  2593 solver.cpp:310]     Train net output #0: loss = 0.505138 (* 1 = 0.505138 loss)
I1110 23:05:41.710299  2593 sgd_solver.cpp:106] Iteration 1419, lr = 0.001
I1110 23:05:43.710428  2593 solver.cpp:295] Iteration 1420 (no loss supplied for SingleUpdateStep)
I1110 23:05:43.710523  2593 solver.cpp:310]     Train net output #0: loss = 0.50136 (* 1 = 0.50136 loss)
I1110 23:05:43.710543  2593 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I1110 23:05:45.788185  2593 solver.cpp:295] Iteration 1421 (no loss supplied for SingleUpdateStep)
I1110 23:05:45.788297  2593 solver.cpp:310]     Train net output #0: loss = 0.50743 (* 1 = 0.50743 loss)
I1110 23:05:45.788319  2593 sgd_solver.cpp:106] Iteration 1421, lr = 0.001
I1110 23:05:47.580036  2593 solver.cpp:295] Iteration 1422 (no loss supplied for SingleUpdateStep)
I1110 23:05:47.580195  2593 solver.cpp:310]     Train net output #0: loss = 0.48417 (* 1 = 0.48417 loss)
I1110 23:05:47.580224  2593 sgd_solver.cpp:106] Iteration 1422, lr = 0.001
I1110 23:05:49.879647  2593 solver.cpp:295] Iteration 1423 (no loss supplied for SingleUpdateStep)
I1110 23:05:49.879714  2593 solver.cpp:310]     Train net output #0: loss = 0.516626 (* 1 = 0.516626 loss)
I1110 23:05:49.879734  2593 sgd_solver.cpp:106] Iteration 1423, lr = 0.001
I1110 23:05:51.901921  2593 solver.cpp:295] Iteration 1424 (no loss supplied for SingleUpdateStep)
I1110 23:05:51.901979  2593 solver.cpp:310]     Train net output #0: loss = 0.501951 (* 1 = 0.501951 loss)
I1110 23:05:51.901999  2593 sgd_solver.cpp:106] Iteration 1424, lr = 0.001
I1110 23:05:54.320325  2593 solver.cpp:295] Iteration 1425 (no loss supplied for SingleUpdateStep)
I1110 23:05:54.320430  2593 solver.cpp:310]     Train net output #0: loss = 0.527045 (* 1 = 0.527045 loss)
I1110 23:05:54.320452  2593 sgd_solver.cpp:106] Iteration 1425, lr = 0.001
I1110 23:05:56.335358  2593 solver.cpp:295] Iteration 1426 (no loss supplied for SingleUpdateStep)
I1110 23:05:56.336321  2593 solver.cpp:310]     Train net output #0: loss = 0.517095 (* 1 = 0.517095 loss)
I1110 23:05:56.336365  2593 sgd_solver.cpp:106] Iteration 1426, lr = 0.001
I1110 23:05:58.528314  2593 solver.cpp:295] Iteration 1427 (no loss supplied for SingleUpdateStep)
I1110 23:05:58.528372  2593 solver.cpp:310]     Train net output #0: loss = 0.498391 (* 1 = 0.498391 loss)
I1110 23:05:58.528391  2593 sgd_solver.cpp:106] Iteration 1427, lr = 0.001
I1110 23:06:00.866560  2593 solver.cpp:295] Iteration 1428 (no loss supplied for SingleUpdateStep)
I1110 23:06:00.866669  2593 solver.cpp:310]     Train net output #0: loss = 0.518017 (* 1 = 0.518017 loss)
I1110 23:06:00.866696  2593 sgd_solver.cpp:106] Iteration 1428, lr = 0.001
I1110 23:06:02.700044  2593 solver.cpp:295] Iteration 1429 (no loss supplied for SingleUpdateStep)
I1110 23:06:02.700145  2593 solver.cpp:310]     Train net output #0: loss = 0.519303 (* 1 = 0.519303 loss)
I1110 23:06:02.700170  2593 sgd_solver.cpp:106] Iteration 1429, lr = 0.001
I1110 23:06:04.521200  2593 solver.cpp:295] Iteration 1430 (no loss supplied for SingleUpdateStep)
I1110 23:06:04.521303  2593 solver.cpp:310]     Train net output #0: loss = 0.487669 (* 1 = 0.487669 loss)
I1110 23:06:04.521327  2593 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I1110 23:06:06.515583  2593 solver.cpp:295] Iteration 1431 (no loss supplied for SingleUpdateStep)
I1110 23:06:06.515707  2593 solver.cpp:310]     Train net output #0: loss = 0.499177 (* 1 = 0.499177 loss)
I1110 23:06:06.515733  2593 sgd_solver.cpp:106] Iteration 1431, lr = 0.001
I1110 23:06:08.395104  2593 solver.cpp:295] Iteration 1432 (no loss supplied for SingleUpdateStep)
I1110 23:06:08.395182  2593 solver.cpp:310]     Train net output #0: loss = 0.529 (* 1 = 0.529 loss)
I1110 23:06:08.395202  2593 sgd_solver.cpp:106] Iteration 1432, lr = 0.001
I1110 23:06:10.584619  2593 solver.cpp:295] Iteration 1433 (no loss supplied for SingleUpdateStep)
I1110 23:06:10.584708  2593 solver.cpp:310]     Train net output #0: loss = 0.537436 (* 1 = 0.537436 loss)
I1110 23:06:10.584729  2593 sgd_solver.cpp:106] Iteration 1433, lr = 0.001
I1110 23:06:13.283450  2593 solver.cpp:295] Iteration 1434 (no loss supplied for SingleUpdateStep)
I1110 23:06:13.283534  2593 solver.cpp:310]     Train net output #0: loss = 0.476751 (* 1 = 0.476751 loss)
I1110 23:06:13.283553  2593 sgd_solver.cpp:106] Iteration 1434, lr = 0.001
I1110 23:06:15.352633  2593 solver.cpp:295] Iteration 1435 (no loss supplied for SingleUpdateStep)
I1110 23:06:15.352753  2593 solver.cpp:310]     Train net output #0: loss = 0.51704 (* 1 = 0.51704 loss)
I1110 23:06:15.352777  2593 sgd_solver.cpp:106] Iteration 1435, lr = 0.001
I1110 23:06:17.725255  2593 solver.cpp:295] Iteration 1436 (no loss supplied for SingleUpdateStep)
I1110 23:06:17.725373  2593 solver.cpp:310]     Train net output #0: loss = 0.506151 (* 1 = 0.506151 loss)
I1110 23:06:17.725396  2593 sgd_solver.cpp:106] Iteration 1436, lr = 0.001
I1110 23:06:19.900357  2593 solver.cpp:295] Iteration 1437 (no loss supplied for SingleUpdateStep)
I1110 23:06:19.900459  2593 solver.cpp:310]     Train net output #0: loss = 0.503145 (* 1 = 0.503145 loss)
I1110 23:06:19.900482  2593 sgd_solver.cpp:106] Iteration 1437, lr = 0.001
I1110 23:06:22.752914  2593 solver.cpp:295] Iteration 1438 (no loss supplied for SingleUpdateStep)
I1110 23:06:22.753001  2593 solver.cpp:310]     Train net output #0: loss = 0.502153 (* 1 = 0.502153 loss)
I1110 23:06:22.753022  2593 sgd_solver.cpp:106] Iteration 1438, lr = 0.001
I1110 23:06:25.081960  2593 solver.cpp:295] Iteration 1439 (no loss supplied for SingleUpdateStep)
I1110 23:06:25.082085  2593 solver.cpp:310]     Train net output #0: loss = 0.540783 (* 1 = 0.540783 loss)
I1110 23:06:25.082108  2593 sgd_solver.cpp:106] Iteration 1439, lr = 0.001
I1110 23:06:28.456401  2593 solver.cpp:295] Iteration 1440 (no loss supplied for SingleUpdateStep)
I1110 23:06:28.456468  2593 solver.cpp:310]     Train net output #0: loss = 0.499415 (* 1 = 0.499415 loss)
I1110 23:06:28.456488  2593 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I1110 23:06:31.532068  2593 solver.cpp:295] Iteration 1441 (no loss supplied for SingleUpdateStep)
I1110 23:06:31.532172  2593 solver.cpp:310]     Train net output #0: loss = 0.492573 (* 1 = 0.492573 loss)
I1110 23:06:31.532196  2593 sgd_solver.cpp:106] Iteration 1441, lr = 0.001
I1110 23:06:34.191041  2593 solver.cpp:295] Iteration 1442 (no loss supplied for SingleUpdateStep)
I1110 23:06:34.191120  2593 solver.cpp:310]     Train net output #0: loss = 0.496937 (* 1 = 0.496937 loss)
I1110 23:06:34.191143  2593 sgd_solver.cpp:106] Iteration 1442, lr = 0.001
I1110 23:06:36.821749  2593 solver.cpp:295] Iteration 1443 (no loss supplied for SingleUpdateStep)
I1110 23:06:36.821874  2593 solver.cpp:310]     Train net output #0: loss = 0.535417 (* 1 = 0.535417 loss)
I1110 23:06:36.821899  2593 sgd_solver.cpp:106] Iteration 1443, lr = 0.001
I1110 23:06:39.245445  2593 solver.cpp:295] Iteration 1444 (no loss supplied for SingleUpdateStep)
I1110 23:06:39.245501  2593 solver.cpp:310]     Train net output #0: loss = 0.531293 (* 1 = 0.531293 loss)
I1110 23:06:39.245519  2593 sgd_solver.cpp:106] Iteration 1444, lr = 0.001
I1110 23:06:42.066556  2593 solver.cpp:295] Iteration 1445 (no loss supplied for SingleUpdateStep)
I1110 23:06:42.066663  2593 solver.cpp:310]     Train net output #0: loss = 0.458842 (* 1 = 0.458842 loss)
I1110 23:06:42.066685  2593 sgd_solver.cpp:106] Iteration 1445, lr = 0.001
I1110 23:06:44.424636  2593 solver.cpp:295] Iteration 1446 (no loss supplied for SingleUpdateStep)
I1110 23:06:44.424748  2593 solver.cpp:310]     Train net output #0: loss = 0.528631 (* 1 = 0.528631 loss)
I1110 23:06:44.424772  2593 sgd_solver.cpp:106] Iteration 1446, lr = 0.001
I1110 23:06:47.307644  2593 solver.cpp:295] Iteration 1447 (no loss supplied for SingleUpdateStep)
I1110 23:06:47.307793  2593 solver.cpp:310]     Train net output #0: loss = 0.49934 (* 1 = 0.49934 loss)
I1110 23:06:47.307824  2593 sgd_solver.cpp:106] Iteration 1447, lr = 0.001
I1110 23:06:49.880291  2593 solver.cpp:295] Iteration 1448 (no loss supplied for SingleUpdateStep)
I1110 23:06:49.880440  2593 solver.cpp:310]     Train net output #0: loss = 0.529399 (* 1 = 0.529399 loss)
I1110 23:06:49.880466  2593 sgd_solver.cpp:106] Iteration 1448, lr = 0.001
I1110 23:06:52.543894  2593 solver.cpp:295] Iteration 1449 (no loss supplied for SingleUpdateStep)
I1110 23:06:52.544018  2593 solver.cpp:310]     Train net output #0: loss = 0.501024 (* 1 = 0.501024 loss)
I1110 23:06:52.544042  2593 sgd_solver.cpp:106] Iteration 1449, lr = 0.001
I1110 23:06:54.938030  2593 solver.cpp:295] Iteration 1450 (no loss supplied for SingleUpdateStep)
I1110 23:06:54.938139  2593 solver.cpp:310]     Train net output #0: loss = 0.497939 (* 1 = 0.497939 loss)
I1110 23:06:54.938160  2593 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I1110 23:06:57.893178  2593 solver.cpp:295] Iteration 1451 (no loss supplied for SingleUpdateStep)
I1110 23:06:57.893231  2593 solver.cpp:310]     Train net output #0: loss = 0.492848 (* 1 = 0.492848 loss)
I1110 23:06:57.893250  2593 sgd_solver.cpp:106] Iteration 1451, lr = 0.001
I1110 23:07:00.309563  2593 solver.cpp:295] Iteration 1452 (no loss supplied for SingleUpdateStep)
I1110 23:07:00.309708  2593 solver.cpp:310]     Train net output #0: loss = 0.492575 (* 1 = 0.492575 loss)
I1110 23:07:00.309732  2593 sgd_solver.cpp:106] Iteration 1452, lr = 0.001
I1110 23:07:02.613415  2593 solver.cpp:295] Iteration 1453 (no loss supplied for SingleUpdateStep)
I1110 23:07:02.613538  2593 solver.cpp:310]     Train net output #0: loss = 0.479116 (* 1 = 0.479116 loss)
I1110 23:07:02.613561  2593 sgd_solver.cpp:106] Iteration 1453, lr = 0.001
I1110 23:07:05.100170  2593 solver.cpp:295] Iteration 1454 (no loss supplied for SingleUpdateStep)
I1110 23:07:05.100294  2593 solver.cpp:310]     Train net output #0: loss = 0.504437 (* 1 = 0.504437 loss)
I1110 23:07:05.100318  2593 sgd_solver.cpp:106] Iteration 1454, lr = 0.001
I1110 23:07:07.581646  2593 solver.cpp:295] Iteration 1455 (no loss supplied for SingleUpdateStep)
I1110 23:07:07.581714  2593 solver.cpp:310]     Train net output #0: loss = 0.488396 (* 1 = 0.488396 loss)
I1110 23:07:07.581734  2593 sgd_solver.cpp:106] Iteration 1455, lr = 0.001
I1110 23:07:09.942423  2593 solver.cpp:295] Iteration 1456 (no loss supplied for SingleUpdateStep)
I1110 23:07:09.942575  2593 solver.cpp:310]     Train net output #0: loss = 0.502666 (* 1 = 0.502666 loss)
I1110 23:07:09.942616  2593 sgd_solver.cpp:106] Iteration 1456, lr = 0.001
I1110 23:07:12.220758  2593 solver.cpp:295] Iteration 1457 (no loss supplied for SingleUpdateStep)
I1110 23:07:12.220834  2593 solver.cpp:310]     Train net output #0: loss = 0.492836 (* 1 = 0.492836 loss)
I1110 23:07:12.220854  2593 sgd_solver.cpp:106] Iteration 1457, lr = 0.001
I1110 23:07:14.433868  2593 solver.cpp:295] Iteration 1458 (no loss supplied for SingleUpdateStep)
I1110 23:07:14.434006  2593 solver.cpp:310]     Train net output #0: loss = 0.474515 (* 1 = 0.474515 loss)
I1110 23:07:14.434031  2593 sgd_solver.cpp:106] Iteration 1458, lr = 0.001
I1110 23:07:16.650779  2593 solver.cpp:295] Iteration 1459 (no loss supplied for SingleUpdateStep)
I1110 23:07:16.650872  2593 solver.cpp:310]     Train net output #0: loss = 0.542298 (* 1 = 0.542298 loss)
I1110 23:07:16.650893  2593 sgd_solver.cpp:106] Iteration 1459, lr = 0.001
I1110 23:07:18.970321  2593 solver.cpp:295] Iteration 1460 (no loss supplied for SingleUpdateStep)
I1110 23:07:18.970474  2593 solver.cpp:310]     Train net output #0: loss = 0.513905 (* 1 = 0.513905 loss)
I1110 23:07:18.970501  2593 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I1110 23:07:21.174089  2593 solver.cpp:295] Iteration 1461 (no loss supplied for SingleUpdateStep)
I1110 23:07:21.174206  2593 solver.cpp:310]     Train net output #0: loss = 0.510664 (* 1 = 0.510664 loss)
I1110 23:07:21.174228  2593 sgd_solver.cpp:106] Iteration 1461, lr = 0.001
I1110 23:07:23.307488  2593 solver.cpp:295] Iteration 1462 (no loss supplied for SingleUpdateStep)
I1110 23:07:23.307620  2593 solver.cpp:310]     Train net output #0: loss = 0.523329 (* 1 = 0.523329 loss)
I1110 23:07:23.307648  2593 sgd_solver.cpp:106] Iteration 1462, lr = 0.001
I1110 23:07:25.618813  2593 solver.cpp:295] Iteration 1463 (no loss supplied for SingleUpdateStep)
I1110 23:07:25.618921  2593 solver.cpp:310]     Train net output #0: loss = 0.483465 (* 1 = 0.483465 loss)
I1110 23:07:25.618943  2593 sgd_solver.cpp:106] Iteration 1463, lr = 0.001
I1110 23:07:27.924451  2593 solver.cpp:295] Iteration 1464 (no loss supplied for SingleUpdateStep)
I1110 23:07:27.924510  2593 solver.cpp:310]     Train net output #0: loss = 0.528538 (* 1 = 0.528538 loss)
I1110 23:07:27.924532  2593 sgd_solver.cpp:106] Iteration 1464, lr = 0.001
I1110 23:07:30.312193  2593 solver.cpp:295] Iteration 1465 (no loss supplied for SingleUpdateStep)
I1110 23:07:30.312371  2593 solver.cpp:310]     Train net output #0: loss = 0.490497 (* 1 = 0.490497 loss)
I1110 23:07:30.312394  2593 sgd_solver.cpp:106] Iteration 1465, lr = 0.001
I1110 23:07:32.756412  2593 solver.cpp:295] Iteration 1466 (no loss supplied for SingleUpdateStep)
I1110 23:07:32.756491  2593 solver.cpp:310]     Train net output #0: loss = 0.497065 (* 1 = 0.497065 loss)
I1110 23:07:32.756512  2593 sgd_solver.cpp:106] Iteration 1466, lr = 0.001
I1110 23:07:35.029023  2593 solver.cpp:295] Iteration 1467 (no loss supplied for SingleUpdateStep)
I1110 23:07:35.029178  2593 solver.cpp:310]     Train net output #0: loss = 0.519602 (* 1 = 0.519602 loss)
I1110 23:07:35.029217  2593 sgd_solver.cpp:106] Iteration 1467, lr = 0.001
I1110 23:07:37.282837  2593 solver.cpp:295] Iteration 1468 (no loss supplied for SingleUpdateStep)
I1110 23:07:37.282912  2593 solver.cpp:310]     Train net output #0: loss = 0.537204 (* 1 = 0.537204 loss)
I1110 23:07:37.282930  2593 sgd_solver.cpp:106] Iteration 1468, lr = 0.001
I1110 23:07:39.886246  2593 solver.cpp:295] Iteration 1469 (no loss supplied for SingleUpdateStep)
I1110 23:07:39.886348  2593 solver.cpp:310]     Train net output #0: loss = 0.46803 (* 1 = 0.46803 loss)
I1110 23:07:39.886370  2593 sgd_solver.cpp:106] Iteration 1469, lr = 0.001
I1110 23:07:42.247802  2593 solver.cpp:295] Iteration 1470 (no loss supplied for SingleUpdateStep)
I1110 23:07:42.247927  2593 solver.cpp:310]     Train net output #0: loss = 0.477484 (* 1 = 0.477484 loss)
I1110 23:07:42.247951  2593 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I1110 23:07:44.480680  2593 solver.cpp:295] Iteration 1471 (no loss supplied for SingleUpdateStep)
I1110 23:07:44.480727  2593 solver.cpp:310]     Train net output #0: loss = 0.476772 (* 1 = 0.476772 loss)
I1110 23:07:44.480746  2593 sgd_solver.cpp:106] Iteration 1471, lr = 0.001
I1110 23:07:46.718411  2593 solver.cpp:295] Iteration 1472 (no loss supplied for SingleUpdateStep)
I1110 23:07:46.718489  2593 solver.cpp:310]     Train net output #0: loss = 0.522575 (* 1 = 0.522575 loss)
I1110 23:07:46.718511  2593 sgd_solver.cpp:106] Iteration 1472, lr = 0.001
I1110 23:07:49.276904  2593 solver.cpp:295] Iteration 1473 (no loss supplied for SingleUpdateStep)
I1110 23:07:49.276983  2593 solver.cpp:310]     Train net output #0: loss = 0.472249 (* 1 = 0.472249 loss)
I1110 23:07:49.277003  2593 sgd_solver.cpp:106] Iteration 1473, lr = 0.001
I1110 23:07:51.566717  2593 solver.cpp:295] Iteration 1474 (no loss supplied for SingleUpdateStep)
I1110 23:07:51.566833  2593 solver.cpp:310]     Train net output #0: loss = 0.489957 (* 1 = 0.489957 loss)
I1110 23:07:51.566854  2593 sgd_solver.cpp:106] Iteration 1474, lr = 0.001
I1110 23:07:53.813740  2593 solver.cpp:295] Iteration 1475 (no loss supplied for SingleUpdateStep)
I1110 23:07:53.813841  2593 solver.cpp:310]     Train net output #0: loss = 0.486004 (* 1 = 0.486004 loss)
I1110 23:07:53.813863  2593 sgd_solver.cpp:106] Iteration 1475, lr = 0.001
I1110 23:07:55.883361  2593 solver.cpp:295] Iteration 1476 (no loss supplied for SingleUpdateStep)
I1110 23:07:55.883474  2593 solver.cpp:310]     Train net output #0: loss = 0.559211 (* 1 = 0.559211 loss)
I1110 23:07:55.883496  2593 sgd_solver.cpp:106] Iteration 1476, lr = 0.001
I1110 23:07:58.556071  2593 solver.cpp:295] Iteration 1477 (no loss supplied for SingleUpdateStep)
I1110 23:07:58.556229  2593 solver.cpp:310]     Train net output #0: loss = 0.489155 (* 1 = 0.489155 loss)
I1110 23:07:58.556258  2593 sgd_solver.cpp:106] Iteration 1477, lr = 0.001
I1110 23:08:00.747416  2593 solver.cpp:295] Iteration 1478 (no loss supplied for SingleUpdateStep)
I1110 23:08:00.747534  2593 solver.cpp:310]     Train net output #0: loss = 0.502885 (* 1 = 0.502885 loss)
I1110 23:08:00.747558  2593 sgd_solver.cpp:106] Iteration 1478, lr = 0.001
I1110 23:08:02.936983  2593 solver.cpp:295] Iteration 1479 (no loss supplied for SingleUpdateStep)
I1110 23:08:02.937111  2593 solver.cpp:310]     Train net output #0: loss = 0.501706 (* 1 = 0.501706 loss)
I1110 23:08:02.937135  2593 sgd_solver.cpp:106] Iteration 1479, lr = 0.001
I1110 23:08:05.344547  2593 solver.cpp:295] Iteration 1480 (no loss supplied for SingleUpdateStep)
I1110 23:08:05.344646  2593 solver.cpp:310]     Train net output #0: loss = 0.538018 (* 1 = 0.538018 loss)
I1110 23:08:05.344666  2593 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I1110 23:08:07.925585  2593 solver.cpp:295] Iteration 1481 (no loss supplied for SingleUpdateStep)
I1110 23:08:07.925642  2593 solver.cpp:310]     Train net output #0: loss = 0.490182 (* 1 = 0.490182 loss)
I1110 23:08:07.925660  2593 sgd_solver.cpp:106] Iteration 1481, lr = 0.001
I1110 23:08:10.876021  2593 solver.cpp:295] Iteration 1482 (no loss supplied for SingleUpdateStep)
I1110 23:08:10.876133  2593 solver.cpp:310]     Train net output #0: loss = 0.495917 (* 1 = 0.495917 loss)
I1110 23:08:10.876157  2593 sgd_solver.cpp:106] Iteration 1482, lr = 0.001
I1110 23:08:14.069110  2593 solver.cpp:295] Iteration 1483 (no loss supplied for SingleUpdateStep)
I1110 23:08:14.069259  2593 solver.cpp:310]     Train net output #0: loss = 0.474344 (* 1 = 0.474344 loss)
I1110 23:08:14.069291  2593 sgd_solver.cpp:106] Iteration 1483, lr = 0.001
I1110 23:08:16.654570  2593 solver.cpp:295] Iteration 1484 (no loss supplied for SingleUpdateStep)
I1110 23:08:16.654706  2593 solver.cpp:310]     Train net output #0: loss = 0.539368 (* 1 = 0.539368 loss)
I1110 23:08:16.654731  2593 sgd_solver.cpp:106] Iteration 1484, lr = 0.001
I1110 23:08:19.193230  2593 solver.cpp:295] Iteration 1485 (no loss supplied for SingleUpdateStep)
I1110 23:08:19.193349  2593 solver.cpp:310]     Train net output #0: loss = 0.483617 (* 1 = 0.483617 loss)
I1110 23:08:19.193372  2593 sgd_solver.cpp:106] Iteration 1485, lr = 0.001
I1110 23:08:21.454963  2593 solver.cpp:295] Iteration 1486 (no loss supplied for SingleUpdateStep)
I1110 23:08:21.455065  2593 solver.cpp:310]     Train net output #0: loss = 0.457323 (* 1 = 0.457323 loss)
I1110 23:08:21.455085  2593 sgd_solver.cpp:106] Iteration 1486, lr = 0.001
I1110 23:08:23.733512  2593 solver.cpp:295] Iteration 1487 (no loss supplied for SingleUpdateStep)
I1110 23:08:23.733618  2593 solver.cpp:310]     Train net output #0: loss = 0.553968 (* 1 = 0.553968 loss)
I1110 23:08:23.733640  2593 sgd_solver.cpp:106] Iteration 1487, lr = 0.001
I1110 23:08:26.097924  2593 solver.cpp:295] Iteration 1488 (no loss supplied for SingleUpdateStep)
I1110 23:08:26.098021  2593 solver.cpp:310]     Train net output #0: loss = 0.501162 (* 1 = 0.501162 loss)
I1110 23:08:26.098042  2593 sgd_solver.cpp:106] Iteration 1488, lr = 0.001
I1110 23:08:28.740756  2593 solver.cpp:295] Iteration 1489 (no loss supplied for SingleUpdateStep)
I1110 23:08:28.740818  2593 solver.cpp:310]     Train net output #0: loss = 0.537002 (* 1 = 0.537002 loss)
I1110 23:08:28.740836  2593 sgd_solver.cpp:106] Iteration 1489, lr = 0.001
I1110 23:08:30.981613  2593 solver.cpp:295] Iteration 1490 (no loss supplied for SingleUpdateStep)
I1110 23:08:30.981703  2593 solver.cpp:310]     Train net output #0: loss = 0.52027 (* 1 = 0.52027 loss)
I1110 23:08:30.981721  2593 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I1110 23:08:33.256994  2593 solver.cpp:295] Iteration 1491 (no loss supplied for SingleUpdateStep)
I1110 23:08:33.257120  2593 solver.cpp:310]     Train net output #0: loss = 0.441165 (* 1 = 0.441165 loss)
I1110 23:08:33.257143  2593 sgd_solver.cpp:106] Iteration 1491, lr = 0.001
I1110 23:08:35.620767  2593 solver.cpp:295] Iteration 1492 (no loss supplied for SingleUpdateStep)
I1110 23:08:35.620842  2593 solver.cpp:310]     Train net output #0: loss = 0.480189 (* 1 = 0.480189 loss)
I1110 23:08:35.620865  2593 sgd_solver.cpp:106] Iteration 1492, lr = 0.001
I1110 23:08:37.996445  2593 solver.cpp:295] Iteration 1493 (no loss supplied for SingleUpdateStep)
I1110 23:08:37.996507  2593 solver.cpp:310]     Train net output #0: loss = 0.491177 (* 1 = 0.491177 loss)
I1110 23:08:37.996527  2593 sgd_solver.cpp:106] Iteration 1493, lr = 0.001
I1110 23:08:40.526643  2593 solver.cpp:295] Iteration 1494 (no loss supplied for SingleUpdateStep)
I1110 23:08:40.526733  2593 solver.cpp:310]     Train net output #0: loss = 0.509789 (* 1 = 0.509789 loss)
I1110 23:08:40.526753  2593 sgd_solver.cpp:106] Iteration 1494, lr = 0.001
I1110 23:08:42.793333  2593 solver.cpp:295] Iteration 1495 (no loss supplied for SingleUpdateStep)
I1110 23:08:42.793416  2593 solver.cpp:310]     Train net output #0: loss = 0.512475 (* 1 = 0.512475 loss)
I1110 23:08:42.793437  2593 sgd_solver.cpp:106] Iteration 1495, lr = 0.001
I1110 23:08:45.047009  2593 solver.cpp:295] Iteration 1496 (no loss supplied for SingleUpdateStep)
I1110 23:08:45.047133  2593 solver.cpp:310]     Train net output #0: loss = 0.509316 (* 1 = 0.509316 loss)
I1110 23:08:45.047159  2593 sgd_solver.cpp:106] Iteration 1496, lr = 0.001
I1110 23:08:47.405627  2593 solver.cpp:295] Iteration 1497 (no loss supplied for SingleUpdateStep)
I1110 23:08:47.405732  2593 solver.cpp:310]     Train net output #0: loss = 0.528509 (* 1 = 0.528509 loss)
I1110 23:08:47.405757  2593 sgd_solver.cpp:106] Iteration 1497, lr = 0.001
I1110 23:08:49.561801  2593 solver.cpp:295] Iteration 1498 (no loss supplied for SingleUpdateStep)
I1110 23:08:49.561892  2593 solver.cpp:310]     Train net output #0: loss = 0.496612 (* 1 = 0.496612 loss)
I1110 23:08:49.561913  2593 sgd_solver.cpp:106] Iteration 1498, lr = 0.001
I1110 23:08:51.851300  2593 solver.cpp:295] Iteration 1499 (no loss supplied for SingleUpdateStep)
I1110 23:08:51.851430  2593 solver.cpp:310]     Train net output #0: loss = 0.511731 (* 1 = 0.511731 loss)
I1110 23:08:51.851454  2593 sgd_solver.cpp:106] Iteration 1499, lr = 0.001
I1110 23:08:53.994133  2593 solver.cpp:295] Iteration 1500 (no loss supplied for SingleUpdateStep)
I1110 23:08:53.994187  2593 solver.cpp:310]     Train net output #0: loss = 0.506722 (* 1 = 0.506722 loss)
I1110 23:08:53.994206  2593 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I1110 23:08:56.180976  2593 solver.cpp:295] Iteration 1501 (no loss supplied for SingleUpdateStep)
I1110 23:08:56.181082  2593 solver.cpp:310]     Train net output #0: loss = 0.520751 (* 1 = 0.520751 loss)
I1110 23:08:56.181104  2593 sgd_solver.cpp:106] Iteration 1501, lr = 0.0005
I1110 23:08:58.803614  2593 solver.cpp:295] Iteration 1502 (no loss supplied for SingleUpdateStep)
I1110 23:08:58.803732  2593 solver.cpp:310]     Train net output #0: loss = 0.489646 (* 1 = 0.489646 loss)
I1110 23:08:58.803755  2593 sgd_solver.cpp:106] Iteration 1502, lr = 0.0005
I1110 23:09:01.271870  2593 solver.cpp:295] Iteration 1503 (no loss supplied for SingleUpdateStep)
I1110 23:09:01.271996  2593 solver.cpp:310]     Train net output #0: loss = 0.495807 (* 1 = 0.495807 loss)
I1110 23:09:01.272020  2593 sgd_solver.cpp:106] Iteration 1503, lr = 0.0005
I1110 23:09:03.542922  2593 solver.cpp:295] Iteration 1504 (no loss supplied for SingleUpdateStep)
I1110 23:09:03.542999  2593 solver.cpp:310]     Train net output #0: loss = 0.503886 (* 1 = 0.503886 loss)
I1110 23:09:03.543018  2593 sgd_solver.cpp:106] Iteration 1504, lr = 0.0005
I1110 23:09:05.915220  2593 solver.cpp:295] Iteration 1505 (no loss supplied for SingleUpdateStep)
I1110 23:09:05.915357  2593 solver.cpp:310]     Train net output #0: loss = 0.509007 (* 1 = 0.509007 loss)
I1110 23:09:05.915390  2593 sgd_solver.cpp:106] Iteration 1505, lr = 0.0005
I1110 23:09:08.259604  2593 solver.cpp:295] Iteration 1506 (no loss supplied for SingleUpdateStep)
I1110 23:09:08.259661  2593 solver.cpp:310]     Train net output #0: loss = 0.468652 (* 1 = 0.468652 loss)
I1110 23:09:08.259680  2593 sgd_solver.cpp:106] Iteration 1506, lr = 0.0005
I1110 23:09:10.417577  2593 solver.cpp:295] Iteration 1507 (no loss supplied for SingleUpdateStep)
I1110 23:09:10.417631  2593 solver.cpp:310]     Train net output #0: loss = 0.492064 (* 1 = 0.492064 loss)
I1110 23:09:10.417650  2593 sgd_solver.cpp:106] Iteration 1507, lr = 0.0005
I1110 23:09:12.679237  2593 solver.cpp:295] Iteration 1508 (no loss supplied for SingleUpdateStep)
I1110 23:09:12.679332  2593 solver.cpp:310]     Train net output #0: loss = 0.500615 (* 1 = 0.500615 loss)
I1110 23:09:12.679352  2593 sgd_solver.cpp:106] Iteration 1508, lr = 0.0005
I1110 23:09:14.836825  2593 solver.cpp:295] Iteration 1509 (no loss supplied for SingleUpdateStep)
I1110 23:09:14.836931  2593 solver.cpp:310]     Train net output #0: loss = 0.492555 (* 1 = 0.492555 loss)
I1110 23:09:14.836954  2593 sgd_solver.cpp:106] Iteration 1509, lr = 0.0005
I1110 23:09:17.369245  2593 solver.cpp:295] Iteration 1510 (no loss supplied for SingleUpdateStep)
I1110 23:09:17.369402  2593 solver.cpp:310]     Train net output #0: loss = 0.503978 (* 1 = 0.503978 loss)
I1110 23:09:17.369427  2593 sgd_solver.cpp:106] Iteration 1510, lr = 0.0005
I1110 23:09:19.753615  2593 solver.cpp:295] Iteration 1511 (no loss supplied for SingleUpdateStep)
I1110 23:09:19.753737  2593 solver.cpp:310]     Train net output #0: loss = 0.486579 (* 1 = 0.486579 loss)
I1110 23:09:19.753764  2593 sgd_solver.cpp:106] Iteration 1511, lr = 0.0005
I1110 23:09:22.204921  2593 solver.cpp:295] Iteration 1512 (no loss supplied for SingleUpdateStep)
I1110 23:09:22.205039  2593 solver.cpp:310]     Train net output #0: loss = 0.460182 (* 1 = 0.460182 loss)
I1110 23:09:22.205067  2593 sgd_solver.cpp:106] Iteration 1512, lr = 0.0005
I1110 23:09:24.475826  2593 solver.cpp:295] Iteration 1513 (no loss supplied for SingleUpdateStep)
I1110 23:09:24.475914  2593 solver.cpp:310]     Train net output #0: loss = 0.48428 (* 1 = 0.48428 loss)
I1110 23:09:24.475934  2593 sgd_solver.cpp:106] Iteration 1513, lr = 0.0005
I1110 23:09:26.812862  2593 solver.cpp:295] Iteration 1514 (no loss supplied for SingleUpdateStep)
I1110 23:09:26.812973  2593 solver.cpp:310]     Train net output #0: loss = 0.477598 (* 1 = 0.477598 loss)
I1110 23:09:26.812994  2593 sgd_solver.cpp:106] Iteration 1514, lr = 0.0005
I1110 23:09:29.255414  2593 solver.cpp:295] Iteration 1515 (no loss supplied for SingleUpdateStep)
I1110 23:09:29.255480  2593 solver.cpp:310]     Train net output #0: loss = 0.487708 (* 1 = 0.487708 loss)
I1110 23:09:29.255501  2593 sgd_solver.cpp:106] Iteration 1515, lr = 0.0005
I1110 23:09:31.698348  2593 solver.cpp:295] Iteration 1516 (no loss supplied for SingleUpdateStep)
I1110 23:09:31.698403  2593 solver.cpp:310]     Train net output #0: loss = 0.507915 (* 1 = 0.507915 loss)
I1110 23:09:31.698421  2593 sgd_solver.cpp:106] Iteration 1516, lr = 0.0005
I1110 23:09:34.223244  2593 solver.cpp:295] Iteration 1517 (no loss supplied for SingleUpdateStep)
I1110 23:09:34.223383  2593 solver.cpp:310]     Train net output #0: loss = 0.49785 (* 1 = 0.49785 loss)
I1110 23:09:34.223410  2593 sgd_solver.cpp:106] Iteration 1517, lr = 0.0005
I1110 23:09:37.382794  2593 solver.cpp:295] Iteration 1518 (no loss supplied for SingleUpdateStep)
I1110 23:09:37.382884  2593 solver.cpp:310]     Train net output #0: loss = 0.470858 (* 1 = 0.470858 loss)
I1110 23:09:37.382905  2593 sgd_solver.cpp:106] Iteration 1518, lr = 0.0005
I1110 23:09:41.802992  2593 solver.cpp:295] Iteration 1519 (no loss supplied for SingleUpdateStep)
I1110 23:09:41.803117  2593 solver.cpp:310]     Train net output #0: loss = 0.476195 (* 1 = 0.476195 loss)
I1110 23:09:41.803139  2593 sgd_solver.cpp:106] Iteration 1519, lr = 0.0005
I1110 23:09:44.363965  2593 solver.cpp:295] Iteration 1520 (no loss supplied for SingleUpdateStep)
I1110 23:09:44.364048  2593 solver.cpp:310]     Train net output #0: loss = 0.487908 (* 1 = 0.487908 loss)
I1110 23:09:44.364068  2593 sgd_solver.cpp:106] Iteration 1520, lr = 0.0005
I1110 23:09:46.921717  2593 solver.cpp:295] Iteration 1521 (no loss supplied for SingleUpdateStep)
I1110 23:09:46.921823  2593 solver.cpp:310]     Train net output #0: loss = 0.49755 (* 1 = 0.49755 loss)
I1110 23:09:46.921846  2593 sgd_solver.cpp:106] Iteration 1521, lr = 0.0005
I1110 23:09:49.195971  2593 solver.cpp:295] Iteration 1522 (no loss supplied for SingleUpdateStep)
I1110 23:09:49.196105  2593 solver.cpp:310]     Train net output #0: loss = 0.488757 (* 1 = 0.488757 loss)
I1110 23:09:49.196128  2593 sgd_solver.cpp:106] Iteration 1522, lr = 0.0005
I1110 23:09:51.483732  2593 solver.cpp:295] Iteration 1523 (no loss supplied for SingleUpdateStep)
I1110 23:09:51.483880  2593 solver.cpp:310]     Train net output #0: loss = 0.483116 (* 1 = 0.483116 loss)
I1110 23:09:51.483904  2593 sgd_solver.cpp:106] Iteration 1523, lr = 0.0005
I1110 23:09:53.785648  2593 solver.cpp:295] Iteration 1524 (no loss supplied for SingleUpdateStep)
I1110 23:09:53.785773  2593 solver.cpp:310]     Train net output #0: loss = 0.491655 (* 1 = 0.491655 loss)
I1110 23:09:53.785801  2593 sgd_solver.cpp:106] Iteration 1524, lr = 0.0005
I1110 23:09:56.013926  2593 solver.cpp:295] Iteration 1525 (no loss supplied for SingleUpdateStep)
I1110 23:09:56.014017  2593 solver.cpp:310]     Train net output #0: loss = 0.444131 (* 1 = 0.444131 loss)
I1110 23:09:56.014039  2593 sgd_solver.cpp:106] Iteration 1525, lr = 0.0005
I1110 23:09:58.453083  2593 solver.cpp:295] Iteration 1526 (no loss supplied for SingleUpdateStep)
I1110 23:09:58.453215  2593 solver.cpp:310]     Train net output #0: loss = 0.508907 (* 1 = 0.508907 loss)
I1110 23:09:58.453241  2593 sgd_solver.cpp:106] Iteration 1526, lr = 0.0005
I1110 23:10:00.837250  2593 solver.cpp:295] Iteration 1527 (no loss supplied for SingleUpdateStep)
I1110 23:10:00.837332  2593 solver.cpp:310]     Train net output #0: loss = 0.495638 (* 1 = 0.495638 loss)
I1110 23:10:00.837352  2593 sgd_solver.cpp:106] Iteration 1527, lr = 0.0005
I1110 23:10:03.162103  2593 solver.cpp:295] Iteration 1528 (no loss supplied for SingleUpdateStep)
I1110 23:10:03.162205  2593 solver.cpp:310]     Train net output #0: loss = 0.495557 (* 1 = 0.495557 loss)
I1110 23:10:03.162227  2593 sgd_solver.cpp:106] Iteration 1528, lr = 0.0005
I1110 23:10:05.930562  2593 solver.cpp:295] Iteration 1529 (no loss supplied for SingleUpdateStep)
I1110 23:10:05.930657  2593 solver.cpp:310]     Train net output #0: loss = 0.537656 (* 1 = 0.537656 loss)
I1110 23:10:05.930680  2593 sgd_solver.cpp:106] Iteration 1529, lr = 0.0005
I1110 23:10:08.717665  2593 solver.cpp:295] Iteration 1530 (no loss supplied for SingleUpdateStep)
I1110 23:10:08.717726  2593 solver.cpp:310]     Train net output #0: loss = 0.483952 (* 1 = 0.483952 loss)
I1110 23:10:08.717746  2593 sgd_solver.cpp:106] Iteration 1530, lr = 0.0005
I1110 23:10:11.308836  2593 solver.cpp:295] Iteration 1531 (no loss supplied for SingleUpdateStep)
I1110 23:10:11.308956  2593 solver.cpp:310]     Train net output #0: loss = 0.50669 (* 1 = 0.50669 loss)
I1110 23:10:11.308977  2593 sgd_solver.cpp:106] Iteration 1531, lr = 0.0005
I1110 23:10:13.871685  2593 solver.cpp:295] Iteration 1532 (no loss supplied for SingleUpdateStep)
I1110 23:10:13.871749  2593 solver.cpp:310]     Train net output #0: loss = 0.483735 (* 1 = 0.483735 loss)
I1110 23:10:13.871772  2593 sgd_solver.cpp:106] Iteration 1532, lr = 0.0005
I1110 23:10:16.516615  2593 solver.cpp:295] Iteration 1533 (no loss supplied for SingleUpdateStep)
I1110 23:10:16.516665  2593 solver.cpp:310]     Train net output #0: loss = 0.478743 (* 1 = 0.478743 loss)
I1110 23:10:16.516683  2593 sgd_solver.cpp:106] Iteration 1533, lr = 0.0005
I1110 23:10:19.191519  2593 solver.cpp:295] Iteration 1534 (no loss supplied for SingleUpdateStep)
I1110 23:10:19.191650  2593 solver.cpp:310]     Train net output #0: loss = 0.475606 (* 1 = 0.475606 loss)
I1110 23:10:19.191674  2593 sgd_solver.cpp:106] Iteration 1534, lr = 0.0005
I1110 23:10:21.782987  2593 solver.cpp:295] Iteration 1535 (no loss supplied for SingleUpdateStep)
I1110 23:10:21.783143  2593 solver.cpp:310]     Train net output #0: loss = 0.478007 (* 1 = 0.478007 loss)
I1110 23:10:21.783169  2593 sgd_solver.cpp:106] Iteration 1535, lr = 0.0005
I1110 23:10:24.612983  2593 solver.cpp:295] Iteration 1536 (no loss supplied for SingleUpdateStep)
I1110 23:10:24.613091  2593 solver.cpp:310]     Train net output #0: loss = 0.465723 (* 1 = 0.465723 loss)
I1110 23:10:24.613111  2593 sgd_solver.cpp:106] Iteration 1536, lr = 0.0005
I1110 23:10:29.402664  2593 solver.cpp:295] Iteration 1537 (no loss supplied for SingleUpdateStep)
I1110 23:10:29.402753  2593 solver.cpp:310]     Train net output #0: loss = 0.493331 (* 1 = 0.493331 loss)
I1110 23:10:29.402776  2593 sgd_solver.cpp:106] Iteration 1537, lr = 0.0005
I1110 23:10:33.125687  2593 solver.cpp:295] Iteration 1538 (no loss supplied for SingleUpdateStep)
I1110 23:10:33.125761  2593 solver.cpp:310]     Train net output #0: loss = 0.470851 (* 1 = 0.470851 loss)
I1110 23:10:33.125779  2593 sgd_solver.cpp:106] Iteration 1538, lr = 0.0005
I1110 23:10:36.908897  2593 solver.cpp:295] Iteration 1539 (no loss supplied for SingleUpdateStep)
I1110 23:10:36.909005  2593 solver.cpp:310]     Train net output #0: loss = 0.460734 (* 1 = 0.460734 loss)
I1110 23:10:36.909029  2593 sgd_solver.cpp:106] Iteration 1539, lr = 0.0005
I1110 23:10:39.806187  2593 solver.cpp:295] Iteration 1540 (no loss supplied for SingleUpdateStep)
I1110 23:10:39.806296  2593 solver.cpp:310]     Train net output #0: loss = 0.46656 (* 1 = 0.46656 loss)
I1110 23:10:39.806318  2593 sgd_solver.cpp:106] Iteration 1540, lr = 0.0005
I1110 23:10:42.155131  2593 solver.cpp:295] Iteration 1541 (no loss supplied for SingleUpdateStep)
I1110 23:10:42.155284  2593 solver.cpp:310]     Train net output #0: loss = 0.489124 (* 1 = 0.489124 loss)
I1110 23:10:42.155313  2593 sgd_solver.cpp:106] Iteration 1541, lr = 0.0005
I1110 23:10:44.465941  2593 solver.cpp:295] Iteration 1542 (no loss supplied for SingleUpdateStep)
I1110 23:10:44.466104  2593 solver.cpp:310]     Train net output #0: loss = 0.467513 (* 1 = 0.467513 loss)
I1110 23:10:44.466130  2593 sgd_solver.cpp:106] Iteration 1542, lr = 0.0005
I1110 23:10:46.884620  2593 solver.cpp:295] Iteration 1543 (no loss supplied for SingleUpdateStep)
I1110 23:10:46.884711  2593 solver.cpp:310]     Train net output #0: loss = 0.495874 (* 1 = 0.495874 loss)
I1110 23:10:46.884732  2593 sgd_solver.cpp:106] Iteration 1543, lr = 0.0005
I1110 23:10:49.587790  2593 solver.cpp:295] Iteration 1544 (no loss supplied for SingleUpdateStep)
I1110 23:10:49.587903  2593 solver.cpp:310]     Train net output #0: loss = 0.487781 (* 1 = 0.487781 loss)
I1110 23:10:49.587925  2593 sgd_solver.cpp:106] Iteration 1544, lr = 0.0005
I1110 23:10:52.022541  2593 solver.cpp:295] Iteration 1545 (no loss supplied for SingleUpdateStep)
I1110 23:10:52.022703  2593 solver.cpp:310]     Train net output #0: loss = 0.48991 (* 1 = 0.48991 loss)
I1110 23:10:52.022737  2593 sgd_solver.cpp:106] Iteration 1545, lr = 0.0005
I1110 23:10:54.271797  2593 solver.cpp:295] Iteration 1546 (no loss supplied for SingleUpdateStep)
I1110 23:10:54.271941  2593 solver.cpp:310]     Train net output #0: loss = 0.506182 (* 1 = 0.506182 loss)
I1110 23:10:54.271968  2593 sgd_solver.cpp:106] Iteration 1546, lr = 0.0005
I1110 23:10:56.598822  2593 solver.cpp:295] Iteration 1547 (no loss supplied for SingleUpdateStep)
I1110 23:10:56.598933  2593 solver.cpp:310]     Train net output #0: loss = 0.48609 (* 1 = 0.48609 loss)
I1110 23:10:56.598955  2593 sgd_solver.cpp:106] Iteration 1547, lr = 0.0005
I1110 23:10:58.878599  2593 solver.cpp:295] Iteration 1548 (no loss supplied for SingleUpdateStep)
I1110 23:10:58.878710  2593 solver.cpp:310]     Train net output #0: loss = 0.497496 (* 1 = 0.497496 loss)
I1110 23:10:58.878732  2593 sgd_solver.cpp:106] Iteration 1548, lr = 0.0005
I1110 23:11:01.368911  2593 solver.cpp:295] Iteration 1549 (no loss supplied for SingleUpdateStep)
I1110 23:11:01.369027  2593 solver.cpp:310]     Train net output #0: loss = 0.489472 (* 1 = 0.489472 loss)
I1110 23:11:01.369050  2593 sgd_solver.cpp:106] Iteration 1549, lr = 0.0005
I1110 23:11:04.209347  2593 solver.cpp:295] Iteration 1550 (no loss supplied for SingleUpdateStep)
I1110 23:11:04.209455  2593 solver.cpp:310]     Train net output #0: loss = 0.475664 (* 1 = 0.475664 loss)
I1110 23:11:04.209476  2593 sgd_solver.cpp:106] Iteration 1550, lr = 0.0005
I1110 23:11:06.774739  2593 solver.cpp:295] Iteration 1551 (no loss supplied for SingleUpdateStep)
I1110 23:11:06.774838  2593 solver.cpp:310]     Train net output #0: loss = 0.478599 (* 1 = 0.478599 loss)
I1110 23:11:06.774860  2593 sgd_solver.cpp:106] Iteration 1551, lr = 0.0005
I1110 23:11:09.106096  2593 solver.cpp:295] Iteration 1552 (no loss supplied for SingleUpdateStep)
I1110 23:11:09.106222  2593 solver.cpp:310]     Train net output #0: loss = 0.512792 (* 1 = 0.512792 loss)
I1110 23:11:09.106245  2593 sgd_solver.cpp:106] Iteration 1552, lr = 0.0005
I1110 23:11:11.378082  2593 solver.cpp:295] Iteration 1553 (no loss supplied for SingleUpdateStep)
I1110 23:11:11.378167  2593 solver.cpp:310]     Train net output #0: loss = 0.431925 (* 1 = 0.431925 loss)
I1110 23:11:11.378187  2593 sgd_solver.cpp:106] Iteration 1553, lr = 0.0005
I1110 23:11:13.594849  2593 solver.cpp:295] Iteration 1554 (no loss supplied for SingleUpdateStep)
I1110 23:11:13.594975  2593 solver.cpp:310]     Train net output #0: loss = 0.471409 (* 1 = 0.471409 loss)
I1110 23:11:13.595003  2593 sgd_solver.cpp:106] Iteration 1554, lr = 0.0005
I1110 23:11:15.838886  2593 solver.cpp:295] Iteration 1555 (no loss supplied for SingleUpdateStep)
I1110 23:11:15.838986  2593 solver.cpp:310]     Train net output #0: loss = 0.480056 (* 1 = 0.480056 loss)
I1110 23:11:15.839007  2593 sgd_solver.cpp:106] Iteration 1555, lr = 0.0005
I1110 23:11:18.175608  2593 solver.cpp:295] Iteration 1556 (no loss supplied for SingleUpdateStep)
I1110 23:11:18.175740  2593 solver.cpp:310]     Train net output #0: loss = 0.470507 (* 1 = 0.470507 loss)
I1110 23:11:18.175767  2593 sgd_solver.cpp:106] Iteration 1556, lr = 0.0005
I1110 23:11:20.564079  2593 solver.cpp:295] Iteration 1557 (no loss supplied for SingleUpdateStep)
I1110 23:11:20.564178  2593 solver.cpp:310]     Train net output #0: loss = 0.463606 (* 1 = 0.463606 loss)
I1110 23:11:20.564201  2593 sgd_solver.cpp:106] Iteration 1557, lr = 0.0005
I1110 23:11:22.887450  2593 solver.cpp:295] Iteration 1558 (no loss supplied for SingleUpdateStep)
I1110 23:11:22.887557  2593 solver.cpp:310]     Train net output #0: loss = 0.483851 (* 1 = 0.483851 loss)
I1110 23:11:22.887585  2593 sgd_solver.cpp:106] Iteration 1558, lr = 0.0005
I1110 23:11:25.229109  2593 solver.cpp:295] Iteration 1559 (no loss supplied for SingleUpdateStep)
I1110 23:11:25.229225  2593 solver.cpp:310]     Train net output #0: loss = 0.498028 (* 1 = 0.498028 loss)
I1110 23:11:25.229249  2593 sgd_solver.cpp:106] Iteration 1559, lr = 0.0005
I1110 23:11:27.489681  2593 solver.cpp:295] Iteration 1560 (no loss supplied for SingleUpdateStep)
I1110 23:11:27.489754  2593 solver.cpp:310]     Train net output #0: loss = 0.479282 (* 1 = 0.479282 loss)
I1110 23:11:27.489774  2593 sgd_solver.cpp:106] Iteration 1560, lr = 0.0005
I1110 23:11:29.889791  2593 solver.cpp:295] Iteration 1561 (no loss supplied for SingleUpdateStep)
I1110 23:11:29.889905  2593 solver.cpp:310]     Train net output #0: loss = 0.475881 (* 1 = 0.475881 loss)
I1110 23:11:29.889927  2593 sgd_solver.cpp:106] Iteration 1561, lr = 0.0005
I1110 23:11:32.729250  2593 solver.cpp:295] Iteration 1562 (no loss supplied for SingleUpdateStep)
I1110 23:11:32.729322  2593 solver.cpp:310]     Train net output #0: loss = 0.496152 (* 1 = 0.496152 loss)
I1110 23:11:32.729342  2593 sgd_solver.cpp:106] Iteration 1562, lr = 0.0005
I1110 23:11:35.829975  2593 solver.cpp:295] Iteration 1563 (no loss supplied for SingleUpdateStep)
I1110 23:11:35.946338  2593 solver.cpp:310]     Train net output #0: loss = 0.506399 (* 1 = 0.506399 loss)
I1110 23:11:35.946379  2593 sgd_solver.cpp:106] Iteration 1563, lr = 0.0005
I1110 23:11:39.158664  2593 solver.cpp:295] Iteration 1564 (no loss supplied for SingleUpdateStep)
I1110 23:11:39.158763  2593 solver.cpp:310]     Train net output #0: loss = 0.462703 (* 1 = 0.462703 loss)
I1110 23:11:39.158787  2593 sgd_solver.cpp:106] Iteration 1564, lr = 0.0005
I1110 23:11:42.474530  2593 solver.cpp:295] Iteration 1565 (no loss supplied for SingleUpdateStep)
I1110 23:11:42.474676  2593 solver.cpp:310]     Train net output #0: loss = 0.498187 (* 1 = 0.498187 loss)
I1110 23:11:42.474704  2593 sgd_solver.cpp:106] Iteration 1565, lr = 0.0005
I1110 23:11:45.965487  2593 solver.cpp:295] Iteration 1566 (no loss supplied for SingleUpdateStep)
I1110 23:11:45.965617  2593 solver.cpp:310]     Train net output #0: loss = 0.517678 (* 1 = 0.517678 loss)
I1110 23:11:45.965646  2593 sgd_solver.cpp:106] Iteration 1566, lr = 0.0005
I1110 23:11:48.466496  2593 solver.cpp:295] Iteration 1567 (no loss supplied for SingleUpdateStep)
I1110 23:11:48.466614  2593 solver.cpp:310]     Train net output #0: loss = 0.490319 (* 1 = 0.490319 loss)
I1110 23:11:48.466639  2593 sgd_solver.cpp:106] Iteration 1567, lr = 0.0005
I1110 23:11:50.889716  2593 solver.cpp:295] Iteration 1568 (no loss supplied for SingleUpdateStep)
I1110 23:11:50.889816  2593 solver.cpp:310]     Train net output #0: loss = 0.499313 (* 1 = 0.499313 loss)
I1110 23:11:50.889835  2593 sgd_solver.cpp:106] Iteration 1568, lr = 0.0005
I1110 23:11:53.556494  2593 solver.cpp:295] Iteration 1569 (no loss supplied for SingleUpdateStep)
I1110 23:11:53.556623  2593 solver.cpp:310]     Train net output #0: loss = 0.473273 (* 1 = 0.473273 loss)
I1110 23:11:53.556646  2593 sgd_solver.cpp:106] Iteration 1569, lr = 0.0005
I1110 23:11:55.760746  2593 solver.cpp:295] Iteration 1570 (no loss supplied for SingleUpdateStep)
I1110 23:11:55.760892  2593 solver.cpp:310]     Train net output #0: loss = 0.455258 (* 1 = 0.455258 loss)
I1110 23:11:55.760916  2593 sgd_solver.cpp:106] Iteration 1570, lr = 0.0005
I1110 23:11:58.561619  2593 solver.cpp:295] Iteration 1571 (no loss supplied for SingleUpdateStep)
I1110 23:11:58.561733  2593 solver.cpp:310]     Train net output #0: loss = 0.478607 (* 1 = 0.478607 loss)
I1110 23:11:58.561756  2593 sgd_solver.cpp:106] Iteration 1571, lr = 0.0005
I1110 23:12:01.076036  2593 solver.cpp:295] Iteration 1572 (no loss supplied for SingleUpdateStep)
I1110 23:12:01.076150  2593 solver.cpp:310]     Train net output #0: loss = 0.489772 (* 1 = 0.489772 loss)
I1110 23:12:01.076175  2593 sgd_solver.cpp:106] Iteration 1572, lr = 0.0005
I1110 23:12:04.378559  2593 solver.cpp:295] Iteration 1573 (no loss supplied for SingleUpdateStep)
I1110 23:12:04.378657  2593 solver.cpp:310]     Train net output #0: loss = 0.516094 (* 1 = 0.516094 loss)
I1110 23:12:04.378679  2593 sgd_solver.cpp:106] Iteration 1573, lr = 0.0005
I1110 23:12:07.772645  2593 solver.cpp:295] Iteration 1574 (no loss supplied for SingleUpdateStep)
I1110 23:12:07.772750  2593 solver.cpp:310]     Train net output #0: loss = 0.513754 (* 1 = 0.513754 loss)
I1110 23:12:07.772774  2593 sgd_solver.cpp:106] Iteration 1574, lr = 0.0005
I1110 23:12:10.838143  2593 solver.cpp:295] Iteration 1575 (no loss supplied for SingleUpdateStep)
I1110 23:12:10.838199  2593 solver.cpp:310]     Train net output #0: loss = 0.454865 (* 1 = 0.454865 loss)
I1110 23:12:10.838219  2593 sgd_solver.cpp:106] Iteration 1575, lr = 0.0005
I1110 23:12:13.598531  2593 solver.cpp:295] Iteration 1576 (no loss supplied for SingleUpdateStep)
I1110 23:12:13.598634  2593 solver.cpp:310]     Train net output #0: loss = 0.456664 (* 1 = 0.456664 loss)
I1110 23:12:13.598654  2593 sgd_solver.cpp:106] Iteration 1576, lr = 0.0005
I1110 23:12:16.082500  2593 solver.cpp:295] Iteration 1577 (no loss supplied for SingleUpdateStep)
I1110 23:12:16.082607  2593 solver.cpp:310]     Train net output #0: loss = 0.44134 (* 1 = 0.44134 loss)
I1110 23:12:16.082629  2593 sgd_solver.cpp:106] Iteration 1577, lr = 0.0005
I1110 23:12:18.510824  2593 solver.cpp:295] Iteration 1578 (no loss supplied for SingleUpdateStep)
I1110 23:12:18.510931  2593 solver.cpp:310]     Train net output #0: loss = 0.483963 (* 1 = 0.483963 loss)
I1110 23:12:18.510951  2593 sgd_solver.cpp:106] Iteration 1578, lr = 0.0005
I1110 23:12:21.430665  2593 solver.cpp:295] Iteration 1579 (no loss supplied for SingleUpdateStep)
I1110 23:12:21.430788  2593 solver.cpp:310]     Train net output #0: loss = 0.456674 (* 1 = 0.456674 loss)
I1110 23:12:21.430811  2593 sgd_solver.cpp:106] Iteration 1579, lr = 0.0005
I1110 23:12:24.646337  2593 solver.cpp:295] Iteration 1580 (no loss supplied for SingleUpdateStep)
I1110 23:12:24.646481  2593 solver.cpp:310]     Train net output #0: loss = 0.461972 (* 1 = 0.461972 loss)
I1110 23:12:24.646509  2593 sgd_solver.cpp:106] Iteration 1580, lr = 0.0005
I1110 23:12:27.351095  2593 solver.cpp:295] Iteration 1581 (no loss supplied for SingleUpdateStep)
I1110 23:12:27.351191  2593 solver.cpp:310]     Train net output #0: loss = 0.491509 (* 1 = 0.491509 loss)
I1110 23:12:27.351212  2593 sgd_solver.cpp:106] Iteration 1581, lr = 0.0005
I1110 23:12:29.875890  2593 solver.cpp:295] Iteration 1582 (no loss supplied for SingleUpdateStep)
I1110 23:12:29.876029  2593 solver.cpp:310]     Train net output #0: loss = 0.487256 (* 1 = 0.487256 loss)
I1110 23:12:29.876060  2593 sgd_solver.cpp:106] Iteration 1582, lr = 0.0005
I1110 23:12:32.487407  2593 solver.cpp:295] Iteration 1583 (no loss supplied for SingleUpdateStep)
I1110 23:12:32.487464  2593 solver.cpp:310]     Train net output #0: loss = 0.495468 (* 1 = 0.495468 loss)
I1110 23:12:32.487484  2593 sgd_solver.cpp:106] Iteration 1583, lr = 0.0005
I1110 23:12:34.996644  2593 solver.cpp:295] Iteration 1584 (no loss supplied for SingleUpdateStep)
I1110 23:12:34.996719  2593 solver.cpp:310]     Train net output #0: loss = 0.457053 (* 1 = 0.457053 loss)
I1110 23:12:34.996742  2593 sgd_solver.cpp:106] Iteration 1584, lr = 0.0005
I1110 23:12:37.638867  2593 solver.cpp:295] Iteration 1585 (no loss supplied for SingleUpdateStep)
I1110 23:12:37.638954  2593 solver.cpp:310]     Train net output #0: loss = 0.487393 (* 1 = 0.487393 loss)
I1110 23:12:37.638977  2593 sgd_solver.cpp:106] Iteration 1585, lr = 0.0005
I1110 23:12:39.914331  2593 solver.cpp:295] Iteration 1586 (no loss supplied for SingleUpdateStep)
I1110 23:12:39.914397  2593 solver.cpp:310]     Train net output #0: loss = 0.413723 (* 1 = 0.413723 loss)
I1110 23:12:39.914417  2593 sgd_solver.cpp:106] Iteration 1586, lr = 0.0005
I1110 23:12:42.130272  2593 solver.cpp:295] Iteration 1587 (no loss supplied for SingleUpdateStep)
I1110 23:12:42.130416  2593 solver.cpp:310]     Train net output #0: loss = 0.490701 (* 1 = 0.490701 loss)
I1110 23:12:42.130446  2593 sgd_solver.cpp:106] Iteration 1587, lr = 0.0005
I1110 23:12:44.559792  2593 solver.cpp:295] Iteration 1588 (no loss supplied for SingleUpdateStep)
I1110 23:12:44.559893  2593 solver.cpp:310]     Train net output #0: loss = 0.474666 (* 1 = 0.474666 loss)
I1110 23:12:44.559916  2593 sgd_solver.cpp:106] Iteration 1588, lr = 0.0005
I1110 23:12:46.822685  2593 solver.cpp:295] Iteration 1589 (no loss supplied for SingleUpdateStep)
I1110 23:12:46.822788  2593 solver.cpp:310]     Train net output #0: loss = 0.472072 (* 1 = 0.472072 loss)
I1110 23:12:46.822810  2593 sgd_solver.cpp:106] Iteration 1589, lr = 0.0005
I1110 23:12:49.177290  2593 solver.cpp:295] Iteration 1590 (no loss supplied for SingleUpdateStep)
I1110 23:12:49.177425  2593 solver.cpp:310]     Train net output #0: loss = 0.482073 (* 1 = 0.482073 loss)
I1110 23:12:49.177448  2593 sgd_solver.cpp:106] Iteration 1590, lr = 0.0005
I1110 23:12:51.583607  2593 solver.cpp:295] Iteration 1591 (no loss supplied for SingleUpdateStep)
I1110 23:12:51.583705  2593 solver.cpp:310]     Train net output #0: loss = 0.501425 (* 1 = 0.501425 loss)
I1110 23:12:51.583726  2593 sgd_solver.cpp:106] Iteration 1591, lr = 0.0005
I1110 23:12:53.925782  2593 solver.cpp:295] Iteration 1592 (no loss supplied for SingleUpdateStep)
I1110 23:12:53.925835  2593 solver.cpp:310]     Train net output #0: loss = 0.476656 (* 1 = 0.476656 loss)
I1110 23:12:53.925854  2593 sgd_solver.cpp:106] Iteration 1592, lr = 0.0005
I1110 23:12:56.291194  2593 solver.cpp:295] Iteration 1593 (no loss supplied for SingleUpdateStep)
I1110 23:12:56.291285  2593 solver.cpp:310]     Train net output #0: loss = 0.470047 (* 1 = 0.470047 loss)
I1110 23:12:56.291308  2593 sgd_solver.cpp:106] Iteration 1593, lr = 0.0005
I1110 23:12:58.664410  2593 solver.cpp:295] Iteration 1594 (no loss supplied for SingleUpdateStep)
I1110 23:12:58.664506  2593 solver.cpp:310]     Train net output #0: loss = 0.452971 (* 1 = 0.452971 loss)
I1110 23:12:58.664526  2593 sgd_solver.cpp:106] Iteration 1594, lr = 0.0005
I1110 23:13:00.992600  2593 solver.cpp:295] Iteration 1595 (no loss supplied for SingleUpdateStep)
I1110 23:13:00.992681  2593 solver.cpp:310]     Train net output #0: loss = 0.468932 (* 1 = 0.468932 loss)
I1110 23:13:00.992702  2593 sgd_solver.cpp:106] Iteration 1595, lr = 0.0005
I1110 23:13:03.419865  2593 solver.cpp:295] Iteration 1596 (no loss supplied for SingleUpdateStep)
I1110 23:13:03.419958  2593 solver.cpp:310]     Train net output #0: loss = 0.434398 (* 1 = 0.434398 loss)
I1110 23:13:03.419981  2593 sgd_solver.cpp:106] Iteration 1596, lr = 0.0005
I1110 23:13:05.678706  2593 solver.cpp:295] Iteration 1597 (no loss supplied for SingleUpdateStep)
I1110 23:13:05.678817  2593 solver.cpp:310]     Train net output #0: loss = 0.496062 (* 1 = 0.496062 loss)
I1110 23:13:05.678839  2593 sgd_solver.cpp:106] Iteration 1597, lr = 0.0005
I1110 23:13:08.236995  2593 solver.cpp:295] Iteration 1598 (no loss supplied for SingleUpdateStep)
I1110 23:13:08.237099  2593 solver.cpp:310]     Train net output #0: loss = 0.475751 (* 1 = 0.475751 loss)
I1110 23:13:08.237123  2593 sgd_solver.cpp:106] Iteration 1598, lr = 0.0005
I1110 23:13:10.489475  2593 solver.cpp:295] Iteration 1599 (no loss supplied for SingleUpdateStep)
I1110 23:13:10.489552  2593 solver.cpp:310]     Train net output #0: loss = 0.500331 (* 1 = 0.500331 loss)
I1110 23:13:10.489573  2593 sgd_solver.cpp:106] Iteration 1599, lr = 0.0005
I1110 23:13:13.111248  2593 solver.cpp:295] Iteration 1600 (no loss supplied for SingleUpdateStep)
I1110 23:13:13.111310  2593 solver.cpp:310]     Train net output #0: loss = 0.46706 (* 1 = 0.46706 loss)
I1110 23:13:13.111330  2593 sgd_solver.cpp:106] Iteration 1600, lr = 0.0005
I1110 23:13:15.594786  2593 solver.cpp:295] Iteration 1601 (no loss supplied for SingleUpdateStep)
I1110 23:13:15.594882  2593 solver.cpp:310]     Train net output #0: loss = 0.489391 (* 1 = 0.489391 loss)
I1110 23:13:15.594902  2593 sgd_solver.cpp:106] Iteration 1601, lr = 0.0005
I1110 23:13:18.133560  2593 solver.cpp:295] Iteration 1602 (no loss supplied for SingleUpdateStep)
I1110 23:13:18.133708  2593 solver.cpp:310]     Train net output #0: loss = 0.46265 (* 1 = 0.46265 loss)
I1110 23:13:18.133733  2593 sgd_solver.cpp:106] Iteration 1602, lr = 0.0005
I1110 23:13:20.369709  2593 solver.cpp:295] Iteration 1603 (no loss supplied for SingleUpdateStep)
I1110 23:13:20.369806  2593 solver.cpp:310]     Train net output #0: loss = 0.491376 (* 1 = 0.491376 loss)
I1110 23:13:20.369827  2593 sgd_solver.cpp:106] Iteration 1603, lr = 0.0005
I1110 23:13:22.691391  2593 solver.cpp:295] Iteration 1604 (no loss supplied for SingleUpdateStep)
I1110 23:13:22.691565  2593 solver.cpp:310]     Train net output #0: loss = 0.462744 (* 1 = 0.462744 loss)
I1110 23:13:22.691596  2593 sgd_solver.cpp:106] Iteration 1604, lr = 0.0005
I1110 23:13:24.943547  2593 solver.cpp:295] Iteration 1605 (no loss supplied for SingleUpdateStep)
I1110 23:13:24.943677  2593 solver.cpp:310]     Train net output #0: loss = 0.439673 (* 1 = 0.439673 loss)
I1110 23:13:24.943704  2593 sgd_solver.cpp:106] Iteration 1605, lr = 0.0005
I1110 23:13:27.256723  2593 solver.cpp:295] Iteration 1606 (no loss supplied for SingleUpdateStep)
I1110 23:13:27.256830  2593 solver.cpp:310]     Train net output #0: loss = 0.501895 (* 1 = 0.501895 loss)
I1110 23:13:27.256852  2593 sgd_solver.cpp:106] Iteration 1606, lr = 0.0005
I1110 23:13:29.783213  2593 solver.cpp:295] Iteration 1607 (no loss supplied for SingleUpdateStep)
I1110 23:13:29.783336  2593 solver.cpp:310]     Train net output #0: loss = 0.457093 (* 1 = 0.457093 loss)
I1110 23:13:29.783361  2593 sgd_solver.cpp:106] Iteration 1607, lr = 0.0005
I1110 23:13:32.168483  2593 solver.cpp:295] Iteration 1608 (no loss supplied for SingleUpdateStep)
I1110 23:13:32.168570  2593 solver.cpp:310]     Train net output #0: loss = 0.468109 (* 1 = 0.468109 loss)
I1110 23:13:32.168594  2593 sgd_solver.cpp:106] Iteration 1608, lr = 0.0005
I1110 23:13:34.734701  2593 solver.cpp:295] Iteration 1609 (no loss supplied for SingleUpdateStep)
I1110 23:13:34.734812  2593 solver.cpp:310]     Train net output #0: loss = 0.487682 (* 1 = 0.487682 loss)
I1110 23:13:34.734836  2593 sgd_solver.cpp:106] Iteration 1609, lr = 0.0005
I1110 23:13:37.165309  2593 solver.cpp:295] Iteration 1610 (no loss supplied for SingleUpdateStep)
I1110 23:13:37.165383  2593 solver.cpp:310]     Train net output #0: loss = 0.460765 (* 1 = 0.460765 loss)
I1110 23:13:37.165403  2593 sgd_solver.cpp:106] Iteration 1610, lr = 0.0005
I1110 23:13:39.794874  2593 solver.cpp:295] Iteration 1611 (no loss supplied for SingleUpdateStep)
I1110 23:13:39.795001  2593 solver.cpp:310]     Train net output #0: loss = 0.504063 (* 1 = 0.504063 loss)
I1110 23:13:39.795023  2593 sgd_solver.cpp:106] Iteration 1611, lr = 0.0005
I1110 23:13:43.327466  2593 solver.cpp:295] Iteration 1612 (no loss supplied for SingleUpdateStep)
I1110 23:13:43.327553  2593 solver.cpp:310]     Train net output #0: loss = 0.455546 (* 1 = 0.455546 loss)
I1110 23:13:43.327574  2593 sgd_solver.cpp:106] Iteration 1612, lr = 0.0005
I1110 23:13:45.767304  2593 solver.cpp:295] Iteration 1613 (no loss supplied for SingleUpdateStep)
I1110 23:13:45.767412  2593 solver.cpp:310]     Train net output #0: loss = 0.483322 (* 1 = 0.483322 loss)
I1110 23:13:45.767434  2593 sgd_solver.cpp:106] Iteration 1613, lr = 0.0005
I1110 23:13:48.517053  2593 solver.cpp:295] Iteration 1614 (no loss supplied for SingleUpdateStep)
I1110 23:13:48.517139  2593 solver.cpp:310]     Train net output #0: loss = 0.450937 (* 1 = 0.450937 loss)
I1110 23:13:48.517161  2593 sgd_solver.cpp:106] Iteration 1614, lr = 0.0005
I1110 23:13:51.252804  2593 solver.cpp:295] Iteration 1615 (no loss supplied for SingleUpdateStep)
I1110 23:13:51.252863  2593 solver.cpp:310]     Train net output #0: loss = 0.483895 (* 1 = 0.483895 loss)
I1110 23:13:51.252884  2593 sgd_solver.cpp:106] Iteration 1615, lr = 0.0005
I1110 23:13:53.644851  2593 solver.cpp:295] Iteration 1616 (no loss supplied for SingleUpdateStep)
I1110 23:13:53.644989  2593 solver.cpp:310]     Train net output #0: loss = 0.473771 (* 1 = 0.473771 loss)
I1110 23:13:53.645014  2593 sgd_solver.cpp:106] Iteration 1616, lr = 0.0005
I1110 23:13:56.531024  2593 solver.cpp:295] Iteration 1617 (no loss supplied for SingleUpdateStep)
I1110 23:13:56.531111  2593 solver.cpp:310]     Train net output #0: loss = 0.456281 (* 1 = 0.456281 loss)
I1110 23:13:56.531131  2593 sgd_solver.cpp:106] Iteration 1617, lr = 0.0005
I1110 23:13:59.444479  2593 solver.cpp:295] Iteration 1618 (no loss supplied for SingleUpdateStep)
I1110 23:13:59.444573  2593 solver.cpp:310]     Train net output #0: loss = 0.438563 (* 1 = 0.438563 loss)
I1110 23:13:59.444597  2593 sgd_solver.cpp:106] Iteration 1618, lr = 0.0005
I1110 23:14:01.755925  2593 solver.cpp:295] Iteration 1619 (no loss supplied for SingleUpdateStep)
I1110 23:14:01.756036  2593 solver.cpp:310]     Train net output #0: loss = 0.441819 (* 1 = 0.441819 loss)
I1110 23:14:01.756057  2593 sgd_solver.cpp:106] Iteration 1619, lr = 0.0005
I1110 23:14:04.070518  2593 solver.cpp:295] Iteration 1620 (no loss supplied for SingleUpdateStep)
I1110 23:14:04.070616  2593 solver.cpp:310]     Train net output #0: loss = 0.496224 (* 1 = 0.496224 loss)
I1110 23:14:04.070637  2593 sgd_solver.cpp:106] Iteration 1620, lr = 0.0005
I1110 23:14:06.451496  2593 solver.cpp:295] Iteration 1621 (no loss supplied for SingleUpdateStep)
I1110 23:14:06.451592  2593 solver.cpp:310]     Train net output #0: loss = 0.470922 (* 1 = 0.470922 loss)
I1110 23:14:06.451614  2593 sgd_solver.cpp:106] Iteration 1621, lr = 0.0005
I1110 23:14:08.976691  2593 solver.cpp:295] Iteration 1622 (no loss supplied for SingleUpdateStep)
I1110 23:14:08.976796  2593 solver.cpp:310]     Train net output #0: loss = 0.516155 (* 1 = 0.516155 loss)
I1110 23:14:08.976819  2593 sgd_solver.cpp:106] Iteration 1622, lr = 0.0005
I1110 23:14:11.539849  2593 solver.cpp:295] Iteration 1623 (no loss supplied for SingleUpdateStep)
I1110 23:14:11.539943  2593 solver.cpp:310]     Train net output #0: loss = 0.46025 (* 1 = 0.46025 loss)
I1110 23:14:11.539964  2593 sgd_solver.cpp:106] Iteration 1623, lr = 0.0005
I1110 23:14:14.225474  2593 solver.cpp:295] Iteration 1624 (no loss supplied for SingleUpdateStep)
I1110 23:14:14.225543  2593 solver.cpp:310]     Train net output #0: loss = 0.478314 (* 1 = 0.478314 loss)
I1110 23:14:14.225564  2593 sgd_solver.cpp:106] Iteration 1624, lr = 0.0005
I1110 23:14:16.823750  2593 solver.cpp:295] Iteration 1625 (no loss supplied for SingleUpdateStep)
I1110 23:14:16.823865  2593 solver.cpp:310]     Train net output #0: loss = 0.482557 (* 1 = 0.482557 loss)
I1110 23:14:16.823890  2593 sgd_solver.cpp:106] Iteration 1625, lr = 0.0005
I1110 23:14:19.241546  2593 solver.cpp:295] Iteration 1626 (no loss supplied for SingleUpdateStep)
I1110 23:14:19.241657  2593 solver.cpp:310]     Train net output #0: loss = 0.45874 (* 1 = 0.45874 loss)
I1110 23:14:19.241680  2593 sgd_solver.cpp:106] Iteration 1626, lr = 0.0005
I1110 23:14:21.613587  2593 solver.cpp:295] Iteration 1627 (no loss supplied for SingleUpdateStep)
I1110 23:14:21.613697  2593 solver.cpp:310]     Train net output #0: loss = 0.500616 (* 1 = 0.500616 loss)
I1110 23:14:21.613719  2593 sgd_solver.cpp:106] Iteration 1627, lr = 0.0005
I1110 23:14:24.028022  2593 solver.cpp:295] Iteration 1628 (no loss supplied for SingleUpdateStep)
I1110 23:14:24.028136  2593 solver.cpp:310]     Train net output #0: loss = 0.48419 (* 1 = 0.48419 loss)
I1110 23:14:24.028162  2593 sgd_solver.cpp:106] Iteration 1628, lr = 0.0005
I1110 23:14:26.702556  2593 solver.cpp:295] Iteration 1629 (no loss supplied for SingleUpdateStep)
I1110 23:14:26.702680  2593 solver.cpp:310]     Train net output #0: loss = 0.456863 (* 1 = 0.456863 loss)
I1110 23:14:26.702708  2593 sgd_solver.cpp:106] Iteration 1629, lr = 0.0005
I1110 23:14:29.088618  2593 solver.cpp:295] Iteration 1630 (no loss supplied for SingleUpdateStep)
I1110 23:14:29.088776  2593 solver.cpp:310]     Train net output #0: loss = 0.500615 (* 1 = 0.500615 loss)
I1110 23:14:29.088805  2593 sgd_solver.cpp:106] Iteration 1630, lr = 0.0005
I1110 23:14:31.487067  2593 solver.cpp:295] Iteration 1631 (no loss supplied for SingleUpdateStep)
I1110 23:14:31.487190  2593 solver.cpp:310]     Train net output #0: loss = 0.495332 (* 1 = 0.495332 loss)
I1110 23:14:31.487212  2593 sgd_solver.cpp:106] Iteration 1631, lr = 0.0005
I1110 23:14:33.727448  2593 solver.cpp:295] Iteration 1632 (no loss supplied for SingleUpdateStep)
I1110 23:14:33.727537  2593 solver.cpp:310]     Train net output #0: loss = 0.46942 (* 1 = 0.46942 loss)
I1110 23:14:33.727558  2593 sgd_solver.cpp:106] Iteration 1632, lr = 0.0005
I1110 23:14:35.956940  2593 solver.cpp:295] Iteration 1633 (no loss supplied for SingleUpdateStep)
I1110 23:14:35.957090  2593 solver.cpp:310]     Train net output #0: loss = 0.440039 (* 1 = 0.440039 loss)
I1110 23:14:35.957121  2593 sgd_solver.cpp:106] Iteration 1633, lr = 0.0005
I1110 23:14:38.317391  2593 solver.cpp:295] Iteration 1634 (no loss supplied for SingleUpdateStep)
I1110 23:14:38.317533  2593 solver.cpp:310]     Train net output #0: loss = 0.498295 (* 1 = 0.498295 loss)
I1110 23:14:38.317556  2593 sgd_solver.cpp:106] Iteration 1634, lr = 0.0005
I1110 23:14:41.157367  2593 solver.cpp:295] Iteration 1635 (no loss supplied for SingleUpdateStep)
I1110 23:14:41.157436  2593 solver.cpp:310]     Train net output #0: loss = 0.457525 (* 1 = 0.457525 loss)
I1110 23:14:41.157455  2593 sgd_solver.cpp:106] Iteration 1635, lr = 0.0005
I1110 23:14:43.869827  2593 solver.cpp:295] Iteration 1636 (no loss supplied for SingleUpdateStep)
I1110 23:14:43.869962  2593 solver.cpp:310]     Train net output #0: loss = 0.476649 (* 1 = 0.476649 loss)
I1110 23:14:43.869987  2593 sgd_solver.cpp:106] Iteration 1636, lr = 0.0005
I1110 23:14:46.738140  2593 solver.cpp:295] Iteration 1637 (no loss supplied for SingleUpdateStep)
I1110 23:14:46.738209  2593 solver.cpp:310]     Train net output #0: loss = 0.50345 (* 1 = 0.50345 loss)
I1110 23:14:46.738229  2593 sgd_solver.cpp:106] Iteration 1637, lr = 0.0005
I1110 23:14:49.548018  2593 solver.cpp:295] Iteration 1638 (no loss supplied for SingleUpdateStep)
I1110 23:14:49.548096  2593 solver.cpp:310]     Train net output #0: loss = 0.484526 (* 1 = 0.484526 loss)
I1110 23:14:49.548118  2593 sgd_solver.cpp:106] Iteration 1638, lr = 0.0005
I1110 23:14:53.347586  2593 solver.cpp:295] Iteration 1639 (no loss supplied for SingleUpdateStep)
I1110 23:14:53.347731  2593 solver.cpp:310]     Train net output #0: loss = 0.476704 (* 1 = 0.476704 loss)
I1110 23:14:53.347757  2593 sgd_solver.cpp:106] Iteration 1639, lr = 0.0005
I1110 23:14:56.068482  2593 solver.cpp:295] Iteration 1640 (no loss supplied for SingleUpdateStep)
I1110 23:14:56.068624  2593 solver.cpp:310]     Train net output #0: loss = 0.491353 (* 1 = 0.491353 loss)
I1110 23:14:56.068651  2593 sgd_solver.cpp:106] Iteration 1640, lr = 0.0005
I1110 23:14:59.369783  2593 solver.cpp:295] Iteration 1641 (no loss supplied for SingleUpdateStep)
I1110 23:14:59.369861  2593 solver.cpp:310]     Train net output #0: loss = 0.504022 (* 1 = 0.504022 loss)
I1110 23:14:59.369882  2593 sgd_solver.cpp:106] Iteration 1641, lr = 0.0005
I1110 23:15:01.757208  2593 solver.cpp:295] Iteration 1642 (no loss supplied for SingleUpdateStep)
I1110 23:15:01.757287  2593 solver.cpp:310]     Train net output #0: loss = 0.499764 (* 1 = 0.499764 loss)
I1110 23:15:01.757308  2593 sgd_solver.cpp:106] Iteration 1642, lr = 0.0005
I1110 23:15:04.068527  2593 solver.cpp:295] Iteration 1643 (no loss supplied for SingleUpdateStep)
I1110 23:15:04.068611  2593 solver.cpp:310]     Train net output #0: loss = 0.460983 (* 1 = 0.460983 loss)
I1110 23:15:04.068632  2593 sgd_solver.cpp:106] Iteration 1643, lr = 0.0005
I1110 23:15:06.318876  2593 solver.cpp:295] Iteration 1644 (no loss supplied for SingleUpdateStep)
I1110 23:15:06.319031  2593 solver.cpp:310]     Train net output #0: loss = 0.452586 (* 1 = 0.452586 loss)
I1110 23:15:06.319064  2593 sgd_solver.cpp:106] Iteration 1644, lr = 0.0005
I1110 23:15:08.531991  2593 solver.cpp:295] Iteration 1645 (no loss supplied for SingleUpdateStep)
I1110 23:15:08.532063  2593 solver.cpp:310]     Train net output #0: loss = 0.484228 (* 1 = 0.484228 loss)
I1110 23:15:08.532084  2593 sgd_solver.cpp:106] Iteration 1645, lr = 0.0005
I1110 23:15:10.783124  2593 solver.cpp:295] Iteration 1646 (no loss supplied for SingleUpdateStep)
I1110 23:15:10.783248  2593 solver.cpp:310]     Train net output #0: loss = 0.490584 (* 1 = 0.490584 loss)
I1110 23:15:10.783270  2593 sgd_solver.cpp:106] Iteration 1646, lr = 0.0005
I1110 23:15:13.039477  2593 solver.cpp:295] Iteration 1647 (no loss supplied for SingleUpdateStep)
I1110 23:15:13.039603  2593 solver.cpp:310]     Train net output #0: loss = 0.46565 (* 1 = 0.46565 loss)
I1110 23:15:13.039626  2593 sgd_solver.cpp:106] Iteration 1647, lr = 0.0005
I1110 23:15:15.325835  2593 solver.cpp:295] Iteration 1648 (no loss supplied for SingleUpdateStep)
I1110 23:15:15.325943  2593 solver.cpp:310]     Train net output #0: loss = 0.473929 (* 1 = 0.473929 loss)
I1110 23:15:15.325964  2593 sgd_solver.cpp:106] Iteration 1648, lr = 0.0005
I1110 23:15:17.659016  2593 solver.cpp:295] Iteration 1649 (no loss supplied for SingleUpdateStep)
I1110 23:15:17.659126  2593 solver.cpp:310]     Train net output #0: loss = 0.450254 (* 1 = 0.450254 loss)
I1110 23:15:17.659148  2593 sgd_solver.cpp:106] Iteration 1649, lr = 0.0005
I1110 23:15:20.252027  2593 solver.cpp:295] Iteration 1650 (no loss supplied for SingleUpdateStep)
I1110 23:15:20.252135  2593 solver.cpp:310]     Train net output #0: loss = 0.499613 (* 1 = 0.499613 loss)
I1110 23:15:20.252158  2593 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I1110 23:15:22.586609  2593 solver.cpp:295] Iteration 1651 (no loss supplied for SingleUpdateStep)
I1110 23:15:22.586725  2593 solver.cpp:310]     Train net output #0: loss = 0.453153 (* 1 = 0.453153 loss)
I1110 23:15:22.586748  2593 sgd_solver.cpp:106] Iteration 1651, lr = 0.0005
I1110 23:15:24.844671  2593 solver.cpp:295] Iteration 1652 (no loss supplied for SingleUpdateStep)
I1110 23:15:24.844780  2593 solver.cpp:310]     Train net output #0: loss = 0.482796 (* 1 = 0.482796 loss)
I1110 23:15:24.844802  2593 sgd_solver.cpp:106] Iteration 1652, lr = 0.0005
I1110 23:15:27.239120  2593 solver.cpp:295] Iteration 1653 (no loss supplied for SingleUpdateStep)
I1110 23:15:27.239181  2593 solver.cpp:310]     Train net output #0: loss = 0.491219 (* 1 = 0.491219 loss)
I1110 23:15:27.239202  2593 sgd_solver.cpp:106] Iteration 1653, lr = 0.0005
I1110 23:15:29.408849  2593 solver.cpp:295] Iteration 1654 (no loss supplied for SingleUpdateStep)
I1110 23:15:29.409034  2593 solver.cpp:310]     Train net output #0: loss = 0.450041 (* 1 = 0.450041 loss)
I1110 23:15:29.409060  2593 sgd_solver.cpp:106] Iteration 1654, lr = 0.0005
I1110 23:15:31.632596  2593 solver.cpp:295] Iteration 1655 (no loss supplied for SingleUpdateStep)
I1110 23:15:31.632669  2593 solver.cpp:310]     Train net output #0: loss = 0.480123 (* 1 = 0.480123 loss)
I1110 23:15:31.632690  2593 sgd_solver.cpp:106] Iteration 1655, lr = 0.0005
I1110 23:15:34.079793  2593 solver.cpp:295] Iteration 1656 (no loss supplied for SingleUpdateStep)
I1110 23:15:34.079913  2593 solver.cpp:310]     Train net output #0: loss = 0.457282 (* 1 = 0.457282 loss)
I1110 23:15:34.079936  2593 sgd_solver.cpp:106] Iteration 1656, lr = 0.0005
I1110 23:15:36.459152  2593 solver.cpp:295] Iteration 1657 (no loss supplied for SingleUpdateStep)
I1110 23:15:36.459257  2593 solver.cpp:310]     Train net output #0: loss = 0.516507 (* 1 = 0.516507 loss)
I1110 23:15:36.459280  2593 sgd_solver.cpp:106] Iteration 1657, lr = 0.0005
I1110 23:15:39.058423  2593 solver.cpp:295] Iteration 1658 (no loss supplied for SingleUpdateStep)
I1110 23:15:39.058521  2593 solver.cpp:310]     Train net output #0: loss = 0.509695 (* 1 = 0.509695 loss)
I1110 23:15:39.058542  2593 sgd_solver.cpp:106] Iteration 1658, lr = 0.0005
I1110 23:15:41.938127  2593 solver.cpp:295] Iteration 1659 (no loss supplied for SingleUpdateStep)
I1110 23:15:41.938269  2593 solver.cpp:310]     Train net output #0: loss = 0.422488 (* 1 = 0.422488 loss)
I1110 23:15:41.938292  2593 sgd_solver.cpp:106] Iteration 1659, lr = 0.0005
I1110 23:15:44.200474  2593 solver.cpp:295] Iteration 1660 (no loss supplied for SingleUpdateStep)
I1110 23:15:44.200563  2593 solver.cpp:310]     Train net output #0: loss = 0.466881 (* 1 = 0.466881 loss)
I1110 23:15:44.200589  2593 sgd_solver.cpp:106] Iteration 1660, lr = 0.0005
I1110 23:15:46.449286  2593 solver.cpp:295] Iteration 1661 (no loss supplied for SingleUpdateStep)
I1110 23:15:46.449419  2593 solver.cpp:310]     Train net output #0: loss = 0.490024 (* 1 = 0.490024 loss)
I1110 23:15:46.449450  2593 sgd_solver.cpp:106] Iteration 1661, lr = 0.0005
I1110 23:15:48.704912  2593 solver.cpp:295] Iteration 1662 (no loss supplied for SingleUpdateStep)
I1110 23:15:48.705029  2593 solver.cpp:310]     Train net output #0: loss = 0.475394 (* 1 = 0.475394 loss)
I1110 23:15:48.705059  2593 sgd_solver.cpp:106] Iteration 1662, lr = 0.0005
I1110 23:15:51.024875  2593 solver.cpp:295] Iteration 1663 (no loss supplied for SingleUpdateStep)
I1110 23:15:51.024976  2593 solver.cpp:310]     Train net output #0: loss = 0.444913 (* 1 = 0.444913 loss)
I1110 23:15:51.024997  2593 sgd_solver.cpp:106] Iteration 1663, lr = 0.0005
I1110 23:15:53.134150  2593 solver.cpp:295] Iteration 1664 (no loss supplied for SingleUpdateStep)
I1110 23:15:53.134295  2593 solver.cpp:310]     Train net output #0: loss = 0.455273 (* 1 = 0.455273 loss)
I1110 23:15:53.134320  2593 sgd_solver.cpp:106] Iteration 1664, lr = 0.0005
I1110 23:15:55.622861  2593 solver.cpp:295] Iteration 1665 (no loss supplied for SingleUpdateStep)
I1110 23:15:55.622972  2593 solver.cpp:310]     Train net output #0: loss = 0.459179 (* 1 = 0.459179 loss)
I1110 23:15:55.622994  2593 sgd_solver.cpp:106] Iteration 1665, lr = 0.0005
I1110 23:15:58.033493  2593 solver.cpp:295] Iteration 1666 (no loss supplied for SingleUpdateStep)
I1110 23:15:58.033553  2593 solver.cpp:310]     Train net output #0: loss = 0.501875 (* 1 = 0.501875 loss)
I1110 23:15:58.033572  2593 sgd_solver.cpp:106] Iteration 1666, lr = 0.0005
I1110 23:16:00.413938  2593 solver.cpp:295] Iteration 1667 (no loss supplied for SingleUpdateStep)
I1110 23:16:00.414011  2593 solver.cpp:310]     Train net output #0: loss = 0.43792 (* 1 = 0.43792 loss)
I1110 23:16:00.414032  2593 sgd_solver.cpp:106] Iteration 1667, lr = 0.0005
I1110 23:16:02.846777  2593 solver.cpp:295] Iteration 1668 (no loss supplied for SingleUpdateStep)
I1110 23:16:02.846865  2593 solver.cpp:310]     Train net output #0: loss = 0.449874 (* 1 = 0.449874 loss)
I1110 23:16:02.846885  2593 sgd_solver.cpp:106] Iteration 1668, lr = 0.0005
I1110 23:16:05.165190  2593 solver.cpp:295] Iteration 1669 (no loss supplied for SingleUpdateStep)
I1110 23:16:05.165315  2593 solver.cpp:310]     Train net output #0: loss = 0.492539 (* 1 = 0.492539 loss)
I1110 23:16:05.165338  2593 sgd_solver.cpp:106] Iteration 1669, lr = 0.0005
I1110 23:16:07.381340  2593 solver.cpp:295] Iteration 1670 (no loss supplied for SingleUpdateStep)
I1110 23:16:07.381440  2593 solver.cpp:310]     Train net output #0: loss = 0.474815 (* 1 = 0.474815 loss)
I1110 23:16:07.381460  2593 sgd_solver.cpp:106] Iteration 1670, lr = 0.0005
I1110 23:16:09.670717  2593 solver.cpp:295] Iteration 1671 (no loss supplied for SingleUpdateStep)
I1110 23:16:09.670835  2593 solver.cpp:310]     Train net output #0: loss = 0.427806 (* 1 = 0.427806 loss)
I1110 23:16:09.670856  2593 sgd_solver.cpp:106] Iteration 1671, lr = 0.0005
I1110 23:16:11.847782  2593 solver.cpp:295] Iteration 1672 (no loss supplied for SingleUpdateStep)
I1110 23:16:11.847846  2593 solver.cpp:310]     Train net output #0: loss = 0.480904 (* 1 = 0.480904 loss)
I1110 23:16:11.847864  2593 sgd_solver.cpp:106] Iteration 1672, lr = 0.0005
I1110 23:16:13.999106  2593 solver.cpp:295] Iteration 1673 (no loss supplied for SingleUpdateStep)
I1110 23:16:13.999203  2593 solver.cpp:310]     Train net output #0: loss = 0.476336 (* 1 = 0.476336 loss)
I1110 23:16:13.999224  2593 sgd_solver.cpp:106] Iteration 1673, lr = 0.0005
I1110 23:16:16.199146  2593 solver.cpp:295] Iteration 1674 (no loss supplied for SingleUpdateStep)
I1110 23:16:16.199236  2593 solver.cpp:310]     Train net output #0: loss = 0.446556 (* 1 = 0.446556 loss)
I1110 23:16:16.199257  2593 sgd_solver.cpp:106] Iteration 1674, lr = 0.0005
I1110 23:16:18.298007  2593 solver.cpp:295] Iteration 1675 (no loss supplied for SingleUpdateStep)
I1110 23:16:18.298123  2593 solver.cpp:310]     Train net output #0: loss = 0.46866 (* 1 = 0.46866 loss)
I1110 23:16:18.298151  2593 sgd_solver.cpp:106] Iteration 1675, lr = 0.0005
I1110 23:16:20.522096  2593 solver.cpp:295] Iteration 1676 (no loss supplied for SingleUpdateStep)
I1110 23:16:20.522152  2593 solver.cpp:310]     Train net output #0: loss = 0.453673 (* 1 = 0.453673 loss)
I1110 23:16:20.522171  2593 sgd_solver.cpp:106] Iteration 1676, lr = 0.0005
I1110 23:16:23.177386  2593 solver.cpp:295] Iteration 1677 (no loss supplied for SingleUpdateStep)
I1110 23:16:23.177459  2593 solver.cpp:310]     Train net output #0: loss = 0.495491 (* 1 = 0.495491 loss)
I1110 23:16:23.177479  2593 sgd_solver.cpp:106] Iteration 1677, lr = 0.0005
I1110 23:16:26.451472  2593 solver.cpp:295] Iteration 1678 (no loss supplied for SingleUpdateStep)
I1110 23:16:26.451572  2593 solver.cpp:310]     Train net output #0: loss = 0.464494 (* 1 = 0.464494 loss)
I1110 23:16:26.451596  2593 sgd_solver.cpp:106] Iteration 1678, lr = 0.0005
I1110 23:16:28.782469  2593 solver.cpp:295] Iteration 1679 (no loss supplied for SingleUpdateStep)
I1110 23:16:28.782600  2593 solver.cpp:310]     Train net output #0: loss = 0.438839 (* 1 = 0.438839 loss)
I1110 23:16:28.782624  2593 sgd_solver.cpp:106] Iteration 1679, lr = 0.0005
I1110 23:16:31.133652  2593 solver.cpp:295] Iteration 1680 (no loss supplied for SingleUpdateStep)
I1110 23:16:31.133791  2593 solver.cpp:310]     Train net output #0: loss = 0.478051 (* 1 = 0.478051 loss)
I1110 23:16:31.133816  2593 sgd_solver.cpp:106] Iteration 1680, lr = 0.0005
I1110 23:16:33.588425  2593 solver.cpp:295] Iteration 1681 (no loss supplied for SingleUpdateStep)
I1110 23:16:33.588547  2593 solver.cpp:310]     Train net output #0: loss = 0.46864 (* 1 = 0.46864 loss)
I1110 23:16:33.588568  2593 sgd_solver.cpp:106] Iteration 1681, lr = 0.0005
I1110 23:16:35.916524  2593 solver.cpp:295] Iteration 1682 (no loss supplied for SingleUpdateStep)
I1110 23:16:35.916604  2593 solver.cpp:310]     Train net output #0: loss = 0.435688 (* 1 = 0.435688 loss)
I1110 23:16:35.916626  2593 sgd_solver.cpp:106] Iteration 1682, lr = 0.0005
I1110 23:16:38.224457  2593 solver.cpp:295] Iteration 1683 (no loss supplied for SingleUpdateStep)
I1110 23:16:38.224535  2593 solver.cpp:310]     Train net output #0: loss = 0.486303 (* 1 = 0.486303 loss)
I1110 23:16:38.224555  2593 sgd_solver.cpp:106] Iteration 1683, lr = 0.0005
I1110 23:16:40.628226  2593 solver.cpp:295] Iteration 1684 (no loss supplied for SingleUpdateStep)
I1110 23:16:40.628284  2593 solver.cpp:310]     Train net output #0: loss = 0.45522 (* 1 = 0.45522 loss)
I1110 23:16:40.628304  2593 sgd_solver.cpp:106] Iteration 1684, lr = 0.0005
I1110 23:16:42.805131  2593 solver.cpp:295] Iteration 1685 (no loss supplied for SingleUpdateStep)
I1110 23:16:42.805249  2593 solver.cpp:310]     Train net output #0: loss = 0.477466 (* 1 = 0.477466 loss)
I1110 23:16:42.805271  2593 sgd_solver.cpp:106] Iteration 1685, lr = 0.0005
I1110 23:16:45.035987  2593 solver.cpp:295] Iteration 1686 (no loss supplied for SingleUpdateStep)
I1110 23:16:45.036041  2593 solver.cpp:310]     Train net output #0: loss = 0.44275 (* 1 = 0.44275 loss)
I1110 23:16:45.036059  2593 sgd_solver.cpp:106] Iteration 1686, lr = 0.0005
I1110 23:16:47.271670  2593 solver.cpp:295] Iteration 1687 (no loss supplied for SingleUpdateStep)
I1110 23:16:47.271756  2593 solver.cpp:310]     Train net output #0: loss = 0.47573 (* 1 = 0.47573 loss)
I1110 23:16:47.271778  2593 sgd_solver.cpp:106] Iteration 1687, lr = 0.0005
I1110 23:16:49.486707  2593 solver.cpp:295] Iteration 1688 (no loss supplied for SingleUpdateStep)
I1110 23:16:49.486819  2593 solver.cpp:310]     Train net output #0: loss = 0.472196 (* 1 = 0.472196 loss)
I1110 23:16:49.486840  2593 sgd_solver.cpp:106] Iteration 1688, lr = 0.0005
I1110 23:16:51.784704  2593 solver.cpp:295] Iteration 1689 (no loss supplied for SingleUpdateStep)
I1110 23:16:51.784785  2593 solver.cpp:310]     Train net output #0: loss = 0.443594 (* 1 = 0.443594 loss)
I1110 23:16:51.784806  2593 sgd_solver.cpp:106] Iteration 1689, lr = 0.0005
I1110 23:16:54.078654  2593 solver.cpp:295] Iteration 1690 (no loss supplied for SingleUpdateStep)
I1110 23:16:54.078795  2593 solver.cpp:310]     Train net output #0: loss = 0.459526 (* 1 = 0.459526 loss)
I1110 23:16:54.078821  2593 sgd_solver.cpp:106] Iteration 1690, lr = 0.0005
I1110 23:16:56.215121  2593 solver.cpp:295] Iteration 1691 (no loss supplied for SingleUpdateStep)
I1110 23:16:56.215230  2593 solver.cpp:310]     Train net output #0: loss = 0.467829 (* 1 = 0.467829 loss)
I1110 23:16:56.215251  2593 sgd_solver.cpp:106] Iteration 1691, lr = 0.0005
I1110 23:16:58.560842  2593 solver.cpp:295] Iteration 1692 (no loss supplied for SingleUpdateStep)
I1110 23:16:58.560987  2593 solver.cpp:310]     Train net output #0: loss = 0.459759 (* 1 = 0.459759 loss)
I1110 23:16:58.561014  2593 sgd_solver.cpp:106] Iteration 1692, lr = 0.0005
I1110 23:17:00.805423  2593 solver.cpp:295] Iteration 1693 (no loss supplied for SingleUpdateStep)
I1110 23:17:00.805521  2593 solver.cpp:310]     Train net output #0: loss = 0.487666 (* 1 = 0.487666 loss)
I1110 23:17:00.805541  2593 sgd_solver.cpp:106] Iteration 1693, lr = 0.0005
I1110 23:17:02.979121  2593 solver.cpp:295] Iteration 1694 (no loss supplied for SingleUpdateStep)
I1110 23:17:02.979257  2593 solver.cpp:310]     Train net output #0: loss = 0.434997 (* 1 = 0.434997 loss)
I1110 23:17:02.979285  2593 sgd_solver.cpp:106] Iteration 1694, lr = 0.0005
I1110 23:17:05.276005  2593 solver.cpp:295] Iteration 1695 (no loss supplied for SingleUpdateStep)
I1110 23:17:05.276139  2593 solver.cpp:310]     Train net output #0: loss = 0.442674 (* 1 = 0.442674 loss)
I1110 23:17:05.276167  2593 sgd_solver.cpp:106] Iteration 1695, lr = 0.0005
I1110 23:17:07.559406  2593 solver.cpp:295] Iteration 1696 (no loss supplied for SingleUpdateStep)
I1110 23:17:07.559471  2593 solver.cpp:310]     Train net output #0: loss = 0.504765 (* 1 = 0.504765 loss)
I1110 23:17:07.559492  2593 sgd_solver.cpp:106] Iteration 1696, lr = 0.0005
I1110 23:17:09.778100  2593 solver.cpp:295] Iteration 1697 (no loss supplied for SingleUpdateStep)
I1110 23:17:09.778156  2593 solver.cpp:310]     Train net output #0: loss = 0.44727 (* 1 = 0.44727 loss)
I1110 23:17:09.778175  2593 sgd_solver.cpp:106] Iteration 1697, lr = 0.0005
I1110 23:17:12.763603  2593 solver.cpp:295] Iteration 1698 (no loss supplied for SingleUpdateStep)
I1110 23:17:12.763700  2593 solver.cpp:310]     Train net output #0: loss = 0.480402 (* 1 = 0.480402 loss)
I1110 23:17:12.763721  2593 sgd_solver.cpp:106] Iteration 1698, lr = 0.0005
I1110 23:17:16.759011  2593 solver.cpp:295] Iteration 1699 (no loss supplied for SingleUpdateStep)
I1110 23:17:16.759093  2593 solver.cpp:310]     Train net output #0: loss = 0.471227 (* 1 = 0.471227 loss)
I1110 23:17:16.759114  2593 sgd_solver.cpp:106] Iteration 1699, lr = 0.0005
I1110 23:17:21.047744  2593 solver.cpp:295] Iteration 1700 (no loss supplied for SingleUpdateStep)
I1110 23:17:21.047806  2593 solver.cpp:310]     Train net output #0: loss = 0.46995 (* 1 = 0.46995 loss)
I1110 23:17:21.047826  2593 sgd_solver.cpp:106] Iteration 1700, lr = 0.0005
I1110 23:17:24.039878  2593 solver.cpp:295] Iteration 1701 (no loss supplied for SingleUpdateStep)
I1110 23:17:24.047598  2593 solver.cpp:310]     Train net output #0: loss = 0.518165 (* 1 = 0.518165 loss)
I1110 23:17:24.047679  2593 sgd_solver.cpp:106] Iteration 1701, lr = 0.0005
I1110 23:17:26.568815  2593 solver.cpp:295] Iteration 1702 (no loss supplied for SingleUpdateStep)
I1110 23:17:26.568966  2593 solver.cpp:310]     Train net output #0: loss = 0.459389 (* 1 = 0.459389 loss)
I1110 23:17:26.568990  2593 sgd_solver.cpp:106] Iteration 1702, lr = 0.0005
I1110 23:17:29.122772  2593 solver.cpp:295] Iteration 1703 (no loss supplied for SingleUpdateStep)
I1110 23:17:29.122891  2593 solver.cpp:310]     Train net output #0: loss = 0.438725 (* 1 = 0.438725 loss)
I1110 23:17:29.122915  2593 sgd_solver.cpp:106] Iteration 1703, lr = 0.0005
I1110 23:17:31.605312  2593 solver.cpp:295] Iteration 1704 (no loss supplied for SingleUpdateStep)
I1110 23:17:31.605425  2593 solver.cpp:310]     Train net output #0: loss = 0.466294 (* 1 = 0.466294 loss)
I1110 23:17:31.605449  2593 sgd_solver.cpp:106] Iteration 1704, lr = 0.0005
I1110 23:17:33.831732  2593 solver.cpp:295] Iteration 1705 (no loss supplied for SingleUpdateStep)
I1110 23:17:33.831838  2593 solver.cpp:310]     Train net output #0: loss = 0.521358 (* 1 = 0.521358 loss)
I1110 23:17:33.831861  2593 sgd_solver.cpp:106] Iteration 1705, lr = 0.0005
I1110 23:17:36.153218  2593 solver.cpp:295] Iteration 1706 (no loss supplied for SingleUpdateStep)
I1110 23:17:36.153365  2593 solver.cpp:310]     Train net output #0: loss = 0.453328 (* 1 = 0.453328 loss)
I1110 23:17:36.153394  2593 sgd_solver.cpp:106] Iteration 1706, lr = 0.0005
I1110 23:17:38.624466  2593 solver.cpp:295] Iteration 1707 (no loss supplied for SingleUpdateStep)
I1110 23:17:38.624610  2593 solver.cpp:310]     Train net output #0: loss = 0.468493 (* 1 = 0.468493 loss)
I1110 23:17:38.624639  2593 sgd_solver.cpp:106] Iteration 1707, lr = 0.0005
I1110 23:17:42.811233  2593 solver.cpp:295] Iteration 1708 (no loss supplied for SingleUpdateStep)
I1110 23:17:42.811353  2593 solver.cpp:310]     Train net output #0: loss = 0.491228 (* 1 = 0.491228 loss)
I1110 23:17:42.811375  2593 sgd_solver.cpp:106] Iteration 1708, lr = 0.0005
I1110 23:17:47.264572  2593 solver.cpp:295] Iteration 1709 (no loss supplied for SingleUpdateStep)
I1110 23:17:47.264696  2593 solver.cpp:310]     Train net output #0: loss = 0.470886 (* 1 = 0.470886 loss)
I1110 23:17:47.264720  2593 sgd_solver.cpp:106] Iteration 1709, lr = 0.0005
I1110 23:17:50.616314  2593 solver.cpp:295] Iteration 1710 (no loss supplied for SingleUpdateStep)
I1110 23:17:50.616420  2593 solver.cpp:310]     Train net output #0: loss = 0.541005 (* 1 = 0.541005 loss)
I1110 23:17:50.616441  2593 sgd_solver.cpp:106] Iteration 1710, lr = 0.0005
I1110 23:17:54.095250  2593 solver.cpp:295] Iteration 1711 (no loss supplied for SingleUpdateStep)
I1110 23:17:54.095357  2593 solver.cpp:310]     Train net output #0: loss = 0.455879 (* 1 = 0.455879 loss)
I1110 23:17:54.095378  2593 sgd_solver.cpp:106] Iteration 1711, lr = 0.0005
I1110 23:17:58.207454  2593 solver.cpp:295] Iteration 1712 (no loss supplied for SingleUpdateStep)
I1110 23:17:58.207562  2593 solver.cpp:310]     Train net output #0: loss = 0.458508 (* 1 = 0.458508 loss)
I1110 23:17:58.207586  2593 sgd_solver.cpp:106] Iteration 1712, lr = 0.0005
I1110 23:18:02.905238  2593 solver.cpp:295] Iteration 1713 (no loss supplied for SingleUpdateStep)
I1110 23:18:02.905329  2593 solver.cpp:310]     Train net output #0: loss = 0.4724 (* 1 = 0.4724 loss)
I1110 23:18:02.905350  2593 sgd_solver.cpp:106] Iteration 1713, lr = 0.0005
I1110 23:18:06.725139  2593 solver.cpp:295] Iteration 1714 (no loss supplied for SingleUpdateStep)
I1110 23:18:06.725220  2593 solver.cpp:310]     Train net output #0: loss = 0.459142 (* 1 = 0.459142 loss)
I1110 23:18:06.725240  2593 sgd_solver.cpp:106] Iteration 1714, lr = 0.0005
I1110 23:18:09.587724  2593 solver.cpp:295] Iteration 1715 (no loss supplied for SingleUpdateStep)
I1110 23:18:09.587852  2593 solver.cpp:310]     Train net output #0: loss = 0.468445 (* 1 = 0.468445 loss)
I1110 23:18:09.587875  2593 sgd_solver.cpp:106] Iteration 1715, lr = 0.0005
I1110 23:18:12.107255  2593 solver.cpp:295] Iteration 1716 (no loss supplied for SingleUpdateStep)
I1110 23:18:12.107309  2593 solver.cpp:310]     Train net output #0: loss = 0.476805 (* 1 = 0.476805 loss)
I1110 23:18:12.107329  2593 sgd_solver.cpp:106] Iteration 1716, lr = 0.0005
I1110 23:18:14.504874  2593 solver.cpp:295] Iteration 1717 (no loss supplied for SingleUpdateStep)
I1110 23:18:14.505000  2593 solver.cpp:310]     Train net output #0: loss = 0.474741 (* 1 = 0.474741 loss)
I1110 23:18:14.505030  2593 sgd_solver.cpp:106] Iteration 1717, lr = 0.0005
I1110 23:18:16.838670  2593 solver.cpp:295] Iteration 1718 (no loss supplied for SingleUpdateStep)
I1110 23:18:16.838773  2593 solver.cpp:310]     Train net output #0: loss = 0.453213 (* 1 = 0.453213 loss)
I1110 23:18:16.838795  2593 sgd_solver.cpp:106] Iteration 1718, lr = 0.0005
I1110 23:18:19.171210  2593 solver.cpp:295] Iteration 1719 (no loss supplied for SingleUpdateStep)
I1110 23:18:19.171298  2593 solver.cpp:310]     Train net output #0: loss = 0.434486 (* 1 = 0.434486 loss)
I1110 23:18:19.171319  2593 sgd_solver.cpp:106] Iteration 1719, lr = 0.0005
I1110 23:18:21.456123  2593 solver.cpp:295] Iteration 1720 (no loss supplied for SingleUpdateStep)
I1110 23:18:21.456275  2593 solver.cpp:310]     Train net output #0: loss = 0.474941 (* 1 = 0.474941 loss)
I1110 23:18:21.456300  2593 sgd_solver.cpp:106] Iteration 1720, lr = 0.0005
I1110 23:18:23.620901  2593 solver.cpp:295] Iteration 1721 (no loss supplied for SingleUpdateStep)
I1110 23:18:23.621001  2593 solver.cpp:310]     Train net output #0: loss = 0.481205 (* 1 = 0.481205 loss)
I1110 23:18:23.621023  2593 sgd_solver.cpp:106] Iteration 1721, lr = 0.0005
I1110 23:18:25.970163  2593 solver.cpp:295] Iteration 1722 (no loss supplied for SingleUpdateStep)
I1110 23:18:25.970268  2593 solver.cpp:310]     Train net output #0: loss = 0.473859 (* 1 = 0.473859 loss)
I1110 23:18:25.970291  2593 sgd_solver.cpp:106] Iteration 1722, lr = 0.0005
I1110 23:18:28.236827  2593 solver.cpp:295] Iteration 1723 (no loss supplied for SingleUpdateStep)
I1110 23:18:28.236903  2593 solver.cpp:310]     Train net output #0: loss = 0.452398 (* 1 = 0.452398 loss)
I1110 23:18:28.236925  2593 sgd_solver.cpp:106] Iteration 1723, lr = 0.0005
I1110 23:18:30.560659  2593 solver.cpp:295] Iteration 1724 (no loss supplied for SingleUpdateStep)
I1110 23:18:30.560745  2593 solver.cpp:310]     Train net output #0: loss = 0.438385 (* 1 = 0.438385 loss)
I1110 23:18:30.560765  2593 sgd_solver.cpp:106] Iteration 1724, lr = 0.0005
I1110 23:18:33.006476  2593 solver.cpp:295] Iteration 1725 (no loss supplied for SingleUpdateStep)
I1110 23:18:33.006583  2593 solver.cpp:310]     Train net output #0: loss = 0.51218 (* 1 = 0.51218 loss)
I1110 23:18:33.006606  2593 sgd_solver.cpp:106] Iteration 1725, lr = 0.0005
I1110 23:18:35.450471  2593 solver.cpp:295] Iteration 1726 (no loss supplied for SingleUpdateStep)
I1110 23:18:35.450592  2593 solver.cpp:310]     Train net output #0: loss = 0.448209 (* 1 = 0.448209 loss)
I1110 23:18:35.450616  2593 sgd_solver.cpp:106] Iteration 1726, lr = 0.0005
I1110 23:18:37.735551  2593 solver.cpp:295] Iteration 1727 (no loss supplied for SingleUpdateStep)
I1110 23:18:37.735630  2593 solver.cpp:310]     Train net output #0: loss = 0.425168 (* 1 = 0.425168 loss)
I1110 23:18:37.735651  2593 sgd_solver.cpp:106] Iteration 1727, lr = 0.0005
I1110 23:18:40.038707  2593 solver.cpp:295] Iteration 1728 (no loss supplied for SingleUpdateStep)
I1110 23:18:40.038833  2593 solver.cpp:310]     Train net output #0: loss = 0.468584 (* 1 = 0.468584 loss)
I1110 23:18:40.038856  2593 sgd_solver.cpp:106] Iteration 1728, lr = 0.0005
I1110 23:18:42.365780  2593 solver.cpp:295] Iteration 1729 (no loss supplied for SingleUpdateStep)
I1110 23:18:42.365898  2593 solver.cpp:310]     Train net output #0: loss = 0.478779 (* 1 = 0.478779 loss)
I1110 23:18:42.365923  2593 sgd_solver.cpp:106] Iteration 1729, lr = 0.0005
I1110 23:18:44.544011  2593 solver.cpp:295] Iteration 1730 (no loss supplied for SingleUpdateStep)
I1110 23:18:44.544128  2593 solver.cpp:310]     Train net output #0: loss = 0.436203 (* 1 = 0.436203 loss)
I1110 23:18:44.544152  2593 sgd_solver.cpp:106] Iteration 1730, lr = 0.0005
I1110 23:18:47.028962  2593 solver.cpp:295] Iteration 1731 (no loss supplied for SingleUpdateStep)
I1110 23:18:47.029045  2593 solver.cpp:310]     Train net output #0: loss = 0.455177 (* 1 = 0.455177 loss)
I1110 23:18:47.029065  2593 sgd_solver.cpp:106] Iteration 1731, lr = 0.0005
I1110 23:18:50.040431  2593 solver.cpp:295] Iteration 1732 (no loss supplied for SingleUpdateStep)
I1110 23:18:50.040521  2593 solver.cpp:310]     Train net output #0: loss = 0.428445 (* 1 = 0.428445 loss)
I1110 23:18:50.040555  2593 sgd_solver.cpp:106] Iteration 1732, lr = 0.0005
I1110 23:18:53.365092  2593 solver.cpp:295] Iteration 1733 (no loss supplied for SingleUpdateStep)
I1110 23:18:53.365173  2593 solver.cpp:310]     Train net output #0: loss = 0.469478 (* 1 = 0.469478 loss)
I1110 23:18:53.365193  2593 sgd_solver.cpp:106] Iteration 1733, lr = 0.0005
I1110 23:18:56.200134  2593 solver.cpp:295] Iteration 1734 (no loss supplied for SingleUpdateStep)
I1110 23:18:56.200242  2593 solver.cpp:310]     Train net output #0: loss = 0.502229 (* 1 = 0.502229 loss)
I1110 23:18:56.200266  2593 sgd_solver.cpp:106] Iteration 1734, lr = 0.0005
I1110 23:18:58.712105  2593 solver.cpp:295] Iteration 1735 (no loss supplied for SingleUpdateStep)
I1110 23:18:58.712165  2593 solver.cpp:310]     Train net output #0: loss = 0.466885 (* 1 = 0.466885 loss)
I1110 23:18:58.712184  2593 sgd_solver.cpp:106] Iteration 1735, lr = 0.0005
I1110 23:19:01.260378  2593 solver.cpp:295] Iteration 1736 (no loss supplied for SingleUpdateStep)
I1110 23:19:01.260465  2593 solver.cpp:310]     Train net output #0: loss = 0.511329 (* 1 = 0.511329 loss)
I1110 23:19:01.260485  2593 sgd_solver.cpp:106] Iteration 1736, lr = 0.0005
I1110 23:19:03.669324  2593 solver.cpp:295] Iteration 1737 (no loss supplied for SingleUpdateStep)
I1110 23:19:03.669415  2593 solver.cpp:310]     Train net output #0: loss = 0.494654 (* 1 = 0.494654 loss)
I1110 23:19:03.669436  2593 sgd_solver.cpp:106] Iteration 1737, lr = 0.0005
I1110 23:19:05.984544  2593 solver.cpp:295] Iteration 1738 (no loss supplied for SingleUpdateStep)
I1110 23:19:05.984649  2593 solver.cpp:310]     Train net output #0: loss = 0.43799 (* 1 = 0.43799 loss)
I1110 23:19:05.984670  2593 sgd_solver.cpp:106] Iteration 1738, lr = 0.0005
I1110 23:19:08.286039  2593 solver.cpp:295] Iteration 1739 (no loss supplied for SingleUpdateStep)
I1110 23:19:08.286144  2593 solver.cpp:310]     Train net output #0: loss = 0.467363 (* 1 = 0.467363 loss)
I1110 23:19:08.286167  2593 sgd_solver.cpp:106] Iteration 1739, lr = 0.0005
I1110 23:19:10.612347  2593 solver.cpp:295] Iteration 1740 (no loss supplied for SingleUpdateStep)
I1110 23:19:10.612396  2593 solver.cpp:310]     Train net output #0: loss = 0.453049 (* 1 = 0.453049 loss)
I1110 23:19:10.612414  2593 sgd_solver.cpp:106] Iteration 1740, lr = 0.0005
I1110 23:19:12.991135  2593 solver.cpp:295] Iteration 1741 (no loss supplied for SingleUpdateStep)
I1110 23:19:12.991195  2593 solver.cpp:310]     Train net output #0: loss = 0.495025 (* 1 = 0.495025 loss)
I1110 23:19:12.991215  2593 sgd_solver.cpp:106] Iteration 1741, lr = 0.0005
I1110 23:19:15.493715  2593 solver.cpp:295] Iteration 1742 (no loss supplied for SingleUpdateStep)
I1110 23:19:15.493875  2593 solver.cpp:310]     Train net output #0: loss = 0.473539 (* 1 = 0.473539 loss)
I1110 23:19:15.493901  2593 sgd_solver.cpp:106] Iteration 1742, lr = 0.0005
I1110 23:19:18.170114  2593 solver.cpp:295] Iteration 1743 (no loss supplied for SingleUpdateStep)
I1110 23:19:18.170270  2593 solver.cpp:310]     Train net output #0: loss = 0.488261 (* 1 = 0.488261 loss)
I1110 23:19:18.170296  2593 sgd_solver.cpp:106] Iteration 1743, lr = 0.0005
I1110 23:19:20.763594  2593 solver.cpp:295] Iteration 1744 (no loss supplied for SingleUpdateStep)
I1110 23:19:20.763711  2593 solver.cpp:310]     Train net output #0: loss = 0.461259 (* 1 = 0.461259 loss)
I1110 23:19:20.763739  2593 sgd_solver.cpp:106] Iteration 1744, lr = 0.0005
I1110 23:19:23.110869  2593 solver.cpp:295] Iteration 1745 (no loss supplied for SingleUpdateStep)
I1110 23:19:23.110975  2593 solver.cpp:310]     Train net output #0: loss = 0.461884 (* 1 = 0.461884 loss)
I1110 23:19:23.110997  2593 sgd_solver.cpp:106] Iteration 1745, lr = 0.0005
I1110 23:19:25.511572  2593 solver.cpp:295] Iteration 1746 (no loss supplied for SingleUpdateStep)
I1110 23:19:25.511719  2593 solver.cpp:310]     Train net output #0: loss = 0.475101 (* 1 = 0.475101 loss)
I1110 23:19:25.511744  2593 sgd_solver.cpp:106] Iteration 1746, lr = 0.0005
I1110 23:19:27.864526  2593 solver.cpp:295] Iteration 1747 (no loss supplied for SingleUpdateStep)
I1110 23:19:27.864598  2593 solver.cpp:310]     Train net output #0: loss = 0.434583 (* 1 = 0.434583 loss)
I1110 23:19:27.864619  2593 sgd_solver.cpp:106] Iteration 1747, lr = 0.0005
I1110 23:19:30.203824  2593 solver.cpp:295] Iteration 1748 (no loss supplied for SingleUpdateStep)
I1110 23:19:30.203920  2593 solver.cpp:310]     Train net output #0: loss = 0.497392 (* 1 = 0.497392 loss)
I1110 23:19:30.203941  2593 sgd_solver.cpp:106] Iteration 1748, lr = 0.0005
I1110 23:19:32.564890  2593 solver.cpp:295] Iteration 1749 (no loss supplied for SingleUpdateStep)
I1110 23:19:32.565008  2593 solver.cpp:310]     Train net output #0: loss = 0.48675 (* 1 = 0.48675 loss)
I1110 23:19:32.565031  2593 sgd_solver.cpp:106] Iteration 1749, lr = 0.0005
I1110 23:19:34.884892  2593 solver.cpp:295] Iteration 1750 (no loss supplied for SingleUpdateStep)
I1110 23:19:34.885015  2593 solver.cpp:310]     Train net output #0: loss = 0.480624 (* 1 = 0.480624 loss)
I1110 23:19:34.885040  2593 sgd_solver.cpp:106] Iteration 1750, lr = 0.0005
I1110 23:19:37.165205  2593 solver.cpp:295] Iteration 1751 (no loss supplied for SingleUpdateStep)
I1110 23:19:37.165257  2593 solver.cpp:310]     Train net output #0: loss = 0.462763 (* 1 = 0.462763 loss)
I1110 23:19:37.165276  2593 sgd_solver.cpp:106] Iteration 1751, lr = 0.0005
I1110 23:19:39.837926  2593 solver.cpp:295] Iteration 1752 (no loss supplied for SingleUpdateStep)
I1110 23:19:39.837985  2593 solver.cpp:310]     Train net output #0: loss = 0.455888 (* 1 = 0.455888 loss)
I1110 23:19:39.838003  2593 sgd_solver.cpp:106] Iteration 1752, lr = 0.0005
I1110 23:19:42.406494  2593 solver.cpp:295] Iteration 1753 (no loss supplied for SingleUpdateStep)
I1110 23:19:42.406579  2593 solver.cpp:310]     Train net output #0: loss = 0.510081 (* 1 = 0.510081 loss)
I1110 23:19:42.406600  2593 sgd_solver.cpp:106] Iteration 1753, lr = 0.0005
I1110 23:19:45.373291  2593 solver.cpp:295] Iteration 1754 (no loss supplied for SingleUpdateStep)
I1110 23:19:45.373340  2593 solver.cpp:310]     Train net output #0: loss = 0.48088 (* 1 = 0.48088 loss)
I1110 23:19:45.373358  2593 sgd_solver.cpp:106] Iteration 1754, lr = 0.0005
I1110 23:19:48.619328  2593 solver.cpp:295] Iteration 1755 (no loss supplied for SingleUpdateStep)
I1110 23:19:48.619396  2593 solver.cpp:310]     Train net output #0: loss = 0.500004 (* 1 = 0.500004 loss)
I1110 23:19:48.619417  2593 sgd_solver.cpp:106] Iteration 1755, lr = 0.0005
I1110 23:19:51.506572  2593 solver.cpp:295] Iteration 1756 (no loss supplied for SingleUpdateStep)
I1110 23:19:51.506695  2593 solver.cpp:310]     Train net output #0: loss = 0.457711 (* 1 = 0.457711 loss)
I1110 23:19:51.506719  2593 sgd_solver.cpp:106] Iteration 1756, lr = 0.0005
I1110 23:19:54.841219  2593 solver.cpp:295] Iteration 1757 (no loss supplied for SingleUpdateStep)
I1110 23:19:54.841302  2593 solver.cpp:310]     Train net output #0: loss = 0.465513 (* 1 = 0.465513 loss)
I1110 23:19:54.841323  2593 sgd_solver.cpp:106] Iteration 1757, lr = 0.0005
I1110 23:19:57.416245  2593 solver.cpp:295] Iteration 1758 (no loss supplied for SingleUpdateStep)
I1110 23:19:57.416363  2593 solver.cpp:310]     Train net output #0: loss = 0.460889 (* 1 = 0.460889 loss)
I1110 23:19:57.416388  2593 sgd_solver.cpp:106] Iteration 1758, lr = 0.0005
I1110 23:19:59.743340  2593 solver.cpp:295] Iteration 1759 (no loss supplied for SingleUpdateStep)
I1110 23:19:59.743427  2593 solver.cpp:310]     Train net output #0: loss = 0.457196 (* 1 = 0.457196 loss)
I1110 23:19:59.743448  2593 sgd_solver.cpp:106] Iteration 1759, lr = 0.0005
I1110 23:20:02.142282  2593 solver.cpp:295] Iteration 1760 (no loss supplied for SingleUpdateStep)
I1110 23:20:02.142391  2593 solver.cpp:310]     Train net output #0: loss = 0.464704 (* 1 = 0.464704 loss)
I1110 23:20:02.142416  2593 sgd_solver.cpp:106] Iteration 1760, lr = 0.0005
I1110 23:20:04.472684  2593 solver.cpp:295] Iteration 1761 (no loss supplied for SingleUpdateStep)
I1110 23:20:04.472803  2593 solver.cpp:310]     Train net output #0: loss = 0.44744 (* 1 = 0.44744 loss)
I1110 23:20:04.472828  2593 sgd_solver.cpp:106] Iteration 1761, lr = 0.0005
I1110 23:20:06.879880  2593 solver.cpp:295] Iteration 1762 (no loss supplied for SingleUpdateStep)
I1110 23:20:06.879981  2593 solver.cpp:310]     Train net output #0: loss = 0.473238 (* 1 = 0.473238 loss)
I1110 23:20:06.880003  2593 sgd_solver.cpp:106] Iteration 1762, lr = 0.0005
I1110 23:20:09.112702  2593 solver.cpp:295] Iteration 1763 (no loss supplied for SingleUpdateStep)
I1110 23:20:09.112783  2593 solver.cpp:310]     Train net output #0: loss = 0.464226 (* 1 = 0.464226 loss)
I1110 23:20:09.112805  2593 sgd_solver.cpp:106] Iteration 1763, lr = 0.0005
I1110 23:20:11.546857  2593 solver.cpp:295] Iteration 1764 (no loss supplied for SingleUpdateStep)
I1110 23:20:11.547040  2593 solver.cpp:310]     Train net output #0: loss = 0.437805 (* 1 = 0.437805 loss)
I1110 23:20:11.547070  2593 sgd_solver.cpp:106] Iteration 1764, lr = 0.0005
I1110 23:20:13.703222  2593 solver.cpp:295] Iteration 1765 (no loss supplied for SingleUpdateStep)
I1110 23:20:13.703344  2593 solver.cpp:310]     Train net output #0: loss = 0.459815 (* 1 = 0.459815 loss)
I1110 23:20:13.703366  2593 sgd_solver.cpp:106] Iteration 1765, lr = 0.0005
I1110 23:20:16.142118  2593 solver.cpp:295] Iteration 1766 (no loss supplied for SingleUpdateStep)
I1110 23:20:16.142181  2593 solver.cpp:310]     Train net output #0: loss = 0.435404 (* 1 = 0.435404 loss)
I1110 23:20:16.142201  2593 sgd_solver.cpp:106] Iteration 1766, lr = 0.0005
I1110 23:20:18.461948  2593 solver.cpp:295] Iteration 1767 (no loss supplied for SingleUpdateStep)
I1110 23:20:18.462116  2593 solver.cpp:310]     Train net output #0: loss = 0.492473 (* 1 = 0.492473 loss)
I1110 23:20:18.462141  2593 sgd_solver.cpp:106] Iteration 1767, lr = 0.0005
I1110 23:20:20.832653  2593 solver.cpp:295] Iteration 1768 (no loss supplied for SingleUpdateStep)
I1110 23:20:20.832844  2593 solver.cpp:310]     Train net output #0: loss = 0.467934 (* 1 = 0.467934 loss)
I1110 23:20:20.832875  2593 sgd_solver.cpp:106] Iteration 1768, lr = 0.0005
I1110 23:20:23.117780  2593 solver.cpp:295] Iteration 1769 (no loss supplied for SingleUpdateStep)
I1110 23:20:23.117992  2593 solver.cpp:310]     Train net output #0: loss = 0.453537 (* 1 = 0.453537 loss)
I1110 23:20:23.118028  2593 sgd_solver.cpp:106] Iteration 1769, lr = 0.0005
I1110 23:20:25.424629  2593 solver.cpp:295] Iteration 1770 (no loss supplied for SingleUpdateStep)
I1110 23:20:25.424813  2593 solver.cpp:310]     Train net output #0: loss = 0.5003 (* 1 = 0.5003 loss)
I1110 23:20:25.424839  2593 sgd_solver.cpp:106] Iteration 1770, lr = 0.0005
I1110 23:20:28.019865  2593 solver.cpp:295] Iteration 1771 (no loss supplied for SingleUpdateStep)
I1110 23:20:28.019960  2593 solver.cpp:310]     Train net output #0: loss = 0.478316 (* 1 = 0.478316 loss)
I1110 23:20:28.019983  2593 sgd_solver.cpp:106] Iteration 1771, lr = 0.0005
I1110 23:20:30.749658  2593 solver.cpp:295] Iteration 1772 (no loss supplied for SingleUpdateStep)
I1110 23:20:30.749774  2593 solver.cpp:310]     Train net output #0: loss = 0.511163 (* 1 = 0.511163 loss)
I1110 23:20:30.749796  2593 sgd_solver.cpp:106] Iteration 1772, lr = 0.0005
I1110 23:20:33.125092  2593 solver.cpp:295] Iteration 1773 (no loss supplied for SingleUpdateStep)
I1110 23:20:33.125237  2593 solver.cpp:310]     Train net output #0: loss = 0.471169 (* 1 = 0.471169 loss)
I1110 23:20:33.125260  2593 sgd_solver.cpp:106] Iteration 1773, lr = 0.0005
I1110 23:20:35.976126  2593 solver.cpp:295] Iteration 1774 (no loss supplied for SingleUpdateStep)
I1110 23:20:35.976227  2593 solver.cpp:310]     Train net output #0: loss = 0.463659 (* 1 = 0.463659 loss)
I1110 23:20:35.976246  2593 sgd_solver.cpp:106] Iteration 1774, lr = 0.0005
I1110 23:20:38.494338  2593 solver.cpp:295] Iteration 1775 (no loss supplied for SingleUpdateStep)
I1110 23:20:38.494426  2593 solver.cpp:310]     Train net output #0: loss = 0.46561 (* 1 = 0.46561 loss)
I1110 23:20:38.494448  2593 sgd_solver.cpp:106] Iteration 1775, lr = 0.0005
I1110 23:20:41.019323  2593 solver.cpp:295] Iteration 1776 (no loss supplied for SingleUpdateStep)
I1110 23:20:41.019398  2593 solver.cpp:310]     Train net output #0: loss = 0.491326 (* 1 = 0.491326 loss)
I1110 23:20:41.019438  2593 sgd_solver.cpp:106] Iteration 1776, lr = 0.0005
I1110 23:20:43.773849  2593 solver.cpp:295] Iteration 1777 (no loss supplied for SingleUpdateStep)
I1110 23:20:43.773962  2593 solver.cpp:310]     Train net output #0: loss = 0.460019 (* 1 = 0.460019 loss)
I1110 23:20:43.773983  2593 sgd_solver.cpp:106] Iteration 1777, lr = 0.0005
I1110 23:20:46.109073  2593 solver.cpp:295] Iteration 1778 (no loss supplied for SingleUpdateStep)
I1110 23:20:46.109192  2593 solver.cpp:310]     Train net output #0: loss = 0.432388 (* 1 = 0.432388 loss)
I1110 23:20:46.109216  2593 sgd_solver.cpp:106] Iteration 1778, lr = 0.0005
I1110 23:20:48.713776  2593 solver.cpp:295] Iteration 1779 (no loss supplied for SingleUpdateStep)
I1110 23:20:48.714014  2593 solver.cpp:310]     Train net output #0: loss = 0.487035 (* 1 = 0.487035 loss)
I1110 23:20:48.714058  2593 sgd_solver.cpp:106] Iteration 1779, lr = 0.0005
I1110 23:20:52.734580  2593 solver.cpp:295] Iteration 1780 (no loss supplied for SingleUpdateStep)
I1110 23:20:52.734714  2593 solver.cpp:310]     Train net output #0: loss = 0.44079 (* 1 = 0.44079 loss)
I1110 23:20:52.734738  2593 sgd_solver.cpp:106] Iteration 1780, lr = 0.0005
I1110 23:20:55.369551  2593 solver.cpp:295] Iteration 1781 (no loss supplied for SingleUpdateStep)
I1110 23:20:55.369606  2593 solver.cpp:310]     Train net output #0: loss = 0.499316 (* 1 = 0.499316 loss)
I1110 23:20:55.369624  2593 sgd_solver.cpp:106] Iteration 1781, lr = 0.0005
I1110 23:20:58.413722  2593 solver.cpp:295] Iteration 1782 (no loss supplied for SingleUpdateStep)
I1110 23:20:58.413831  2593 solver.cpp:310]     Train net output #0: loss = 0.460032 (* 1 = 0.460032 loss)
I1110 23:20:58.413858  2593 sgd_solver.cpp:106] Iteration 1782, lr = 0.0005
I1110 23:21:00.887028  2593 solver.cpp:295] Iteration 1783 (no loss supplied for SingleUpdateStep)
I1110 23:21:00.887151  2593 solver.cpp:310]     Train net output #0: loss = 0.446174 (* 1 = 0.446174 loss)
I1110 23:21:00.887172  2593 sgd_solver.cpp:106] Iteration 1783, lr = 0.0005
I1110 23:21:03.304193  2593 solver.cpp:295] Iteration 1784 (no loss supplied for SingleUpdateStep)
I1110 23:21:03.304246  2593 solver.cpp:310]     Train net output #0: loss = 0.500908 (* 1 = 0.500908 loss)
I1110 23:21:03.304265  2593 sgd_solver.cpp:106] Iteration 1784, lr = 0.0005
I1110 23:21:05.711745  2593 solver.cpp:295] Iteration 1785 (no loss supplied for SingleUpdateStep)
I1110 23:21:05.711807  2593 solver.cpp:310]     Train net output #0: loss = 0.439739 (* 1 = 0.439739 loss)
I1110 23:21:05.711827  2593 sgd_solver.cpp:106] Iteration 1785, lr = 0.0005
I1110 23:21:07.972620  2593 solver.cpp:295] Iteration 1786 (no loss supplied for SingleUpdateStep)
I1110 23:21:07.972676  2593 solver.cpp:310]     Train net output #0: loss = 0.464166 (* 1 = 0.464166 loss)
I1110 23:21:07.972693  2593 sgd_solver.cpp:106] Iteration 1786, lr = 0.0005
I1110 23:21:10.233681  2593 solver.cpp:295] Iteration 1787 (no loss supplied for SingleUpdateStep)
I1110 23:21:10.233732  2593 solver.cpp:310]     Train net output #0: loss = 0.485691 (* 1 = 0.485691 loss)
I1110 23:21:10.233753  2593 sgd_solver.cpp:106] Iteration 1787, lr = 0.0005
I1110 23:21:12.545475  2593 solver.cpp:295] Iteration 1788 (no loss supplied for SingleUpdateStep)
I1110 23:21:12.545567  2593 solver.cpp:310]     Train net output #0: loss = 0.454526 (* 1 = 0.454526 loss)
I1110 23:21:12.545588  2593 sgd_solver.cpp:106] Iteration 1788, lr = 0.0005
I1110 23:21:14.841284  2593 solver.cpp:295] Iteration 1789 (no loss supplied for SingleUpdateStep)
I1110 23:21:14.841501  2593 solver.cpp:310]     Train net output #0: loss = 0.480258 (* 1 = 0.480258 loss)
I1110 23:21:14.841552  2593 sgd_solver.cpp:106] Iteration 1789, lr = 0.0005
I1110 23:21:17.021926  2593 solver.cpp:295] Iteration 1790 (no loss supplied for SingleUpdateStep)
I1110 23:21:17.021991  2593 solver.cpp:310]     Train net output #0: loss = 0.445271 (* 1 = 0.445271 loss)
I1110 23:21:17.022009  2593 sgd_solver.cpp:106] Iteration 1790, lr = 0.0005
I1110 23:21:19.277962  2593 solver.cpp:295] Iteration 1791 (no loss supplied for SingleUpdateStep)
I1110 23:21:19.278089  2593 solver.cpp:310]     Train net output #0: loss = 0.474836 (* 1 = 0.474836 loss)
I1110 23:21:19.278112  2593 sgd_solver.cpp:106] Iteration 1791, lr = 0.0005
I1110 23:21:21.850270  2593 solver.cpp:295] Iteration 1792 (no loss supplied for SingleUpdateStep)
I1110 23:21:21.850376  2593 solver.cpp:310]     Train net output #0: loss = 0.482922 (* 1 = 0.482922 loss)
I1110 23:21:21.850399  2593 sgd_solver.cpp:106] Iteration 1792, lr = 0.0005
I1110 23:21:24.272862  2593 solver.cpp:295] Iteration 1793 (no loss supplied for SingleUpdateStep)
I1110 23:21:24.272927  2593 solver.cpp:310]     Train net output #0: loss = 0.471724 (* 1 = 0.471724 loss)
I1110 23:21:24.272945  2593 sgd_solver.cpp:106] Iteration 1793, lr = 0.0005
I1110 23:21:26.678803  2593 solver.cpp:295] Iteration 1794 (no loss supplied for SingleUpdateStep)
I1110 23:21:26.678930  2593 solver.cpp:310]     Train net output #0: loss = 0.44001 (* 1 = 0.44001 loss)
I1110 23:21:26.678951  2593 sgd_solver.cpp:106] Iteration 1794, lr = 0.0005
I1110 23:21:29.286571  2593 solver.cpp:295] Iteration 1795 (no loss supplied for SingleUpdateStep)
I1110 23:21:29.286692  2593 solver.cpp:310]     Train net output #0: loss = 0.450072 (* 1 = 0.450072 loss)
I1110 23:21:29.286717  2593 sgd_solver.cpp:106] Iteration 1795, lr = 0.0005
I1110 23:21:32.031771  2593 solver.cpp:295] Iteration 1796 (no loss supplied for SingleUpdateStep)
I1110 23:21:32.031880  2593 solver.cpp:310]     Train net output #0: loss = 0.456722 (* 1 = 0.456722 loss)
I1110 23:21:32.031903  2593 sgd_solver.cpp:106] Iteration 1796, lr = 0.0005
I1110 23:21:34.984237  2593 solver.cpp:295] Iteration 1797 (no loss supplied for SingleUpdateStep)
I1110 23:21:34.984351  2593 solver.cpp:310]     Train net output #0: loss = 0.443484 (* 1 = 0.443484 loss)
I1110 23:21:34.984375  2593 sgd_solver.cpp:106] Iteration 1797, lr = 0.0005
I1110 23:21:37.379189  2593 solver.cpp:295] Iteration 1798 (no loss supplied for SingleUpdateStep)
I1110 23:21:37.379315  2593 solver.cpp:310]     Train net output #0: loss = 0.484553 (* 1 = 0.484553 loss)
I1110 23:21:37.379343  2593 sgd_solver.cpp:106] Iteration 1798, lr = 0.0005
I1110 23:21:39.810240  2593 solver.cpp:295] Iteration 1799 (no loss supplied for SingleUpdateStep)
I1110 23:21:39.810354  2593 solver.cpp:310]     Train net output #0: loss = 0.439968 (* 1 = 0.439968 loss)
I1110 23:21:39.810377  2593 sgd_solver.cpp:106] Iteration 1799, lr = 0.0005
I1110 23:21:42.417701  2593 solver.cpp:295] Iteration 1800 (no loss supplied for SingleUpdateStep)
I1110 23:21:42.417786  2593 solver.cpp:310]     Train net output #0: loss = 0.426585 (* 1 = 0.426585 loss)
I1110 23:21:42.417807  2593 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I1110 23:21:44.694605  2593 solver.cpp:295] Iteration 1801 (no loss supplied for SingleUpdateStep)
I1110 23:21:44.694835  2593 solver.cpp:310]     Train net output #0: loss = 0.493245 (* 1 = 0.493245 loss)
I1110 23:21:44.694883  2593 sgd_solver.cpp:106] Iteration 1801, lr = 0.0005
I1110 23:21:47.118046  2593 solver.cpp:295] Iteration 1802 (no loss supplied for SingleUpdateStep)
I1110 23:21:47.118167  2593 solver.cpp:310]     Train net output #0: loss = 0.487134 (* 1 = 0.487134 loss)
I1110 23:21:47.118193  2593 sgd_solver.cpp:106] Iteration 1802, lr = 0.0005
I1110 23:21:49.390655  2593 solver.cpp:295] Iteration 1803 (no loss supplied for SingleUpdateStep)
I1110 23:21:49.390776  2593 solver.cpp:310]     Train net output #0: loss = 0.46128 (* 1 = 0.46128 loss)
I1110 23:21:49.390800  2593 sgd_solver.cpp:106] Iteration 1803, lr = 0.0005
I1110 23:21:51.715656  2593 solver.cpp:295] Iteration 1804 (no loss supplied for SingleUpdateStep)
I1110 23:21:51.715714  2593 solver.cpp:310]     Train net output #0: loss = 0.483844 (* 1 = 0.483844 loss)
I1110 23:21:51.715734  2593 sgd_solver.cpp:106] Iteration 1804, lr = 0.0005
I1110 23:21:54.132207  2593 solver.cpp:295] Iteration 1805 (no loss supplied for SingleUpdateStep)
I1110 23:21:54.132319  2593 solver.cpp:310]     Train net output #0: loss = 0.445087 (* 1 = 0.445087 loss)
I1110 23:21:54.132344  2593 sgd_solver.cpp:106] Iteration 1805, lr = 0.0005
I1110 23:21:56.540690  2593 solver.cpp:295] Iteration 1806 (no loss supplied for SingleUpdateStep)
I1110 23:21:56.540786  2593 solver.cpp:310]     Train net output #0: loss = 0.438169 (* 1 = 0.438169 loss)
I1110 23:21:56.540808  2593 sgd_solver.cpp:106] Iteration 1806, lr = 0.0005
I1110 23:21:59.050537  2593 solver.cpp:295] Iteration 1807 (no loss supplied for SingleUpdateStep)
I1110 23:21:59.050622  2593 solver.cpp:310]     Train net output #0: loss = 0.448834 (* 1 = 0.448834 loss)
I1110 23:21:59.050642  2593 sgd_solver.cpp:106] Iteration 1807, lr = 0.0005
I1110 23:22:01.461670  2593 solver.cpp:295] Iteration 1808 (no loss supplied for SingleUpdateStep)
I1110 23:22:01.461748  2593 solver.cpp:310]     Train net output #0: loss = 0.48817 (* 1 = 0.48817 loss)
I1110 23:22:01.461769  2593 sgd_solver.cpp:106] Iteration 1808, lr = 0.0005
I1110 23:22:03.714612  2593 solver.cpp:295] Iteration 1809 (no loss supplied for SingleUpdateStep)
I1110 23:22:03.714715  2593 solver.cpp:310]     Train net output #0: loss = 0.472934 (* 1 = 0.472934 loss)
I1110 23:22:03.714736  2593 sgd_solver.cpp:106] Iteration 1809, lr = 0.0005
I1110 23:22:06.142848  2593 solver.cpp:295] Iteration 1810 (no loss supplied for SingleUpdateStep)
I1110 23:22:06.142981  2593 solver.cpp:310]     Train net output #0: loss = 0.481338 (* 1 = 0.481338 loss)
I1110 23:22:06.143007  2593 sgd_solver.cpp:106] Iteration 1810, lr = 0.0005
I1110 23:22:08.796895  2593 solver.cpp:295] Iteration 1811 (no loss supplied for SingleUpdateStep)
I1110 23:22:08.797003  2593 solver.cpp:310]     Train net output #0: loss = 0.469543 (* 1 = 0.469543 loss)
I1110 23:22:08.797026  2593 sgd_solver.cpp:106] Iteration 1811, lr = 0.0005
I1110 23:22:11.266746  2593 solver.cpp:295] Iteration 1812 (no loss supplied for SingleUpdateStep)
I1110 23:22:11.266855  2593 solver.cpp:310]     Train net output #0: loss = 0.489792 (* 1 = 0.489792 loss)
I1110 23:22:11.266877  2593 sgd_solver.cpp:106] Iteration 1812, lr = 0.0005
I1110 23:22:13.872187  2593 solver.cpp:295] Iteration 1813 (no loss supplied for SingleUpdateStep)
I1110 23:22:13.872242  2593 solver.cpp:310]     Train net output #0: loss = 0.439232 (* 1 = 0.439232 loss)
I1110 23:22:13.872262  2593 sgd_solver.cpp:106] Iteration 1813, lr = 0.0005
I1110 23:22:16.260706  2593 solver.cpp:295] Iteration 1814 (no loss supplied for SingleUpdateStep)
I1110 23:22:16.260809  2593 solver.cpp:310]     Train net output #0: loss = 0.427168 (* 1 = 0.427168 loss)
I1110 23:22:16.260833  2593 sgd_solver.cpp:106] Iteration 1814, lr = 0.0005
I1110 23:22:18.797962  2593 solver.cpp:295] Iteration 1815 (no loss supplied for SingleUpdateStep)
I1110 23:22:18.798040  2593 solver.cpp:310]     Train net output #0: loss = 0.454522 (* 1 = 0.454522 loss)
I1110 23:22:18.798060  2593 sgd_solver.cpp:106] Iteration 1815, lr = 0.0005
I1110 23:22:22.049087  2593 solver.cpp:295] Iteration 1816 (no loss supplied for SingleUpdateStep)
I1110 23:22:22.049193  2593 solver.cpp:310]     Train net output #0: loss = 0.492063 (* 1 = 0.492063 loss)
I1110 23:22:22.049213  2593 sgd_solver.cpp:106] Iteration 1816, lr = 0.0005
I1110 23:22:24.844949  2593 solver.cpp:295] Iteration 1817 (no loss supplied for SingleUpdateStep)
I1110 23:22:24.845060  2593 solver.cpp:310]     Train net output #0: loss = 0.413939 (* 1 = 0.413939 loss)
I1110 23:22:24.845088  2593 sgd_solver.cpp:106] Iteration 1817, lr = 0.0005
I1110 23:22:27.329504  2593 solver.cpp:295] Iteration 1818 (no loss supplied for SingleUpdateStep)
I1110 23:22:27.329582  2593 solver.cpp:310]     Train net output #0: loss = 0.467077 (* 1 = 0.467077 loss)
I1110 23:22:27.329602  2593 sgd_solver.cpp:106] Iteration 1818, lr = 0.0005
I1110 23:22:29.858530  2593 solver.cpp:295] Iteration 1819 (no loss supplied for SingleUpdateStep)
I1110 23:22:29.858706  2593 solver.cpp:310]     Train net output #0: loss = 0.439861 (* 1 = 0.439861 loss)
I1110 23:22:29.858734  2593 sgd_solver.cpp:106] Iteration 1819, lr = 0.0005
I1110 23:22:32.173864  2593 solver.cpp:295] Iteration 1820 (no loss supplied for SingleUpdateStep)
I1110 23:22:32.173956  2593 solver.cpp:310]     Train net output #0: loss = 0.4734 (* 1 = 0.4734 loss)
I1110 23:22:32.173977  2593 sgd_solver.cpp:106] Iteration 1820, lr = 0.0005
I1110 23:22:34.499197  2593 solver.cpp:295] Iteration 1821 (no loss supplied for SingleUpdateStep)
I1110 23:22:34.499311  2593 solver.cpp:310]     Train net output #0: loss = 0.443966 (* 1 = 0.443966 loss)
I1110 23:22:34.499336  2593 sgd_solver.cpp:106] Iteration 1821, lr = 0.0005
I1110 23:22:36.820559  2593 solver.cpp:295] Iteration 1822 (no loss supplied for SingleUpdateStep)
I1110 23:22:36.820696  2593 solver.cpp:310]     Train net output #0: loss = 0.473798 (* 1 = 0.473798 loss)
I1110 23:22:36.820719  2593 sgd_solver.cpp:106] Iteration 1822, lr = 0.0005
I1110 23:22:39.251909  2593 solver.cpp:295] Iteration 1823 (no loss supplied for SingleUpdateStep)
I1110 23:22:39.251981  2593 solver.cpp:310]     Train net output #0: loss = 0.441357 (* 1 = 0.441357 loss)
I1110 23:22:39.252002  2593 sgd_solver.cpp:106] Iteration 1823, lr = 0.0005
I1110 23:22:41.622010  2593 solver.cpp:295] Iteration 1824 (no loss supplied for SingleUpdateStep)
I1110 23:22:41.622074  2593 solver.cpp:310]     Train net output #0: loss = 0.440744 (* 1 = 0.440744 loss)
I1110 23:22:41.622094  2593 sgd_solver.cpp:106] Iteration 1824, lr = 0.0005
I1110 23:22:43.924906  2593 solver.cpp:295] Iteration 1825 (no loss supplied for SingleUpdateStep)
I1110 23:22:43.925014  2593 solver.cpp:310]     Train net output #0: loss = 0.467877 (* 1 = 0.467877 loss)
I1110 23:22:43.925040  2593 sgd_solver.cpp:106] Iteration 1825, lr = 0.0005
I1110 23:22:46.447880  2593 solver.cpp:295] Iteration 1826 (no loss supplied for SingleUpdateStep)
I1110 23:22:46.447986  2593 solver.cpp:310]     Train net output #0: loss = 0.429715 (* 1 = 0.429715 loss)
I1110 23:22:46.448009  2593 sgd_solver.cpp:106] Iteration 1826, lr = 0.0005
I1110 23:22:49.475466  2593 solver.cpp:295] Iteration 1827 (no loss supplied for SingleUpdateStep)
I1110 23:22:49.475647  2593 solver.cpp:310]     Train net output #0: loss = 0.466355 (* 1 = 0.466355 loss)
I1110 23:22:49.475677  2593 sgd_solver.cpp:106] Iteration 1827, lr = 0.0005
I1110 23:22:52.132586  2593 solver.cpp:295] Iteration 1828 (no loss supplied for SingleUpdateStep)
I1110 23:22:52.132675  2593 solver.cpp:310]     Train net output #0: loss = 0.452327 (* 1 = 0.452327 loss)
I1110 23:22:52.132696  2593 sgd_solver.cpp:106] Iteration 1828, lr = 0.0005
I1110 23:22:55.108945  2593 solver.cpp:295] Iteration 1829 (no loss supplied for SingleUpdateStep)
I1110 23:22:55.109050  2593 solver.cpp:310]     Train net output #0: loss = 0.452239 (* 1 = 0.452239 loss)
I1110 23:22:55.109074  2593 sgd_solver.cpp:106] Iteration 1829, lr = 0.0005
I1110 23:22:58.868352  2593 solver.cpp:295] Iteration 1830 (no loss supplied for SingleUpdateStep)
I1110 23:22:58.868449  2593 solver.cpp:310]     Train net output #0: loss = 0.473441 (* 1 = 0.473441 loss)
I1110 23:22:58.868486  2593 sgd_solver.cpp:106] Iteration 1830, lr = 0.0005
I1110 23:23:02.534277  2593 solver.cpp:295] Iteration 1831 (no loss supplied for SingleUpdateStep)
I1110 23:23:02.534368  2593 solver.cpp:310]     Train net output #0: loss = 0.456862 (* 1 = 0.456862 loss)
I1110 23:23:02.534389  2593 sgd_solver.cpp:106] Iteration 1831, lr = 0.0005
I1110 23:23:06.532044  2593 solver.cpp:295] Iteration 1832 (no loss supplied for SingleUpdateStep)
I1110 23:23:06.532130  2593 solver.cpp:310]     Train net output #0: loss = 0.463641 (* 1 = 0.463641 loss)
I1110 23:23:06.532150  2593 sgd_solver.cpp:106] Iteration 1832, lr = 0.0005
I1110 23:23:09.539741  2593 solver.cpp:295] Iteration 1833 (no loss supplied for SingleUpdateStep)
I1110 23:23:09.539858  2593 solver.cpp:310]     Train net output #0: loss = 0.447493 (* 1 = 0.447493 loss)
I1110 23:23:09.539880  2593 sgd_solver.cpp:106] Iteration 1833, lr = 0.0005
I1110 23:23:12.276576  2593 solver.cpp:295] Iteration 1834 (no loss supplied for SingleUpdateStep)
I1110 23:23:12.276711  2593 solver.cpp:310]     Train net output #0: loss = 0.464255 (* 1 = 0.464255 loss)
I1110 23:23:12.276734  2593 sgd_solver.cpp:106] Iteration 1834, lr = 0.0005
I1110 23:23:14.962559  2593 solver.cpp:295] Iteration 1835 (no loss supplied for SingleUpdateStep)
I1110 23:23:14.962661  2593 solver.cpp:310]     Train net output #0: loss = 0.471299 (* 1 = 0.471299 loss)
I1110 23:23:14.962685  2593 sgd_solver.cpp:106] Iteration 1835, lr = 0.0005
I1110 23:23:17.664254  2593 solver.cpp:295] Iteration 1836 (no loss supplied for SingleUpdateStep)
I1110 23:23:17.664417  2593 solver.cpp:310]     Train net output #0: loss = 0.451063 (* 1 = 0.451063 loss)
I1110 23:23:17.664443  2593 sgd_solver.cpp:106] Iteration 1836, lr = 0.0005
I1110 23:23:20.649478  2593 solver.cpp:295] Iteration 1837 (no loss supplied for SingleUpdateStep)
I1110 23:23:20.649595  2593 solver.cpp:310]     Train net output #0: loss = 0.461495 (* 1 = 0.461495 loss)
I1110 23:23:20.649618  2593 sgd_solver.cpp:106] Iteration 1837, lr = 0.0005
I1110 23:23:23.444641  2593 solver.cpp:295] Iteration 1838 (no loss supplied for SingleUpdateStep)
I1110 23:23:23.444768  2593 solver.cpp:310]     Train net output #0: loss = 0.464575 (* 1 = 0.464575 loss)
I1110 23:23:23.444794  2593 sgd_solver.cpp:106] Iteration 1838, lr = 0.0005
I1110 23:23:26.717620  2593 solver.cpp:295] Iteration 1839 (no loss supplied for SingleUpdateStep)
I1110 23:23:26.717679  2593 solver.cpp:310]     Train net output #0: loss = 0.443407 (* 1 = 0.443407 loss)
I1110 23:23:26.717700  2593 sgd_solver.cpp:106] Iteration 1839, lr = 0.0005
I1110 23:23:29.223500  2593 solver.cpp:295] Iteration 1840 (no loss supplied for SingleUpdateStep)
I1110 23:23:29.223690  2593 solver.cpp:310]     Train net output #0: loss = 0.474519 (* 1 = 0.474519 loss)
I1110 23:23:29.223717  2593 sgd_solver.cpp:106] Iteration 1840, lr = 0.0005
I1110 23:23:31.587203  2593 solver.cpp:295] Iteration 1841 (no loss supplied for SingleUpdateStep)
I1110 23:23:31.587317  2593 solver.cpp:310]     Train net output #0: loss = 0.445509 (* 1 = 0.445509 loss)
I1110 23:23:31.587342  2593 sgd_solver.cpp:106] Iteration 1841, lr = 0.0005
I1110 23:23:34.046998  2593 solver.cpp:295] Iteration 1842 (no loss supplied for SingleUpdateStep)
I1110 23:23:34.047116  2593 solver.cpp:310]     Train net output #0: loss = 0.450389 (* 1 = 0.450389 loss)
I1110 23:23:34.047142  2593 sgd_solver.cpp:106] Iteration 1842, lr = 0.0005
I1110 23:23:36.525085  2593 solver.cpp:295] Iteration 1843 (no loss supplied for SingleUpdateStep)
I1110 23:23:36.525187  2593 solver.cpp:310]     Train net output #0: loss = 0.458081 (* 1 = 0.458081 loss)
I1110 23:23:36.525209  2593 sgd_solver.cpp:106] Iteration 1843, lr = 0.0005
I1110 23:23:39.381146  2593 solver.cpp:295] Iteration 1844 (no loss supplied for SingleUpdateStep)
I1110 23:23:39.381258  2593 solver.cpp:310]     Train net output #0: loss = 0.456061 (* 1 = 0.456061 loss)
I1110 23:23:39.381283  2593 sgd_solver.cpp:106] Iteration 1844, lr = 0.0005
I1110 23:23:42.323711  2593 solver.cpp:295] Iteration 1845 (no loss supplied for SingleUpdateStep)
I1110 23:23:42.323777  2593 solver.cpp:310]     Train net output #0: loss = 0.466398 (* 1 = 0.466398 loss)
I1110 23:23:42.323798  2593 sgd_solver.cpp:106] Iteration 1845, lr = 0.0005
I1110 23:23:45.306952  2593 solver.cpp:295] Iteration 1846 (no loss supplied for SingleUpdateStep)
I1110 23:23:45.307049  2593 solver.cpp:310]     Train net output #0: loss = 0.444913 (* 1 = 0.444913 loss)
I1110 23:23:45.307071  2593 sgd_solver.cpp:106] Iteration 1846, lr = 0.0005
I1110 23:23:48.044637  2593 solver.cpp:295] Iteration 1847 (no loss supplied for SingleUpdateStep)
I1110 23:23:48.044723  2593 solver.cpp:310]     Train net output #0: loss = 0.427789 (* 1 = 0.427789 loss)
I1110 23:23:48.044744  2593 sgd_solver.cpp:106] Iteration 1847, lr = 0.0005
I1110 23:23:50.433367  2593 solver.cpp:295] Iteration 1848 (no loss supplied for SingleUpdateStep)
I1110 23:23:50.433435  2593 solver.cpp:310]     Train net output #0: loss = 0.464345 (* 1 = 0.464345 loss)
I1110 23:23:50.433455  2593 sgd_solver.cpp:106] Iteration 1848, lr = 0.0005
I1110 23:23:52.969677  2593 solver.cpp:295] Iteration 1849 (no loss supplied for SingleUpdateStep)
I1110 23:23:52.969733  2593 solver.cpp:310]     Train net output #0: loss = 0.491123 (* 1 = 0.491123 loss)
I1110 23:23:52.969753  2593 sgd_solver.cpp:106] Iteration 1849, lr = 0.0005
I1110 23:23:56.062927  2593 solver.cpp:295] Iteration 1850 (no loss supplied for SingleUpdateStep)
I1110 23:23:56.063079  2593 solver.cpp:310]     Train net output #0: loss = 0.471765 (* 1 = 0.471765 loss)
I1110 23:23:56.063105  2593 sgd_solver.cpp:106] Iteration 1850, lr = 0.0005
I1110 23:23:58.559218  2593 solver.cpp:295] Iteration 1851 (no loss supplied for SingleUpdateStep)
I1110 23:23:58.559310  2593 solver.cpp:310]     Train net output #0: loss = 0.453035 (* 1 = 0.453035 loss)
I1110 23:23:58.559334  2593 sgd_solver.cpp:106] Iteration 1851, lr = 0.0005
I1110 23:24:01.536088  2593 solver.cpp:295] Iteration 1852 (no loss supplied for SingleUpdateStep)
I1110 23:24:01.536202  2593 solver.cpp:310]     Train net output #0: loss = 0.429261 (* 1 = 0.429261 loss)
I1110 23:24:01.536224  2593 sgd_solver.cpp:106] Iteration 1852, lr = 0.0005
I1110 23:24:04.814071  2593 solver.cpp:295] Iteration 1853 (no loss supplied for SingleUpdateStep)
I1110 23:24:04.814187  2593 solver.cpp:310]     Train net output #0: loss = 0.453642 (* 1 = 0.453642 loss)
I1110 23:24:04.814210  2593 sgd_solver.cpp:106] Iteration 1853, lr = 0.0005
I1110 23:24:08.207650  2593 solver.cpp:295] Iteration 1854 (no loss supplied for SingleUpdateStep)
I1110 23:24:08.207787  2593 solver.cpp:310]     Train net output #0: loss = 0.478617 (* 1 = 0.478617 loss)
I1110 23:24:08.207813  2593 sgd_solver.cpp:106] Iteration 1854, lr = 0.0005
I1110 23:24:10.883725  2593 solver.cpp:295] Iteration 1855 (no loss supplied for SingleUpdateStep)
I1110 23:24:10.883865  2593 solver.cpp:310]     Train net output #0: loss = 0.457568 (* 1 = 0.457568 loss)
I1110 23:24:10.883891  2593 sgd_solver.cpp:106] Iteration 1855, lr = 0.0005
I1110 23:24:13.374547  2593 solver.cpp:295] Iteration 1856 (no loss supplied for SingleUpdateStep)
I1110 23:24:13.374645  2593 solver.cpp:310]     Train net output #0: loss = 0.444686 (* 1 = 0.444686 loss)
I1110 23:24:13.374666  2593 sgd_solver.cpp:106] Iteration 1856, lr = 0.0005
I1110 23:24:15.505091  2593 solver.cpp:295] Iteration 1857 (no loss supplied for SingleUpdateStep)
I1110 23:24:15.505249  2593 solver.cpp:310]     Train net output #0: loss = 0.454291 (* 1 = 0.454291 loss)
I1110 23:24:15.505280  2593 sgd_solver.cpp:106] Iteration 1857, lr = 0.0005
I1110 23:24:17.723543  2593 solver.cpp:295] Iteration 1858 (no loss supplied for SingleUpdateStep)
I1110 23:24:17.723690  2593 solver.cpp:310]     Train net output #0: loss = 0.490922 (* 1 = 0.490922 loss)
I1110 23:24:17.723719  2593 sgd_solver.cpp:106] Iteration 1858, lr = 0.0005
I1110 23:24:20.096998  2593 solver.cpp:295] Iteration 1859 (no loss supplied for SingleUpdateStep)
I1110 23:24:20.097093  2593 solver.cpp:310]     Train net output #0: loss = 0.471622 (* 1 = 0.471622 loss)
I1110 23:24:20.097125  2593 sgd_solver.cpp:106] Iteration 1859, lr = 0.0005
I1110 23:24:22.395741  2593 solver.cpp:295] Iteration 1860 (no loss supplied for SingleUpdateStep)
I1110 23:24:22.395855  2593 solver.cpp:310]     Train net output #0: loss = 0.436532 (* 1 = 0.436532 loss)
I1110 23:24:22.395881  2593 sgd_solver.cpp:106] Iteration 1860, lr = 0.0005
I1110 23:24:24.604068  2593 solver.cpp:295] Iteration 1861 (no loss supplied for SingleUpdateStep)
I1110 23:24:24.604138  2593 solver.cpp:310]     Train net output #0: loss = 0.426434 (* 1 = 0.426434 loss)
I1110 23:24:24.604159  2593 sgd_solver.cpp:106] Iteration 1861, lr = 0.0005
I1110 23:24:27.073269  2593 solver.cpp:295] Iteration 1862 (no loss supplied for SingleUpdateStep)
I1110 23:24:27.073348  2593 solver.cpp:310]     Train net output #0: loss = 0.432147 (* 1 = 0.432147 loss)
I1110 23:24:27.073369  2593 sgd_solver.cpp:106] Iteration 1862, lr = 0.0005
I1110 23:24:29.463763  2593 solver.cpp:295] Iteration 1863 (no loss supplied for SingleUpdateStep)
I1110 23:24:29.463897  2593 solver.cpp:310]     Train net output #0: loss = 0.488619 (* 1 = 0.488619 loss)
I1110 23:24:29.463923  2593 sgd_solver.cpp:106] Iteration 1863, lr = 0.0005
I1110 23:24:31.869071  2593 solver.cpp:295] Iteration 1864 (no loss supplied for SingleUpdateStep)
I1110 23:24:31.869127  2593 solver.cpp:310]     Train net output #0: loss = 0.459866 (* 1 = 0.459866 loss)
I1110 23:24:31.869145  2593 sgd_solver.cpp:106] Iteration 1864, lr = 0.0005
I1110 23:24:34.269109  2593 solver.cpp:295] Iteration 1865 (no loss supplied for SingleUpdateStep)
I1110 23:24:34.269181  2593 solver.cpp:310]     Train net output #0: loss = 0.410629 (* 1 = 0.410629 loss)
I1110 23:24:34.269203  2593 sgd_solver.cpp:106] Iteration 1865, lr = 0.0005
I1110 23:24:36.608008  2593 solver.cpp:295] Iteration 1866 (no loss supplied for SingleUpdateStep)
I1110 23:24:36.608139  2593 solver.cpp:310]     Train net output #0: loss = 0.440921 (* 1 = 0.440921 loss)
I1110 23:24:36.608161  2593 sgd_solver.cpp:106] Iteration 1866, lr = 0.0005
I1110 23:24:38.902895  2593 solver.cpp:295] Iteration 1867 (no loss supplied for SingleUpdateStep)
I1110 23:24:38.903045  2593 solver.cpp:310]     Train net output #0: loss = 0.427896 (* 1 = 0.427896 loss)
I1110 23:24:38.903084  2593 sgd_solver.cpp:106] Iteration 1867, lr = 0.0005
I1110 23:24:41.110975  2593 solver.cpp:295] Iteration 1868 (no loss supplied for SingleUpdateStep)
I1110 23:24:41.111088  2593 solver.cpp:310]     Train net output #0: loss = 0.437034 (* 1 = 0.437034 loss)
I1110 23:24:41.111110  2593 sgd_solver.cpp:106] Iteration 1868, lr = 0.0005
I1110 23:24:43.314625  2593 solver.cpp:295] Iteration 1869 (no loss supplied for SingleUpdateStep)
I1110 23:24:43.314752  2593 solver.cpp:310]     Train net output #0: loss = 0.442156 (* 1 = 0.442156 loss)
I1110 23:24:43.314777  2593 sgd_solver.cpp:106] Iteration 1869, lr = 0.0005
I1110 23:24:45.499042  2593 solver.cpp:295] Iteration 1870 (no loss supplied for SingleUpdateStep)
I1110 23:24:45.499147  2593 solver.cpp:310]     Train net output #0: loss = 0.462782 (* 1 = 0.462782 loss)
I1110 23:24:45.499168  2593 sgd_solver.cpp:106] Iteration 1870, lr = 0.0005
I1110 23:24:47.712460  2593 solver.cpp:295] Iteration 1871 (no loss supplied for SingleUpdateStep)
I1110 23:24:47.712582  2593 solver.cpp:310]     Train net output #0: loss = 0.44648 (* 1 = 0.44648 loss)
I1110 23:24:47.712604  2593 sgd_solver.cpp:106] Iteration 1871, lr = 0.0005
I1110 23:24:49.896515  2593 solver.cpp:295] Iteration 1872 (no loss supplied for SingleUpdateStep)
I1110 23:24:49.896620  2593 solver.cpp:310]     Train net output #0: loss = 0.424277 (* 1 = 0.424277 loss)
I1110 23:24:49.896642  2593 sgd_solver.cpp:106] Iteration 1872, lr = 0.0005
I1110 23:24:52.297091  2593 solver.cpp:295] Iteration 1873 (no loss supplied for SingleUpdateStep)
I1110 23:24:52.297160  2593 solver.cpp:310]     Train net output #0: loss = 0.475161 (* 1 = 0.475161 loss)
I1110 23:24:52.297181  2593 sgd_solver.cpp:106] Iteration 1873, lr = 0.0005
I1110 23:24:54.507133  2593 solver.cpp:295] Iteration 1874 (no loss supplied for SingleUpdateStep)
I1110 23:24:54.507251  2593 solver.cpp:310]     Train net output #0: loss = 0.44039 (* 1 = 0.44039 loss)
I1110 23:24:54.507279  2593 sgd_solver.cpp:106] Iteration 1874, lr = 0.0005
I1110 23:24:56.740164  2593 solver.cpp:295] Iteration 1875 (no loss supplied for SingleUpdateStep)
I1110 23:24:56.740242  2593 solver.cpp:310]     Train net output #0: loss = 0.425313 (* 1 = 0.425313 loss)
I1110 23:24:56.740262  2593 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I1110 23:24:59.083765  2593 solver.cpp:295] Iteration 1876 (no loss supplied for SingleUpdateStep)
I1110 23:24:59.083905  2593 solver.cpp:310]     Train net output #0: loss = 0.450581 (* 1 = 0.450581 loss)
I1110 23:24:59.083933  2593 sgd_solver.cpp:106] Iteration 1876, lr = 0.0005
I1110 23:25:01.446406  2593 solver.cpp:295] Iteration 1877 (no loss supplied for SingleUpdateStep)
I1110 23:25:01.446497  2593 solver.cpp:310]     Train net output #0: loss = 0.472743 (* 1 = 0.472743 loss)
I1110 23:25:01.446518  2593 sgd_solver.cpp:106] Iteration 1877, lr = 0.0005
I1110 23:25:03.683120  2593 solver.cpp:295] Iteration 1878 (no loss supplied for SingleUpdateStep)
I1110 23:25:03.683233  2593 solver.cpp:310]     Train net output #0: loss = 0.471186 (* 1 = 0.471186 loss)
I1110 23:25:03.683257  2593 sgd_solver.cpp:106] Iteration 1878, lr = 0.0005
I1110 23:25:06.249856  2593 solver.cpp:295] Iteration 1879 (no loss supplied for SingleUpdateStep)
I1110 23:25:06.249999  2593 solver.cpp:310]     Train net output #0: loss = 0.442023 (* 1 = 0.442023 loss)
I1110 23:25:06.250022  2593 sgd_solver.cpp:106] Iteration 1879, lr = 0.0005
I1110 23:25:08.619580  2593 solver.cpp:295] Iteration 1880 (no loss supplied for SingleUpdateStep)
I1110 23:25:08.619668  2593 solver.cpp:310]     Train net output #0: loss = 0.415438 (* 1 = 0.415438 loss)
I1110 23:25:08.619690  2593 sgd_solver.cpp:106] Iteration 1880, lr = 0.0005
I1110 23:25:11.012856  2593 solver.cpp:295] Iteration 1881 (no loss supplied for SingleUpdateStep)
I1110 23:25:11.012909  2593 solver.cpp:310]     Train net output #0: loss = 0.50294 (* 1 = 0.50294 loss)
I1110 23:25:11.012928  2593 sgd_solver.cpp:106] Iteration 1881, lr = 0.0005
I1110 23:25:13.194213  2593 solver.cpp:295] Iteration 1882 (no loss supplied for SingleUpdateStep)
I1110 23:25:13.194295  2593 solver.cpp:310]     Train net output #0: loss = 0.430814 (* 1 = 0.430814 loss)
I1110 23:25:13.194315  2593 sgd_solver.cpp:106] Iteration 1882, lr = 0.0005
I1110 23:25:15.681845  2593 solver.cpp:295] Iteration 1883 (no loss supplied for SingleUpdateStep)
I1110 23:25:15.681910  2593 solver.cpp:310]     Train net output #0: loss = 0.46666 (* 1 = 0.46666 loss)
I1110 23:25:15.681929  2593 sgd_solver.cpp:106] Iteration 1883, lr = 0.0005
I1110 23:25:17.988240  2593 solver.cpp:295] Iteration 1884 (no loss supplied for SingleUpdateStep)
I1110 23:25:17.988348  2593 solver.cpp:310]     Train net output #0: loss = 0.457642 (* 1 = 0.457642 loss)
I1110 23:25:17.988373  2593 sgd_solver.cpp:106] Iteration 1884, lr = 0.0005
I1110 23:25:20.104903  2593 solver.cpp:295] Iteration 1885 (no loss supplied for SingleUpdateStep)
I1110 23:25:20.105005  2593 solver.cpp:310]     Train net output #0: loss = 0.448775 (* 1 = 0.448775 loss)
I1110 23:25:20.105031  2593 sgd_solver.cpp:106] Iteration 1885, lr = 0.0005
I1110 23:25:22.458904  2593 solver.cpp:295] Iteration 1886 (no loss supplied for SingleUpdateStep)
I1110 23:25:22.459069  2593 solver.cpp:310]     Train net output #0: loss = 0.440274 (* 1 = 0.440274 loss)
I1110 23:25:22.459096  2593 sgd_solver.cpp:106] Iteration 1886, lr = 0.0005
I1110 23:25:24.802865  2593 solver.cpp:295] Iteration 1887 (no loss supplied for SingleUpdateStep)
I1110 23:25:24.802973  2593 solver.cpp:310]     Train net output #0: loss = 0.466273 (* 1 = 0.466273 loss)
I1110 23:25:24.802999  2593 sgd_solver.cpp:106] Iteration 1887, lr = 0.0005
I1110 23:25:27.057682  2593 solver.cpp:295] Iteration 1888 (no loss supplied for SingleUpdateStep)
I1110 23:25:27.057778  2593 solver.cpp:310]     Train net output #0: loss = 0.444685 (* 1 = 0.444685 loss)
I1110 23:25:27.057801  2593 sgd_solver.cpp:106] Iteration 1888, lr = 0.0005
I1110 23:25:29.334470  2593 solver.cpp:295] Iteration 1889 (no loss supplied for SingleUpdateStep)
I1110 23:25:29.334650  2593 solver.cpp:310]     Train net output #0: loss = 0.477893 (* 1 = 0.477893 loss)
I1110 23:25:29.334676  2593 sgd_solver.cpp:106] Iteration 1889, lr = 0.0005
I1110 23:25:31.571157  2593 solver.cpp:295] Iteration 1890 (no loss supplied for SingleUpdateStep)
I1110 23:25:31.571269  2593 solver.cpp:310]     Train net output #0: loss = 0.457312 (* 1 = 0.457312 loss)
I1110 23:25:31.571295  2593 sgd_solver.cpp:106] Iteration 1890, lr = 0.0005
I1110 23:25:33.915459  2593 solver.cpp:295] Iteration 1891 (no loss supplied for SingleUpdateStep)
I1110 23:25:33.915612  2593 solver.cpp:310]     Train net output #0: loss = 0.462431 (* 1 = 0.462431 loss)
I1110 23:25:33.915638  2593 sgd_solver.cpp:106] Iteration 1891, lr = 0.0005
I1110 23:25:36.164126  2593 solver.cpp:295] Iteration 1892 (no loss supplied for SingleUpdateStep)
I1110 23:25:36.164222  2593 solver.cpp:310]     Train net output #0: loss = 0.448522 (* 1 = 0.448522 loss)
I1110 23:25:36.164243  2593 sgd_solver.cpp:106] Iteration 1892, lr = 0.0005
I1110 23:25:38.536460  2593 solver.cpp:295] Iteration 1893 (no loss supplied for SingleUpdateStep)
I1110 23:25:38.536572  2593 solver.cpp:310]     Train net output #0: loss = 0.44958 (* 1 = 0.44958 loss)
I1110 23:25:38.536598  2593 sgd_solver.cpp:106] Iteration 1893, lr = 0.0005
I1110 23:25:40.959121  2593 solver.cpp:295] Iteration 1894 (no loss supplied for SingleUpdateStep)
I1110 23:25:40.959259  2593 solver.cpp:310]     Train net output #0: loss = 0.46708 (* 1 = 0.46708 loss)
I1110 23:25:40.959290  2593 sgd_solver.cpp:106] Iteration 1894, lr = 0.0005
I1110 23:25:43.236029  2593 solver.cpp:295] Iteration 1895 (no loss supplied for SingleUpdateStep)
I1110 23:25:43.236148  2593 solver.cpp:310]     Train net output #0: loss = 0.50801 (* 1 = 0.50801 loss)
I1110 23:25:43.236176  2593 sgd_solver.cpp:106] Iteration 1895, lr = 0.0005
I1110 23:25:45.570976  2593 solver.cpp:295] Iteration 1896 (no loss supplied for SingleUpdateStep)
I1110 23:25:45.571080  2593 solver.cpp:310]     Train net output #0: loss = 0.446641 (* 1 = 0.446641 loss)
I1110 23:25:45.571105  2593 sgd_solver.cpp:106] Iteration 1896, lr = 0.0005
I1110 23:25:47.878183  2593 solver.cpp:295] Iteration 1897 (no loss supplied for SingleUpdateStep)
I1110 23:25:47.878265  2593 solver.cpp:310]     Train net output #0: loss = 0.438852 (* 1 = 0.438852 loss)
I1110 23:25:47.878288  2593 sgd_solver.cpp:106] Iteration 1897, lr = 0.0005
I1110 23:25:50.106756  2593 solver.cpp:295] Iteration 1898 (no loss supplied for SingleUpdateStep)
I1110 23:25:50.106812  2593 solver.cpp:310]     Train net output #0: loss = 0.448759 (* 1 = 0.448759 loss)
I1110 23:25:50.106830  2593 sgd_solver.cpp:106] Iteration 1898, lr = 0.0005
I1110 23:25:52.647538  2593 solver.cpp:295] Iteration 1899 (no loss supplied for SingleUpdateStep)
I1110 23:25:52.647627  2593 solver.cpp:310]     Train net output #0: loss = 0.480848 (* 1 = 0.480848 loss)
I1110 23:25:52.647647  2593 sgd_solver.cpp:106] Iteration 1899, lr = 0.0005
I1110 23:25:54.982532  2593 solver.cpp:295] Iteration 1900 (no loss supplied for SingleUpdateStep)
I1110 23:25:54.982597  2593 solver.cpp:310]     Train net output #0: loss = 0.457507 (* 1 = 0.457507 loss)
I1110 23:25:54.982617  2593 sgd_solver.cpp:106] Iteration 1900, lr = 0.0005
I1110 23:25:57.229528  2593 solver.cpp:295] Iteration 1901 (no loss supplied for SingleUpdateStep)
I1110 23:25:57.229674  2593 solver.cpp:310]     Train net output #0: loss = 0.444317 (* 1 = 0.444317 loss)
I1110 23:25:57.229698  2593 sgd_solver.cpp:106] Iteration 1901, lr = 0.0005
I1110 23:25:59.535018  2593 solver.cpp:295] Iteration 1902 (no loss supplied for SingleUpdateStep)
I1110 23:25:59.535187  2593 solver.cpp:310]     Train net output #0: loss = 0.456562 (* 1 = 0.456562 loss)
I1110 23:25:59.535212  2593 sgd_solver.cpp:106] Iteration 1902, lr = 0.0005
I1110 23:26:01.773983  2593 solver.cpp:295] Iteration 1903 (no loss supplied for SingleUpdateStep)
I1110 23:26:01.774144  2593 solver.cpp:310]     Train net output #0: loss = 0.436574 (* 1 = 0.436574 loss)
I1110 23:26:01.774171  2593 sgd_solver.cpp:106] Iteration 1903, lr = 0.0005
I1110 23:26:03.978237  2593 solver.cpp:295] Iteration 1904 (no loss supplied for SingleUpdateStep)
I1110 23:26:03.978322  2593 solver.cpp:310]     Train net output #0: loss = 0.45019 (* 1 = 0.45019 loss)
I1110 23:26:03.978341  2593 sgd_solver.cpp:106] Iteration 1904, lr = 0.0005
I1110 23:26:06.208602  2593 solver.cpp:295] Iteration 1905 (no loss supplied for SingleUpdateStep)
I1110 23:26:06.208717  2593 solver.cpp:310]     Train net output #0: loss = 0.45536 (* 1 = 0.45536 loss)
I1110 23:26:06.208739  2593 sgd_solver.cpp:106] Iteration 1905, lr = 0.0005
I1110 23:26:08.444530  2593 solver.cpp:295] Iteration 1906 (no loss supplied for SingleUpdateStep)
I1110 23:26:08.444639  2593 solver.cpp:310]     Train net output #0: loss = 0.423788 (* 1 = 0.423788 loss)
I1110 23:26:08.444660  2593 sgd_solver.cpp:106] Iteration 1906, lr = 0.0005
I1110 23:26:10.816294  2593 solver.cpp:295] Iteration 1907 (no loss supplied for SingleUpdateStep)
I1110 23:26:10.816375  2593 solver.cpp:310]     Train net output #0: loss = 0.457309 (* 1 = 0.457309 loss)
I1110 23:26:10.816396  2593 sgd_solver.cpp:106] Iteration 1907, lr = 0.0005
I1110 23:26:13.044842  2593 solver.cpp:295] Iteration 1908 (no loss supplied for SingleUpdateStep)
I1110 23:26:13.044901  2593 solver.cpp:310]     Train net output #0: loss = 0.451396 (* 1 = 0.451396 loss)
I1110 23:26:13.044920  2593 sgd_solver.cpp:106] Iteration 1908, lr = 0.0005
I1110 23:26:15.287722  2593 solver.cpp:295] Iteration 1909 (no loss supplied for SingleUpdateStep)
I1110 23:26:15.287822  2593 solver.cpp:310]     Train net output #0: loss = 0.439671 (* 1 = 0.439671 loss)
I1110 23:26:15.287843  2593 sgd_solver.cpp:106] Iteration 1909, lr = 0.0005
I1110 23:26:17.714865  2593 solver.cpp:295] Iteration 1910 (no loss supplied for SingleUpdateStep)
I1110 23:26:17.714974  2593 solver.cpp:310]     Train net output #0: loss = 0.471904 (* 1 = 0.471904 loss)
I1110 23:26:17.715000  2593 sgd_solver.cpp:106] Iteration 1910, lr = 0.0005
I1110 23:26:20.127485  2593 solver.cpp:295] Iteration 1911 (no loss supplied for SingleUpdateStep)
I1110 23:26:20.127624  2593 solver.cpp:310]     Train net output #0: loss = 0.487226 (* 1 = 0.487226 loss)
I1110 23:26:20.127658  2593 sgd_solver.cpp:106] Iteration 1911, lr = 0.0005
I1110 23:26:22.412431  2593 solver.cpp:295] Iteration 1912 (no loss supplied for SingleUpdateStep)
I1110 23:26:22.412483  2593 solver.cpp:310]     Train net output #0: loss = 0.475531 (* 1 = 0.475531 loss)
I1110 23:26:22.412502  2593 sgd_solver.cpp:106] Iteration 1912, lr = 0.0005
I1110 23:26:24.970791  2593 solver.cpp:295] Iteration 1913 (no loss supplied for SingleUpdateStep)
I1110 23:26:24.970924  2593 solver.cpp:310]     Train net output #0: loss = 0.441685 (* 1 = 0.441685 loss)
I1110 23:26:24.970948  2593 sgd_solver.cpp:106] Iteration 1913, lr = 0.0005
I1110 23:26:27.355394  2593 solver.cpp:295] Iteration 1914 (no loss supplied for SingleUpdateStep)
I1110 23:26:27.355518  2593 solver.cpp:310]     Train net output #0: loss = 0.466261 (* 1 = 0.466261 loss)
I1110 23:26:27.355545  2593 sgd_solver.cpp:106] Iteration 1914, lr = 0.0005
I1110 23:26:29.674321  2593 solver.cpp:295] Iteration 1915 (no loss supplied for SingleUpdateStep)
I1110 23:26:29.674422  2593 solver.cpp:310]     Train net output #0: loss = 0.440204 (* 1 = 0.440204 loss)
I1110 23:26:29.674443  2593 sgd_solver.cpp:106] Iteration 1915, lr = 0.0005
I1110 23:26:32.023418  2593 solver.cpp:295] Iteration 1916 (no loss supplied for SingleUpdateStep)
I1110 23:26:32.023537  2593 solver.cpp:310]     Train net output #0: loss = 0.458251 (* 1 = 0.458251 loss)
I1110 23:26:32.023561  2593 sgd_solver.cpp:106] Iteration 1916, lr = 0.0005
I1110 23:26:34.234918  2593 solver.cpp:295] Iteration 1917 (no loss supplied for SingleUpdateStep)
I1110 23:26:34.235038  2593 solver.cpp:310]     Train net output #0: loss = 0.436555 (* 1 = 0.436555 loss)
I1110 23:26:34.235061  2593 sgd_solver.cpp:106] Iteration 1917, lr = 0.0005
I1110 23:26:36.507421  2593 solver.cpp:295] Iteration 1918 (no loss supplied for SingleUpdateStep)
I1110 23:26:36.507506  2593 solver.cpp:310]     Train net output #0: loss = 0.47206 (* 1 = 0.47206 loss)
I1110 23:26:36.507529  2593 sgd_solver.cpp:106] Iteration 1918, lr = 0.0005
I1110 23:26:38.828668  2593 solver.cpp:295] Iteration 1919 (no loss supplied for SingleUpdateStep)
I1110 23:26:38.828776  2593 solver.cpp:310]     Train net output #0: loss = 0.439055 (* 1 = 0.439055 loss)
I1110 23:26:38.828799  2593 sgd_solver.cpp:106] Iteration 1919, lr = 0.0005
I1110 23:26:41.203135  2593 solver.cpp:295] Iteration 1920 (no loss supplied for SingleUpdateStep)
I1110 23:26:41.203250  2593 solver.cpp:310]     Train net output #0: loss = 0.448572 (* 1 = 0.448572 loss)
I1110 23:26:41.203271  2593 sgd_solver.cpp:106] Iteration 1920, lr = 0.0005
I1110 23:26:43.534626  2593 solver.cpp:295] Iteration 1921 (no loss supplied for SingleUpdateStep)
I1110 23:26:43.534696  2593 solver.cpp:310]     Train net output #0: loss = 0.465993 (* 1 = 0.465993 loss)
I1110 23:26:43.534716  2593 sgd_solver.cpp:106] Iteration 1921, lr = 0.0005
I1110 23:26:45.986179  2593 solver.cpp:295] Iteration 1922 (no loss supplied for SingleUpdateStep)
I1110 23:26:45.986302  2593 solver.cpp:310]     Train net output #0: loss = 0.479789 (* 1 = 0.479789 loss)
I1110 23:26:45.986326  2593 sgd_solver.cpp:106] Iteration 1922, lr = 0.0005
I1110 23:26:48.330355  2593 solver.cpp:295] Iteration 1923 (no loss supplied for SingleUpdateStep)
I1110 23:26:48.330479  2593 solver.cpp:310]     Train net output #0: loss = 0.461939 (* 1 = 0.461939 loss)
I1110 23:26:48.330503  2593 sgd_solver.cpp:106] Iteration 1923, lr = 0.0005
I1110 23:26:50.649731  2593 solver.cpp:295] Iteration 1924 (no loss supplied for SingleUpdateStep)
I1110 23:26:50.649842  2593 solver.cpp:310]     Train net output #0: loss = 0.461955 (* 1 = 0.461955 loss)
I1110 23:26:50.649873  2593 sgd_solver.cpp:106] Iteration 1924, lr = 0.0005
I1110 23:26:53.145601  2593 solver.cpp:295] Iteration 1925 (no loss supplied for SingleUpdateStep)
I1110 23:26:53.145753  2593 solver.cpp:310]     Train net output #0: loss = 0.472612 (* 1 = 0.472612 loss)
I1110 23:26:53.145776  2593 sgd_solver.cpp:106] Iteration 1925, lr = 0.0005
I1110 23:26:55.688879  2593 solver.cpp:295] Iteration 1926 (no loss supplied for SingleUpdateStep)
I1110 23:26:55.689019  2593 solver.cpp:310]     Train net output #0: loss = 0.415154 (* 1 = 0.415154 loss)
I1110 23:26:55.689043  2593 sgd_solver.cpp:106] Iteration 1926, lr = 0.0005
I1110 23:26:58.317034  2593 solver.cpp:295] Iteration 1927 (no loss supplied for SingleUpdateStep)
I1110 23:26:58.317097  2593 solver.cpp:310]     Train net output #0: loss = 0.440967 (* 1 = 0.440967 loss)
I1110 23:26:58.317116  2593 sgd_solver.cpp:106] Iteration 1927, lr = 0.0005
I1110 23:27:00.900794  2593 solver.cpp:295] Iteration 1928 (no loss supplied for SingleUpdateStep)
I1110 23:27:00.900918  2593 solver.cpp:310]     Train net output #0: loss = 0.475149 (* 1 = 0.475149 loss)
I1110 23:27:00.900945  2593 sgd_solver.cpp:106] Iteration 1928, lr = 0.0005
I1110 23:27:03.275928  2593 solver.cpp:295] Iteration 1929 (no loss supplied for SingleUpdateStep)
I1110 23:27:03.276000  2593 solver.cpp:310]     Train net output #0: loss = 0.422588 (* 1 = 0.422588 loss)
I1110 23:27:03.276021  2593 sgd_solver.cpp:106] Iteration 1929, lr = 0.0005
I1110 23:27:05.643942  2593 solver.cpp:295] Iteration 1930 (no loss supplied for SingleUpdateStep)
I1110 23:27:05.644069  2593 solver.cpp:310]     Train net output #0: loss = 0.461041 (* 1 = 0.461041 loss)
I1110 23:27:05.644094  2593 sgd_solver.cpp:106] Iteration 1930, lr = 0.0005
I1110 23:27:07.939688  2593 solver.cpp:295] Iteration 1931 (no loss supplied for SingleUpdateStep)
I1110 23:27:07.939795  2593 solver.cpp:310]     Train net output #0: loss = 0.458127 (* 1 = 0.458127 loss)
I1110 23:27:07.939817  2593 sgd_solver.cpp:106] Iteration 1931, lr = 0.0005
I1110 23:27:10.496001  2593 solver.cpp:295] Iteration 1932 (no loss supplied for SingleUpdateStep)
I1110 23:27:10.496135  2593 solver.cpp:310]     Train net output #0: loss = 0.436941 (* 1 = 0.436941 loss)
I1110 23:27:10.496158  2593 sgd_solver.cpp:106] Iteration 1932, lr = 0.0005
I1110 23:27:12.931327  2593 solver.cpp:295] Iteration 1933 (no loss supplied for SingleUpdateStep)
I1110 23:27:12.931411  2593 solver.cpp:310]     Train net output #0: loss = 0.455791 (* 1 = 0.455791 loss)
I1110 23:27:12.931432  2593 sgd_solver.cpp:106] Iteration 1933, lr = 0.0005
I1110 23:27:15.897531  2593 solver.cpp:295] Iteration 1934 (no loss supplied for SingleUpdateStep)
I1110 23:27:15.897670  2593 solver.cpp:310]     Train net output #0: loss = 0.487755 (* 1 = 0.487755 loss)
I1110 23:27:15.897706  2593 sgd_solver.cpp:106] Iteration 1934, lr = 0.0005
I1110 23:27:18.786846  2593 solver.cpp:295] Iteration 1935 (no loss supplied for SingleUpdateStep)
I1110 23:27:18.786957  2593 solver.cpp:310]     Train net output #0: loss = 0.456452 (* 1 = 0.456452 loss)
I1110 23:27:18.787005  2593 sgd_solver.cpp:106] Iteration 1935, lr = 0.0005
I1110 23:27:21.853520  2593 solver.cpp:295] Iteration 1936 (no loss supplied for SingleUpdateStep)
I1110 23:27:21.853657  2593 solver.cpp:310]     Train net output #0: loss = 0.424856 (* 1 = 0.424856 loss)
I1110 23:27:21.853682  2593 sgd_solver.cpp:106] Iteration 1936, lr = 0.0005
I1110 23:27:25.019505  2593 solver.cpp:295] Iteration 1937 (no loss supplied for SingleUpdateStep)
I1110 23:27:25.019603  2593 solver.cpp:310]     Train net output #0: loss = 0.450658 (* 1 = 0.450658 loss)
I1110 23:27:25.019623  2593 sgd_solver.cpp:106] Iteration 1937, lr = 0.0005
I1110 23:27:27.981036  2593 solver.cpp:295] Iteration 1938 (no loss supplied for SingleUpdateStep)
I1110 23:27:27.981134  2593 solver.cpp:310]     Train net output #0: loss = 0.455053 (* 1 = 0.455053 loss)
I1110 23:27:27.981158  2593 sgd_solver.cpp:106] Iteration 1938, lr = 0.0005
I1110 23:27:30.360201  2593 solver.cpp:295] Iteration 1939 (no loss supplied for SingleUpdateStep)
I1110 23:27:30.360285  2593 solver.cpp:310]     Train net output #0: loss = 0.466832 (* 1 = 0.466832 loss)
I1110 23:27:30.360304  2593 sgd_solver.cpp:106] Iteration 1939, lr = 0.0005
I1110 23:27:32.723620  2593 solver.cpp:295] Iteration 1940 (no loss supplied for SingleUpdateStep)
I1110 23:27:32.723721  2593 solver.cpp:310]     Train net output #0: loss = 0.438397 (* 1 = 0.438397 loss)
I1110 23:27:32.723743  2593 sgd_solver.cpp:106] Iteration 1940, lr = 0.0005
I1110 23:27:35.105936  2593 solver.cpp:295] Iteration 1941 (no loss supplied for SingleUpdateStep)
I1110 23:27:35.106021  2593 solver.cpp:310]     Train net output #0: loss = 0.453748 (* 1 = 0.453748 loss)
I1110 23:27:35.106053  2593 sgd_solver.cpp:106] Iteration 1941, lr = 0.0005
I1110 23:27:37.298784  2593 solver.cpp:295] Iteration 1942 (no loss supplied for SingleUpdateStep)
I1110 23:27:37.298845  2593 solver.cpp:310]     Train net output #0: loss = 0.41927 (* 1 = 0.41927 loss)
I1110 23:27:37.298863  2593 sgd_solver.cpp:106] Iteration 1942, lr = 0.0005
I1110 23:27:39.574518  2593 solver.cpp:295] Iteration 1943 (no loss supplied for SingleUpdateStep)
I1110 23:27:39.574617  2593 solver.cpp:310]     Train net output #0: loss = 0.453221 (* 1 = 0.453221 loss)
I1110 23:27:39.574637  2593 sgd_solver.cpp:106] Iteration 1943, lr = 0.0005
I1110 23:27:41.848829  2593 solver.cpp:295] Iteration 1944 (no loss supplied for SingleUpdateStep)
I1110 23:27:41.848897  2593 solver.cpp:310]     Train net output #0: loss = 0.486977 (* 1 = 0.486977 loss)
I1110 23:27:41.848918  2593 sgd_solver.cpp:106] Iteration 1944, lr = 0.0005
I1110 23:27:44.284804  2593 solver.cpp:295] Iteration 1945 (no loss supplied for SingleUpdateStep)
I1110 23:27:44.284904  2593 solver.cpp:310]     Train net output #0: loss = 0.461301 (* 1 = 0.461301 loss)
I1110 23:27:44.284926  2593 sgd_solver.cpp:106] Iteration 1945, lr = 0.0005
I1110 23:27:46.749867  2593 solver.cpp:295] Iteration 1946 (no loss supplied for SingleUpdateStep)
I1110 23:27:46.749979  2593 solver.cpp:310]     Train net output #0: loss = 0.455351 (* 1 = 0.455351 loss)
I1110 23:27:46.750001  2593 sgd_solver.cpp:106] Iteration 1946, lr = 0.0005
I1110 23:27:49.069135  2593 solver.cpp:295] Iteration 1947 (no loss supplied for SingleUpdateStep)
I1110 23:27:49.069277  2593 solver.cpp:310]     Train net output #0: loss = 0.458552 (* 1 = 0.458552 loss)
I1110 23:27:49.069300  2593 sgd_solver.cpp:106] Iteration 1947, lr = 0.0005
I1110 23:27:51.309334  2593 solver.cpp:295] Iteration 1948 (no loss supplied for SingleUpdateStep)
I1110 23:27:51.309465  2593 solver.cpp:310]     Train net output #0: loss = 0.441727 (* 1 = 0.441727 loss)
I1110 23:27:51.309489  2593 sgd_solver.cpp:106] Iteration 1948, lr = 0.0005
I1110 23:27:53.565553  2593 solver.cpp:295] Iteration 1949 (no loss supplied for SingleUpdateStep)
I1110 23:27:53.565660  2593 solver.cpp:310]     Train net output #0: loss = 0.438529 (* 1 = 0.438529 loss)
I1110 23:27:53.565685  2593 sgd_solver.cpp:106] Iteration 1949, lr = 0.0005
I1110 23:27:55.781505  2593 solver.cpp:295] Iteration 1950 (no loss supplied for SingleUpdateStep)
I1110 23:27:55.781608  2593 solver.cpp:310]     Train net output #0: loss = 0.453766 (* 1 = 0.453766 loss)
I1110 23:27:55.781630  2593 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I1110 23:27:58.003526  2593 solver.cpp:295] Iteration 1951 (no loss supplied for SingleUpdateStep)
I1110 23:27:58.003626  2593 solver.cpp:310]     Train net output #0: loss = 0.470973 (* 1 = 0.470973 loss)
I1110 23:27:58.003648  2593 sgd_solver.cpp:106] Iteration 1951, lr = 0.0005
I1110 23:28:00.217957  2593 solver.cpp:295] Iteration 1952 (no loss supplied for SingleUpdateStep)
I1110 23:28:00.218039  2593 solver.cpp:310]     Train net output #0: loss = 0.47086 (* 1 = 0.47086 loss)
I1110 23:28:00.218060  2593 sgd_solver.cpp:106] Iteration 1952, lr = 0.0005
I1110 23:28:02.543092  2593 solver.cpp:295] Iteration 1953 (no loss supplied for SingleUpdateStep)
I1110 23:28:02.543212  2593 solver.cpp:310]     Train net output #0: loss = 0.453564 (* 1 = 0.453564 loss)
I1110 23:28:02.543236  2593 sgd_solver.cpp:106] Iteration 1953, lr = 0.0005
I1110 23:28:04.871023  2593 solver.cpp:295] Iteration 1954 (no loss supplied for SingleUpdateStep)
I1110 23:28:04.871120  2593 solver.cpp:310]     Train net output #0: loss = 0.435161 (* 1 = 0.435161 loss)
I1110 23:28:04.871143  2593 sgd_solver.cpp:106] Iteration 1954, lr = 0.0005
I1110 23:28:07.170824  2593 solver.cpp:295] Iteration 1955 (no loss supplied for SingleUpdateStep)
I1110 23:28:07.170919  2593 solver.cpp:310]     Train net output #0: loss = 0.491141 (* 1 = 0.491141 loss)
I1110 23:28:07.170941  2593 sgd_solver.cpp:106] Iteration 1955, lr = 0.0005
I1110 23:28:09.881686  2593 solver.cpp:295] Iteration 1956 (no loss supplied for SingleUpdateStep)
I1110 23:28:09.881783  2593 solver.cpp:310]     Train net output #0: loss = 0.426846 (* 1 = 0.426846 loss)
I1110 23:28:09.881803  2593 sgd_solver.cpp:106] Iteration 1956, lr = 0.0005
I1110 23:28:12.665597  2593 solver.cpp:295] Iteration 1957 (no loss supplied for SingleUpdateStep)
I1110 23:28:12.665652  2593 solver.cpp:310]     Train net output #0: loss = 0.435881 (* 1 = 0.435881 loss)
I1110 23:28:12.665670  2593 sgd_solver.cpp:106] Iteration 1957, lr = 0.0005
I1110 23:28:16.266728  2593 solver.cpp:295] Iteration 1958 (no loss supplied for SingleUpdateStep)
I1110 23:28:16.266824  2593 solver.cpp:310]     Train net output #0: loss = 0.436932 (* 1 = 0.436932 loss)
I1110 23:28:16.266845  2593 sgd_solver.cpp:106] Iteration 1958, lr = 0.0005
I1110 23:28:19.861552  2593 solver.cpp:295] Iteration 1959 (no loss supplied for SingleUpdateStep)
I1110 23:28:19.861709  2593 solver.cpp:310]     Train net output #0: loss = 0.458896 (* 1 = 0.458896 loss)
I1110 23:28:19.861735  2593 sgd_solver.cpp:106] Iteration 1959, lr = 0.0005
I1110 23:28:22.879436  2593 solver.cpp:295] Iteration 1960 (no loss supplied for SingleUpdateStep)
I1110 23:28:22.879570  2593 solver.cpp:310]     Train net output #0: loss = 0.46028 (* 1 = 0.46028 loss)
I1110 23:28:22.879593  2593 sgd_solver.cpp:106] Iteration 1960, lr = 0.0005
I1110 23:28:25.886052  2593 solver.cpp:295] Iteration 1961 (no loss supplied for SingleUpdateStep)
I1110 23:28:25.886153  2593 solver.cpp:310]     Train net output #0: loss = 0.452521 (* 1 = 0.452521 loss)
I1110 23:28:25.886175  2593 sgd_solver.cpp:106] Iteration 1961, lr = 0.0005
I1110 23:28:28.778856  2593 solver.cpp:295] Iteration 1962 (no loss supplied for SingleUpdateStep)
I1110 23:28:28.778980  2593 solver.cpp:310]     Train net output #0: loss = 0.493122 (* 1 = 0.493122 loss)
I1110 23:28:28.779003  2593 sgd_solver.cpp:106] Iteration 1962, lr = 0.0005
I1110 23:28:31.387323  2593 solver.cpp:295] Iteration 1963 (no loss supplied for SingleUpdateStep)
I1110 23:28:31.387403  2593 solver.cpp:310]     Train net output #0: loss = 0.421254 (* 1 = 0.421254 loss)
I1110 23:28:31.387425  2593 sgd_solver.cpp:106] Iteration 1963, lr = 0.0005
I1110 23:28:33.900290  2593 solver.cpp:295] Iteration 1964 (no loss supplied for SingleUpdateStep)
I1110 23:28:33.900408  2593 solver.cpp:310]     Train net output #0: loss = 0.412262 (* 1 = 0.412262 loss)
I1110 23:28:33.900429  2593 sgd_solver.cpp:106] Iteration 1964, lr = 0.0005
I1110 23:28:36.290520  2593 solver.cpp:295] Iteration 1965 (no loss supplied for SingleUpdateStep)
I1110 23:28:36.290613  2593 solver.cpp:310]     Train net output #0: loss = 0.441828 (* 1 = 0.441828 loss)
I1110 23:28:36.290635  2593 sgd_solver.cpp:106] Iteration 1965, lr = 0.0005
I1110 23:28:38.839694  2593 solver.cpp:295] Iteration 1966 (no loss supplied for SingleUpdateStep)
I1110 23:28:38.839823  2593 solver.cpp:310]     Train net output #0: loss = 0.453886 (* 1 = 0.453886 loss)
I1110 23:28:38.839846  2593 sgd_solver.cpp:106] Iteration 1966, lr = 0.0005
I1110 23:28:41.426653  2593 solver.cpp:295] Iteration 1967 (no loss supplied for SingleUpdateStep)
I1110 23:28:41.426746  2593 solver.cpp:310]     Train net output #0: loss = 0.444983 (* 1 = 0.444983 loss)
I1110 23:28:41.426770  2593 sgd_solver.cpp:106] Iteration 1967, lr = 0.0005
I1110 23:28:43.693421  2593 solver.cpp:295] Iteration 1968 (no loss supplied for SingleUpdateStep)
I1110 23:28:43.693492  2593 solver.cpp:310]     Train net output #0: loss = 0.466504 (* 1 = 0.466504 loss)
I1110 23:28:43.693513  2593 sgd_solver.cpp:106] Iteration 1968, lr = 0.0005
I1110 23:28:46.121234  2593 solver.cpp:295] Iteration 1969 (no loss supplied for SingleUpdateStep)
I1110 23:28:46.121412  2593 solver.cpp:310]     Train net output #0: loss = 0.468132 (* 1 = 0.468132 loss)
I1110 23:28:46.121440  2593 sgd_solver.cpp:106] Iteration 1969, lr = 0.0005
I1110 23:28:48.386248  2593 solver.cpp:295] Iteration 1970 (no loss supplied for SingleUpdateStep)
I1110 23:28:48.386356  2593 solver.cpp:310]     Train net output #0: loss = 0.413346 (* 1 = 0.413346 loss)
I1110 23:28:48.386379  2593 sgd_solver.cpp:106] Iteration 1970, lr = 0.0005
I1110 23:28:50.750221  2593 solver.cpp:295] Iteration 1971 (no loss supplied for SingleUpdateStep)
I1110 23:28:50.750326  2593 solver.cpp:310]     Train net output #0: loss = 0.425566 (* 1 = 0.425566 loss)
I1110 23:28:50.750350  2593 sgd_solver.cpp:106] Iteration 1971, lr = 0.0005
I1110 23:28:53.084071  2593 solver.cpp:295] Iteration 1972 (no loss supplied for SingleUpdateStep)
I1110 23:28:53.084197  2593 solver.cpp:310]     Train net output #0: loss = 0.457369 (* 1 = 0.457369 loss)
I1110 23:28:53.084218  2593 sgd_solver.cpp:106] Iteration 1972, lr = 0.0005
I1110 23:28:55.442582  2593 solver.cpp:295] Iteration 1973 (no loss supplied for SingleUpdateStep)
I1110 23:28:55.442723  2593 solver.cpp:310]     Train net output #0: loss = 0.423255 (* 1 = 0.423255 loss)
I1110 23:28:55.442746  2593 sgd_solver.cpp:106] Iteration 1973, lr = 0.0005
I1110 23:28:57.827718  2593 solver.cpp:295] Iteration 1974 (no loss supplied for SingleUpdateStep)
I1110 23:28:57.827843  2593 solver.cpp:310]     Train net output #0: loss = 0.425928 (* 1 = 0.425928 loss)
I1110 23:28:57.827867  2593 sgd_solver.cpp:106] Iteration 1974, lr = 0.0005
I1110 23:29:00.056583  2593 solver.cpp:295] Iteration 1975 (no loss supplied for SingleUpdateStep)
I1110 23:29:00.056653  2593 solver.cpp:310]     Train net output #0: loss = 0.481512 (* 1 = 0.481512 loss)
I1110 23:29:00.056673  2593 sgd_solver.cpp:106] Iteration 1975, lr = 0.0005
I1110 23:29:02.317361  2593 solver.cpp:295] Iteration 1976 (no loss supplied for SingleUpdateStep)
I1110 23:29:02.317530  2593 solver.cpp:310]     Train net output #0: loss = 0.447446 (* 1 = 0.447446 loss)
I1110 23:29:02.317562  2593 sgd_solver.cpp:106] Iteration 1976, lr = 0.0005
I1110 23:29:04.673393  2593 solver.cpp:295] Iteration 1977 (no loss supplied for SingleUpdateStep)
I1110 23:29:04.673503  2593 solver.cpp:310]     Train net output #0: loss = 0.473962 (* 1 = 0.473962 loss)
I1110 23:29:04.673527  2593 sgd_solver.cpp:106] Iteration 1977, lr = 0.0005
I1110 23:29:07.297507  2593 solver.cpp:295] Iteration 1978 (no loss supplied for SingleUpdateStep)
I1110 23:29:07.297597  2593 solver.cpp:310]     Train net output #0: loss = 0.439011 (* 1 = 0.439011 loss)
I1110 23:29:07.297619  2593 sgd_solver.cpp:106] Iteration 1978, lr = 0.0005
I1110 23:29:09.895491  2593 solver.cpp:295] Iteration 1979 (no loss supplied for SingleUpdateStep)
I1110 23:29:09.895694  2593 solver.cpp:310]     Train net output #0: loss = 0.435025 (* 1 = 0.435025 loss)
I1110 23:29:09.895726  2593 sgd_solver.cpp:106] Iteration 1979, lr = 0.0005
I1110 23:29:12.561688  2593 solver.cpp:295] Iteration 1980 (no loss supplied for SingleUpdateStep)
I1110 23:29:12.561746  2593 solver.cpp:310]     Train net output #0: loss = 0.465227 (* 1 = 0.465227 loss)
I1110 23:29:12.561766  2593 sgd_solver.cpp:106] Iteration 1980, lr = 0.0005
I1110 23:29:15.158335  2593 solver.cpp:295] Iteration 1981 (no loss supplied for SingleUpdateStep)
I1110 23:29:15.158434  2593 solver.cpp:310]     Train net output #0: loss = 0.458113 (* 1 = 0.458113 loss)
I1110 23:29:15.158457  2593 sgd_solver.cpp:106] Iteration 1981, lr = 0.0005
I1110 23:29:17.444129  2593 solver.cpp:295] Iteration 1982 (no loss supplied for SingleUpdateStep)
I1110 23:29:17.444191  2593 solver.cpp:310]     Train net output #0: loss = 0.4698 (* 1 = 0.4698 loss)
I1110 23:29:17.444214  2593 sgd_solver.cpp:106] Iteration 1982, lr = 0.0005
I1110 23:29:20.146636  2593 solver.cpp:295] Iteration 1983 (no loss supplied for SingleUpdateStep)
I1110 23:29:20.146746  2593 solver.cpp:310]     Train net output #0: loss = 0.460578 (* 1 = 0.460578 loss)
I1110 23:29:20.146770  2593 sgd_solver.cpp:106] Iteration 1983, lr = 0.0005
I1110 23:29:22.379526  2593 solver.cpp:295] Iteration 1984 (no loss supplied for SingleUpdateStep)
I1110 23:29:22.379717  2593 solver.cpp:310]     Train net output #0: loss = 0.443504 (* 1 = 0.443504 loss)
I1110 23:29:22.379758  2593 sgd_solver.cpp:106] Iteration 1984, lr = 0.0005
I1110 23:29:24.830485  2593 solver.cpp:295] Iteration 1985 (no loss supplied for SingleUpdateStep)
I1110 23:29:24.830602  2593 solver.cpp:310]     Train net output #0: loss = 0.441056 (* 1 = 0.441056 loss)
I1110 23:29:24.830624  2593 sgd_solver.cpp:106] Iteration 1985, lr = 0.0005
I1110 23:29:27.447687  2593 solver.cpp:295] Iteration 1986 (no loss supplied for SingleUpdateStep)
I1110 23:29:27.447862  2593 solver.cpp:310]     Train net output #0: loss = 0.452284 (* 1 = 0.452284 loss)
I1110 23:29:27.447901  2593 sgd_solver.cpp:106] Iteration 1986, lr = 0.0005
I1110 23:29:29.834136  2593 solver.cpp:295] Iteration 1987 (no loss supplied for SingleUpdateStep)
I1110 23:29:29.834254  2593 solver.cpp:310]     Train net output #0: loss = 0.433393 (* 1 = 0.433393 loss)
I1110 23:29:29.834277  2593 sgd_solver.cpp:106] Iteration 1987, lr = 0.0005
I1110 23:29:32.267568  2593 solver.cpp:295] Iteration 1988 (no loss supplied for SingleUpdateStep)
I1110 23:29:32.267642  2593 solver.cpp:310]     Train net output #0: loss = 0.448404 (* 1 = 0.448404 loss)
I1110 23:29:32.267663  2593 sgd_solver.cpp:106] Iteration 1988, lr = 0.0005
I1110 23:29:34.449833  2593 solver.cpp:295] Iteration 1989 (no loss supplied for SingleUpdateStep)
I1110 23:29:34.449940  2593 solver.cpp:310]     Train net output #0: loss = 0.4431 (* 1 = 0.4431 loss)
I1110 23:29:34.449964  2593 sgd_solver.cpp:106] Iteration 1989, lr = 0.0005
I1110 23:29:37.019158  2593 solver.cpp:295] Iteration 1990 (no loss supplied for SingleUpdateStep)
I1110 23:29:37.019273  2593 solver.cpp:310]     Train net output #0: loss = 0.426906 (* 1 = 0.426906 loss)
I1110 23:29:37.019296  2593 sgd_solver.cpp:106] Iteration 1990, lr = 0.0005
I1110 23:29:39.273547  2593 solver.cpp:295] Iteration 1991 (no loss supplied for SingleUpdateStep)
I1110 23:29:39.273614  2593 solver.cpp:310]     Train net output #0: loss = 0.428538 (* 1 = 0.428538 loss)
I1110 23:29:39.273634  2593 sgd_solver.cpp:106] Iteration 1991, lr = 0.0005
I1110 23:29:41.516973  2593 solver.cpp:295] Iteration 1992 (no loss supplied for SingleUpdateStep)
I1110 23:29:41.517108  2593 solver.cpp:310]     Train net output #0: loss = 0.458083 (* 1 = 0.458083 loss)
I1110 23:29:41.517132  2593 sgd_solver.cpp:106] Iteration 1992, lr = 0.0005
I1110 23:29:43.871408  2593 solver.cpp:295] Iteration 1993 (no loss supplied for SingleUpdateStep)
I1110 23:29:43.871508  2593 solver.cpp:310]     Train net output #0: loss = 0.47622 (* 1 = 0.47622 loss)
I1110 23:29:43.871532  2593 sgd_solver.cpp:106] Iteration 1993, lr = 0.0005
I1110 23:29:46.340875  2593 solver.cpp:295] Iteration 1994 (no loss supplied for SingleUpdateStep)
I1110 23:29:46.340956  2593 solver.cpp:310]     Train net output #0: loss = 0.440953 (* 1 = 0.440953 loss)
I1110 23:29:46.340976  2593 sgd_solver.cpp:106] Iteration 1994, lr = 0.0005
I1110 23:29:48.655683  2593 solver.cpp:295] Iteration 1995 (no loss supplied for SingleUpdateStep)
I1110 23:29:48.655791  2593 solver.cpp:310]     Train net output #0: loss = 0.426367 (* 1 = 0.426367 loss)
I1110 23:29:48.655813  2593 sgd_solver.cpp:106] Iteration 1995, lr = 0.0005
I1110 23:29:50.947805  2593 solver.cpp:295] Iteration 1996 (no loss supplied for SingleUpdateStep)
I1110 23:29:50.947901  2593 solver.cpp:310]     Train net output #0: loss = 0.454415 (* 1 = 0.454415 loss)
I1110 23:29:50.947971  2593 sgd_solver.cpp:106] Iteration 1996, lr = 0.0005
I1110 23:29:53.222252  2593 solver.cpp:295] Iteration 1997 (no loss supplied for SingleUpdateStep)
I1110 23:29:53.222329  2593 solver.cpp:310]     Train net output #0: loss = 0.444188 (* 1 = 0.444188 loss)
I1110 23:29:53.222349  2593 sgd_solver.cpp:106] Iteration 1997, lr = 0.0005
I1110 23:29:55.646124  2593 solver.cpp:295] Iteration 1998 (no loss supplied for SingleUpdateStep)
I1110 23:29:55.646222  2593 solver.cpp:310]     Train net output #0: loss = 0.462166 (* 1 = 0.462166 loss)
I1110 23:29:55.646245  2593 sgd_solver.cpp:106] Iteration 1998, lr = 0.0005
I1110 23:29:58.259397  2593 solver.cpp:295] Iteration 1999 (no loss supplied for SingleUpdateStep)
I1110 23:29:58.259448  2593 solver.cpp:310]     Train net output #0: loss = 0.444145 (* 1 = 0.444145 loss)
I1110 23:29:58.259464  2593 sgd_solver.cpp:106] Iteration 1999, lr = 0.0005
I1110 23:29:58.259551  2593 solver.cpp:534] Snapshotting to binary proto file stitch_iter_2000.caffemodel
I1110 23:29:58.259573  2593 net.cpp:1022] Serializing 2 layers
I1110 23:29:58.330021  2593 sgd_solver.cpp:269] Snapshotting solver state to binary proto file stitch_iter_2000.solverstate
I1110 23:30:01.821316  2593 solver.cpp:295] Iteration 2000 (no loss supplied for SingleUpdateStep)
I1110 23:30:01.821414  2593 solver.cpp:310]     Train net output #0: loss = 0.457576 (* 1 = 0.457576 loss)
I1110 23:30:01.821436  2593 sgd_solver.cpp:106] Iteration 2000, lr = 0.0005
I1110 23:30:04.525776  2593 solver.cpp:295] Iteration 2001 (no loss supplied for SingleUpdateStep)
I1110 23:30:04.525921  2593 solver.cpp:310]     Train net output #0: loss = 0.450843 (* 1 = 0.450843 loss)
I1110 23:30:04.525943  2593 sgd_solver.cpp:106] Iteration 2001, lr = 0.0005
I1110 23:30:08.617307  2593 solver.cpp:295] Iteration 2002 (no loss supplied for SingleUpdateStep)
I1110 23:30:08.617370  2593 solver.cpp:310]     Train net output #0: loss = 0.458733 (* 1 = 0.458733 loss)
I1110 23:30:08.617389  2593 sgd_solver.cpp:106] Iteration 2002, lr = 0.0005
I1110 23:30:12.239240  2593 solver.cpp:295] Iteration 2003 (no loss supplied for SingleUpdateStep)
I1110 23:30:12.239356  2593 solver.cpp:310]     Train net output #0: loss = 0.410024 (* 1 = 0.410024 loss)
I1110 23:30:12.239378  2593 sgd_solver.cpp:106] Iteration 2003, lr = 0.0005
I1110 23:30:16.022649  2593 solver.cpp:295] Iteration 2004 (no loss supplied for SingleUpdateStep)
I1110 23:30:16.022755  2593 solver.cpp:310]     Train net output #0: loss = 0.453734 (* 1 = 0.453734 loss)
I1110 23:30:16.022780  2593 sgd_solver.cpp:106] Iteration 2004, lr = 0.0005
I1110 23:30:19.006186  2593 solver.cpp:295] Iteration 2005 (no loss supplied for SingleUpdateStep)
I1110 23:30:19.006304  2593 solver.cpp:310]     Train net output #0: loss = 0.438732 (* 1 = 0.438732 loss)
I1110 23:30:19.006325  2593 sgd_solver.cpp:106] Iteration 2005, lr = 0.0005
I1110 23:30:21.419234  2593 solver.cpp:295] Iteration 2006 (no loss supplied for SingleUpdateStep)
I1110 23:30:21.419404  2593 solver.cpp:310]     Train net output #0: loss = 0.429217 (* 1 = 0.429217 loss)
I1110 23:30:21.419430  2593 sgd_solver.cpp:106] Iteration 2006, lr = 0.0005
I1110 23:30:24.004029  2593 solver.cpp:295] Iteration 2007 (no loss supplied for SingleUpdateStep)
I1110 23:30:24.004148  2593 solver.cpp:310]     Train net output #0: loss = 0.442103 (* 1 = 0.442103 loss)
I1110 23:30:24.004173  2593 sgd_solver.cpp:106] Iteration 2007, lr = 0.0005
I1110 23:30:26.492058  2593 solver.cpp:295] Iteration 2008 (no loss supplied for SingleUpdateStep)
I1110 23:30:26.492158  2593 solver.cpp:310]     Train net output #0: loss = 0.478576 (* 1 = 0.478576 loss)
I1110 23:30:26.492180  2593 sgd_solver.cpp:106] Iteration 2008, lr = 0.0005
I1110 23:30:29.248211  2593 solver.cpp:295] Iteration 2009 (no loss supplied for SingleUpdateStep)
I1110 23:30:29.248272  2593 solver.cpp:310]     Train net output #0: loss = 0.460197 (* 1 = 0.460197 loss)
I1110 23:30:29.248291  2593 sgd_solver.cpp:106] Iteration 2009, lr = 0.0005
I1110 23:30:32.010087  2593 solver.cpp:295] Iteration 2010 (no loss supplied for SingleUpdateStep)
I1110 23:30:32.010148  2593 solver.cpp:310]     Train net output #0: loss = 0.450282 (* 1 = 0.450282 loss)
I1110 23:30:32.010165  2593 sgd_solver.cpp:106] Iteration 2010, lr = 0.0005
I1110 23:30:34.530429  2593 solver.cpp:295] Iteration 2011 (no loss supplied for SingleUpdateStep)
I1110 23:30:34.530544  2593 solver.cpp:310]     Train net output #0: loss = 0.445501 (* 1 = 0.445501 loss)
I1110 23:30:34.530567  2593 sgd_solver.cpp:106] Iteration 2011, lr = 0.0005
I1110 23:30:37.017041  2593 solver.cpp:295] Iteration 2012 (no loss supplied for SingleUpdateStep)
I1110 23:30:37.017091  2593 solver.cpp:310]     Train net output #0: loss = 0.453573 (* 1 = 0.453573 loss)
I1110 23:30:37.017109  2593 sgd_solver.cpp:106] Iteration 2012, lr = 0.0005
I1110 23:30:39.687592  2593 solver.cpp:295] Iteration 2013 (no loss supplied for SingleUpdateStep)
I1110 23:30:39.687666  2593 solver.cpp:310]     Train net output #0: loss = 0.479631 (* 1 = 0.479631 loss)
I1110 23:30:39.687687  2593 sgd_solver.cpp:106] Iteration 2013, lr = 0.0005
I1110 23:30:42.522500  2593 solver.cpp:295] Iteration 2014 (no loss supplied for SingleUpdateStep)
I1110 23:30:42.522580  2593 solver.cpp:310]     Train net output #0: loss = 0.440985 (* 1 = 0.440985 loss)
I1110 23:30:42.522604  2593 sgd_solver.cpp:106] Iteration 2014, lr = 0.0005
I1110 23:30:45.499467  2593 solver.cpp:295] Iteration 2015 (no loss supplied for SingleUpdateStep)
I1110 23:30:45.499586  2593 solver.cpp:310]     Train net output #0: loss = 0.453292 (* 1 = 0.453292 loss)
I1110 23:30:45.499614  2593 sgd_solver.cpp:106] Iteration 2015, lr = 0.0005
I1110 23:30:48.323963  2593 solver.cpp:295] Iteration 2016 (no loss supplied for SingleUpdateStep)
I1110 23:30:48.324026  2593 solver.cpp:310]     Train net output #0: loss = 0.471125 (* 1 = 0.471125 loss)
I1110 23:30:48.324046  2593 sgd_solver.cpp:106] Iteration 2016, lr = 0.0005
I1110 23:30:51.015398  2593 solver.cpp:295] Iteration 2017 (no loss supplied for SingleUpdateStep)
I1110 23:30:51.015506  2593 solver.cpp:310]     Train net output #0: loss = 0.455294 (* 1 = 0.455294 loss)
I1110 23:30:51.015527  2593 sgd_solver.cpp:106] Iteration 2017, lr = 0.0005
I1110 23:30:53.607291  2593 solver.cpp:295] Iteration 2018 (no loss supplied for SingleUpdateStep)
I1110 23:30:53.607353  2593 solver.cpp:310]     Train net output #0: loss = 0.440009 (* 1 = 0.440009 loss)
I1110 23:30:53.607372  2593 sgd_solver.cpp:106] Iteration 2018, lr = 0.0005
I1110 23:30:55.963187  2593 solver.cpp:295] Iteration 2019 (no loss supplied for SingleUpdateStep)
I1110 23:30:55.963241  2593 solver.cpp:310]     Train net output #0: loss = 0.471159 (* 1 = 0.471159 loss)
I1110 23:30:55.963260  2593 sgd_solver.cpp:106] Iteration 2019, lr = 0.0005
I1110 23:30:58.097725  2593 solver.cpp:295] Iteration 2020 (no loss supplied for SingleUpdateStep)
I1110 23:30:58.097844  2593 solver.cpp:310]     Train net output #0: loss = 0.426539 (* 1 = 0.426539 loss)
I1110 23:30:58.097872  2593 sgd_solver.cpp:106] Iteration 2020, lr = 0.0005
I1110 23:31:00.386674  2593 solver.cpp:295] Iteration 2021 (no loss supplied for SingleUpdateStep)
I1110 23:31:00.386759  2593 solver.cpp:310]     Train net output #0: loss = 0.449299 (* 1 = 0.449299 loss)
I1110 23:31:00.386778  2593 sgd_solver.cpp:106] Iteration 2021, lr = 0.0005
I1110 23:31:02.723785  2593 solver.cpp:295] Iteration 2022 (no loss supplied for SingleUpdateStep)
I1110 23:31:02.723906  2593 solver.cpp:310]     Train net output #0: loss = 0.432105 (* 1 = 0.432105 loss)
I1110 23:31:02.723932  2593 sgd_solver.cpp:106] Iteration 2022, lr = 0.0005
I1110 23:31:04.983603  2593 solver.cpp:295] Iteration 2023 (no loss supplied for SingleUpdateStep)
I1110 23:31:04.983736  2593 solver.cpp:310]     Train net output #0: loss = 0.455137 (* 1 = 0.455137 loss)
I1110 23:31:04.983759  2593 sgd_solver.cpp:106] Iteration 2023, lr = 0.0005
I1110 23:31:07.267537  2593 solver.cpp:295] Iteration 2024 (no loss supplied for SingleUpdateStep)
I1110 23:31:07.267614  2593 solver.cpp:310]     Train net output #0: loss = 0.441285 (* 1 = 0.441285 loss)
I1110 23:31:07.267637  2593 sgd_solver.cpp:106] Iteration 2024, lr = 0.0005
I1110 23:31:09.575767  2593 solver.cpp:295] Iteration 2025 (no loss supplied for SingleUpdateStep)
I1110 23:31:09.575862  2593 solver.cpp:310]     Train net output #0: loss = 0.457404 (* 1 = 0.457404 loss)
I1110 23:31:09.575882  2593 sgd_solver.cpp:106] Iteration 2025, lr = 0.0005
I1110 23:31:12.006557  2593 solver.cpp:295] Iteration 2026 (no loss supplied for SingleUpdateStep)
I1110 23:31:12.006664  2593 solver.cpp:310]     Train net output #0: loss = 0.459191 (* 1 = 0.459191 loss)
I1110 23:31:12.006685  2593 sgd_solver.cpp:106] Iteration 2026, lr = 0.0005
I1110 23:31:14.263952  2593 solver.cpp:295] Iteration 2027 (no loss supplied for SingleUpdateStep)
I1110 23:31:14.264053  2593 solver.cpp:310]     Train net output #0: loss = 0.447009 (* 1 = 0.447009 loss)
I1110 23:31:14.264075  2593 sgd_solver.cpp:106] Iteration 2027, lr = 0.0005
I1110 23:31:16.598289  2593 solver.cpp:295] Iteration 2028 (no loss supplied for SingleUpdateStep)
I1110 23:31:16.598376  2593 solver.cpp:310]     Train net output #0: loss = 0.44881 (* 1 = 0.44881 loss)
I1110 23:31:16.598399  2593 sgd_solver.cpp:106] Iteration 2028, lr = 0.0005
I1110 23:31:19.003545  2593 solver.cpp:295] Iteration 2029 (no loss supplied for SingleUpdateStep)
I1110 23:31:19.003618  2593 solver.cpp:310]     Train net output #0: loss = 0.454535 (* 1 = 0.454535 loss)
I1110 23:31:19.003641  2593 sgd_solver.cpp:106] Iteration 2029, lr = 0.0005
I1110 23:31:21.343694  2593 solver.cpp:295] Iteration 2030 (no loss supplied for SingleUpdateStep)
I1110 23:31:21.343804  2593 solver.cpp:310]     Train net output #0: loss = 0.439429 (* 1 = 0.439429 loss)
I1110 23:31:21.343830  2593 sgd_solver.cpp:106] Iteration 2030, lr = 0.0005
I1110 23:31:23.708806  2593 solver.cpp:295] Iteration 2031 (no loss supplied for SingleUpdateStep)
I1110 23:31:23.708983  2593 solver.cpp:310]     Train net output #0: loss = 0.424161 (* 1 = 0.424161 loss)
I1110 23:31:23.709017  2593 sgd_solver.cpp:106] Iteration 2031, lr = 0.0005
I1110 23:31:26.057132  2593 solver.cpp:295] Iteration 2032 (no loss supplied for SingleUpdateStep)
I1110 23:31:26.057265  2593 solver.cpp:310]     Train net output #0: loss = 0.430964 (* 1 = 0.430964 loss)
I1110 23:31:26.057287  2593 sgd_solver.cpp:106] Iteration 2032, lr = 0.0005
I1110 23:31:28.277696  2593 solver.cpp:295] Iteration 2033 (no loss supplied for SingleUpdateStep)
I1110 23:31:28.277814  2593 solver.cpp:310]     Train net output #0: loss = 0.456802 (* 1 = 0.456802 loss)
I1110 23:31:28.277840  2593 sgd_solver.cpp:106] Iteration 2033, lr = 0.0005
I1110 23:31:30.828521  2593 solver.cpp:295] Iteration 2034 (no loss supplied for SingleUpdateStep)
I1110 23:31:30.828593  2593 solver.cpp:310]     Train net output #0: loss = 0.464837 (* 1 = 0.464837 loss)
I1110 23:31:30.828613  2593 sgd_solver.cpp:106] Iteration 2034, lr = 0.0005
I1110 23:31:33.224192  2593 solver.cpp:295] Iteration 2035 (no loss supplied for SingleUpdateStep)
I1110 23:31:33.224282  2593 solver.cpp:310]     Train net output #0: loss = 0.42479 (* 1 = 0.42479 loss)
I1110 23:31:33.224303  2593 sgd_solver.cpp:106] Iteration 2035, lr = 0.0005
I1110 23:31:35.737270  2593 solver.cpp:295] Iteration 2036 (no loss supplied for SingleUpdateStep)
I1110 23:31:35.737365  2593 solver.cpp:310]     Train net output #0: loss = 0.417065 (* 1 = 0.417065 loss)
I1110 23:31:35.737385  2593 sgd_solver.cpp:106] Iteration 2036, lr = 0.0005
I1110 23:31:38.189651  2593 solver.cpp:295] Iteration 2037 (no loss supplied for SingleUpdateStep)
I1110 23:31:38.189764  2593 solver.cpp:310]     Train net output #0: loss = 0.458889 (* 1 = 0.458889 loss)
I1110 23:31:38.189785  2593 sgd_solver.cpp:106] Iteration 2037, lr = 0.0005
I1110 23:31:41.181876  2593 solver.cpp:295] Iteration 2038 (no loss supplied for SingleUpdateStep)
I1110 23:31:41.181977  2593 solver.cpp:310]     Train net output #0: loss = 0.465611 (* 1 = 0.465611 loss)
I1110 23:31:41.181998  2593 sgd_solver.cpp:106] Iteration 2038, lr = 0.0005
I1110 23:31:43.592281  2593 solver.cpp:295] Iteration 2039 (no loss supplied for SingleUpdateStep)
I1110 23:31:43.592337  2593 solver.cpp:310]     Train net output #0: loss = 0.465074 (* 1 = 0.465074 loss)
I1110 23:31:43.592356  2593 sgd_solver.cpp:106] Iteration 2039, lr = 0.0005
I1110 23:31:46.116345  2593 solver.cpp:295] Iteration 2040 (no loss supplied for SingleUpdateStep)
I1110 23:31:46.116447  2593 solver.cpp:310]     Train net output #0: loss = 0.451632 (* 1 = 0.451632 loss)
I1110 23:31:46.116471  2593 sgd_solver.cpp:106] Iteration 2040, lr = 0.0005
I1110 23:31:50.081228  2593 solver.cpp:295] Iteration 2041 (no loss supplied for SingleUpdateStep)
I1110 23:31:50.081380  2593 solver.cpp:310]     Train net output #0: loss = 0.429619 (* 1 = 0.429619 loss)
I1110 23:31:50.081408  2593 sgd_solver.cpp:106] Iteration 2041, lr = 0.0005
I1110 23:31:53.365535  2593 solver.cpp:295] Iteration 2042 (no loss supplied for SingleUpdateStep)
I1110 23:31:53.365675  2593 solver.cpp:310]     Train net output #0: loss = 0.43212 (* 1 = 0.43212 loss)
I1110 23:31:53.365701  2593 sgd_solver.cpp:106] Iteration 2042, lr = 0.0005
I1110 23:31:56.735947  2593 solver.cpp:295] Iteration 2043 (no loss supplied for SingleUpdateStep)
I1110 23:31:56.736027  2593 solver.cpp:310]     Train net output #0: loss = 0.469465 (* 1 = 0.469465 loss)
I1110 23:31:56.736048  2593 sgd_solver.cpp:106] Iteration 2043, lr = 0.0005
I1110 23:31:59.927958  2593 solver.cpp:295] Iteration 2044 (no loss supplied for SingleUpdateStep)
I1110 23:31:59.928067  2593 solver.cpp:310]     Train net output #0: loss = 0.469801 (* 1 = 0.469801 loss)
I1110 23:31:59.928091  2593 sgd_solver.cpp:106] Iteration 2044, lr = 0.0005
I1110 23:32:03.033613  2593 solver.cpp:295] Iteration 2045 (no loss supplied for SingleUpdateStep)
I1110 23:32:03.033725  2593 solver.cpp:310]     Train net output #0: loss = 0.42502 (* 1 = 0.42502 loss)
I1110 23:32:03.033752  2593 sgd_solver.cpp:106] Iteration 2045, lr = 0.0005
I1110 23:32:05.682129  2593 solver.cpp:295] Iteration 2046 (no loss supplied for SingleUpdateStep)
I1110 23:32:05.682188  2593 solver.cpp:310]     Train net output #0: loss = 0.469972 (* 1 = 0.469972 loss)
I1110 23:32:05.682206  2593 sgd_solver.cpp:106] Iteration 2046, lr = 0.0005
I1110 23:32:07.978554  2593 solver.cpp:295] Iteration 2047 (no loss supplied for SingleUpdateStep)
I1110 23:32:07.978677  2593 solver.cpp:310]     Train net output #0: loss = 0.433544 (* 1 = 0.433544 loss)
I1110 23:32:07.978699  2593 sgd_solver.cpp:106] Iteration 2047, lr = 0.0005
I1110 23:32:10.527266  2593 solver.cpp:295] Iteration 2048 (no loss supplied for SingleUpdateStep)
I1110 23:32:10.527318  2593 solver.cpp:310]     Train net output #0: loss = 0.422325 (* 1 = 0.422325 loss)
I1110 23:32:10.527336  2593 sgd_solver.cpp:106] Iteration 2048, lr = 0.0005
I1110 23:32:12.895982  2593 solver.cpp:295] Iteration 2049 (no loss supplied for SingleUpdateStep)
I1110 23:32:12.896091  2593 solver.cpp:310]     Train net output #0: loss = 0.432914 (* 1 = 0.432914 loss)
I1110 23:32:12.896116  2593 sgd_solver.cpp:106] Iteration 2049, lr = 0.0005
I1110 23:32:15.489300  2593 solver.cpp:295] Iteration 2050 (no loss supplied for SingleUpdateStep)
I1110 23:32:15.489349  2593 solver.cpp:310]     Train net output #0: loss = 0.48033 (* 1 = 0.48033 loss)
I1110 23:32:15.489368  2593 sgd_solver.cpp:106] Iteration 2050, lr = 0.0005
I1110 23:32:18.516955  2593 solver.cpp:295] Iteration 2051 (no loss supplied for SingleUpdateStep)
I1110 23:32:18.517110  2593 solver.cpp:310]     Train net output #0: loss = 0.433274 (* 1 = 0.433274 loss)
I1110 23:32:18.517141  2593 sgd_solver.cpp:106] Iteration 2051, lr = 0.0005
I1110 23:32:20.815428  2593 solver.cpp:295] Iteration 2052 (no loss supplied for SingleUpdateStep)
I1110 23:32:20.815495  2593 solver.cpp:310]     Train net output #0: loss = 0.430972 (* 1 = 0.430972 loss)
I1110 23:32:20.815515  2593 sgd_solver.cpp:106] Iteration 2052, lr = 0.0005
I1110 23:32:23.265632  2593 solver.cpp:295] Iteration 2053 (no loss supplied for SingleUpdateStep)
I1110 23:32:23.265805  2593 solver.cpp:310]     Train net output #0: loss = 0.447159 (* 1 = 0.447159 loss)
I1110 23:32:23.265830  2593 sgd_solver.cpp:106] Iteration 2053, lr = 0.0005
I1110 23:32:25.661797  2593 solver.cpp:295] Iteration 2054 (no loss supplied for SingleUpdateStep)
I1110 23:32:25.661975  2593 solver.cpp:310]     Train net output #0: loss = 0.436186 (* 1 = 0.436186 loss)
I1110 23:32:25.662003  2593 sgd_solver.cpp:106] Iteration 2054, lr = 0.0005
I1110 23:32:28.167863  2593 solver.cpp:295] Iteration 2055 (no loss supplied for SingleUpdateStep)
I1110 23:32:28.167935  2593 solver.cpp:310]     Train net output #0: loss = 0.454812 (* 1 = 0.454812 loss)
I1110 23:32:28.167955  2593 sgd_solver.cpp:106] Iteration 2055, lr = 0.0005
I1110 23:32:30.757113  2593 solver.cpp:295] Iteration 2056 (no loss supplied for SingleUpdateStep)
I1110 23:32:30.757266  2593 solver.cpp:310]     Train net output #0: loss = 0.423412 (* 1 = 0.423412 loss)
I1110 23:32:30.757293  2593 sgd_solver.cpp:106] Iteration 2056, lr = 0.0005
I1110 23:32:33.241863  2593 solver.cpp:295] Iteration 2057 (no loss supplied for SingleUpdateStep)
I1110 23:32:33.241981  2593 solver.cpp:310]     Train net output #0: loss = 0.424307 (* 1 = 0.424307 loss)
I1110 23:32:33.242002  2593 sgd_solver.cpp:106] Iteration 2057, lr = 0.0005
I1110 23:32:35.519230  2593 solver.cpp:295] Iteration 2058 (no loss supplied for SingleUpdateStep)
I1110 23:32:35.519326  2593 solver.cpp:310]     Train net output #0: loss = 0.439568 (* 1 = 0.439568 loss)
I1110 23:32:35.519347  2593 sgd_solver.cpp:106] Iteration 2058, lr = 0.0005
I1110 23:32:38.000726  2593 solver.cpp:295] Iteration 2059 (no loss supplied for SingleUpdateStep)
I1110 23:32:38.000821  2593 solver.cpp:310]     Train net output #0: loss = 0.431805 (* 1 = 0.431805 loss)
I1110 23:32:38.000841  2593 sgd_solver.cpp:106] Iteration 2059, lr = 0.0005
I1110 23:32:40.365578  2593 solver.cpp:295] Iteration 2060 (no loss supplied for SingleUpdateStep)
I1110 23:32:40.365736  2593 solver.cpp:310]     Train net output #0: loss = 0.459847 (* 1 = 0.459847 loss)
I1110 23:32:40.365759  2593 sgd_solver.cpp:106] Iteration 2060, lr = 0.0005
I1110 23:32:42.607590  2593 solver.cpp:295] Iteration 2061 (no loss supplied for SingleUpdateStep)
I1110 23:32:42.607692  2593 solver.cpp:310]     Train net output #0: loss = 0.438231 (* 1 = 0.438231 loss)
I1110 23:32:42.607713  2593 sgd_solver.cpp:106] Iteration 2061, lr = 0.0005
I1110 23:32:45.022076  2593 solver.cpp:295] Iteration 2062 (no loss supplied for SingleUpdateStep)
I1110 23:32:45.022202  2593 solver.cpp:310]     Train net output #0: loss = 0.417542 (* 1 = 0.417542 loss)
I1110 23:32:45.022223  2593 sgd_solver.cpp:106] Iteration 2062, lr = 0.0005
I1110 23:32:47.550570  2593 solver.cpp:295] Iteration 2063 (no loss supplied for SingleUpdateStep)
I1110 23:32:47.550699  2593 solver.cpp:310]     Train net output #0: loss = 0.44961 (* 1 = 0.44961 loss)
I1110 23:32:47.550726  2593 sgd_solver.cpp:106] Iteration 2063, lr = 0.0005
I1110 23:32:49.705893  2593 solver.cpp:295] Iteration 2064 (no loss supplied for SingleUpdateStep)
I1110 23:32:49.706034  2593 solver.cpp:310]     Train net output #0: loss = 0.453032 (* 1 = 0.453032 loss)
I1110 23:32:49.706058  2593 sgd_solver.cpp:106] Iteration 2064, lr = 0.0005
I1110 23:32:52.041998  2593 solver.cpp:295] Iteration 2065 (no loss supplied for SingleUpdateStep)
I1110 23:32:52.042157  2593 solver.cpp:310]     Train net output #0: loss = 0.414006 (* 1 = 0.414006 loss)
I1110 23:32:52.042181  2593 sgd_solver.cpp:106] Iteration 2065, lr = 0.0005
I1110 23:32:54.280133  2593 solver.cpp:295] Iteration 2066 (no loss supplied for SingleUpdateStep)
I1110 23:32:54.280194  2593 solver.cpp:310]     Train net output #0: loss = 0.400878 (* 1 = 0.400878 loss)
I1110 23:32:54.280212  2593 sgd_solver.cpp:106] Iteration 2066, lr = 0.0005
I1110 23:32:56.485059  2593 solver.cpp:295] Iteration 2067 (no loss supplied for SingleUpdateStep)
I1110 23:32:56.485112  2593 solver.cpp:310]     Train net output #0: loss = 0.445367 (* 1 = 0.445367 loss)
I1110 23:32:56.485131  2593 sgd_solver.cpp:106] Iteration 2067, lr = 0.0005
I1110 23:32:58.851240  2593 solver.cpp:295] Iteration 2068 (no loss supplied for SingleUpdateStep)
I1110 23:32:58.851354  2593 solver.cpp:310]     Train net output #0: loss = 0.406023 (* 1 = 0.406023 loss)
I1110 23:32:58.851377  2593 sgd_solver.cpp:106] Iteration 2068, lr = 0.0005
I1110 23:33:01.302788  2593 solver.cpp:295] Iteration 2069 (no loss supplied for SingleUpdateStep)
I1110 23:33:01.302883  2593 solver.cpp:310]     Train net output #0: loss = 0.453779 (* 1 = 0.453779 loss)
I1110 23:33:01.302906  2593 sgd_solver.cpp:106] Iteration 2069, lr = 0.0005
I1110 23:33:03.689532  2593 solver.cpp:295] Iteration 2070 (no loss supplied for SingleUpdateStep)
I1110 23:33:03.689631  2593 solver.cpp:310]     Train net output #0: loss = 0.461542 (* 1 = 0.461542 loss)
I1110 23:33:03.689654  2593 sgd_solver.cpp:106] Iteration 2070, lr = 0.0005
I1110 23:33:06.232727  2593 solver.cpp:295] Iteration 2071 (no loss supplied for SingleUpdateStep)
I1110 23:33:06.232880  2593 solver.cpp:310]     Train net output #0: loss = 0.423103 (* 1 = 0.423103 loss)
I1110 23:33:06.232904  2593 sgd_solver.cpp:106] Iteration 2071, lr = 0.0005
I1110 23:33:08.445149  2593 solver.cpp:295] Iteration 2072 (no loss supplied for SingleUpdateStep)
I1110 23:33:08.445248  2593 solver.cpp:310]     Train net output #0: loss = 0.463377 (* 1 = 0.463377 loss)
I1110 23:33:08.445269  2593 sgd_solver.cpp:106] Iteration 2072, lr = 0.0005
I1110 23:33:10.785773  2593 solver.cpp:295] Iteration 2073 (no loss supplied for SingleUpdateStep)
I1110 23:33:10.785837  2593 solver.cpp:310]     Train net output #0: loss = 0.454741 (* 1 = 0.454741 loss)
I1110 23:33:10.785856  2593 sgd_solver.cpp:106] Iteration 2073, lr = 0.0005
I1110 23:33:13.366701  2593 solver.cpp:295] Iteration 2074 (no loss supplied for SingleUpdateStep)
I1110 23:33:13.366766  2593 solver.cpp:310]     Train net output #0: loss = 0.473084 (* 1 = 0.473084 loss)
I1110 23:33:13.366786  2593 sgd_solver.cpp:106] Iteration 2074, lr = 0.0005
I1110 23:33:15.854990  2593 solver.cpp:295] Iteration 2075 (no loss supplied for SingleUpdateStep)
I1110 23:33:15.855060  2593 solver.cpp:310]     Train net output #0: loss = 0.461977 (* 1 = 0.461977 loss)
I1110 23:33:15.855080  2593 sgd_solver.cpp:106] Iteration 2075, lr = 0.0005
I1110 23:33:18.474200  2593 solver.cpp:295] Iteration 2076 (no loss supplied for SingleUpdateStep)
I1110 23:33:18.474326  2593 solver.cpp:310]     Train net output #0: loss = 0.464262 (* 1 = 0.464262 loss)
I1110 23:33:18.474351  2593 sgd_solver.cpp:106] Iteration 2076, lr = 0.0005
I1110 23:33:20.813985  2593 solver.cpp:295] Iteration 2077 (no loss supplied for SingleUpdateStep)
I1110 23:33:20.814129  2593 solver.cpp:310]     Train net output #0: loss = 0.461806 (* 1 = 0.461806 loss)
I1110 23:33:20.814152  2593 sgd_solver.cpp:106] Iteration 2077, lr = 0.0005
I1110 23:33:23.193487  2593 solver.cpp:295] Iteration 2078 (no loss supplied for SingleUpdateStep)
I1110 23:33:23.193594  2593 solver.cpp:310]     Train net output #0: loss = 0.44412 (* 1 = 0.44412 loss)
I1110 23:33:23.193614  2593 sgd_solver.cpp:106] Iteration 2078, lr = 0.0005
I1110 23:33:25.619804  2593 solver.cpp:295] Iteration 2079 (no loss supplied for SingleUpdateStep)
I1110 23:33:25.619859  2593 solver.cpp:310]     Train net output #0: loss = 0.445399 (* 1 = 0.445399 loss)
I1110 23:33:25.619879  2593 sgd_solver.cpp:106] Iteration 2079, lr = 0.0005
I1110 23:33:27.903631  2593 solver.cpp:295] Iteration 2080 (no loss supplied for SingleUpdateStep)
I1110 23:33:27.903733  2593 solver.cpp:310]     Train net output #0: loss = 0.461156 (* 1 = 0.461156 loss)
I1110 23:33:27.903755  2593 sgd_solver.cpp:106] Iteration 2080, lr = 0.0005
I1110 23:33:30.309905  2593 solver.cpp:295] Iteration 2081 (no loss supplied for SingleUpdateStep)
I1110 23:33:30.310014  2593 solver.cpp:310]     Train net output #0: loss = 0.417412 (* 1 = 0.417412 loss)
I1110 23:33:30.310039  2593 sgd_solver.cpp:106] Iteration 2081, lr = 0.0005
I1110 23:33:32.807391  2593 solver.cpp:295] Iteration 2082 (no loss supplied for SingleUpdateStep)
I1110 23:33:32.807448  2593 solver.cpp:310]     Train net output #0: loss = 0.473947 (* 1 = 0.473947 loss)
I1110 23:33:32.807467  2593 sgd_solver.cpp:106] Iteration 2082, lr = 0.0005
I1110 23:33:36.461064  2593 solver.cpp:295] Iteration 2083 (no loss supplied for SingleUpdateStep)
I1110 23:33:36.461197  2593 solver.cpp:310]     Train net output #0: loss = 0.463502 (* 1 = 0.463502 loss)
I1110 23:33:36.461222  2593 sgd_solver.cpp:106] Iteration 2083, lr = 0.0005
I1110 23:33:40.215494  2593 solver.cpp:295] Iteration 2084 (no loss supplied for SingleUpdateStep)
I1110 23:33:40.215644  2593 solver.cpp:310]     Train net output #0: loss = 0.451078 (* 1 = 0.451078 loss)
I1110 23:33:40.215674  2593 sgd_solver.cpp:106] Iteration 2084, lr = 0.0005
I1110 23:33:43.156858  2593 solver.cpp:295] Iteration 2085 (no loss supplied for SingleUpdateStep)
I1110 23:33:43.156983  2593 solver.cpp:310]     Train net output #0: loss = 0.446515 (* 1 = 0.446515 loss)
I1110 23:33:43.157012  2593 sgd_solver.cpp:106] Iteration 2085, lr = 0.0005
I1110 23:33:46.437834  2593 solver.cpp:295] Iteration 2086 (no loss supplied for SingleUpdateStep)
I1110 23:33:46.437953  2593 solver.cpp:310]     Train net output #0: loss = 0.443504 (* 1 = 0.443504 loss)
I1110 23:33:46.437975  2593 sgd_solver.cpp:106] Iteration 2086, lr = 0.0005
I1110 23:33:48.955096  2593 solver.cpp:295] Iteration 2087 (no loss supplied for SingleUpdateStep)
I1110 23:33:48.955194  2593 solver.cpp:310]     Train net output #0: loss = 0.41776 (* 1 = 0.41776 loss)
I1110 23:33:48.955215  2593 sgd_solver.cpp:106] Iteration 2087, lr = 0.0005
I1110 23:33:51.741632  2593 solver.cpp:295] Iteration 2088 (no loss supplied for SingleUpdateStep)
I1110 23:33:51.741709  2593 solver.cpp:310]     Train net output #0: loss = 0.475736 (* 1 = 0.475736 loss)
I1110 23:33:51.741729  2593 sgd_solver.cpp:106] Iteration 2088, lr = 0.0005
I1110 23:33:54.228778  2593 solver.cpp:295] Iteration 2089 (no loss supplied for SingleUpdateStep)
I1110 23:33:54.228940  2593 solver.cpp:310]     Train net output #0: loss = 0.438493 (* 1 = 0.438493 loss)
I1110 23:33:54.228972  2593 sgd_solver.cpp:106] Iteration 2089, lr = 0.0005
I1110 23:33:56.725394  2593 solver.cpp:295] Iteration 2090 (no loss supplied for SingleUpdateStep)
I1110 23:33:56.725529  2593 solver.cpp:310]     Train net output #0: loss = 0.445105 (* 1 = 0.445105 loss)
I1110 23:33:56.725554  2593 sgd_solver.cpp:106] Iteration 2090, lr = 0.0005
I1110 23:33:59.282405  2593 solver.cpp:295] Iteration 2091 (no loss supplied for SingleUpdateStep)
I1110 23:33:59.282510  2593 solver.cpp:310]     Train net output #0: loss = 0.468226 (* 1 = 0.468226 loss)
I1110 23:33:59.282531  2593 sgd_solver.cpp:106] Iteration 2091, lr = 0.0005
I1110 23:34:02.064684  2593 solver.cpp:295] Iteration 2092 (no loss supplied for SingleUpdateStep)
I1110 23:34:02.064827  2593 solver.cpp:310]     Train net output #0: loss = 0.409551 (* 1 = 0.409551 loss)
I1110 23:34:02.064851  2593 sgd_solver.cpp:106] Iteration 2092, lr = 0.0005
I1110 23:34:04.396453  2593 solver.cpp:295] Iteration 2093 (no loss supplied for SingleUpdateStep)
I1110 23:34:04.396630  2593 solver.cpp:310]     Train net output #0: loss = 0.407455 (* 1 = 0.407455 loss)
I1110 23:34:04.396661  2593 sgd_solver.cpp:106] Iteration 2093, lr = 0.0005
I1110 23:34:06.873141  2593 solver.cpp:295] Iteration 2094 (no loss supplied for SingleUpdateStep)
I1110 23:34:06.873275  2593 solver.cpp:310]     Train net output #0: loss = 0.413503 (* 1 = 0.413503 loss)
I1110 23:34:06.873298  2593 sgd_solver.cpp:106] Iteration 2094, lr = 0.0005
I1110 23:34:09.688263  2593 solver.cpp:295] Iteration 2095 (no loss supplied for SingleUpdateStep)
I1110 23:34:09.688443  2593 solver.cpp:310]     Train net output #0: loss = 0.426422 (* 1 = 0.426422 loss)
I1110 23:34:09.688480  2593 sgd_solver.cpp:106] Iteration 2095, lr = 0.0005
I1110 23:34:12.403872  2593 solver.cpp:295] Iteration 2096 (no loss supplied for SingleUpdateStep)
I1110 23:34:12.403978  2593 solver.cpp:310]     Train net output #0: loss = 0.417545 (* 1 = 0.417545 loss)
I1110 23:34:12.404000  2593 sgd_solver.cpp:106] Iteration 2096, lr = 0.0005
I1110 23:34:14.817263  2593 solver.cpp:295] Iteration 2097 (no loss supplied for SingleUpdateStep)
I1110 23:34:14.817324  2593 solver.cpp:310]     Train net output #0: loss = 0.439966 (* 1 = 0.439966 loss)
I1110 23:34:14.817343  2593 sgd_solver.cpp:106] Iteration 2097, lr = 0.0005
I1110 23:34:17.140146  2593 solver.cpp:295] Iteration 2098 (no loss supplied for SingleUpdateStep)
I1110 23:34:17.140233  2593 solver.cpp:310]     Train net output #0: loss = 0.48294 (* 1 = 0.48294 loss)
I1110 23:34:17.140254  2593 sgd_solver.cpp:106] Iteration 2098, lr = 0.0005
I1110 23:34:19.576272  2593 solver.cpp:295] Iteration 2099 (no loss supplied for SingleUpdateStep)
I1110 23:34:19.576381  2593 solver.cpp:310]     Train net output #0: loss = 0.46159 (* 1 = 0.46159 loss)
I1110 23:34:19.576405  2593 sgd_solver.cpp:106] Iteration 2099, lr = 0.0005
I1110 23:34:22.610571  2593 solver.cpp:295] Iteration 2100 (no loss supplied for SingleUpdateStep)
I1110 23:34:22.610682  2593 solver.cpp:310]     Train net output #0: loss = 0.443651 (* 1 = 0.443651 loss)
I1110 23:34:22.610704  2593 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I1110 23:34:26.289048  2593 solver.cpp:295] Iteration 2101 (no loss supplied for SingleUpdateStep)
I1110 23:34:26.289141  2593 solver.cpp:310]     Train net output #0: loss = 0.45005 (* 1 = 0.45005 loss)
I1110 23:34:26.289162  2593 sgd_solver.cpp:106] Iteration 2101, lr = 0.0005
I1110 23:34:29.641141  2593 solver.cpp:295] Iteration 2102 (no loss supplied for SingleUpdateStep)
I1110 23:34:29.641247  2593 solver.cpp:310]     Train net output #0: loss = 0.429491 (* 1 = 0.429491 loss)
I1110 23:34:29.641269  2593 sgd_solver.cpp:106] Iteration 2102, lr = 0.0005
I1110 23:34:31.950767  2593 solver.cpp:295] Iteration 2103 (no loss supplied for SingleUpdateStep)
I1110 23:34:31.950906  2593 solver.cpp:310]     Train net output #0: loss = 0.428899 (* 1 = 0.428899 loss)
I1110 23:34:31.950929  2593 sgd_solver.cpp:106] Iteration 2103, lr = 0.0005
I1110 23:34:34.324247  2593 solver.cpp:295] Iteration 2104 (no loss supplied for SingleUpdateStep)
I1110 23:34:34.324311  2593 solver.cpp:310]     Train net output #0: loss = 0.443199 (* 1 = 0.443199 loss)
I1110 23:34:34.324331  2593 sgd_solver.cpp:106] Iteration 2104, lr = 0.0005
I1110 23:34:36.801973  2593 solver.cpp:295] Iteration 2105 (no loss supplied for SingleUpdateStep)
I1110 23:34:36.802047  2593 solver.cpp:310]     Train net output #0: loss = 0.468666 (* 1 = 0.468666 loss)
I1110 23:34:36.802068  2593 sgd_solver.cpp:106] Iteration 2105, lr = 0.0005
I1110 23:34:39.079107  2593 solver.cpp:295] Iteration 2106 (no loss supplied for SingleUpdateStep)
I1110 23:34:39.079188  2593 solver.cpp:310]     Train net output #0: loss = 0.44089 (* 1 = 0.44089 loss)
I1110 23:34:39.079208  2593 sgd_solver.cpp:106] Iteration 2106, lr = 0.0005
I1110 23:34:41.425199  2593 solver.cpp:295] Iteration 2107 (no loss supplied for SingleUpdateStep)
I1110 23:34:41.425323  2593 solver.cpp:310]     Train net output #0: loss = 0.437718 (* 1 = 0.437718 loss)
I1110 23:34:41.425349  2593 sgd_solver.cpp:106] Iteration 2107, lr = 0.0005
I1110 23:34:43.771805  2593 solver.cpp:295] Iteration 2108 (no loss supplied for SingleUpdateStep)
I1110 23:34:43.771853  2593 solver.cpp:310]     Train net output #0: loss = 0.427014 (* 1 = 0.427014 loss)
I1110 23:34:43.771870  2593 sgd_solver.cpp:106] Iteration 2108, lr = 0.0005
I1110 23:34:46.092355  2593 solver.cpp:295] Iteration 2109 (no loss supplied for SingleUpdateStep)
I1110 23:34:46.092470  2593 solver.cpp:310]     Train net output #0: loss = 0.484733 (* 1 = 0.484733 loss)
I1110 23:34:46.092492  2593 sgd_solver.cpp:106] Iteration 2109, lr = 0.0005
I1110 23:34:48.558040  2593 solver.cpp:295] Iteration 2110 (no loss supplied for SingleUpdateStep)
I1110 23:34:48.558111  2593 solver.cpp:310]     Train net output #0: loss = 0.461063 (* 1 = 0.461063 loss)
I1110 23:34:48.558131  2593 sgd_solver.cpp:106] Iteration 2110, lr = 0.0005
I1110 23:34:50.739549  2593 solver.cpp:295] Iteration 2111 (no loss supplied for SingleUpdateStep)
I1110 23:34:50.739650  2593 solver.cpp:310]     Train net output #0: loss = 0.453672 (* 1 = 0.453672 loss)
I1110 23:34:50.739673  2593 sgd_solver.cpp:106] Iteration 2111, lr = 0.0005
I1110 23:34:53.091229  2593 solver.cpp:295] Iteration 2112 (no loss supplied for SingleUpdateStep)
I1110 23:34:53.091315  2593 solver.cpp:310]     Train net output #0: loss = 0.412917 (* 1 = 0.412917 loss)
I1110 23:34:53.091336  2593 sgd_solver.cpp:106] Iteration 2112, lr = 0.0005
I1110 23:34:55.568055  2593 solver.cpp:295] Iteration 2113 (no loss supplied for SingleUpdateStep)
I1110 23:34:55.568150  2593 solver.cpp:310]     Train net output #0: loss = 0.434257 (* 1 = 0.434257 loss)
I1110 23:34:55.568171  2593 sgd_solver.cpp:106] Iteration 2113, lr = 0.0005
I1110 23:34:57.769652  2593 solver.cpp:295] Iteration 2114 (no loss supplied for SingleUpdateStep)
I1110 23:34:57.769747  2593 solver.cpp:310]     Train net output #0: loss = 0.457725 (* 1 = 0.457725 loss)
I1110 23:34:57.769768  2593 sgd_solver.cpp:106] Iteration 2114, lr = 0.0005
I1110 23:34:59.962136  2593 solver.cpp:295] Iteration 2115 (no loss supplied for SingleUpdateStep)
I1110 23:34:59.962271  2593 solver.cpp:310]     Train net output #0: loss = 0.459026 (* 1 = 0.459026 loss)
I1110 23:34:59.962292  2593 sgd_solver.cpp:106] Iteration 2115, lr = 0.0005
I1110 23:35:02.330214  2593 solver.cpp:295] Iteration 2116 (no loss supplied for SingleUpdateStep)
I1110 23:35:02.330323  2593 solver.cpp:310]     Train net output #0: loss = 0.487085 (* 1 = 0.487085 loss)
I1110 23:35:02.330348  2593 sgd_solver.cpp:106] Iteration 2116, lr = 0.0005
I1110 23:35:04.724295  2593 solver.cpp:295] Iteration 2117 (no loss supplied for SingleUpdateStep)
I1110 23:35:04.724424  2593 solver.cpp:310]     Train net output #0: loss = 0.436969 (* 1 = 0.436969 loss)
I1110 23:35:04.724454  2593 sgd_solver.cpp:106] Iteration 2117, lr = 0.0005
I1110 23:35:07.431979  2593 solver.cpp:295] Iteration 2118 (no loss supplied for SingleUpdateStep)
I1110 23:35:07.432072  2593 solver.cpp:310]     Train net output #0: loss = 0.479243 (* 1 = 0.479243 loss)
I1110 23:35:07.432096  2593 sgd_solver.cpp:106] Iteration 2118, lr = 0.0005
I1110 23:35:10.033313  2593 solver.cpp:295] Iteration 2119 (no loss supplied for SingleUpdateStep)
I1110 23:35:10.033370  2593 solver.cpp:310]     Train net output #0: loss = 0.427134 (* 1 = 0.427134 loss)
I1110 23:35:10.033390  2593 sgd_solver.cpp:106] Iteration 2119, lr = 0.0005
I1110 23:35:12.733659  2593 solver.cpp:295] Iteration 2120 (no loss supplied for SingleUpdateStep)
I1110 23:35:12.733760  2593 solver.cpp:310]     Train net output #0: loss = 0.413741 (* 1 = 0.413741 loss)
I1110 23:35:12.733782  2593 sgd_solver.cpp:106] Iteration 2120, lr = 0.0005
I1110 23:35:15.264158  2593 solver.cpp:295] Iteration 2121 (no loss supplied for SingleUpdateStep)
I1110 23:35:15.264266  2593 solver.cpp:310]     Train net output #0: loss = 0.48689 (* 1 = 0.48689 loss)
I1110 23:35:15.264286  2593 sgd_solver.cpp:106] Iteration 2121, lr = 0.0005
I1110 23:35:17.614012  2593 solver.cpp:295] Iteration 2122 (no loss supplied for SingleUpdateStep)
I1110 23:35:17.614156  2593 solver.cpp:310]     Train net output #0: loss = 0.446452 (* 1 = 0.446452 loss)
I1110 23:35:17.614181  2593 sgd_solver.cpp:106] Iteration 2122, lr = 0.0005
I1110 23:35:19.883478  2593 solver.cpp:295] Iteration 2123 (no loss supplied for SingleUpdateStep)
I1110 23:35:19.883580  2593 solver.cpp:310]     Train net output #0: loss = 0.471772 (* 1 = 0.471772 loss)
I1110 23:35:19.883602  2593 sgd_solver.cpp:106] Iteration 2123, lr = 0.0005
I1110 23:35:22.303819  2593 solver.cpp:295] Iteration 2124 (no loss supplied for SingleUpdateStep)
I1110 23:35:22.303964  2593 solver.cpp:310]     Train net output #0: loss = 0.421159 (* 1 = 0.421159 loss)
I1110 23:35:22.303987  2593 sgd_solver.cpp:106] Iteration 2124, lr = 0.0005
I1110 23:35:24.548800  2593 solver.cpp:295] Iteration 2125 (no loss supplied for SingleUpdateStep)
I1110 23:35:24.548853  2593 solver.cpp:310]     Train net output #0: loss = 0.437231 (* 1 = 0.437231 loss)
I1110 23:35:24.548871  2593 sgd_solver.cpp:106] Iteration 2125, lr = 0.0005
I1110 23:35:27.491035  2593 solver.cpp:295] Iteration 2126 (no loss supplied for SingleUpdateStep)
I1110 23:35:27.491178  2593 solver.cpp:310]     Train net output #0: loss = 0.483571 (* 1 = 0.483571 loss)
I1110 23:35:27.491206  2593 sgd_solver.cpp:106] Iteration 2126, lr = 0.0005
I1110 23:35:30.873821  2593 solver.cpp:295] Iteration 2127 (no loss supplied for SingleUpdateStep)
I1110 23:35:30.873903  2593 solver.cpp:310]     Train net output #0: loss = 0.476287 (* 1 = 0.476287 loss)
I1110 23:35:30.873930  2593 sgd_solver.cpp:106] Iteration 2127, lr = 0.0005
I1110 23:35:34.161748  2593 solver.cpp:295] Iteration 2128 (no loss supplied for SingleUpdateStep)
I1110 23:35:34.161883  2593 solver.cpp:310]     Train net output #0: loss = 0.45597 (* 1 = 0.45597 loss)
I1110 23:35:34.161909  2593 sgd_solver.cpp:106] Iteration 2128, lr = 0.0005
I1110 23:35:36.707092  2593 solver.cpp:295] Iteration 2129 (no loss supplied for SingleUpdateStep)
I1110 23:35:36.707262  2593 solver.cpp:310]     Train net output #0: loss = 0.42884 (* 1 = 0.42884 loss)
I1110 23:35:36.707289  2593 sgd_solver.cpp:106] Iteration 2129, lr = 0.0005
I1110 23:35:39.164427  2593 solver.cpp:295] Iteration 2130 (no loss supplied for SingleUpdateStep)
I1110 23:35:39.164572  2593 solver.cpp:310]     Train net output #0: loss = 0.446671 (* 1 = 0.446671 loss)
I1110 23:35:39.164604  2593 sgd_solver.cpp:106] Iteration 2130, lr = 0.0005
I1110 23:35:41.576649  2593 solver.cpp:295] Iteration 2131 (no loss supplied for SingleUpdateStep)
I1110 23:35:41.576838  2593 solver.cpp:310]     Train net output #0: loss = 0.417482 (* 1 = 0.417482 loss)
I1110 23:35:41.576877  2593 sgd_solver.cpp:106] Iteration 2131, lr = 0.0005
I1110 23:35:44.131781  2593 solver.cpp:295] Iteration 2132 (no loss supplied for SingleUpdateStep)
I1110 23:35:44.131876  2593 solver.cpp:310]     Train net output #0: loss = 0.433252 (* 1 = 0.433252 loss)
I1110 23:35:44.131896  2593 sgd_solver.cpp:106] Iteration 2132, lr = 0.0005
I1110 23:35:46.705148  2593 solver.cpp:295] Iteration 2133 (no loss supplied for SingleUpdateStep)
I1110 23:35:46.705265  2593 solver.cpp:310]     Train net output #0: loss = 0.461083 (* 1 = 0.461083 loss)
I1110 23:35:46.705289  2593 sgd_solver.cpp:106] Iteration 2133, lr = 0.0005
I1110 23:35:49.980674  2593 solver.cpp:295] Iteration 2134 (no loss supplied for SingleUpdateStep)
I1110 23:35:49.980782  2593 solver.cpp:310]     Train net output #0: loss = 0.439318 (* 1 = 0.439318 loss)
I1110 23:35:49.980806  2593 sgd_solver.cpp:106] Iteration 2134, lr = 0.0005
I1110 23:35:52.857005  2593 solver.cpp:295] Iteration 2135 (no loss supplied for SingleUpdateStep)
I1110 23:35:52.857084  2593 solver.cpp:310]     Train net output #0: loss = 0.417809 (* 1 = 0.417809 loss)
I1110 23:35:52.857103  2593 sgd_solver.cpp:106] Iteration 2135, lr = 0.0005
I1110 23:35:59.181025  2593 solver.cpp:295] Iteration 2136 (no loss supplied for SingleUpdateStep)
I1110 23:35:59.181107  2593 solver.cpp:310]     Train net output #0: loss = 0.42362 (* 1 = 0.42362 loss)
I1110 23:35:59.181129  2593 sgd_solver.cpp:106] Iteration 2136, lr = 0.0005
I1110 23:36:05.270994  2593 solver.cpp:295] Iteration 2137 (no loss supplied for SingleUpdateStep)
I1110 23:36:05.271108  2593 solver.cpp:310]     Train net output #0: loss = 0.4467 (* 1 = 0.4467 loss)
I1110 23:36:05.271131  2593 sgd_solver.cpp:106] Iteration 2137, lr = 0.0005
I1110 23:36:10.126302  2593 solver.cpp:295] Iteration 2138 (no loss supplied for SingleUpdateStep)
I1110 23:36:10.126422  2593 solver.cpp:310]     Train net output #0: loss = 0.433726 (* 1 = 0.433726 loss)
I1110 23:36:10.126444  2593 sgd_solver.cpp:106] Iteration 2138, lr = 0.0005
I1110 23:36:13.640949  2593 solver.cpp:295] Iteration 2139 (no loss supplied for SingleUpdateStep)
I1110 23:36:13.641026  2593 solver.cpp:310]     Train net output #0: loss = 0.45129 (* 1 = 0.45129 loss)
I1110 23:36:13.641046  2593 sgd_solver.cpp:106] Iteration 2139, lr = 0.0005
I1110 23:36:16.342248  2593 solver.cpp:295] Iteration 2140 (no loss supplied for SingleUpdateStep)
I1110 23:36:16.342337  2593 solver.cpp:310]     Train net output #0: loss = 0.44714 (* 1 = 0.44714 loss)
I1110 23:36:16.342357  2593 sgd_solver.cpp:106] Iteration 2140, lr = 0.0005
I1110 23:36:19.914124  2593 solver.cpp:295] Iteration 2141 (no loss supplied for SingleUpdateStep)
I1110 23:36:19.914186  2593 solver.cpp:310]     Train net output #0: loss = 0.447275 (* 1 = 0.447275 loss)
I1110 23:36:19.914208  2593 sgd_solver.cpp:106] Iteration 2141, lr = 0.0005
I1110 23:36:22.901129  2593 solver.cpp:295] Iteration 2142 (no loss supplied for SingleUpdateStep)
I1110 23:36:22.901237  2593 solver.cpp:310]     Train net output #0: loss = 0.472855 (* 1 = 0.472855 loss)
I1110 23:36:22.901257  2593 sgd_solver.cpp:106] Iteration 2142, lr = 0.0005
I1110 23:36:25.283082  2593 solver.cpp:295] Iteration 2143 (no loss supplied for SingleUpdateStep)
I1110 23:36:25.283169  2593 solver.cpp:310]     Train net output #0: loss = 0.437164 (* 1 = 0.437164 loss)
I1110 23:36:25.283190  2593 sgd_solver.cpp:106] Iteration 2143, lr = 0.0005
I1110 23:36:27.820966  2593 solver.cpp:295] Iteration 2144 (no loss supplied for SingleUpdateStep)
I1110 23:36:27.821110  2593 solver.cpp:310]     Train net output #0: loss = 0.44679 (* 1 = 0.44679 loss)
I1110 23:36:27.821135  2593 sgd_solver.cpp:106] Iteration 2144, lr = 0.0005
I1110 23:36:30.377132  2593 solver.cpp:295] Iteration 2145 (no loss supplied for SingleUpdateStep)
I1110 23:36:30.377244  2593 solver.cpp:310]     Train net output #0: loss = 0.414674 (* 1 = 0.414674 loss)
I1110 23:36:30.377265  2593 sgd_solver.cpp:106] Iteration 2145, lr = 0.0005
I1110 23:36:33.071959  2593 solver.cpp:295] Iteration 2146 (no loss supplied for SingleUpdateStep)
I1110 23:36:33.072094  2593 solver.cpp:310]     Train net output #0: loss = 0.420351 (* 1 = 0.420351 loss)
I1110 23:36:33.072118  2593 sgd_solver.cpp:106] Iteration 2146, lr = 0.0005
I1110 23:36:35.599254  2593 solver.cpp:295] Iteration 2147 (no loss supplied for SingleUpdateStep)
I1110 23:36:35.599375  2593 solver.cpp:310]     Train net output #0: loss = 0.420103 (* 1 = 0.420103 loss)
I1110 23:36:35.599396  2593 sgd_solver.cpp:106] Iteration 2147, lr = 0.0005
I1110 23:36:38.169667  2593 solver.cpp:295] Iteration 2148 (no loss supplied for SingleUpdateStep)
I1110 23:36:38.169780  2593 solver.cpp:310]     Train net output #0: loss = 0.453541 (* 1 = 0.453541 loss)
I1110 23:36:38.169801  2593 sgd_solver.cpp:106] Iteration 2148, lr = 0.0005
I1110 23:36:40.426116  2593 solver.cpp:295] Iteration 2149 (no loss supplied for SingleUpdateStep)
I1110 23:36:40.426211  2593 solver.cpp:310]     Train net output #0: loss = 0.438584 (* 1 = 0.438584 loss)
I1110 23:36:40.426231  2593 sgd_solver.cpp:106] Iteration 2149, lr = 0.0005
I1110 23:36:42.892021  2593 solver.cpp:295] Iteration 2150 (no loss supplied for SingleUpdateStep)
I1110 23:36:42.892122  2593 solver.cpp:310]     Train net output #0: loss = 0.454603 (* 1 = 0.454603 loss)
I1110 23:36:42.892144  2593 sgd_solver.cpp:106] Iteration 2150, lr = 0.0005
I1110 23:36:45.995147  2593 solver.cpp:295] Iteration 2151 (no loss supplied for SingleUpdateStep)
I1110 23:36:45.995230  2593 solver.cpp:310]     Train net output #0: loss = 0.43628 (* 1 = 0.43628 loss)
I1110 23:36:45.995250  2593 sgd_solver.cpp:106] Iteration 2151, lr = 0.0005
I1110 23:36:49.117899  2593 solver.cpp:295] Iteration 2152 (no loss supplied for SingleUpdateStep)
I1110 23:36:49.117952  2593 solver.cpp:310]     Train net output #0: loss = 0.442901 (* 1 = 0.442901 loss)
I1110 23:36:49.117970  2593 sgd_solver.cpp:106] Iteration 2152, lr = 0.0005
I1110 23:36:51.752475  2593 solver.cpp:295] Iteration 2153 (no loss supplied for SingleUpdateStep)
I1110 23:36:51.752588  2593 solver.cpp:310]     Train net output #0: loss = 0.464292 (* 1 = 0.464292 loss)
I1110 23:36:51.752609  2593 sgd_solver.cpp:106] Iteration 2153, lr = 0.0005
I1110 23:36:55.384045  2593 solver.cpp:295] Iteration 2154 (no loss supplied for SingleUpdateStep)
I1110 23:36:55.384101  2593 solver.cpp:310]     Train net output #0: loss = 0.40066 (* 1 = 0.40066 loss)
I1110 23:36:55.384120  2593 sgd_solver.cpp:106] Iteration 2154, lr = 0.0005
I1110 23:36:58.986238  2593 solver.cpp:295] Iteration 2155 (no loss supplied for SingleUpdateStep)
I1110 23:36:58.986366  2593 solver.cpp:310]     Train net output #0: loss = 0.435168 (* 1 = 0.435168 loss)
I1110 23:36:58.986388  2593 sgd_solver.cpp:106] Iteration 2155, lr = 0.0005
I1110 23:37:03.014072  2593 solver.cpp:295] Iteration 2156 (no loss supplied for SingleUpdateStep)
I1110 23:37:03.014163  2593 solver.cpp:310]     Train net output #0: loss = 0.455306 (* 1 = 0.455306 loss)
I1110 23:37:03.014181  2593 sgd_solver.cpp:106] Iteration 2156, lr = 0.0005
I1110 23:37:07.080109  2593 solver.cpp:295] Iteration 2157 (no loss supplied for SingleUpdateStep)
I1110 23:37:07.080224  2593 solver.cpp:310]     Train net output #0: loss = 0.431777 (* 1 = 0.431777 loss)
I1110 23:37:07.080245  2593 sgd_solver.cpp:106] Iteration 2157, lr = 0.0005
I1110 23:37:11.591747  2593 solver.cpp:295] Iteration 2158 (no loss supplied for SingleUpdateStep)
I1110 23:37:11.591848  2593 solver.cpp:310]     Train net output #0: loss = 0.454351 (* 1 = 0.454351 loss)
I1110 23:37:11.591872  2593 sgd_solver.cpp:106] Iteration 2158, lr = 0.0005
I1110 23:37:15.490285  2593 solver.cpp:295] Iteration 2159 (no loss supplied for SingleUpdateStep)
I1110 23:37:15.490362  2593 solver.cpp:310]     Train net output #0: loss = 0.444817 (* 1 = 0.444817 loss)
I1110 23:37:15.490383  2593 sgd_solver.cpp:106] Iteration 2159, lr = 0.0005
I1110 23:37:18.343901  2593 solver.cpp:295] Iteration 2160 (no loss supplied for SingleUpdateStep)
I1110 23:37:18.344018  2593 solver.cpp:310]     Train net output #0: loss = 0.451285 (* 1 = 0.451285 loss)
I1110 23:37:18.344040  2593 sgd_solver.cpp:106] Iteration 2160, lr = 0.0005
I1110 23:37:20.931752  2593 solver.cpp:295] Iteration 2161 (no loss supplied for SingleUpdateStep)
I1110 23:37:20.931850  2593 solver.cpp:310]     Train net output #0: loss = 0.427621 (* 1 = 0.427621 loss)
I1110 23:37:20.931870  2593 sgd_solver.cpp:106] Iteration 2161, lr = 0.0005
I1110 23:37:23.330021  2593 solver.cpp:295] Iteration 2162 (no loss supplied for SingleUpdateStep)
I1110 23:37:23.330097  2593 solver.cpp:310]     Train net output #0: loss = 0.418088 (* 1 = 0.418088 loss)
I1110 23:37:23.330117  2593 sgd_solver.cpp:106] Iteration 2162, lr = 0.0005
I1110 23:37:25.943663  2593 solver.cpp:295] Iteration 2163 (no loss supplied for SingleUpdateStep)
I1110 23:37:25.943845  2593 solver.cpp:310]     Train net output #0: loss = 0.442666 (* 1 = 0.442666 loss)
I1110 23:37:25.943881  2593 sgd_solver.cpp:106] Iteration 2163, lr = 0.0005
I1110 23:37:28.604130  2593 solver.cpp:295] Iteration 2164 (no loss supplied for SingleUpdateStep)
I1110 23:37:28.604200  2593 solver.cpp:310]     Train net output #0: loss = 0.442771 (* 1 = 0.442771 loss)
I1110 23:37:28.604221  2593 sgd_solver.cpp:106] Iteration 2164, lr = 0.0005
I1110 23:37:31.238682  2593 solver.cpp:295] Iteration 2165 (no loss supplied for SingleUpdateStep)
I1110 23:37:31.238802  2593 solver.cpp:310]     Train net output #0: loss = 0.436719 (* 1 = 0.436719 loss)
I1110 23:37:31.238826  2593 sgd_solver.cpp:106] Iteration 2165, lr = 0.0005
I1110 23:37:33.931607  2593 solver.cpp:295] Iteration 2166 (no loss supplied for SingleUpdateStep)
I1110 23:37:33.931740  2593 solver.cpp:310]     Train net output #0: loss = 0.446151 (* 1 = 0.446151 loss)
I1110 23:37:33.931763  2593 sgd_solver.cpp:106] Iteration 2166, lr = 0.0005
I1110 23:37:36.499521  2593 solver.cpp:295] Iteration 2167 (no loss supplied for SingleUpdateStep)
I1110 23:37:36.499594  2593 solver.cpp:310]     Train net output #0: loss = 0.42801 (* 1 = 0.42801 loss)
I1110 23:37:36.499614  2593 sgd_solver.cpp:106] Iteration 2167, lr = 0.0005
I1110 23:37:38.915460  2593 solver.cpp:295] Iteration 2168 (no loss supplied for SingleUpdateStep)
I1110 23:37:38.915559  2593 solver.cpp:310]     Train net output #0: loss = 0.431592 (* 1 = 0.431592 loss)
I1110 23:37:38.915578  2593 sgd_solver.cpp:106] Iteration 2168, lr = 0.0005
I1110 23:37:41.604508  2593 solver.cpp:295] Iteration 2169 (no loss supplied for SingleUpdateStep)
I1110 23:37:41.604630  2593 solver.cpp:310]     Train net output #0: loss = 0.433448 (* 1 = 0.433448 loss)
I1110 23:37:41.604653  2593 sgd_solver.cpp:106] Iteration 2169, lr = 0.0005
I1110 23:37:44.289011  2593 solver.cpp:295] Iteration 2170 (no loss supplied for SingleUpdateStep)
I1110 23:37:44.289103  2593 solver.cpp:310]     Train net output #0: loss = 0.444029 (* 1 = 0.444029 loss)
I1110 23:37:44.289125  2593 sgd_solver.cpp:106] Iteration 2170, lr = 0.0005
I1110 23:37:46.704234  2593 solver.cpp:295] Iteration 2171 (no loss supplied for SingleUpdateStep)
I1110 23:37:46.704332  2593 solver.cpp:310]     Train net output #0: loss = 0.439816 (* 1 = 0.439816 loss)
I1110 23:37:46.704354  2593 sgd_solver.cpp:106] Iteration 2171, lr = 0.0005
I1110 23:37:49.006188  2593 solver.cpp:295] Iteration 2172 (no loss supplied for SingleUpdateStep)
I1110 23:37:49.006288  2593 solver.cpp:310]     Train net output #0: loss = 0.411276 (* 1 = 0.411276 loss)
I1110 23:37:49.006309  2593 sgd_solver.cpp:106] Iteration 2172, lr = 0.0005
I1110 23:37:51.440637  2593 solver.cpp:295] Iteration 2173 (no loss supplied for SingleUpdateStep)
I1110 23:37:51.440755  2593 solver.cpp:310]     Train net output #0: loss = 0.444939 (* 1 = 0.444939 loss)
I1110 23:37:51.440778  2593 sgd_solver.cpp:106] Iteration 2173, lr = 0.0005
I1110 23:37:53.961915  2593 solver.cpp:295] Iteration 2174 (no loss supplied for SingleUpdateStep)
I1110 23:37:53.962019  2593 solver.cpp:310]     Train net output #0: loss = 0.443292 (* 1 = 0.443292 loss)
I1110 23:37:53.962041  2593 sgd_solver.cpp:106] Iteration 2174, lr = 0.0005
I1110 23:37:56.502529  2593 solver.cpp:295] Iteration 2175 (no loss supplied for SingleUpdateStep)
I1110 23:37:56.502622  2593 solver.cpp:310]     Train net output #0: loss = 0.423817 (* 1 = 0.423817 loss)
I1110 23:37:56.502642  2593 sgd_solver.cpp:106] Iteration 2175, lr = 0.0005
I1110 23:37:59.110548  2593 solver.cpp:295] Iteration 2176 (no loss supplied for SingleUpdateStep)
I1110 23:37:59.110649  2593 solver.cpp:310]     Train net output #0: loss = 0.479607 (* 1 = 0.479607 loss)
I1110 23:37:59.110672  2593 sgd_solver.cpp:106] Iteration 2176, lr = 0.0005
I1110 23:38:01.556363  2593 solver.cpp:295] Iteration 2177 (no loss supplied for SingleUpdateStep)
I1110 23:38:01.556449  2593 solver.cpp:310]     Train net output #0: loss = 0.435987 (* 1 = 0.435987 loss)
I1110 23:38:01.556469  2593 sgd_solver.cpp:106] Iteration 2177, lr = 0.0005
I1110 23:38:03.934098  2593 solver.cpp:295] Iteration 2178 (no loss supplied for SingleUpdateStep)
I1110 23:38:03.934159  2593 solver.cpp:310]     Train net output #0: loss = 0.43331 (* 1 = 0.43331 loss)
I1110 23:38:03.934177  2593 sgd_solver.cpp:106] Iteration 2178, lr = 0.0005
I1110 23:38:06.470510  2593 solver.cpp:295] Iteration 2179 (no loss supplied for SingleUpdateStep)
I1110 23:38:06.470594  2593 solver.cpp:310]     Train net output #0: loss = 0.450691 (* 1 = 0.450691 loss)
I1110 23:38:06.470614  2593 sgd_solver.cpp:106] Iteration 2179, lr = 0.0005
I1110 23:38:09.031615  2593 solver.cpp:295] Iteration 2180 (no loss supplied for SingleUpdateStep)
I1110 23:38:09.031747  2593 solver.cpp:310]     Train net output #0: loss = 0.458243 (* 1 = 0.458243 loss)
I1110 23:38:09.031769  2593 sgd_solver.cpp:106] Iteration 2180, lr = 0.0005
I1110 23:38:11.531558  2593 solver.cpp:295] Iteration 2181 (no loss supplied for SingleUpdateStep)
I1110 23:38:11.531608  2593 solver.cpp:310]     Train net output #0: loss = 0.447324 (* 1 = 0.447324 loss)
I1110 23:38:11.531626  2593 sgd_solver.cpp:106] Iteration 2181, lr = 0.0005
I1110 23:38:14.628758  2593 solver.cpp:295] Iteration 2182 (no loss supplied for SingleUpdateStep)
I1110 23:38:14.628880  2593 solver.cpp:310]     Train net output #0: loss = 0.435901 (* 1 = 0.435901 loss)
I1110 23:38:14.628904  2593 sgd_solver.cpp:106] Iteration 2182, lr = 0.0005
I1110 23:38:16.984555  2593 solver.cpp:295] Iteration 2183 (no loss supplied for SingleUpdateStep)
I1110 23:38:16.984661  2593 solver.cpp:310]     Train net output #0: loss = 0.460335 (* 1 = 0.460335 loss)
I1110 23:38:16.984683  2593 sgd_solver.cpp:106] Iteration 2183, lr = 0.0005
I1110 23:38:19.279512  2593 solver.cpp:295] Iteration 2184 (no loss supplied for SingleUpdateStep)
I1110 23:38:19.279613  2593 solver.cpp:310]     Train net output #0: loss = 0.441503 (* 1 = 0.441503 loss)
I1110 23:38:19.279633  2593 sgd_solver.cpp:106] Iteration 2184, lr = 0.0005
I1110 23:38:21.548290  2593 solver.cpp:295] Iteration 2185 (no loss supplied for SingleUpdateStep)
I1110 23:38:21.548398  2593 solver.cpp:310]     Train net output #0: loss = 0.42336 (* 1 = 0.42336 loss)
I1110 23:38:21.548421  2593 sgd_solver.cpp:106] Iteration 2185, lr = 0.0005
I1110 23:38:23.862507  2593 solver.cpp:295] Iteration 2186 (no loss supplied for SingleUpdateStep)
I1110 23:38:23.862562  2593 solver.cpp:310]     Train net output #0: loss = 0.393017 (* 1 = 0.393017 loss)
I1110 23:38:23.862579  2593 sgd_solver.cpp:106] Iteration 2186, lr = 0.0005
I1110 23:38:26.167590  2593 solver.cpp:295] Iteration 2187 (no loss supplied for SingleUpdateStep)
I1110 23:38:26.167680  2593 solver.cpp:310]     Train net output #0: loss = 0.442299 (* 1 = 0.442299 loss)
I1110 23:38:26.167701  2593 sgd_solver.cpp:106] Iteration 2187, lr = 0.0005
I1110 23:38:28.505120  2593 solver.cpp:295] Iteration 2188 (no loss supplied for SingleUpdateStep)
I1110 23:38:28.505223  2593 solver.cpp:310]     Train net output #0: loss = 0.476481 (* 1 = 0.476481 loss)
I1110 23:38:28.505245  2593 sgd_solver.cpp:106] Iteration 2188, lr = 0.0005
I1110 23:38:30.939618  2593 solver.cpp:295] Iteration 2189 (no loss supplied for SingleUpdateStep)
I1110 23:38:30.939688  2593 solver.cpp:310]     Train net output #0: loss = 0.443068 (* 1 = 0.443068 loss)
I1110 23:38:30.939710  2593 sgd_solver.cpp:106] Iteration 2189, lr = 0.0005
I1110 23:38:33.299377  2593 solver.cpp:295] Iteration 2190 (no loss supplied for SingleUpdateStep)
I1110 23:38:33.299504  2593 solver.cpp:310]     Train net output #0: loss = 0.434202 (* 1 = 0.434202 loss)
I1110 23:38:33.299531  2593 sgd_solver.cpp:106] Iteration 2190, lr = 0.0005
I1110 23:38:35.558568  2593 solver.cpp:295] Iteration 2191 (no loss supplied for SingleUpdateStep)
I1110 23:38:35.558624  2593 solver.cpp:310]     Train net output #0: loss = 0.437784 (* 1 = 0.437784 loss)
I1110 23:38:35.558641  2593 sgd_solver.cpp:106] Iteration 2191, lr = 0.0005
I1110 23:38:37.892920  2593 solver.cpp:295] Iteration 2192 (no loss supplied for SingleUpdateStep)
I1110 23:38:37.893018  2593 solver.cpp:310]     Train net output #0: loss = 0.460468 (* 1 = 0.460468 loss)
I1110 23:38:37.893039  2593 sgd_solver.cpp:106] Iteration 2192, lr = 0.0005
I1110 23:38:40.190865  2593 solver.cpp:295] Iteration 2193 (no loss supplied for SingleUpdateStep)
I1110 23:38:40.190971  2593 solver.cpp:310]     Train net output #0: loss = 0.447789 (* 1 = 0.447789 loss)
I1110 23:38:40.190992  2593 sgd_solver.cpp:106] Iteration 2193, lr = 0.0005
I1110 23:38:42.369675  2593 solver.cpp:295] Iteration 2194 (no loss supplied for SingleUpdateStep)
I1110 23:38:42.369837  2593 solver.cpp:310]     Train net output #0: loss = 0.434296 (* 1 = 0.434296 loss)
I1110 23:38:42.369866  2593 sgd_solver.cpp:106] Iteration 2194, lr = 0.0005
I1110 23:38:44.941268  2593 solver.cpp:295] Iteration 2195 (no loss supplied for SingleUpdateStep)
I1110 23:38:44.941431  2593 solver.cpp:310]     Train net output #0: loss = 0.422204 (* 1 = 0.422204 loss)
I1110 23:38:44.941462  2593 sgd_solver.cpp:106] Iteration 2195, lr = 0.0005
I1110 23:38:47.339494  2593 solver.cpp:295] Iteration 2196 (no loss supplied for SingleUpdateStep)
I1110 23:38:47.339578  2593 solver.cpp:310]     Train net output #0: loss = 0.450224 (* 1 = 0.450224 loss)
I1110 23:38:47.339598  2593 sgd_solver.cpp:106] Iteration 2196, lr = 0.0005
I1110 23:38:49.652004  2593 solver.cpp:295] Iteration 2197 (no loss supplied for SingleUpdateStep)
I1110 23:38:49.652158  2593 solver.cpp:310]     Train net output #0: loss = 0.480735 (* 1 = 0.480735 loss)
I1110 23:38:49.652180  2593 sgd_solver.cpp:106] Iteration 2197, lr = 0.0005
I1110 23:38:52.088268  2593 solver.cpp:295] Iteration 2198 (no loss supplied for SingleUpdateStep)
I1110 23:38:52.088388  2593 solver.cpp:310]     Train net output #0: loss = 0.422096 (* 1 = 0.422096 loss)
I1110 23:38:52.088412  2593 sgd_solver.cpp:106] Iteration 2198, lr = 0.0005
I1110 23:38:54.569000  2593 solver.cpp:295] Iteration 2199 (no loss supplied for SingleUpdateStep)
I1110 23:38:54.569139  2593 solver.cpp:310]     Train net output #0: loss = 0.424251 (* 1 = 0.424251 loss)
I1110 23:38:54.569162  2593 sgd_solver.cpp:106] Iteration 2199, lr = 0.0005
I1110 23:38:56.908459  2593 solver.cpp:295] Iteration 2200 (no loss supplied for SingleUpdateStep)
I1110 23:38:56.908552  2593 solver.cpp:310]     Train net output #0: loss = 0.438977 (* 1 = 0.438977 loss)
I1110 23:38:56.908574  2593 sgd_solver.cpp:106] Iteration 2200, lr = 0.0005
I1110 23:38:59.194903  2593 solver.cpp:295] Iteration 2201 (no loss supplied for SingleUpdateStep)
I1110 23:38:59.195024  2593 solver.cpp:310]     Train net output #0: loss = 0.441567 (* 1 = 0.441567 loss)
I1110 23:38:59.195052  2593 sgd_solver.cpp:106] Iteration 2201, lr = 0.0005
I1110 23:39:01.494645  2593 solver.cpp:295] Iteration 2202 (no loss supplied for SingleUpdateStep)
I1110 23:39:01.494778  2593 solver.cpp:310]     Train net output #0: loss = 0.419871 (* 1 = 0.419871 loss)
I1110 23:39:01.494801  2593 sgd_solver.cpp:106] Iteration 2202, lr = 0.0005
I1110 23:39:03.795589  2593 solver.cpp:295] Iteration 2203 (no loss supplied for SingleUpdateStep)
I1110 23:39:03.795702  2593 solver.cpp:310]     Train net output #0: loss = 0.478249 (* 1 = 0.478249 loss)
I1110 23:39:03.795727  2593 sgd_solver.cpp:106] Iteration 2203, lr = 0.0005
I1110 23:39:06.251886  2593 solver.cpp:295] Iteration 2204 (no loss supplied for SingleUpdateStep)
I1110 23:39:06.251991  2593 solver.cpp:310]     Train net output #0: loss = 0.43283 (* 1 = 0.43283 loss)
I1110 23:39:06.252017  2593 sgd_solver.cpp:106] Iteration 2204, lr = 0.0005
I1110 23:39:08.918416  2593 solver.cpp:295] Iteration 2205 (no loss supplied for SingleUpdateStep)
I1110 23:39:08.918540  2593 solver.cpp:310]     Train net output #0: loss = 0.402337 (* 1 = 0.402337 loss)
I1110 23:39:08.918562  2593 sgd_solver.cpp:106] Iteration 2205, lr = 0.0005
I1110 23:39:11.427047  2593 solver.cpp:295] Iteration 2206 (no loss supplied for SingleUpdateStep)
I1110 23:39:11.427129  2593 solver.cpp:310]     Train net output #0: loss = 0.402826 (* 1 = 0.402826 loss)
I1110 23:39:11.427150  2593 sgd_solver.cpp:106] Iteration 2206, lr = 0.0005
I1110 23:39:13.782407  2593 solver.cpp:295] Iteration 2207 (no loss supplied for SingleUpdateStep)
I1110 23:39:13.782572  2593 solver.cpp:310]     Train net output #0: loss = 0.445373 (* 1 = 0.445373 loss)
I1110 23:39:13.782603  2593 sgd_solver.cpp:106] Iteration 2207, lr = 0.0005
I1110 23:39:16.439563  2593 solver.cpp:295] Iteration 2208 (no loss supplied for SingleUpdateStep)
I1110 23:39:16.439635  2593 solver.cpp:310]     Train net output #0: loss = 0.431874 (* 1 = 0.431874 loss)
I1110 23:39:16.439656  2593 sgd_solver.cpp:106] Iteration 2208, lr = 0.0005
I1110 23:39:18.716856  2593 solver.cpp:295] Iteration 2209 (no loss supplied for SingleUpdateStep)
I1110 23:39:18.716979  2593 solver.cpp:310]     Train net output #0: loss = 0.413937 (* 1 = 0.413937 loss)
I1110 23:39:18.717001  2593 sgd_solver.cpp:106] Iteration 2209, lr = 0.0005
I1110 23:39:20.922572  2593 solver.cpp:295] Iteration 2210 (no loss supplied for SingleUpdateStep)
I1110 23:39:20.922662  2593 solver.cpp:310]     Train net output #0: loss = 0.483535 (* 1 = 0.483535 loss)
I1110 23:39:20.922683  2593 sgd_solver.cpp:106] Iteration 2210, lr = 0.0005
I1110 23:39:23.296612  2593 solver.cpp:295] Iteration 2211 (no loss supplied for SingleUpdateStep)
I1110 23:39:23.296710  2593 solver.cpp:310]     Train net output #0: loss = 0.435476 (* 1 = 0.435476 loss)
I1110 23:39:23.296732  2593 sgd_solver.cpp:106] Iteration 2211, lr = 0.0005
I1110 23:39:25.848137  2593 solver.cpp:295] Iteration 2212 (no loss supplied for SingleUpdateStep)
I1110 23:39:25.848209  2593 solver.cpp:310]     Train net output #0: loss = 0.467858 (* 1 = 0.467858 loss)
I1110 23:39:25.848232  2593 sgd_solver.cpp:106] Iteration 2212, lr = 0.0005
I1110 23:39:28.290385  2593 solver.cpp:295] Iteration 2213 (no loss supplied for SingleUpdateStep)
I1110 23:39:28.290504  2593 solver.cpp:310]     Train net output #0: loss = 0.449861 (* 1 = 0.449861 loss)
I1110 23:39:28.290529  2593 sgd_solver.cpp:106] Iteration 2213, lr = 0.0005
I1110 23:39:30.822856  2593 solver.cpp:295] Iteration 2214 (no loss supplied for SingleUpdateStep)
I1110 23:39:30.823014  2593 solver.cpp:310]     Train net output #0: loss = 0.429903 (* 1 = 0.429903 loss)
I1110 23:39:30.823043  2593 sgd_solver.cpp:106] Iteration 2214, lr = 0.0005
I1110 23:39:33.075525  2593 solver.cpp:295] Iteration 2215 (no loss supplied for SingleUpdateStep)
I1110 23:39:33.075635  2593 solver.cpp:310]     Train net output #0: loss = 0.44441 (* 1 = 0.44441 loss)
I1110 23:39:33.075662  2593 sgd_solver.cpp:106] Iteration 2215, lr = 0.0005
I1110 23:39:35.444947  2593 solver.cpp:295] Iteration 2216 (no loss supplied for SingleUpdateStep)
I1110 23:39:35.445061  2593 solver.cpp:310]     Train net output #0: loss = 0.441393 (* 1 = 0.441393 loss)
I1110 23:39:35.445085  2593 sgd_solver.cpp:106] Iteration 2216, lr = 0.0005
I1110 23:39:37.895418  2593 solver.cpp:295] Iteration 2217 (no loss supplied for SingleUpdateStep)
I1110 23:39:37.895519  2593 solver.cpp:310]     Train net output #0: loss = 0.490489 (* 1 = 0.490489 loss)
I1110 23:39:37.895540  2593 sgd_solver.cpp:106] Iteration 2217, lr = 0.0005
I1110 23:39:40.228567  2593 solver.cpp:295] Iteration 2218 (no loss supplied for SingleUpdateStep)
I1110 23:39:40.228665  2593 solver.cpp:310]     Train net output #0: loss = 0.430389 (* 1 = 0.430389 loss)
I1110 23:39:40.228688  2593 sgd_solver.cpp:106] Iteration 2218, lr = 0.0005
I1110 23:39:42.609325  2593 solver.cpp:295] Iteration 2219 (no loss supplied for SingleUpdateStep)
I1110 23:39:42.609391  2593 solver.cpp:310]     Train net output #0: loss = 0.448351 (* 1 = 0.448351 loss)
I1110 23:39:42.609411  2593 sgd_solver.cpp:106] Iteration 2219, lr = 0.0005
I1110 23:39:44.892998  2593 solver.cpp:295] Iteration 2220 (no loss supplied for SingleUpdateStep)
I1110 23:39:44.893065  2593 solver.cpp:310]     Train net output #0: loss = 0.435641 (* 1 = 0.435641 loss)
I1110 23:39:44.893084  2593 sgd_solver.cpp:106] Iteration 2220, lr = 0.0005
I1110 23:39:47.453644  2593 solver.cpp:295] Iteration 2221 (no loss supplied for SingleUpdateStep)
I1110 23:39:47.453728  2593 solver.cpp:310]     Train net output #0: loss = 0.408535 (* 1 = 0.408535 loss)
I1110 23:39:47.453750  2593 sgd_solver.cpp:106] Iteration 2221, lr = 0.0005
I1110 23:39:49.838538  2593 solver.cpp:295] Iteration 2222 (no loss supplied for SingleUpdateStep)
I1110 23:39:49.838640  2593 solver.cpp:310]     Train net output #0: loss = 0.450927 (* 1 = 0.450927 loss)
I1110 23:39:49.838661  2593 sgd_solver.cpp:106] Iteration 2222, lr = 0.0005
I1110 23:39:52.169543  2593 solver.cpp:295] Iteration 2223 (no loss supplied for SingleUpdateStep)
I1110 23:39:52.169644  2593 solver.cpp:310]     Train net output #0: loss = 0.430614 (* 1 = 0.430614 loss)
I1110 23:39:52.169667  2593 sgd_solver.cpp:106] Iteration 2223, lr = 0.0005
I1110 23:39:54.600383  2593 solver.cpp:295] Iteration 2224 (no loss supplied for SingleUpdateStep)
I1110 23:39:54.600528  2593 solver.cpp:310]     Train net output #0: loss = 0.479096 (* 1 = 0.479096 loss)
I1110 23:39:54.600551  2593 sgd_solver.cpp:106] Iteration 2224, lr = 0.0005
I1110 23:39:56.923642  2593 solver.cpp:295] Iteration 2225 (no loss supplied for SingleUpdateStep)
I1110 23:39:56.923743  2593 solver.cpp:310]     Train net output #0: loss = 0.464807 (* 1 = 0.464807 loss)
I1110 23:39:56.923774  2593 sgd_solver.cpp:106] Iteration 2225, lr = 0.0005
I1110 23:39:59.389135  2593 solver.cpp:295] Iteration 2226 (no loss supplied for SingleUpdateStep)
I1110 23:39:59.389228  2593 solver.cpp:310]     Train net output #0: loss = 0.422213 (* 1 = 0.422213 loss)
I1110 23:39:59.389248  2593 sgd_solver.cpp:106] Iteration 2226, lr = 0.0005
I1110 23:40:01.722576  2593 solver.cpp:295] Iteration 2227 (no loss supplied for SingleUpdateStep)
I1110 23:40:01.722692  2593 solver.cpp:310]     Train net output #0: loss = 0.454423 (* 1 = 0.454423 loss)
I1110 23:40:01.722714  2593 sgd_solver.cpp:106] Iteration 2227, lr = 0.0005
I1110 23:40:04.040457  2593 solver.cpp:295] Iteration 2228 (no loss supplied for SingleUpdateStep)
I1110 23:40:04.040554  2593 solver.cpp:310]     Train net output #0: loss = 0.448072 (* 1 = 0.448072 loss)
I1110 23:40:04.040576  2593 sgd_solver.cpp:106] Iteration 2228, lr = 0.0005
I1110 23:40:06.478705  2593 solver.cpp:295] Iteration 2229 (no loss supplied for SingleUpdateStep)
I1110 23:40:06.478785  2593 solver.cpp:310]     Train net output #0: loss = 0.450827 (* 1 = 0.450827 loss)
I1110 23:40:06.478811  2593 sgd_solver.cpp:106] Iteration 2229, lr = 0.0005
I1110 23:40:09.167707  2593 solver.cpp:295] Iteration 2230 (no loss supplied for SingleUpdateStep)
I1110 23:40:09.167789  2593 solver.cpp:310]     Train net output #0: loss = 0.4584 (* 1 = 0.4584 loss)
I1110 23:40:09.167809  2593 sgd_solver.cpp:106] Iteration 2230, lr = 0.0005
I1110 23:40:12.646479  2593 solver.cpp:295] Iteration 2231 (no loss supplied for SingleUpdateStep)
I1110 23:40:12.646615  2593 solver.cpp:310]     Train net output #0: loss = 0.417235 (* 1 = 0.417235 loss)
I1110 23:40:12.646637  2593 sgd_solver.cpp:106] Iteration 2231, lr = 0.0005
I1110 23:40:15.580530  2593 solver.cpp:295] Iteration 2232 (no loss supplied for SingleUpdateStep)
I1110 23:40:15.580631  2593 solver.cpp:310]     Train net output #0: loss = 0.461612 (* 1 = 0.461612 loss)
I1110 23:40:15.580652  2593 sgd_solver.cpp:106] Iteration 2232, lr = 0.0005
I1110 23:40:19.043396  2593 solver.cpp:295] Iteration 2233 (no loss supplied for SingleUpdateStep)
I1110 23:40:19.043509  2593 solver.cpp:310]     Train net output #0: loss = 0.458195 (* 1 = 0.458195 loss)
I1110 23:40:19.043536  2593 sgd_solver.cpp:106] Iteration 2233, lr = 0.0005
I1110 23:40:22.352612  2593 solver.cpp:295] Iteration 2234 (no loss supplied for SingleUpdateStep)
I1110 23:40:22.352715  2593 solver.cpp:310]     Train net output #0: loss = 0.437315 (* 1 = 0.437315 loss)
I1110 23:40:22.352736  2593 sgd_solver.cpp:106] Iteration 2234, lr = 0.0005
I1110 23:40:26.056291  2593 solver.cpp:295] Iteration 2235 (no loss supplied for SingleUpdateStep)
I1110 23:40:26.056351  2593 solver.cpp:310]     Train net output #0: loss = 0.451701 (* 1 = 0.451701 loss)
I1110 23:40:26.056370  2593 sgd_solver.cpp:106] Iteration 2235, lr = 0.0005
I1110 23:40:30.193737  2593 solver.cpp:295] Iteration 2236 (no loss supplied for SingleUpdateStep)
I1110 23:40:30.193881  2593 solver.cpp:310]     Train net output #0: loss = 0.453688 (* 1 = 0.453688 loss)
I1110 23:40:30.193902  2593 sgd_solver.cpp:106] Iteration 2236, lr = 0.0005
I1110 23:40:33.718842  2593 solver.cpp:295] Iteration 2237 (no loss supplied for SingleUpdateStep)
I1110 23:40:33.718955  2593 solver.cpp:310]     Train net output #0: loss = 0.452696 (* 1 = 0.452696 loss)
I1110 23:40:33.718974  2593 sgd_solver.cpp:106] Iteration 2237, lr = 0.0005
I1110 23:40:36.466907  2593 solver.cpp:295] Iteration 2238 (no loss supplied for SingleUpdateStep)
I1110 23:40:36.466995  2593 solver.cpp:310]     Train net output #0: loss = 0.4496 (* 1 = 0.4496 loss)
I1110 23:40:36.467016  2593 sgd_solver.cpp:106] Iteration 2238, lr = 0.0005
I1110 23:40:39.015027  2593 solver.cpp:295] Iteration 2239 (no loss supplied for SingleUpdateStep)
I1110 23:40:39.124241  2593 solver.cpp:310]     Train net output #0: loss = 0.43963 (* 1 = 0.43963 loss)
I1110 23:40:39.124301  2593 sgd_solver.cpp:106] Iteration 2239, lr = 0.0005
I1110 23:40:41.505213  2593 solver.cpp:295] Iteration 2240 (no loss supplied for SingleUpdateStep)
I1110 23:40:41.505341  2593 solver.cpp:310]     Train net output #0: loss = 0.437699 (* 1 = 0.437699 loss)
I1110 23:40:41.505367  2593 sgd_solver.cpp:106] Iteration 2240, lr = 0.0005
I1110 23:40:43.934483  2593 solver.cpp:295] Iteration 2241 (no loss supplied for SingleUpdateStep)
I1110 23:40:43.934592  2593 solver.cpp:310]     Train net output #0: loss = 0.432235 (* 1 = 0.432235 loss)
I1110 23:40:43.934615  2593 sgd_solver.cpp:106] Iteration 2241, lr = 0.0005
I1110 23:40:46.702915  2593 solver.cpp:295] Iteration 2242 (no loss supplied for SingleUpdateStep)
I1110 23:40:46.702971  2593 solver.cpp:310]     Train net output #0: loss = 0.394063 (* 1 = 0.394063 loss)
I1110 23:40:46.702991  2593 sgd_solver.cpp:106] Iteration 2242, lr = 0.0005
I1110 23:40:49.314208  2593 solver.cpp:295] Iteration 2243 (no loss supplied for SingleUpdateStep)
I1110 23:40:49.314266  2593 solver.cpp:310]     Train net output #0: loss = 0.431601 (* 1 = 0.431601 loss)
I1110 23:40:49.314285  2593 sgd_solver.cpp:106] Iteration 2243, lr = 0.0005
I1110 23:40:52.159054  2593 solver.cpp:295] Iteration 2244 (no loss supplied for SingleUpdateStep)
I1110 23:40:52.159167  2593 solver.cpp:310]     Train net output #0: loss = 0.43785 (* 1 = 0.43785 loss)
I1110 23:40:52.159190  2593 sgd_solver.cpp:106] Iteration 2244, lr = 0.0005
I1110 23:40:54.632020  2593 solver.cpp:295] Iteration 2245 (no loss supplied for SingleUpdateStep)
I1110 23:40:54.632134  2593 solver.cpp:310]     Train net output #0: loss = 0.4602 (* 1 = 0.4602 loss)
I1110 23:40:54.632156  2593 sgd_solver.cpp:106] Iteration 2245, lr = 0.0005
I1110 23:40:57.103682  2593 solver.cpp:295] Iteration 2246 (no loss supplied for SingleUpdateStep)
I1110 23:40:57.103773  2593 solver.cpp:310]     Train net output #0: loss = 0.447203 (* 1 = 0.447203 loss)
I1110 23:40:57.103793  2593 sgd_solver.cpp:106] Iteration 2246, lr = 0.0005
I1110 23:40:59.924021  2593 solver.cpp:295] Iteration 2247 (no loss supplied for SingleUpdateStep)
I1110 23:40:59.924126  2593 solver.cpp:310]     Train net output #0: loss = 0.430003 (* 1 = 0.430003 loss)
I1110 23:40:59.924149  2593 sgd_solver.cpp:106] Iteration 2247, lr = 0.0005
I1110 23:41:02.402539  2593 solver.cpp:295] Iteration 2248 (no loss supplied for SingleUpdateStep)
I1110 23:41:02.402703  2593 solver.cpp:310]     Train net output #0: loss = 0.446689 (* 1 = 0.446689 loss)
I1110 23:41:02.402729  2593 sgd_solver.cpp:106] Iteration 2248, lr = 0.0005
I1110 23:41:04.930119  2593 solver.cpp:295] Iteration 2249 (no loss supplied for SingleUpdateStep)
I1110 23:41:04.930315  2593 solver.cpp:310]     Train net output #0: loss = 0.41262 (* 1 = 0.41262 loss)
I1110 23:41:04.930356  2593 sgd_solver.cpp:106] Iteration 2249, lr = 0.0005
I1110 23:41:07.337954  2593 solver.cpp:295] Iteration 2250 (no loss supplied for SingleUpdateStep)
I1110 23:41:07.338039  2593 solver.cpp:310]     Train net output #0: loss = 0.450974 (* 1 = 0.450974 loss)
I1110 23:41:07.338063  2593 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I1110 23:41:09.658872  2593 solver.cpp:295] Iteration 2251 (no loss supplied for SingleUpdateStep)
I1110 23:41:09.658992  2593 solver.cpp:310]     Train net output #0: loss = 0.47294 (* 1 = 0.47294 loss)
I1110 23:41:09.659013  2593 sgd_solver.cpp:106] Iteration 2251, lr = 0.0005
I1110 23:41:11.893594  2593 solver.cpp:295] Iteration 2252 (no loss supplied for SingleUpdateStep)
I1110 23:41:11.893707  2593 solver.cpp:310]     Train net output #0: loss = 0.46754 (* 1 = 0.46754 loss)
I1110 23:41:11.893729  2593 sgd_solver.cpp:106] Iteration 2252, lr = 0.0005
I1110 23:41:14.043385  2593 solver.cpp:295] Iteration 2253 (no loss supplied for SingleUpdateStep)
I1110 23:41:14.043483  2593 solver.cpp:310]     Train net output #0: loss = 0.457146 (* 1 = 0.457146 loss)
I1110 23:41:14.043504  2593 sgd_solver.cpp:106] Iteration 2253, lr = 0.0005
I1110 23:41:16.702529  2593 solver.cpp:295] Iteration 2254 (no loss supplied for SingleUpdateStep)
I1110 23:41:16.702607  2593 solver.cpp:310]     Train net output #0: loss = 0.422663 (* 1 = 0.422663 loss)
I1110 23:41:16.702628  2593 sgd_solver.cpp:106] Iteration 2254, lr = 0.0005
I1110 23:41:19.259184  2593 solver.cpp:295] Iteration 2255 (no loss supplied for SingleUpdateStep)
I1110 23:41:19.259274  2593 solver.cpp:310]     Train net output #0: loss = 0.423363 (* 1 = 0.423363 loss)
I1110 23:41:19.259294  2593 sgd_solver.cpp:106] Iteration 2255, lr = 0.0005
I1110 23:41:21.996942  2593 solver.cpp:295] Iteration 2256 (no loss supplied for SingleUpdateStep)
I1110 23:41:21.997119  2593 solver.cpp:310]     Train net output #0: loss = 0.448716 (* 1 = 0.448716 loss)
I1110 23:41:21.997158  2593 sgd_solver.cpp:106] Iteration 2256, lr = 0.0005
I1110 23:41:24.434682  2593 solver.cpp:295] Iteration 2257 (no loss supplied for SingleUpdateStep)
I1110 23:41:24.434902  2593 solver.cpp:310]     Train net output #0: loss = 0.486001 (* 1 = 0.486001 loss)
I1110 23:41:24.434928  2593 sgd_solver.cpp:106] Iteration 2257, lr = 0.0005
I1110 23:41:26.745306  2593 solver.cpp:295] Iteration 2258 (no loss supplied for SingleUpdateStep)
I1110 23:41:26.745442  2593 solver.cpp:310]     Train net output #0: loss = 0.432057 (* 1 = 0.432057 loss)
I1110 23:41:26.745468  2593 sgd_solver.cpp:106] Iteration 2258, lr = 0.0005
I1110 23:41:29.140998  2593 solver.cpp:295] Iteration 2259 (no loss supplied for SingleUpdateStep)
I1110 23:41:29.141055  2593 solver.cpp:310]     Train net output #0: loss = 0.454804 (* 1 = 0.454804 loss)
I1110 23:41:29.141073  2593 sgd_solver.cpp:106] Iteration 2259, lr = 0.0005
I1110 23:41:31.424702  2593 solver.cpp:295] Iteration 2260 (no loss supplied for SingleUpdateStep)
I1110 23:41:31.424852  2593 solver.cpp:310]     Train net output #0: loss = 0.429756 (* 1 = 0.429756 loss)
I1110 23:41:31.424876  2593 sgd_solver.cpp:106] Iteration 2260, lr = 0.0005
I1110 23:41:33.800202  2593 solver.cpp:295] Iteration 2261 (no loss supplied for SingleUpdateStep)
I1110 23:41:33.800307  2593 solver.cpp:310]     Train net output #0: loss = 0.458405 (* 1 = 0.458405 loss)
I1110 23:41:33.800328  2593 sgd_solver.cpp:106] Iteration 2261, lr = 0.0005
I1110 23:41:36.138322  2593 solver.cpp:295] Iteration 2262 (no loss supplied for SingleUpdateStep)
I1110 23:41:36.138416  2593 solver.cpp:310]     Train net output #0: loss = 0.474049 (* 1 = 0.474049 loss)
I1110 23:41:36.138438  2593 sgd_solver.cpp:106] Iteration 2262, lr = 0.0005
I1110 23:41:38.429677  2593 solver.cpp:295] Iteration 2263 (no loss supplied for SingleUpdateStep)
I1110 23:41:38.429800  2593 solver.cpp:310]     Train net output #0: loss = 0.419773 (* 1 = 0.419773 loss)
I1110 23:41:38.429826  2593 sgd_solver.cpp:106] Iteration 2263, lr = 0.0005
I1110 23:41:40.809988  2593 solver.cpp:295] Iteration 2264 (no loss supplied for SingleUpdateStep)
I1110 23:41:40.810086  2593 solver.cpp:310]     Train net output #0: loss = 0.401299 (* 1 = 0.401299 loss)
I1110 23:41:40.810107  2593 sgd_solver.cpp:106] Iteration 2264, lr = 0.0005
I1110 23:41:43.154922  2593 solver.cpp:295] Iteration 2265 (no loss supplied for SingleUpdateStep)
I1110 23:41:43.155076  2593 solver.cpp:310]     Train net output #0: loss = 0.436199 (* 1 = 0.436199 loss)
I1110 23:41:43.155098  2593 sgd_solver.cpp:106] Iteration 2265, lr = 0.0005
I1110 23:41:45.568908  2593 solver.cpp:295] Iteration 2266 (no loss supplied for SingleUpdateStep)
I1110 23:41:45.569092  2593 solver.cpp:310]     Train net output #0: loss = 0.448406 (* 1 = 0.448406 loss)
I1110 23:41:45.569128  2593 sgd_solver.cpp:106] Iteration 2266, lr = 0.0005
I1110 23:41:47.923874  2593 solver.cpp:295] Iteration 2267 (no loss supplied for SingleUpdateStep)
I1110 23:41:47.923954  2593 solver.cpp:310]     Train net output #0: loss = 0.426834 (* 1 = 0.426834 loss)
I1110 23:41:47.923975  2593 sgd_solver.cpp:106] Iteration 2267, lr = 0.0005
I1110 23:41:50.443439  2593 solver.cpp:295] Iteration 2268 (no loss supplied for SingleUpdateStep)
I1110 23:41:50.443514  2593 solver.cpp:310]     Train net output #0: loss = 0.424924 (* 1 = 0.424924 loss)
I1110 23:41:50.443536  2593 sgd_solver.cpp:106] Iteration 2268, lr = 0.0005
I1110 23:41:52.720146  2593 solver.cpp:295] Iteration 2269 (no loss supplied for SingleUpdateStep)
I1110 23:41:52.720262  2593 solver.cpp:310]     Train net output #0: loss = 0.413794 (* 1 = 0.413794 loss)
I1110 23:41:52.720286  2593 sgd_solver.cpp:106] Iteration 2269, lr = 0.0005
I1110 23:41:55.298336  2593 solver.cpp:295] Iteration 2270 (no loss supplied for SingleUpdateStep)
I1110 23:41:55.298468  2593 solver.cpp:310]     Train net output #0: loss = 0.443385 (* 1 = 0.443385 loss)
I1110 23:41:55.298497  2593 sgd_solver.cpp:106] Iteration 2270, lr = 0.0005
I1110 23:41:57.554548  2593 solver.cpp:295] Iteration 2271 (no loss supplied for SingleUpdateStep)
I1110 23:41:57.554661  2593 solver.cpp:310]     Train net output #0: loss = 0.402024 (* 1 = 0.402024 loss)
I1110 23:41:57.554683  2593 sgd_solver.cpp:106] Iteration 2271, lr = 0.0005
I1110 23:41:59.923995  2593 solver.cpp:295] Iteration 2272 (no loss supplied for SingleUpdateStep)
I1110 23:41:59.924101  2593 solver.cpp:310]     Train net output #0: loss = 0.398139 (* 1 = 0.398139 loss)
I1110 23:41:59.924123  2593 sgd_solver.cpp:106] Iteration 2272, lr = 0.0005
I1110 23:42:02.153775  2593 solver.cpp:295] Iteration 2273 (no loss supplied for SingleUpdateStep)
I1110 23:42:02.153846  2593 solver.cpp:310]     Train net output #0: loss = 0.450754 (* 1 = 0.450754 loss)
I1110 23:42:02.153866  2593 sgd_solver.cpp:106] Iteration 2273, lr = 0.0005
I1110 23:42:04.484115  2593 solver.cpp:295] Iteration 2274 (no loss supplied for SingleUpdateStep)
I1110 23:42:04.484205  2593 solver.cpp:310]     Train net output #0: loss = 0.405803 (* 1 = 0.405803 loss)
I1110 23:42:04.484222  2593 sgd_solver.cpp:106] Iteration 2274, lr = 0.0005
I1110 23:42:06.790271  2593 solver.cpp:295] Iteration 2275 (no loss supplied for SingleUpdateStep)
I1110 23:42:06.790375  2593 solver.cpp:310]     Train net output #0: loss = 0.424984 (* 1 = 0.424984 loss)
I1110 23:42:06.790395  2593 sgd_solver.cpp:106] Iteration 2275, lr = 0.0005
I1110 23:42:09.508123  2593 solver.cpp:295] Iteration 2276 (no loss supplied for SingleUpdateStep)
I1110 23:42:09.508226  2593 solver.cpp:310]     Train net output #0: loss = 0.436376 (* 1 = 0.436376 loss)
I1110 23:42:09.508251  2593 sgd_solver.cpp:106] Iteration 2276, lr = 0.0005
I1110 23:42:12.148735  2593 solver.cpp:295] Iteration 2277 (no loss supplied for SingleUpdateStep)
I1110 23:42:12.148926  2593 solver.cpp:310]     Train net output #0: loss = 0.404491 (* 1 = 0.404491 loss)
I1110 23:42:12.148951  2593 sgd_solver.cpp:106] Iteration 2277, lr = 0.0005
I1110 23:42:14.565105  2593 solver.cpp:295] Iteration 2278 (no loss supplied for SingleUpdateStep)
I1110 23:42:14.565230  2593 solver.cpp:310]     Train net output #0: loss = 0.438232 (* 1 = 0.438232 loss)
I1110 23:42:14.565254  2593 sgd_solver.cpp:106] Iteration 2278, lr = 0.0005
I1110 23:42:17.066220  2593 solver.cpp:295] Iteration 2279 (no loss supplied for SingleUpdateStep)
I1110 23:42:17.066332  2593 solver.cpp:310]     Train net output #0: loss = 0.416285 (* 1 = 0.416285 loss)
I1110 23:42:17.066354  2593 sgd_solver.cpp:106] Iteration 2279, lr = 0.0005
I1110 23:42:19.403642  2593 solver.cpp:295] Iteration 2280 (no loss supplied for SingleUpdateStep)
I1110 23:42:19.403707  2593 solver.cpp:310]     Train net output #0: loss = 0.432862 (* 1 = 0.432862 loss)
I1110 23:42:19.403728  2593 sgd_solver.cpp:106] Iteration 2280, lr = 0.0005
I1110 23:42:21.667462  2593 solver.cpp:295] Iteration 2281 (no loss supplied for SingleUpdateStep)
I1110 23:42:21.667552  2593 solver.cpp:310]     Train net output #0: loss = 0.433615 (* 1 = 0.433615 loss)
I1110 23:42:21.667573  2593 sgd_solver.cpp:106] Iteration 2281, lr = 0.0005
I1110 23:42:23.935551  2593 solver.cpp:295] Iteration 2282 (no loss supplied for SingleUpdateStep)
I1110 23:42:23.935672  2593 solver.cpp:310]     Train net output #0: loss = 0.430089 (* 1 = 0.430089 loss)
I1110 23:42:23.935696  2593 sgd_solver.cpp:106] Iteration 2282, lr = 0.0005
I1110 23:42:26.310426  2593 solver.cpp:295] Iteration 2283 (no loss supplied for SingleUpdateStep)
I1110 23:42:26.310562  2593 solver.cpp:310]     Train net output #0: loss = 0.414625 (* 1 = 0.414625 loss)
I1110 23:42:26.310585  2593 sgd_solver.cpp:106] Iteration 2283, lr = 0.0005
I1110 23:42:28.706863  2593 solver.cpp:295] Iteration 2284 (no loss supplied for SingleUpdateStep)
I1110 23:42:28.706977  2593 solver.cpp:310]     Train net output #0: loss = 0.428726 (* 1 = 0.428726 loss)
I1110 23:42:28.707000  2593 sgd_solver.cpp:106] Iteration 2284, lr = 0.0005
I1110 23:42:31.104965  2593 solver.cpp:295] Iteration 2285 (no loss supplied for SingleUpdateStep)
I1110 23:42:31.105023  2593 solver.cpp:310]     Train net output #0: loss = 0.457284 (* 1 = 0.457284 loss)
I1110 23:42:31.105041  2593 sgd_solver.cpp:106] Iteration 2285, lr = 0.0005
I1110 23:42:33.586014  2593 solver.cpp:295] Iteration 2286 (no loss supplied for SingleUpdateStep)
I1110 23:42:33.586134  2593 solver.cpp:310]     Train net output #0: loss = 0.460039 (* 1 = 0.460039 loss)
I1110 23:42:33.586158  2593 sgd_solver.cpp:106] Iteration 2286, lr = 0.0005
I1110 23:42:35.873070  2593 solver.cpp:295] Iteration 2287 (no loss supplied for SingleUpdateStep)
I1110 23:42:35.873178  2593 solver.cpp:310]     Train net output #0: loss = 0.455447 (* 1 = 0.455447 loss)
I1110 23:42:35.873201  2593 sgd_solver.cpp:106] Iteration 2287, lr = 0.0005
I1110 23:42:38.237249  2593 solver.cpp:295] Iteration 2288 (no loss supplied for SingleUpdateStep)
I1110 23:42:38.237416  2593 solver.cpp:310]     Train net output #0: loss = 0.414992 (* 1 = 0.414992 loss)
I1110 23:42:38.237449  2593 sgd_solver.cpp:106] Iteration 2288, lr = 0.0005
I1110 23:42:40.525770  2593 solver.cpp:295] Iteration 2289 (no loss supplied for SingleUpdateStep)
I1110 23:42:40.525847  2593 solver.cpp:310]     Train net output #0: loss = 0.426577 (* 1 = 0.426577 loss)
I1110 23:42:40.525867  2593 sgd_solver.cpp:106] Iteration 2289, lr = 0.0005
I1110 23:42:42.774971  2593 solver.cpp:295] Iteration 2290 (no loss supplied for SingleUpdateStep)
I1110 23:42:42.775034  2593 solver.cpp:310]     Train net output #0: loss = 0.448963 (* 1 = 0.448963 loss)
I1110 23:42:42.775053  2593 sgd_solver.cpp:106] Iteration 2290, lr = 0.0005
I1110 23:42:45.038745  2593 solver.cpp:295] Iteration 2291 (no loss supplied for SingleUpdateStep)
I1110 23:42:45.038812  2593 solver.cpp:310]     Train net output #0: loss = 0.447272 (* 1 = 0.447272 loss)
I1110 23:42:45.038832  2593 sgd_solver.cpp:106] Iteration 2291, lr = 0.0005
I1110 23:42:47.175401  2593 solver.cpp:295] Iteration 2292 (no loss supplied for SingleUpdateStep)
I1110 23:42:47.175482  2593 solver.cpp:310]     Train net output #0: loss = 0.419859 (* 1 = 0.419859 loss)
I1110 23:42:47.175503  2593 sgd_solver.cpp:106] Iteration 2292, lr = 0.0005
I1110 23:42:49.346678  2593 solver.cpp:295] Iteration 2293 (no loss supplied for SingleUpdateStep)
I1110 23:42:49.346740  2593 solver.cpp:310]     Train net output #0: loss = 0.419501 (* 1 = 0.419501 loss)
I1110 23:42:49.346757  2593 sgd_solver.cpp:106] Iteration 2293, lr = 0.0005
I1110 23:42:51.396191  2593 solver.cpp:295] Iteration 2294 (no loss supplied for SingleUpdateStep)
I1110 23:42:51.396319  2593 solver.cpp:310]     Train net output #0: loss = 0.427314 (* 1 = 0.427314 loss)
I1110 23:42:51.396342  2593 sgd_solver.cpp:106] Iteration 2294, lr = 0.0005
I1110 23:42:53.549775  2593 solver.cpp:295] Iteration 2295 (no loss supplied for SingleUpdateStep)
I1110 23:42:53.549844  2593 solver.cpp:310]     Train net output #0: loss = 0.423871 (* 1 = 0.423871 loss)
I1110 23:42:53.549862  2593 sgd_solver.cpp:106] Iteration 2295, lr = 0.0005
I1110 23:42:55.782919  2593 solver.cpp:295] Iteration 2296 (no loss supplied for SingleUpdateStep)
I1110 23:42:55.782975  2593 solver.cpp:310]     Train net output #0: loss = 0.441531 (* 1 = 0.441531 loss)
I1110 23:42:55.782994  2593 sgd_solver.cpp:106] Iteration 2296, lr = 0.0005
I1110 23:42:58.064472  2593 solver.cpp:295] Iteration 2297 (no loss supplied for SingleUpdateStep)
I1110 23:42:58.064532  2593 solver.cpp:310]     Train net output #0: loss = 0.42785 (* 1 = 0.42785 loss)
I1110 23:42:58.064551  2593 sgd_solver.cpp:106] Iteration 2297, lr = 0.0005
I1110 23:43:00.455267  2593 solver.cpp:295] Iteration 2298 (no loss supplied for SingleUpdateStep)
I1110 23:43:00.455400  2593 solver.cpp:310]     Train net output #0: loss = 0.445697 (* 1 = 0.445697 loss)
I1110 23:43:00.455425  2593 sgd_solver.cpp:106] Iteration 2298, lr = 0.0005
I1110 23:43:02.634039  2593 solver.cpp:295] Iteration 2299 (no loss supplied for SingleUpdateStep)
I1110 23:43:02.634145  2593 solver.cpp:310]     Train net output #0: loss = 0.421247 (* 1 = 0.421247 loss)
I1110 23:43:02.634165  2593 sgd_solver.cpp:106] Iteration 2299, lr = 0.0005
I1110 23:43:05.014489  2593 solver.cpp:295] Iteration 2300 (no loss supplied for SingleUpdateStep)
I1110 23:43:05.014603  2593 solver.cpp:310]     Train net output #0: loss = 0.459055 (* 1 = 0.459055 loss)
I1110 23:43:05.014626  2593 sgd_solver.cpp:106] Iteration 2300, lr = 0.0005
I1110 23:43:07.367143  2593 solver.cpp:295] Iteration 2301 (no loss supplied for SingleUpdateStep)
I1110 23:43:07.367260  2593 solver.cpp:310]     Train net output #0: loss = 0.428408 (* 1 = 0.428408 loss)
I1110 23:43:07.367285  2593 sgd_solver.cpp:106] Iteration 2301, lr = 0.0005
I1110 23:43:09.662029  2593 solver.cpp:295] Iteration 2302 (no loss supplied for SingleUpdateStep)
I1110 23:43:09.662160  2593 solver.cpp:310]     Train net output #0: loss = 0.427315 (* 1 = 0.427315 loss)
I1110 23:43:09.662184  2593 sgd_solver.cpp:106] Iteration 2302, lr = 0.0005
I1110 23:43:11.834851  2593 solver.cpp:295] Iteration 2303 (no loss supplied for SingleUpdateStep)
I1110 23:43:11.834944  2593 solver.cpp:310]     Train net output #0: loss = 0.443496 (* 1 = 0.443496 loss)
I1110 23:43:11.834962  2593 sgd_solver.cpp:106] Iteration 2303, lr = 0.0005
I1110 23:43:14.169015  2593 solver.cpp:295] Iteration 2304 (no loss supplied for SingleUpdateStep)
I1110 23:43:14.169132  2593 solver.cpp:310]     Train net output #0: loss = 0.447206 (* 1 = 0.447206 loss)
I1110 23:43:14.169154  2593 sgd_solver.cpp:106] Iteration 2304, lr = 0.0005
I1110 23:43:16.453879  2593 solver.cpp:295] Iteration 2305 (no loss supplied for SingleUpdateStep)
I1110 23:43:16.454030  2593 solver.cpp:310]     Train net output #0: loss = 0.441794 (* 1 = 0.441794 loss)
I1110 23:43:16.454054  2593 sgd_solver.cpp:106] Iteration 2305, lr = 0.0005
I1110 23:43:18.843855  2593 solver.cpp:295] Iteration 2306 (no loss supplied for SingleUpdateStep)
I1110 23:43:18.843971  2593 solver.cpp:310]     Train net output #0: loss = 0.433033 (* 1 = 0.433033 loss)
I1110 23:43:18.843993  2593 sgd_solver.cpp:106] Iteration 2306, lr = 0.0005
I1110 23:43:21.119820  2593 solver.cpp:295] Iteration 2307 (no loss supplied for SingleUpdateStep)
I1110 23:43:21.119913  2593 solver.cpp:310]     Train net output #0: loss = 0.402585 (* 1 = 0.402585 loss)
I1110 23:43:21.119935  2593 sgd_solver.cpp:106] Iteration 2307, lr = 0.0005
I1110 23:43:23.335949  2593 solver.cpp:295] Iteration 2308 (no loss supplied for SingleUpdateStep)
I1110 23:43:23.336086  2593 solver.cpp:310]     Train net output #0: loss = 0.410434 (* 1 = 0.410434 loss)
I1110 23:43:23.336110  2593 sgd_solver.cpp:106] Iteration 2308, lr = 0.0005
I1110 23:43:25.649653  2593 solver.cpp:295] Iteration 2309 (no loss supplied for SingleUpdateStep)
I1110 23:43:25.649711  2593 solver.cpp:310]     Train net output #0: loss = 0.430501 (* 1 = 0.430501 loss)
I1110 23:43:25.649729  2593 sgd_solver.cpp:106] Iteration 2309, lr = 0.0005
I1110 23:43:28.010368  2593 solver.cpp:295] Iteration 2310 (no loss supplied for SingleUpdateStep)
I1110 23:43:28.010432  2593 solver.cpp:310]     Train net output #0: loss = 0.437685 (* 1 = 0.437685 loss)
I1110 23:43:28.010452  2593 sgd_solver.cpp:106] Iteration 2310, lr = 0.0005
I1110 23:43:30.486053  2593 solver.cpp:295] Iteration 2311 (no loss supplied for SingleUpdateStep)
I1110 23:43:30.486124  2593 solver.cpp:310]     Train net output #0: loss = 0.433369 (* 1 = 0.433369 loss)
I1110 23:43:30.486143  2593 sgd_solver.cpp:106] Iteration 2311, lr = 0.0005
I1110 23:43:32.863721  2593 solver.cpp:295] Iteration 2312 (no loss supplied for SingleUpdateStep)
I1110 23:43:32.863833  2593 solver.cpp:310]     Train net output #0: loss = 0.403806 (* 1 = 0.403806 loss)
I1110 23:43:32.863854  2593 sgd_solver.cpp:106] Iteration 2312, lr = 0.0005
I1110 23:43:35.234064  2593 solver.cpp:295] Iteration 2313 (no loss supplied for SingleUpdateStep)
I1110 23:43:35.234151  2593 solver.cpp:310]     Train net output #0: loss = 0.431388 (* 1 = 0.431388 loss)
I1110 23:43:35.234170  2593 sgd_solver.cpp:106] Iteration 2313, lr = 0.0005
I1110 23:43:37.510221  2593 solver.cpp:295] Iteration 2314 (no loss supplied for SingleUpdateStep)
I1110 23:43:37.510372  2593 solver.cpp:310]     Train net output #0: loss = 0.415481 (* 1 = 0.415481 loss)
I1110 23:43:37.510398  2593 sgd_solver.cpp:106] Iteration 2314, lr = 0.0005
I1110 23:43:39.845882  2593 solver.cpp:295] Iteration 2315 (no loss supplied for SingleUpdateStep)
I1110 23:43:39.845968  2593 solver.cpp:310]     Train net output #0: loss = 0.441959 (* 1 = 0.441959 loss)
I1110 23:43:39.845988  2593 sgd_solver.cpp:106] Iteration 2315, lr = 0.0005
I1110 23:43:42.428717  2593 solver.cpp:295] Iteration 2316 (no loss supplied for SingleUpdateStep)
I1110 23:43:42.428797  2593 solver.cpp:310]     Train net output #0: loss = 0.404377 (* 1 = 0.404377 loss)
I1110 23:43:42.428819  2593 sgd_solver.cpp:106] Iteration 2316, lr = 0.0005
I1110 23:43:44.777017  2593 solver.cpp:295] Iteration 2317 (no loss supplied for SingleUpdateStep)
I1110 23:43:44.777154  2593 solver.cpp:310]     Train net output #0: loss = 0.443408 (* 1 = 0.443408 loss)
I1110 23:43:44.777179  2593 sgd_solver.cpp:106] Iteration 2317, lr = 0.0005
I1110 23:43:46.936203  2593 solver.cpp:295] Iteration 2318 (no loss supplied for SingleUpdateStep)
I1110 23:43:46.936421  2593 solver.cpp:310]     Train net output #0: loss = 0.43787 (* 1 = 0.43787 loss)
I1110 23:43:46.936445  2593 sgd_solver.cpp:106] Iteration 2318, lr = 0.0005
I1110 23:43:49.299185  2593 solver.cpp:295] Iteration 2319 (no loss supplied for SingleUpdateStep)
I1110 23:43:49.299289  2593 solver.cpp:310]     Train net output #0: loss = 0.432043 (* 1 = 0.432043 loss)
I1110 23:43:49.299311  2593 sgd_solver.cpp:106] Iteration 2319, lr = 0.0005
I1110 23:43:51.592743  2593 solver.cpp:295] Iteration 2320 (no loss supplied for SingleUpdateStep)
I1110 23:43:51.592839  2593 solver.cpp:310]     Train net output #0: loss = 0.426342 (* 1 = 0.426342 loss)
I1110 23:43:51.592861  2593 sgd_solver.cpp:106] Iteration 2320, lr = 0.0005
I1110 23:43:54.115658  2593 solver.cpp:295] Iteration 2321 (no loss supplied for SingleUpdateStep)
I1110 23:43:54.115785  2593 solver.cpp:310]     Train net output #0: loss = 0.41815 (* 1 = 0.41815 loss)
I1110 23:43:54.115810  2593 sgd_solver.cpp:106] Iteration 2321, lr = 0.0005
I1110 23:43:56.474695  2593 solver.cpp:295] Iteration 2322 (no loss supplied for SingleUpdateStep)
I1110 23:43:56.474752  2593 solver.cpp:310]     Train net output #0: loss = 0.437733 (* 1 = 0.437733 loss)
I1110 23:43:56.474771  2593 sgd_solver.cpp:106] Iteration 2322, lr = 0.0005
I1110 23:43:58.817384  2593 solver.cpp:295] Iteration 2323 (no loss supplied for SingleUpdateStep)
I1110 23:43:58.817507  2593 solver.cpp:310]     Train net output #0: loss = 0.44893 (* 1 = 0.44893 loss)
I1110 23:43:58.817528  2593 sgd_solver.cpp:106] Iteration 2323, lr = 0.0005
I1110 23:44:01.427467  2593 solver.cpp:295] Iteration 2324 (no loss supplied for SingleUpdateStep)
I1110 23:44:01.427552  2593 solver.cpp:310]     Train net output #0: loss = 0.455136 (* 1 = 0.455136 loss)
I1110 23:44:01.427572  2593 sgd_solver.cpp:106] Iteration 2324, lr = 0.0005
I1110 23:44:04.055919  2593 solver.cpp:295] Iteration 2325 (no loss supplied for SingleUpdateStep)
I1110 23:44:04.056038  2593 solver.cpp:310]     Train net output #0: loss = 0.419392 (* 1 = 0.419392 loss)
I1110 23:44:04.056062  2593 sgd_solver.cpp:106] Iteration 2325, lr = 0.0005
I1110 23:44:06.633214  2593 solver.cpp:295] Iteration 2326 (no loss supplied for SingleUpdateStep)
I1110 23:44:06.633338  2593 solver.cpp:310]     Train net output #0: loss = 0.415344 (* 1 = 0.415344 loss)
I1110 23:44:06.633375  2593 sgd_solver.cpp:106] Iteration 2326, lr = 0.0005
I1110 23:44:08.937728  2593 solver.cpp:295] Iteration 2327 (no loss supplied for SingleUpdateStep)
I1110 23:44:08.937870  2593 solver.cpp:310]     Train net output #0: loss = 0.419155 (* 1 = 0.419155 loss)
I1110 23:44:08.937892  2593 sgd_solver.cpp:106] Iteration 2327, lr = 0.0005
I1110 23:44:11.410580  2593 solver.cpp:295] Iteration 2328 (no loss supplied for SingleUpdateStep)
I1110 23:44:11.410696  2593 solver.cpp:310]     Train net output #0: loss = 0.435663 (* 1 = 0.435663 loss)
I1110 23:44:11.410724  2593 sgd_solver.cpp:106] Iteration 2328, lr = 0.0005
I1110 23:44:13.856148  2593 solver.cpp:295] Iteration 2329 (no loss supplied for SingleUpdateStep)
I1110 23:44:13.856294  2593 solver.cpp:310]     Train net output #0: loss = 0.43628 (* 1 = 0.43628 loss)
I1110 23:44:13.856318  2593 sgd_solver.cpp:106] Iteration 2329, lr = 0.0005
I1110 23:44:16.906149  2593 solver.cpp:295] Iteration 2330 (no loss supplied for SingleUpdateStep)
I1110 23:44:16.906245  2593 solver.cpp:310]     Train net output #0: loss = 0.470145 (* 1 = 0.470145 loss)
I1110 23:44:16.906266  2593 sgd_solver.cpp:106] Iteration 2330, lr = 0.0005
I1110 23:44:19.713923  2593 solver.cpp:295] Iteration 2331 (no loss supplied for SingleUpdateStep)
I1110 23:44:19.714031  2593 solver.cpp:310]     Train net output #0: loss = 0.416121 (* 1 = 0.416121 loss)
I1110 23:44:19.714054  2593 sgd_solver.cpp:106] Iteration 2331, lr = 0.0005
I1110 23:44:22.243240  2593 solver.cpp:295] Iteration 2332 (no loss supplied for SingleUpdateStep)
I1110 23:44:22.243340  2593 solver.cpp:310]     Train net output #0: loss = 0.41486 (* 1 = 0.41486 loss)
I1110 23:44:22.243360  2593 sgd_solver.cpp:106] Iteration 2332, lr = 0.0005
I1110 23:44:25.610918  2593 solver.cpp:295] Iteration 2333 (no loss supplied for SingleUpdateStep)
I1110 23:44:25.611013  2593 solver.cpp:310]     Train net output #0: loss = 0.467113 (* 1 = 0.467113 loss)
I1110 23:44:25.611035  2593 sgd_solver.cpp:106] Iteration 2333, lr = 0.0005
I1110 23:44:28.633205  2593 solver.cpp:295] Iteration 2334 (no loss supplied for SingleUpdateStep)
I1110 23:44:28.633282  2593 solver.cpp:310]     Train net output #0: loss = 0.425633 (* 1 = 0.425633 loss)
I1110 23:44:28.633302  2593 sgd_solver.cpp:106] Iteration 2334, lr = 0.0005
I1110 23:44:31.117621  2593 solver.cpp:295] Iteration 2335 (no loss supplied for SingleUpdateStep)
I1110 23:44:31.117734  2593 solver.cpp:310]     Train net output #0: loss = 0.448539 (* 1 = 0.448539 loss)
I1110 23:44:31.117756  2593 sgd_solver.cpp:106] Iteration 2335, lr = 0.0005
I1110 23:44:33.386140  2593 solver.cpp:295] Iteration 2336 (no loss supplied for SingleUpdateStep)
I1110 23:44:33.386221  2593 solver.cpp:310]     Train net output #0: loss = 0.429373 (* 1 = 0.429373 loss)
I1110 23:44:33.386242  2593 sgd_solver.cpp:106] Iteration 2336, lr = 0.0005
I1110 23:44:35.804658  2593 solver.cpp:295] Iteration 2337 (no loss supplied for SingleUpdateStep)
I1110 23:44:35.804785  2593 solver.cpp:310]     Train net output #0: loss = 0.422281 (* 1 = 0.422281 loss)
I1110 23:44:35.804807  2593 sgd_solver.cpp:106] Iteration 2337, lr = 0.0005
I1110 23:44:38.383529  2593 solver.cpp:295] Iteration 2338 (no loss supplied for SingleUpdateStep)
I1110 23:44:38.383585  2593 solver.cpp:310]     Train net output #0: loss = 0.414197 (* 1 = 0.414197 loss)
I1110 23:44:38.383605  2593 sgd_solver.cpp:106] Iteration 2338, lr = 0.0005
I1110 23:44:40.926973  2593 solver.cpp:295] Iteration 2339 (no loss supplied for SingleUpdateStep)
I1110 23:44:40.927038  2593 solver.cpp:310]     Train net output #0: loss = 0.427149 (* 1 = 0.427149 loss)
I1110 23:44:40.927057  2593 sgd_solver.cpp:106] Iteration 2339, lr = 0.0005
I1110 23:44:43.832484  2593 solver.cpp:295] Iteration 2340 (no loss supplied for SingleUpdateStep)
I1110 23:44:43.832594  2593 solver.cpp:310]     Train net output #0: loss = 0.438886 (* 1 = 0.438886 loss)
I1110 23:44:43.832617  2593 sgd_solver.cpp:106] Iteration 2340, lr = 0.0005
I1110 23:44:47.670259  2593 solver.cpp:295] Iteration 2341 (no loss supplied for SingleUpdateStep)
I1110 23:44:47.670341  2593 solver.cpp:310]     Train net output #0: loss = 0.386228 (* 1 = 0.386228 loss)
I1110 23:44:47.670361  2593 sgd_solver.cpp:106] Iteration 2341, lr = 0.0005
I1110 23:44:50.471681  2593 solver.cpp:295] Iteration 2342 (no loss supplied for SingleUpdateStep)
I1110 23:44:50.471750  2593 solver.cpp:310]     Train net output #0: loss = 0.413193 (* 1 = 0.413193 loss)
I1110 23:44:50.471806  2593 sgd_solver.cpp:106] Iteration 2342, lr = 0.0005
I1110 23:44:53.020361  2593 solver.cpp:295] Iteration 2343 (no loss supplied for SingleUpdateStep)
I1110 23:44:53.020530  2593 solver.cpp:310]     Train net output #0: loss = 0.400685 (* 1 = 0.400685 loss)
I1110 23:44:53.020557  2593 sgd_solver.cpp:106] Iteration 2343, lr = 0.0005
I1110 23:44:55.549511  2593 solver.cpp:295] Iteration 2344 (no loss supplied for SingleUpdateStep)
I1110 23:44:55.549587  2593 solver.cpp:310]     Train net output #0: loss = 0.435673 (* 1 = 0.435673 loss)
I1110 23:44:55.549604  2593 sgd_solver.cpp:106] Iteration 2344, lr = 0.0005
I1110 23:44:57.780498  2593 solver.cpp:295] Iteration 2345 (no loss supplied for SingleUpdateStep)
I1110 23:44:57.780606  2593 solver.cpp:310]     Train net output #0: loss = 0.456905 (* 1 = 0.456905 loss)
I1110 23:44:57.780627  2593 sgd_solver.cpp:106] Iteration 2345, lr = 0.0005
I1110 23:44:59.956004  2593 solver.cpp:295] Iteration 2346 (no loss supplied for SingleUpdateStep)
I1110 23:44:59.956068  2593 solver.cpp:310]     Train net output #0: loss = 0.446974 (* 1 = 0.446974 loss)
I1110 23:44:59.956086  2593 sgd_solver.cpp:106] Iteration 2346, lr = 0.0005
I1110 23:45:02.243091  2593 solver.cpp:295] Iteration 2347 (no loss supplied for SingleUpdateStep)
I1110 23:45:02.243232  2593 solver.cpp:310]     Train net output #0: loss = 0.416794 (* 1 = 0.416794 loss)
I1110 23:45:02.243258  2593 sgd_solver.cpp:106] Iteration 2347, lr = 0.0005
I1110 23:45:04.651192  2593 solver.cpp:295] Iteration 2348 (no loss supplied for SingleUpdateStep)
I1110 23:45:04.651376  2593 solver.cpp:310]     Train net output #0: loss = 0.46211 (* 1 = 0.46211 loss)
I1110 23:45:04.651403  2593 sgd_solver.cpp:106] Iteration 2348, lr = 0.0005
I1110 23:45:07.017771  2593 solver.cpp:295] Iteration 2349 (no loss supplied for SingleUpdateStep)
I1110 23:45:07.017910  2593 solver.cpp:310]     Train net output #0: loss = 0.417677 (* 1 = 0.417677 loss)
I1110 23:45:07.017933  2593 sgd_solver.cpp:106] Iteration 2349, lr = 0.0005
I1110 23:45:09.364722  2593 solver.cpp:295] Iteration 2350 (no loss supplied for SingleUpdateStep)
I1110 23:45:09.364873  2593 solver.cpp:310]     Train net output #0: loss = 0.409846 (* 1 = 0.409846 loss)
I1110 23:45:09.364907  2593 sgd_solver.cpp:106] Iteration 2350, lr = 0.0005
I1110 23:45:11.642853  2593 solver.cpp:295] Iteration 2351 (no loss supplied for SingleUpdateStep)
I1110 23:45:11.642969  2593 solver.cpp:310]     Train net output #0: loss = 0.439971 (* 1 = 0.439971 loss)
I1110 23:45:11.642992  2593 sgd_solver.cpp:106] Iteration 2351, lr = 0.0005
I1110 23:45:13.952328  2593 solver.cpp:295] Iteration 2352 (no loss supplied for SingleUpdateStep)
I1110 23:45:13.952425  2593 solver.cpp:310]     Train net output #0: loss = 0.428528 (* 1 = 0.428528 loss)
I1110 23:45:13.952445  2593 sgd_solver.cpp:106] Iteration 2352, lr = 0.0005
I1110 23:45:16.627660  2593 solver.cpp:295] Iteration 2353 (no loss supplied for SingleUpdateStep)
I1110 23:45:16.627790  2593 solver.cpp:310]     Train net output #0: loss = 0.414579 (* 1 = 0.414579 loss)
I1110 23:45:16.627813  2593 sgd_solver.cpp:106] Iteration 2353, lr = 0.0005
I1110 23:45:19.379905  2593 solver.cpp:295] Iteration 2354 (no loss supplied for SingleUpdateStep)
I1110 23:45:19.380034  2593 solver.cpp:310]     Train net output #0: loss = 0.451301 (* 1 = 0.451301 loss)
I1110 23:45:19.380056  2593 sgd_solver.cpp:106] Iteration 2354, lr = 0.0005
I1110 23:45:23.405180  2593 solver.cpp:295] Iteration 2355 (no loss supplied for SingleUpdateStep)
I1110 23:45:23.405239  2593 solver.cpp:310]     Train net output #0: loss = 0.448483 (* 1 = 0.448483 loss)
I1110 23:45:23.405257  2593 sgd_solver.cpp:106] Iteration 2355, lr = 0.0005
I1110 23:45:27.163077  2593 solver.cpp:295] Iteration 2356 (no loss supplied for SingleUpdateStep)
I1110 23:45:27.163214  2593 solver.cpp:310]     Train net output #0: loss = 0.497882 (* 1 = 0.497882 loss)
I1110 23:45:27.163239  2593 sgd_solver.cpp:106] Iteration 2356, lr = 0.0005
I1110 23:45:30.347201  2593 solver.cpp:295] Iteration 2357 (no loss supplied for SingleUpdateStep)
I1110 23:45:30.347337  2593 solver.cpp:310]     Train net output #0: loss = 0.4075 (* 1 = 0.4075 loss)
I1110 23:45:30.347370  2593 sgd_solver.cpp:106] Iteration 2357, lr = 0.0005
I1110 23:45:33.549216  2593 solver.cpp:295] Iteration 2358 (no loss supplied for SingleUpdateStep)
I1110 23:45:33.549270  2593 solver.cpp:310]     Train net output #0: loss = 0.417377 (* 1 = 0.417377 loss)
I1110 23:45:33.549289  2593 sgd_solver.cpp:106] Iteration 2358, lr = 0.0005
I1110 23:45:36.629482  2593 solver.cpp:295] Iteration 2359 (no loss supplied for SingleUpdateStep)
I1110 23:45:36.629642  2593 solver.cpp:310]     Train net output #0: loss = 0.431741 (* 1 = 0.431741 loss)
I1110 23:45:36.629670  2593 sgd_solver.cpp:106] Iteration 2359, lr = 0.0005
I1110 23:45:39.178431  2593 solver.cpp:295] Iteration 2360 (no loss supplied for SingleUpdateStep)
I1110 23:45:39.178534  2593 solver.cpp:310]     Train net output #0: loss = 0.425435 (* 1 = 0.425435 loss)
I1110 23:45:39.178553  2593 sgd_solver.cpp:106] Iteration 2360, lr = 0.0005
I1110 23:45:41.504567  2593 solver.cpp:295] Iteration 2361 (no loss supplied for SingleUpdateStep)
I1110 23:45:41.504674  2593 solver.cpp:310]     Train net output #0: loss = 0.435423 (* 1 = 0.435423 loss)
I1110 23:45:41.504695  2593 sgd_solver.cpp:106] Iteration 2361, lr = 0.0005
I1110 23:45:43.977401  2593 solver.cpp:295] Iteration 2362 (no loss supplied for SingleUpdateStep)
I1110 23:45:43.977504  2593 solver.cpp:310]     Train net output #0: loss = 0.424412 (* 1 = 0.424412 loss)
I1110 23:45:43.977529  2593 sgd_solver.cpp:106] Iteration 2362, lr = 0.0005
I1110 23:45:46.275132  2593 solver.cpp:295] Iteration 2363 (no loss supplied for SingleUpdateStep)
I1110 23:45:46.275233  2593 solver.cpp:310]     Train net output #0: loss = 0.453375 (* 1 = 0.453375 loss)
I1110 23:45:46.275254  2593 sgd_solver.cpp:106] Iteration 2363, lr = 0.0005
I1110 23:45:48.438427  2593 solver.cpp:295] Iteration 2364 (no loss supplied for SingleUpdateStep)
I1110 23:45:48.438496  2593 solver.cpp:310]     Train net output #0: loss = 0.436392 (* 1 = 0.436392 loss)
I1110 23:45:48.438519  2593 sgd_solver.cpp:106] Iteration 2364, lr = 0.0005
I1110 23:45:50.742112  2593 solver.cpp:295] Iteration 2365 (no loss supplied for SingleUpdateStep)
I1110 23:45:50.742175  2593 solver.cpp:310]     Train net output #0: loss = 0.414237 (* 1 = 0.414237 loss)
I1110 23:45:50.742194  2593 sgd_solver.cpp:106] Iteration 2365, lr = 0.0005
I1110 23:45:53.133241  2593 solver.cpp:295] Iteration 2366 (no loss supplied for SingleUpdateStep)
I1110 23:45:53.133386  2593 solver.cpp:310]     Train net output #0: loss = 0.470137 (* 1 = 0.470137 loss)
I1110 23:45:53.133410  2593 sgd_solver.cpp:106] Iteration 2366, lr = 0.0005
I1110 23:45:55.340862  2593 solver.cpp:295] Iteration 2367 (no loss supplied for SingleUpdateStep)
I1110 23:45:55.340945  2593 solver.cpp:310]     Train net output #0: loss = 0.43249 (* 1 = 0.43249 loss)
I1110 23:45:55.340963  2593 sgd_solver.cpp:106] Iteration 2367, lr = 0.0005
I1110 23:45:58.132743  2593 solver.cpp:295] Iteration 2368 (no loss supplied for SingleUpdateStep)
I1110 23:45:58.132861  2593 solver.cpp:310]     Train net output #0: loss = 0.418907 (* 1 = 0.418907 loss)
I1110 23:45:58.132884  2593 sgd_solver.cpp:106] Iteration 2368, lr = 0.0005
I1110 23:46:00.919374  2593 solver.cpp:295] Iteration 2369 (no loss supplied for SingleUpdateStep)
I1110 23:46:00.919483  2593 solver.cpp:310]     Train net output #0: loss = 0.453896 (* 1 = 0.453896 loss)
I1110 23:46:00.919507  2593 sgd_solver.cpp:106] Iteration 2369, lr = 0.0005
I1110 23:46:03.396595  2593 solver.cpp:295] Iteration 2370 (no loss supplied for SingleUpdateStep)
I1110 23:46:03.396687  2593 solver.cpp:310]     Train net output #0: loss = 0.441571 (* 1 = 0.441571 loss)
I1110 23:46:03.396706  2593 sgd_solver.cpp:106] Iteration 2370, lr = 0.0005
I1110 23:46:06.028261  2593 solver.cpp:295] Iteration 2371 (no loss supplied for SingleUpdateStep)
I1110 23:46:06.028393  2593 solver.cpp:310]     Train net output #0: loss = 0.439655 (* 1 = 0.439655 loss)
I1110 23:46:06.028416  2593 sgd_solver.cpp:106] Iteration 2371, lr = 0.0005
I1110 23:46:08.483237  2593 solver.cpp:295] Iteration 2372 (no loss supplied for SingleUpdateStep)
I1110 23:46:08.483419  2593 solver.cpp:310]     Train net output #0: loss = 0.456297 (* 1 = 0.456297 loss)
I1110 23:46:08.483461  2593 sgd_solver.cpp:106] Iteration 2372, lr = 0.0005
I1110 23:46:10.747751  2593 solver.cpp:295] Iteration 2373 (no loss supplied for SingleUpdateStep)
I1110 23:46:10.747848  2593 solver.cpp:310]     Train net output #0: loss = 0.46318 (* 1 = 0.46318 loss)
I1110 23:46:10.747869  2593 sgd_solver.cpp:106] Iteration 2373, lr = 0.0005
I1110 23:46:13.405148  2593 solver.cpp:295] Iteration 2374 (no loss supplied for SingleUpdateStep)
I1110 23:46:13.405215  2593 solver.cpp:310]     Train net output #0: loss = 0.466171 (* 1 = 0.466171 loss)
I1110 23:46:13.405235  2593 sgd_solver.cpp:106] Iteration 2374, lr = 0.0005
I1110 23:46:15.852963  2593 solver.cpp:295] Iteration 2375 (no loss supplied for SingleUpdateStep)
I1110 23:46:15.853080  2593 solver.cpp:310]     Train net output #0: loss = 0.432277 (* 1 = 0.432277 loss)
I1110 23:46:15.853101  2593 sgd_solver.cpp:106] Iteration 2375, lr = 0.0005
I1110 23:46:18.167332  2593 solver.cpp:295] Iteration 2376 (no loss supplied for SingleUpdateStep)
I1110 23:46:18.167455  2593 solver.cpp:310]     Train net output #0: loss = 0.421223 (* 1 = 0.421223 loss)
I1110 23:46:18.167476  2593 sgd_solver.cpp:106] Iteration 2376, lr = 0.0005
I1110 23:46:20.633476  2593 solver.cpp:295] Iteration 2377 (no loss supplied for SingleUpdateStep)
I1110 23:46:20.633554  2593 solver.cpp:310]     Train net output #0: loss = 0.421679 (* 1 = 0.421679 loss)
I1110 23:46:20.633572  2593 sgd_solver.cpp:106] Iteration 2377, lr = 0.0005
I1110 23:46:23.001992  2593 solver.cpp:295] Iteration 2378 (no loss supplied for SingleUpdateStep)
I1110 23:46:23.002106  2593 solver.cpp:310]     Train net output #0: loss = 0.423427 (* 1 = 0.423427 loss)
I1110 23:46:23.002130  2593 sgd_solver.cpp:106] Iteration 2378, lr = 0.0005
I1110 23:46:25.381386  2593 solver.cpp:295] Iteration 2379 (no loss supplied for SingleUpdateStep)
I1110 23:46:25.381515  2593 solver.cpp:310]     Train net output #0: loss = 0.43223 (* 1 = 0.43223 loss)
I1110 23:46:25.381536  2593 sgd_solver.cpp:106] Iteration 2379, lr = 0.0005
I1110 23:46:27.634732  2593 solver.cpp:295] Iteration 2380 (no loss supplied for SingleUpdateStep)
I1110 23:46:27.634893  2593 solver.cpp:310]     Train net output #0: loss = 0.432373 (* 1 = 0.432373 loss)
I1110 23:46:27.634922  2593 sgd_solver.cpp:106] Iteration 2380, lr = 0.0005
I1110 23:46:29.995209  2593 solver.cpp:295] Iteration 2381 (no loss supplied for SingleUpdateStep)
I1110 23:46:29.995334  2593 solver.cpp:310]     Train net output #0: loss = 0.448751 (* 1 = 0.448751 loss)
I1110 23:46:29.995355  2593 sgd_solver.cpp:106] Iteration 2381, lr = 0.0005
I1110 23:46:32.609082  2593 solver.cpp:295] Iteration 2382 (no loss supplied for SingleUpdateStep)
I1110 23:46:32.609186  2593 solver.cpp:310]     Train net output #0: loss = 0.404359 (* 1 = 0.404359 loss)
I1110 23:46:32.609206  2593 sgd_solver.cpp:106] Iteration 2382, lr = 0.0005
I1110 23:46:34.929566  2593 solver.cpp:295] Iteration 2383 (no loss supplied for SingleUpdateStep)
I1110 23:46:34.929680  2593 solver.cpp:310]     Train net output #0: loss = 0.433198 (* 1 = 0.433198 loss)
I1110 23:46:34.929702  2593 sgd_solver.cpp:106] Iteration 2383, lr = 0.0005
I1110 23:46:37.250466  2593 solver.cpp:295] Iteration 2384 (no loss supplied for SingleUpdateStep)
I1110 23:46:37.250622  2593 solver.cpp:310]     Train net output #0: loss = 0.452089 (* 1 = 0.452089 loss)
I1110 23:46:37.250644  2593 sgd_solver.cpp:106] Iteration 2384, lr = 0.0005
I1110 23:46:39.650444  2593 solver.cpp:295] Iteration 2385 (no loss supplied for SingleUpdateStep)
I1110 23:46:39.650504  2593 solver.cpp:310]     Train net output #0: loss = 0.411016 (* 1 = 0.411016 loss)
I1110 23:46:39.650521  2593 sgd_solver.cpp:106] Iteration 2385, lr = 0.0005
I1110 23:46:42.035804  2593 solver.cpp:295] Iteration 2386 (no loss supplied for SingleUpdateStep)
I1110 23:46:42.035907  2593 solver.cpp:310]     Train net output #0: loss = 0.4377 (* 1 = 0.4377 loss)
I1110 23:46:42.035931  2593 sgd_solver.cpp:106] Iteration 2386, lr = 0.0005
I1110 23:46:44.390148  2593 solver.cpp:295] Iteration 2387 (no loss supplied for SingleUpdateStep)
I1110 23:46:44.390225  2593 solver.cpp:310]     Train net output #0: loss = 0.415104 (* 1 = 0.415104 loss)
I1110 23:46:44.390245  2593 sgd_solver.cpp:106] Iteration 2387, lr = 0.0005
I1110 23:46:46.661108  2593 solver.cpp:295] Iteration 2388 (no loss supplied for SingleUpdateStep)
I1110 23:46:46.661202  2593 solver.cpp:310]     Train net output #0: loss = 0.437389 (* 1 = 0.437389 loss)
I1110 23:46:46.661223  2593 sgd_solver.cpp:106] Iteration 2388, lr = 0.0005
I1110 23:46:48.846951  2593 solver.cpp:295] Iteration 2389 (no loss supplied for SingleUpdateStep)
I1110 23:46:48.847007  2593 solver.cpp:310]     Train net output #0: loss = 0.445931 (* 1 = 0.445931 loss)
I1110 23:46:48.847026  2593 sgd_solver.cpp:106] Iteration 2389, lr = 0.0005
I1110 23:46:51.145917  2593 solver.cpp:295] Iteration 2390 (no loss supplied for SingleUpdateStep)
I1110 23:46:51.146019  2593 solver.cpp:310]     Train net output #0: loss = 0.431653 (* 1 = 0.431653 loss)
I1110 23:46:51.146044  2593 sgd_solver.cpp:106] Iteration 2390, lr = 0.0005
I1110 23:46:53.328922  2593 solver.cpp:295] Iteration 2391 (no loss supplied for SingleUpdateStep)
I1110 23:46:53.329080  2593 solver.cpp:310]     Train net output #0: loss = 0.458949 (* 1 = 0.458949 loss)
I1110 23:46:53.329115  2593 sgd_solver.cpp:106] Iteration 2391, lr = 0.0005
I1110 23:46:55.760684  2593 solver.cpp:295] Iteration 2392 (no loss supplied for SingleUpdateStep)
I1110 23:46:55.760777  2593 solver.cpp:310]     Train net output #0: loss = 0.409533 (* 1 = 0.409533 loss)
I1110 23:46:55.760797  2593 sgd_solver.cpp:106] Iteration 2392, lr = 0.0005
I1110 23:46:58.444159  2593 solver.cpp:295] Iteration 2393 (no loss supplied for SingleUpdateStep)
I1110 23:46:58.444253  2593 solver.cpp:310]     Train net output #0: loss = 0.456426 (* 1 = 0.456426 loss)
I1110 23:46:58.444273  2593 sgd_solver.cpp:106] Iteration 2393, lr = 0.0005
I1110 23:47:00.783517  2593 solver.cpp:295] Iteration 2394 (no loss supplied for SingleUpdateStep)
I1110 23:47:00.783623  2593 solver.cpp:310]     Train net output #0: loss = 0.459816 (* 1 = 0.459816 loss)
I1110 23:47:00.783644  2593 sgd_solver.cpp:106] Iteration 2394, lr = 0.0005
I1110 23:47:02.970160  2593 solver.cpp:295] Iteration 2395 (no loss supplied for SingleUpdateStep)
I1110 23:47:02.970264  2593 solver.cpp:310]     Train net output #0: loss = 0.427899 (* 1 = 0.427899 loss)
I1110 23:47:02.970286  2593 sgd_solver.cpp:106] Iteration 2395, lr = 0.0005
I1110 23:47:05.516624  2593 solver.cpp:295] Iteration 2396 (no loss supplied for SingleUpdateStep)
I1110 23:47:05.516744  2593 solver.cpp:310]     Train net output #0: loss = 0.421439 (* 1 = 0.421439 loss)
I1110 23:47:05.516768  2593 sgd_solver.cpp:106] Iteration 2396, lr = 0.0005
I1110 23:47:08.182490  2593 solver.cpp:295] Iteration 2397 (no loss supplied for SingleUpdateStep)
I1110 23:47:08.182608  2593 solver.cpp:310]     Train net output #0: loss = 0.412287 (* 1 = 0.412287 loss)
I1110 23:47:08.182632  2593 sgd_solver.cpp:106] Iteration 2397, lr = 0.0005
I1110 23:47:10.532938  2593 solver.cpp:295] Iteration 2398 (no loss supplied for SingleUpdateStep)
I1110 23:47:10.533016  2593 solver.cpp:310]     Train net output #0: loss = 0.449451 (* 1 = 0.449451 loss)
I1110 23:47:10.533036  2593 sgd_solver.cpp:106] Iteration 2398, lr = 0.0005
I1110 23:47:12.825541  2593 solver.cpp:295] Iteration 2399 (no loss supplied for SingleUpdateStep)
I1110 23:47:12.825623  2593 solver.cpp:310]     Train net output #0: loss = 0.417847 (* 1 = 0.417847 loss)
I1110 23:47:12.825644  2593 sgd_solver.cpp:106] Iteration 2399, lr = 0.0005
I1110 23:47:15.255913  2593 solver.cpp:295] Iteration 2400 (no loss supplied for SingleUpdateStep)
I1110 23:47:15.256012  2593 solver.cpp:310]     Train net output #0: loss = 0.411977 (* 1 = 0.411977 loss)
I1110 23:47:15.256033  2593 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I1110 23:47:17.690078  2593 solver.cpp:295] Iteration 2401 (no loss supplied for SingleUpdateStep)
I1110 23:47:17.690141  2593 solver.cpp:310]     Train net output #0: loss = 0.462811 (* 1 = 0.462811 loss)
I1110 23:47:17.690160  2593 sgd_solver.cpp:106] Iteration 2401, lr = 0.0005
I1110 23:47:20.214520  2593 solver.cpp:295] Iteration 2402 (no loss supplied for SingleUpdateStep)
I1110 23:47:20.214668  2593 solver.cpp:310]     Train net output #0: loss = 0.387976 (* 1 = 0.387976 loss)
I1110 23:47:20.214694  2593 sgd_solver.cpp:106] Iteration 2402, lr = 0.0005
I1110 23:47:23.068078  2593 solver.cpp:295] Iteration 2403 (no loss supplied for SingleUpdateStep)
I1110 23:47:23.068235  2593 solver.cpp:310]     Train net output #0: loss = 0.44204 (* 1 = 0.44204 loss)
I1110 23:47:23.068271  2593 sgd_solver.cpp:106] Iteration 2403, lr = 0.0005
I1110 23:47:25.985721  2593 solver.cpp:295] Iteration 2404 (no loss supplied for SingleUpdateStep)
I1110 23:47:25.985836  2593 solver.cpp:310]     Train net output #0: loss = 0.424662 (* 1 = 0.424662 loss)
I1110 23:47:25.985857  2593 sgd_solver.cpp:106] Iteration 2404, lr = 0.0005
I1110 23:47:28.634407  2593 solver.cpp:295] Iteration 2405 (no loss supplied for SingleUpdateStep)
I1110 23:47:28.634534  2593 solver.cpp:310]     Train net output #0: loss = 0.423046 (* 1 = 0.423046 loss)
I1110 23:47:28.634557  2593 sgd_solver.cpp:106] Iteration 2405, lr = 0.0005
I1110 23:47:31.422005  2593 solver.cpp:295] Iteration 2406 (no loss supplied for SingleUpdateStep)
I1110 23:47:31.422132  2593 solver.cpp:310]     Train net output #0: loss = 0.395983 (* 1 = 0.395983 loss)
I1110 23:47:31.422153  2593 sgd_solver.cpp:106] Iteration 2406, lr = 0.0005
I1110 23:47:34.092850  2593 solver.cpp:295] Iteration 2407 (no loss supplied for SingleUpdateStep)
I1110 23:47:34.092933  2593 solver.cpp:310]     Train net output #0: loss = 0.439067 (* 1 = 0.439067 loss)
I1110 23:47:34.092955  2593 sgd_solver.cpp:106] Iteration 2407, lr = 0.0005
I1110 23:47:36.613735  2593 solver.cpp:295] Iteration 2408 (no loss supplied for SingleUpdateStep)
I1110 23:47:36.613840  2593 solver.cpp:310]     Train net output #0: loss = 0.414008 (* 1 = 0.414008 loss)
I1110 23:47:36.613862  2593 sgd_solver.cpp:106] Iteration 2408, lr = 0.0005
I1110 23:47:39.282289  2593 solver.cpp:295] Iteration 2409 (no loss supplied for SingleUpdateStep)
I1110 23:47:39.282371  2593 solver.cpp:310]     Train net output #0: loss = 0.406094 (* 1 = 0.406094 loss)
I1110 23:47:39.282389  2593 sgd_solver.cpp:106] Iteration 2409, lr = 0.0005
I1110 23:47:41.747150  2593 solver.cpp:295] Iteration 2410 (no loss supplied for SingleUpdateStep)
I1110 23:47:41.747231  2593 solver.cpp:310]     Train net output #0: loss = 0.424603 (* 1 = 0.424603 loss)
I1110 23:47:41.747252  2593 sgd_solver.cpp:106] Iteration 2410, lr = 0.0005
I1110 23:47:44.307162  2593 solver.cpp:295] Iteration 2411 (no loss supplied for SingleUpdateStep)
I1110 23:47:44.307302  2593 solver.cpp:310]     Train net output #0: loss = 0.418269 (* 1 = 0.418269 loss)
I1110 23:47:44.307329  2593 sgd_solver.cpp:106] Iteration 2411, lr = 0.0005
I1110 23:47:46.747720  2593 solver.cpp:295] Iteration 2412 (no loss supplied for SingleUpdateStep)
I1110 23:47:46.747845  2593 solver.cpp:310]     Train net output #0: loss = 0.406608 (* 1 = 0.406608 loss)
I1110 23:47:46.747869  2593 sgd_solver.cpp:106] Iteration 2412, lr = 0.0005
I1110 23:47:49.185370  2593 solver.cpp:295] Iteration 2413 (no loss supplied for SingleUpdateStep)
I1110 23:47:49.185468  2593 solver.cpp:310]     Train net output #0: loss = 0.427709 (* 1 = 0.427709 loss)
I1110 23:47:49.185490  2593 sgd_solver.cpp:106] Iteration 2413, lr = 0.0005
I1110 23:47:51.630594  2593 solver.cpp:295] Iteration 2414 (no loss supplied for SingleUpdateStep)
I1110 23:47:51.630753  2593 solver.cpp:310]     Train net output #0: loss = 0.424264 (* 1 = 0.424264 loss)
I1110 23:47:51.630785  2593 sgd_solver.cpp:106] Iteration 2414, lr = 0.0005
I1110 23:47:54.055776  2593 solver.cpp:295] Iteration 2415 (no loss supplied for SingleUpdateStep)
I1110 23:47:54.055835  2593 solver.cpp:310]     Train net output #0: loss = 0.403495 (* 1 = 0.403495 loss)
I1110 23:47:54.055855  2593 sgd_solver.cpp:106] Iteration 2415, lr = 0.0005
I1110 23:47:56.385159  2593 solver.cpp:295] Iteration 2416 (no loss supplied for SingleUpdateStep)
I1110 23:47:56.385221  2593 solver.cpp:310]     Train net output #0: loss = 0.426206 (* 1 = 0.426206 loss)
I1110 23:47:56.385238  2593 sgd_solver.cpp:106] Iteration 2416, lr = 0.0005
I1110 23:47:58.876497  2593 solver.cpp:295] Iteration 2417 (no loss supplied for SingleUpdateStep)
I1110 23:47:58.876623  2593 solver.cpp:310]     Train net output #0: loss = 0.441467 (* 1 = 0.441467 loss)
I1110 23:47:58.876654  2593 sgd_solver.cpp:106] Iteration 2417, lr = 0.0005
I1110 23:48:01.126332  2593 solver.cpp:295] Iteration 2418 (no loss supplied for SingleUpdateStep)
I1110 23:48:01.126519  2593 solver.cpp:310]     Train net output #0: loss = 0.401308 (* 1 = 0.401308 loss)
I1110 23:48:01.126548  2593 sgd_solver.cpp:106] Iteration 2418, lr = 0.0005
I1110 23:48:03.580268  2593 solver.cpp:295] Iteration 2419 (no loss supplied for SingleUpdateStep)
I1110 23:48:03.580478  2593 solver.cpp:310]     Train net output #0: loss = 0.406578 (* 1 = 0.406578 loss)
I1110 23:48:03.580513  2593 sgd_solver.cpp:106] Iteration 2419, lr = 0.0005
I1110 23:48:05.760287  2593 solver.cpp:295] Iteration 2420 (no loss supplied for SingleUpdateStep)
I1110 23:48:05.760412  2593 solver.cpp:310]     Train net output #0: loss = 0.453464 (* 1 = 0.453464 loss)
I1110 23:48:05.760438  2593 sgd_solver.cpp:106] Iteration 2420, lr = 0.0005
I1110 23:48:08.086109  2593 solver.cpp:295] Iteration 2421 (no loss supplied for SingleUpdateStep)
I1110 23:48:08.086238  2593 solver.cpp:310]     Train net output #0: loss = 0.422 (* 1 = 0.422 loss)
I1110 23:48:08.086261  2593 sgd_solver.cpp:106] Iteration 2421, lr = 0.0005
I1110 23:48:10.377434  2593 solver.cpp:295] Iteration 2422 (no loss supplied for SingleUpdateStep)
I1110 23:48:10.377562  2593 solver.cpp:310]     Train net output #0: loss = 0.39338 (* 1 = 0.39338 loss)
I1110 23:48:10.377586  2593 sgd_solver.cpp:106] Iteration 2422, lr = 0.0005
I1110 23:48:12.824900  2593 solver.cpp:295] Iteration 2423 (no loss supplied for SingleUpdateStep)
I1110 23:48:12.825017  2593 solver.cpp:310]     Train net output #0: loss = 0.455256 (* 1 = 0.455256 loss)
I1110 23:48:12.825040  2593 sgd_solver.cpp:106] Iteration 2423, lr = 0.0005
I1110 23:48:15.207590  2593 solver.cpp:295] Iteration 2424 (no loss supplied for SingleUpdateStep)
I1110 23:48:15.207725  2593 solver.cpp:310]     Train net output #0: loss = 0.4305 (* 1 = 0.4305 loss)
I1110 23:48:15.207746  2593 sgd_solver.cpp:106] Iteration 2424, lr = 0.0005
I1110 23:48:17.596127  2593 solver.cpp:295] Iteration 2425 (no loss supplied for SingleUpdateStep)
I1110 23:48:17.596181  2593 solver.cpp:310]     Train net output #0: loss = 0.431222 (* 1 = 0.431222 loss)
I1110 23:48:17.596199  2593 sgd_solver.cpp:106] Iteration 2425, lr = 0.0005
I1110 23:48:20.059937  2593 solver.cpp:295] Iteration 2426 (no loss supplied for SingleUpdateStep)
I1110 23:48:20.060034  2593 solver.cpp:310]     Train net output #0: loss = 0.394871 (* 1 = 0.394871 loss)
I1110 23:48:20.060060  2593 sgd_solver.cpp:106] Iteration 2426, lr = 0.0005
I1110 23:48:22.316259  2593 solver.cpp:295] Iteration 2427 (no loss supplied for SingleUpdateStep)
I1110 23:48:22.316321  2593 solver.cpp:310]     Train net output #0: loss = 0.429607 (* 1 = 0.429607 loss)
I1110 23:48:22.316340  2593 sgd_solver.cpp:106] Iteration 2427, lr = 0.0005
I1110 23:48:24.588785  2593 solver.cpp:295] Iteration 2428 (no loss supplied for SingleUpdateStep)
I1110 23:48:24.588910  2593 solver.cpp:310]     Train net output #0: loss = 0.464601 (* 1 = 0.464601 loss)
I1110 23:48:24.588934  2593 sgd_solver.cpp:106] Iteration 2428, lr = 0.0005
I1110 23:48:27.026777  2593 solver.cpp:295] Iteration 2429 (no loss supplied for SingleUpdateStep)
I1110 23:48:27.026909  2593 solver.cpp:310]     Train net output #0: loss = 0.404018 (* 1 = 0.404018 loss)
I1110 23:48:27.026932  2593 sgd_solver.cpp:106] Iteration 2429, lr = 0.0005
I1110 23:48:29.480151  2593 solver.cpp:295] Iteration 2430 (no loss supplied for SingleUpdateStep)
I1110 23:48:29.480227  2593 solver.cpp:310]     Train net output #0: loss = 0.456768 (* 1 = 0.456768 loss)
I1110 23:48:29.480247  2593 sgd_solver.cpp:106] Iteration 2430, lr = 0.0005
I1110 23:48:31.915498  2593 solver.cpp:295] Iteration 2431 (no loss supplied for SingleUpdateStep)
I1110 23:48:31.915642  2593 solver.cpp:310]     Train net output #0: loss = 0.404394 (* 1 = 0.404394 loss)
I1110 23:48:31.915668  2593 sgd_solver.cpp:106] Iteration 2431, lr = 0.0005
I1110 23:48:34.654355  2593 solver.cpp:295] Iteration 2432 (no loss supplied for SingleUpdateStep)
I1110 23:48:34.654449  2593 solver.cpp:310]     Train net output #0: loss = 0.441429 (* 1 = 0.441429 loss)
I1110 23:48:34.654472  2593 sgd_solver.cpp:106] Iteration 2432, lr = 0.0005
I1110 23:48:37.072724  2593 solver.cpp:295] Iteration 2433 (no loss supplied for SingleUpdateStep)
I1110 23:48:37.072777  2593 solver.cpp:310]     Train net output #0: loss = 0.433103 (* 1 = 0.433103 loss)
I1110 23:48:37.072793  2593 sgd_solver.cpp:106] Iteration 2433, lr = 0.0005
I1110 23:48:39.516824  2593 solver.cpp:295] Iteration 2434 (no loss supplied for SingleUpdateStep)
I1110 23:48:39.516906  2593 solver.cpp:310]     Train net output #0: loss = 0.410503 (* 1 = 0.410503 loss)
I1110 23:48:39.516927  2593 sgd_solver.cpp:106] Iteration 2434, lr = 0.0005
I1110 23:48:42.483893  2593 solver.cpp:295] Iteration 2435 (no loss supplied for SingleUpdateStep)
I1110 23:48:42.484051  2593 solver.cpp:310]     Train net output #0: loss = 0.432259 (* 1 = 0.432259 loss)
I1110 23:48:42.484077  2593 sgd_solver.cpp:106] Iteration 2435, lr = 0.0005
I1110 23:48:45.098085  2593 solver.cpp:295] Iteration 2436 (no loss supplied for SingleUpdateStep)
I1110 23:48:45.098196  2593 solver.cpp:310]     Train net output #0: loss = 0.398159 (* 1 = 0.398159 loss)
I1110 23:48:45.098218  2593 sgd_solver.cpp:106] Iteration 2436, lr = 0.0005
I1110 23:48:48.545919  2593 solver.cpp:295] Iteration 2437 (no loss supplied for SingleUpdateStep)
I1110 23:48:48.545972  2593 solver.cpp:310]     Train net output #0: loss = 0.420698 (* 1 = 0.420698 loss)
I1110 23:48:48.545989  2593 sgd_solver.cpp:106] Iteration 2437, lr = 0.0005
I1110 23:48:51.917618  2593 solver.cpp:295] Iteration 2438 (no loss supplied for SingleUpdateStep)
I1110 23:48:51.917686  2593 solver.cpp:310]     Train net output #0: loss = 0.431138 (* 1 = 0.431138 loss)
I1110 23:48:51.917706  2593 sgd_solver.cpp:106] Iteration 2438, lr = 0.0005
I1110 23:48:55.020133  2593 solver.cpp:295] Iteration 2439 (no loss supplied for SingleUpdateStep)
I1110 23:48:55.020243  2593 solver.cpp:310]     Train net output #0: loss = 0.434601 (* 1 = 0.434601 loss)
I1110 23:48:55.020264  2593 sgd_solver.cpp:106] Iteration 2439, lr = 0.0005
I1110 23:48:58.278424  2593 solver.cpp:295] Iteration 2440 (no loss supplied for SingleUpdateStep)
I1110 23:48:58.278532  2593 solver.cpp:310]     Train net output #0: loss = 0.431573 (* 1 = 0.431573 loss)
I1110 23:48:58.278558  2593 sgd_solver.cpp:106] Iteration 2440, lr = 0.0005
I1110 23:49:01.075065  2593 solver.cpp:295] Iteration 2441 (no loss supplied for SingleUpdateStep)
I1110 23:49:01.075120  2593 solver.cpp:310]     Train net output #0: loss = 0.425657 (* 1 = 0.425657 loss)
I1110 23:49:01.075139  2593 sgd_solver.cpp:106] Iteration 2441, lr = 0.0005
I1110 23:49:03.724995  2593 solver.cpp:295] Iteration 2442 (no loss supplied for SingleUpdateStep)
I1110 23:49:03.725085  2593 solver.cpp:310]     Train net output #0: loss = 0.458381 (* 1 = 0.458381 loss)
I1110 23:49:03.725106  2593 sgd_solver.cpp:106] Iteration 2442, lr = 0.0005
I1110 23:49:06.039669  2593 solver.cpp:295] Iteration 2443 (no loss supplied for SingleUpdateStep)
I1110 23:49:06.039763  2593 solver.cpp:310]     Train net output #0: loss = 0.416988 (* 1 = 0.416988 loss)
I1110 23:49:06.039786  2593 sgd_solver.cpp:106] Iteration 2443, lr = 0.0005
I1110 23:49:08.188107  2593 solver.cpp:295] Iteration 2444 (no loss supplied for SingleUpdateStep)
I1110 23:49:08.188233  2593 solver.cpp:310]     Train net output #0: loss = 0.426513 (* 1 = 0.426513 loss)
I1110 23:49:08.188256  2593 sgd_solver.cpp:106] Iteration 2444, lr = 0.0005
I1110 23:49:10.759239  2593 solver.cpp:295] Iteration 2445 (no loss supplied for SingleUpdateStep)
I1110 23:49:10.759306  2593 solver.cpp:310]     Train net output #0: loss = 0.424712 (* 1 = 0.424712 loss)
I1110 23:49:10.759326  2593 sgd_solver.cpp:106] Iteration 2445, lr = 0.0005
I1110 23:49:13.078423  2593 solver.cpp:295] Iteration 2446 (no loss supplied for SingleUpdateStep)
I1110 23:49:13.078564  2593 solver.cpp:310]     Train net output #0: loss = 0.437927 (* 1 = 0.437927 loss)
I1110 23:49:13.078588  2593 sgd_solver.cpp:106] Iteration 2446, lr = 0.0005
I1110 23:49:15.558001  2593 solver.cpp:295] Iteration 2447 (no loss supplied for SingleUpdateStep)
I1110 23:49:15.558114  2593 solver.cpp:310]     Train net output #0: loss = 0.418094 (* 1 = 0.418094 loss)
I1110 23:49:15.558135  2593 sgd_solver.cpp:106] Iteration 2447, lr = 0.0005
I1110 23:49:17.844619  2593 solver.cpp:295] Iteration 2448 (no loss supplied for SingleUpdateStep)
I1110 23:49:17.844729  2593 solver.cpp:310]     Train net output #0: loss = 0.424191 (* 1 = 0.424191 loss)
I1110 23:49:17.844753  2593 sgd_solver.cpp:106] Iteration 2448, lr = 0.0005
I1110 23:49:20.127512  2593 solver.cpp:295] Iteration 2449 (no loss supplied for SingleUpdateStep)
I1110 23:49:20.127676  2593 solver.cpp:310]     Train net output #0: loss = 0.40881 (* 1 = 0.40881 loss)
I1110 23:49:20.127702  2593 sgd_solver.cpp:106] Iteration 2449, lr = 0.0005
I1110 23:49:22.479468  2593 solver.cpp:295] Iteration 2450 (no loss supplied for SingleUpdateStep)
I1110 23:49:22.479674  2593 solver.cpp:310]     Train net output #0: loss = 0.428308 (* 1 = 0.428308 loss)
I1110 23:49:22.479707  2593 sgd_solver.cpp:106] Iteration 2450, lr = 0.0005
I1110 23:49:24.999471  2593 solver.cpp:295] Iteration 2451 (no loss supplied for SingleUpdateStep)
I1110 23:49:24.999722  2593 solver.cpp:310]     Train net output #0: loss = 0.434775 (* 1 = 0.434775 loss)
I1110 23:49:24.999768  2593 sgd_solver.cpp:106] Iteration 2451, lr = 0.0005
I1110 23:49:27.480394  2593 solver.cpp:295] Iteration 2452 (no loss supplied for SingleUpdateStep)
I1110 23:49:27.480482  2593 solver.cpp:310]     Train net output #0: loss = 0.406022 (* 1 = 0.406022 loss)
I1110 23:49:27.480502  2593 sgd_solver.cpp:106] Iteration 2452, lr = 0.0005
I1110 23:49:29.741066  2593 solver.cpp:295] Iteration 2453 (no loss supplied for SingleUpdateStep)
I1110 23:49:29.741161  2593 solver.cpp:310]     Train net output #0: loss = 0.428875 (* 1 = 0.428875 loss)
I1110 23:49:29.741180  2593 sgd_solver.cpp:106] Iteration 2453, lr = 0.0005
I1110 23:49:32.195637  2593 solver.cpp:295] Iteration 2454 (no loss supplied for SingleUpdateStep)
I1110 23:49:32.195716  2593 solver.cpp:310]     Train net output #0: loss = 0.398958 (* 1 = 0.398958 loss)
I1110 23:49:32.195739  2593 sgd_solver.cpp:106] Iteration 2454, lr = 0.0005
I1110 23:49:34.496110  2593 solver.cpp:295] Iteration 2455 (no loss supplied for SingleUpdateStep)
I1110 23:49:34.496218  2593 solver.cpp:310]     Train net output #0: loss = 0.460932 (* 1 = 0.460932 loss)
I1110 23:49:34.496243  2593 sgd_solver.cpp:106] Iteration 2455, lr = 0.0005
I1110 23:49:36.705139  2593 solver.cpp:295] Iteration 2456 (no loss supplied for SingleUpdateStep)
I1110 23:49:36.705196  2593 solver.cpp:310]     Train net output #0: loss = 0.487138 (* 1 = 0.487138 loss)
I1110 23:49:36.705215  2593 sgd_solver.cpp:106] Iteration 2456, lr = 0.0005
I1110 23:49:39.058439  2593 solver.cpp:295] Iteration 2457 (no loss supplied for SingleUpdateStep)
I1110 23:49:39.058531  2593 solver.cpp:310]     Train net output #0: loss = 0.399359 (* 1 = 0.399359 loss)
I1110 23:49:39.058552  2593 sgd_solver.cpp:106] Iteration 2457, lr = 0.0005
I1110 23:49:41.424865  2593 solver.cpp:295] Iteration 2458 (no loss supplied for SingleUpdateStep)
I1110 23:49:41.424979  2593 solver.cpp:310]     Train net output #0: loss = 0.416903 (* 1 = 0.416903 loss)
I1110 23:49:41.425003  2593 sgd_solver.cpp:106] Iteration 2458, lr = 0.0005
I1110 23:49:43.730965  2593 solver.cpp:295] Iteration 2459 (no loss supplied for SingleUpdateStep)
I1110 23:49:43.731082  2593 solver.cpp:310]     Train net output #0: loss = 0.424131 (* 1 = 0.424131 loss)
I1110 23:49:43.731108  2593 sgd_solver.cpp:106] Iteration 2459, lr = 0.0005
I1110 23:49:46.026844  2593 solver.cpp:295] Iteration 2460 (no loss supplied for SingleUpdateStep)
I1110 23:49:46.026968  2593 solver.cpp:310]     Train net output #0: loss = 0.414257 (* 1 = 0.414257 loss)
I1110 23:49:46.026995  2593 sgd_solver.cpp:106] Iteration 2460, lr = 0.0005
I1110 23:49:48.264273  2593 solver.cpp:295] Iteration 2461 (no loss supplied for SingleUpdateStep)
I1110 23:49:48.264389  2593 solver.cpp:310]     Train net output #0: loss = 0.418628 (* 1 = 0.418628 loss)
I1110 23:49:48.264412  2593 sgd_solver.cpp:106] Iteration 2461, lr = 0.0005
I1110 23:49:50.476399  2593 solver.cpp:295] Iteration 2462 (no loss supplied for SingleUpdateStep)
I1110 23:49:50.476516  2593 solver.cpp:310]     Train net output #0: loss = 0.400946 (* 1 = 0.400946 loss)
I1110 23:49:50.476539  2593 sgd_solver.cpp:106] Iteration 2462, lr = 0.0005
I1110 23:49:52.733191  2593 solver.cpp:295] Iteration 2463 (no loss supplied for SingleUpdateStep)
I1110 23:49:52.733283  2593 solver.cpp:310]     Train net output #0: loss = 0.464031 (* 1 = 0.464031 loss)
I1110 23:49:52.733305  2593 sgd_solver.cpp:106] Iteration 2463, lr = 0.0005
I1110 23:49:55.119803  2593 solver.cpp:295] Iteration 2464 (no loss supplied for SingleUpdateStep)
I1110 23:49:55.119951  2593 solver.cpp:310]     Train net output #0: loss = 0.465526 (* 1 = 0.465526 loss)
I1110 23:49:55.119973  2593 sgd_solver.cpp:106] Iteration 2464, lr = 0.0005
I1110 23:49:57.385711  2593 solver.cpp:295] Iteration 2465 (no loss supplied for SingleUpdateStep)
I1110 23:49:57.385846  2593 solver.cpp:310]     Train net output #0: loss = 0.45382 (* 1 = 0.45382 loss)
I1110 23:49:57.385874  2593 sgd_solver.cpp:106] Iteration 2465, lr = 0.0005
I1110 23:49:59.896478  2593 solver.cpp:295] Iteration 2466 (no loss supplied for SingleUpdateStep)
I1110 23:49:59.896579  2593 solver.cpp:310]     Train net output #0: loss = 0.395535 (* 1 = 0.395535 loss)
I1110 23:49:59.896605  2593 sgd_solver.cpp:106] Iteration 2466, lr = 0.0005
I1110 23:50:02.120939  2593 solver.cpp:295] Iteration 2467 (no loss supplied for SingleUpdateStep)
I1110 23:50:02.121000  2593 solver.cpp:310]     Train net output #0: loss = 0.462047 (* 1 = 0.462047 loss)
I1110 23:50:02.121018  2593 sgd_solver.cpp:106] Iteration 2467, lr = 0.0005
I1110 23:50:04.325629  2593 solver.cpp:295] Iteration 2468 (no loss supplied for SingleUpdateStep)
I1110 23:50:04.325731  2593 solver.cpp:310]     Train net output #0: loss = 0.410934 (* 1 = 0.410934 loss)
I1110 23:50:04.325752  2593 sgd_solver.cpp:106] Iteration 2468, lr = 0.0005
I1110 23:50:06.693666  2593 solver.cpp:295] Iteration 2469 (no loss supplied for SingleUpdateStep)
I1110 23:50:06.693837  2593 solver.cpp:310]     Train net output #0: loss = 0.396223 (* 1 = 0.396223 loss)
I1110 23:50:06.693871  2593 sgd_solver.cpp:106] Iteration 2469, lr = 0.0005
I1110 23:50:08.940667  2593 solver.cpp:295] Iteration 2470 (no loss supplied for SingleUpdateStep)
I1110 23:50:08.940776  2593 solver.cpp:310]     Train net output #0: loss = 0.430721 (* 1 = 0.430721 loss)
I1110 23:50:08.940799  2593 sgd_solver.cpp:106] Iteration 2470, lr = 0.0005
I1110 23:50:11.296422  2593 solver.cpp:295] Iteration 2471 (no loss supplied for SingleUpdateStep)
I1110 23:50:11.296493  2593 solver.cpp:310]     Train net output #0: loss = 0.426998 (* 1 = 0.426998 loss)
I1110 23:50:11.296514  2593 sgd_solver.cpp:106] Iteration 2471, lr = 0.0005
I1110 23:50:13.885918  2593 solver.cpp:295] Iteration 2472 (no loss supplied for SingleUpdateStep)
I1110 23:50:13.886071  2593 solver.cpp:310]     Train net output #0: loss = 0.451 (* 1 = 0.451 loss)
I1110 23:50:13.886099  2593 sgd_solver.cpp:106] Iteration 2472, lr = 0.0005
I1110 23:50:16.260880  2593 solver.cpp:295] Iteration 2473 (no loss supplied for SingleUpdateStep)
I1110 23:50:16.260995  2593 solver.cpp:310]     Train net output #0: loss = 0.406472 (* 1 = 0.406472 loss)
I1110 23:50:16.261016  2593 sgd_solver.cpp:106] Iteration 2473, lr = 0.0005
I1110 23:50:18.464855  2593 solver.cpp:295] Iteration 2474 (no loss supplied for SingleUpdateStep)
I1110 23:50:18.464957  2593 solver.cpp:310]     Train net output #0: loss = 0.428495 (* 1 = 0.428495 loss)
I1110 23:50:18.464979  2593 sgd_solver.cpp:106] Iteration 2474, lr = 0.0005
I1110 23:50:20.779877  2593 solver.cpp:295] Iteration 2475 (no loss supplied for SingleUpdateStep)
I1110 23:50:20.779990  2593 solver.cpp:310]     Train net output #0: loss = 0.394007 (* 1 = 0.394007 loss)
I1110 23:50:20.780012  2593 sgd_solver.cpp:106] Iteration 2475, lr = 0.0005
I1110 23:50:23.110807  2593 solver.cpp:295] Iteration 2476 (no loss supplied for SingleUpdateStep)
I1110 23:50:23.110900  2593 solver.cpp:310]     Train net output #0: loss = 0.420609 (* 1 = 0.420609 loss)
I1110 23:50:23.110925  2593 sgd_solver.cpp:106] Iteration 2476, lr = 0.0005
I1110 23:50:25.359707  2593 solver.cpp:295] Iteration 2477 (no loss supplied for SingleUpdateStep)
I1110 23:50:25.359802  2593 solver.cpp:310]     Train net output #0: loss = 0.424492 (* 1 = 0.424492 loss)
I1110 23:50:25.359824  2593 sgd_solver.cpp:106] Iteration 2477, lr = 0.0005
I1110 23:50:27.726483  2593 solver.cpp:295] Iteration 2478 (no loss supplied for SingleUpdateStep)
I1110 23:50:27.726548  2593 solver.cpp:310]     Train net output #0: loss = 0.448908 (* 1 = 0.448908 loss)
I1110 23:50:27.726567  2593 sgd_solver.cpp:106] Iteration 2478, lr = 0.0005
I1110 23:50:30.569561  2593 solver.cpp:295] Iteration 2479 (no loss supplied for SingleUpdateStep)
I1110 23:50:30.569667  2593 solver.cpp:310]     Train net output #0: loss = 0.435686 (* 1 = 0.435686 loss)
I1110 23:50:30.569690  2593 sgd_solver.cpp:106] Iteration 2479, lr = 0.0005
I1110 23:50:32.976716  2593 solver.cpp:295] Iteration 2480 (no loss supplied for SingleUpdateStep)
I1110 23:50:32.976815  2593 solver.cpp:310]     Train net output #0: loss = 0.410471 (* 1 = 0.410471 loss)
I1110 23:50:32.976836  2593 sgd_solver.cpp:106] Iteration 2480, lr = 0.0005
I1110 23:50:35.240120  2593 solver.cpp:295] Iteration 2481 (no loss supplied for SingleUpdateStep)
I1110 23:50:35.240243  2593 solver.cpp:310]     Train net output #0: loss = 0.441714 (* 1 = 0.441714 loss)
I1110 23:50:35.240272  2593 sgd_solver.cpp:106] Iteration 2481, lr = 0.0005
I1110 23:50:37.443217  2593 solver.cpp:295] Iteration 2482 (no loss supplied for SingleUpdateStep)
I1110 23:50:37.443302  2593 solver.cpp:310]     Train net output #0: loss = 0.421444 (* 1 = 0.421444 loss)
I1110 23:50:37.443323  2593 sgd_solver.cpp:106] Iteration 2482, lr = 0.0005
I1110 23:50:39.843180  2593 solver.cpp:295] Iteration 2483 (no loss supplied for SingleUpdateStep)
I1110 23:50:39.843238  2593 solver.cpp:310]     Train net output #0: loss = 0.435547 (* 1 = 0.435547 loss)
I1110 23:50:39.843256  2593 sgd_solver.cpp:106] Iteration 2483, lr = 0.0005
I1110 23:50:42.275749  2593 solver.cpp:295] Iteration 2484 (no loss supplied for SingleUpdateStep)
I1110 23:50:42.275854  2593 solver.cpp:310]     Train net output #0: loss = 0.443229 (* 1 = 0.443229 loss)
I1110 23:50:42.275877  2593 sgd_solver.cpp:106] Iteration 2484, lr = 0.0005
I1110 23:50:44.730191  2593 solver.cpp:295] Iteration 2485 (no loss supplied for SingleUpdateStep)
I1110 23:50:44.730281  2593 solver.cpp:310]     Train net output #0: loss = 0.425167 (* 1 = 0.425167 loss)
I1110 23:50:44.730301  2593 sgd_solver.cpp:106] Iteration 2485, lr = 0.0005
I1110 23:50:47.447187  2593 solver.cpp:295] Iteration 2486 (no loss supplied for SingleUpdateStep)
I1110 23:50:47.447274  2593 solver.cpp:310]     Train net output #0: loss = 0.424949 (* 1 = 0.424949 loss)
I1110 23:50:47.447295  2593 sgd_solver.cpp:106] Iteration 2486, lr = 0.0005
I1110 23:50:50.298306  2593 solver.cpp:295] Iteration 2487 (no loss supplied for SingleUpdateStep)
I1110 23:50:50.298429  2593 solver.cpp:310]     Train net output #0: loss = 0.399403 (* 1 = 0.399403 loss)
I1110 23:50:50.298454  2593 sgd_solver.cpp:106] Iteration 2487, lr = 0.0005
I1110 23:50:53.290096  2593 solver.cpp:295] Iteration 2488 (no loss supplied for SingleUpdateStep)
I1110 23:50:53.290205  2593 solver.cpp:310]     Train net output #0: loss = 0.404153 (* 1 = 0.404153 loss)
I1110 23:50:53.290228  2593 sgd_solver.cpp:106] Iteration 2488, lr = 0.0005
I1110 23:50:55.833384  2593 solver.cpp:295] Iteration 2489 (no loss supplied for SingleUpdateStep)
I1110 23:50:55.833504  2593 solver.cpp:310]     Train net output #0: loss = 0.433944 (* 1 = 0.433944 loss)
I1110 23:50:55.833526  2593 sgd_solver.cpp:106] Iteration 2489, lr = 0.0005
I1110 23:50:58.415412  2593 solver.cpp:295] Iteration 2490 (no loss supplied for SingleUpdateStep)
I1110 23:50:58.415527  2593 solver.cpp:310]     Train net output #0: loss = 0.431367 (* 1 = 0.431367 loss)
I1110 23:50:58.415555  2593 sgd_solver.cpp:106] Iteration 2490, lr = 0.0005
I1110 23:51:01.659909  2593 solver.cpp:295] Iteration 2491 (no loss supplied for SingleUpdateStep)
I1110 23:51:01.660032  2593 solver.cpp:310]     Train net output #0: loss = 0.415328 (* 1 = 0.415328 loss)
I1110 23:51:01.660055  2593 sgd_solver.cpp:106] Iteration 2491, lr = 0.0005
I1110 23:51:04.272121  2593 solver.cpp:295] Iteration 2492 (no loss supplied for SingleUpdateStep)
I1110 23:51:04.272231  2593 solver.cpp:310]     Train net output #0: loss = 0.448862 (* 1 = 0.448862 loss)
I1110 23:51:04.272254  2593 sgd_solver.cpp:106] Iteration 2492, lr = 0.0005
I1110 23:51:06.727210  2593 solver.cpp:295] Iteration 2493 (no loss supplied for SingleUpdateStep)
I1110 23:51:06.727301  2593 solver.cpp:310]     Train net output #0: loss = 0.428958 (* 1 = 0.428958 loss)
I1110 23:51:06.727322  2593 sgd_solver.cpp:106] Iteration 2493, lr = 0.0005
I1110 23:51:09.211149  2593 solver.cpp:295] Iteration 2494 (no loss supplied for SingleUpdateStep)
I1110 23:51:09.211253  2593 solver.cpp:310]     Train net output #0: loss = 0.390078 (* 1 = 0.390078 loss)
I1110 23:51:09.211275  2593 sgd_solver.cpp:106] Iteration 2494, lr = 0.0005
I1110 23:51:11.574074  2593 solver.cpp:295] Iteration 2495 (no loss supplied for SingleUpdateStep)
I1110 23:51:11.574172  2593 solver.cpp:310]     Train net output #0: loss = 0.425768 (* 1 = 0.425768 loss)
I1110 23:51:11.574194  2593 sgd_solver.cpp:106] Iteration 2495, lr = 0.0005
I1110 23:51:14.057466  2593 solver.cpp:295] Iteration 2496 (no loss supplied for SingleUpdateStep)
I1110 23:51:14.057564  2593 solver.cpp:310]     Train net output #0: loss = 0.458604 (* 1 = 0.458604 loss)
I1110 23:51:14.057585  2593 sgd_solver.cpp:106] Iteration 2496, lr = 0.0005
I1110 23:51:16.684428  2593 solver.cpp:295] Iteration 2497 (no loss supplied for SingleUpdateStep)
I1110 23:51:16.684653  2593 solver.cpp:310]     Train net output #0: loss = 0.421783 (* 1 = 0.421783 loss)
I1110 23:51:16.684695  2593 sgd_solver.cpp:106] Iteration 2497, lr = 0.0005
I1110 23:51:19.207593  2593 solver.cpp:295] Iteration 2498 (no loss supplied for SingleUpdateStep)
I1110 23:51:19.207715  2593 solver.cpp:310]     Train net output #0: loss = 0.42727 (* 1 = 0.42727 loss)
I1110 23:51:19.207737  2593 sgd_solver.cpp:106] Iteration 2498, lr = 0.0005
I1110 23:51:21.622731  2593 solver.cpp:295] Iteration 2499 (no loss supplied for SingleUpdateStep)
I1110 23:51:21.622869  2593 solver.cpp:310]     Train net output #0: loss = 0.443665 (* 1 = 0.443665 loss)
I1110 23:51:21.622892  2593 sgd_solver.cpp:106] Iteration 2499, lr = 0.0005
I1110 23:51:23.888218  2593 solver.cpp:295] Iteration 2500 (no loss supplied for SingleUpdateStep)
I1110 23:51:23.888388  2593 solver.cpp:310]     Train net output #0: loss = 0.405985 (* 1 = 0.405985 loss)
I1110 23:51:23.888411  2593 sgd_solver.cpp:106] Iteration 2500, lr = 0.0005
I1110 23:51:26.202396  2593 solver.cpp:295] Iteration 2501 (no loss supplied for SingleUpdateStep)
I1110 23:51:26.202597  2593 solver.cpp:310]     Train net output #0: loss = 0.426532 (* 1 = 0.426532 loss)
I1110 23:51:26.202628  2593 sgd_solver.cpp:106] Iteration 2501, lr = 0.0005
I1110 23:51:28.575806  2593 solver.cpp:295] Iteration 2502 (no loss supplied for SingleUpdateStep)
I1110 23:51:28.575917  2593 solver.cpp:310]     Train net output #0: loss = 0.442189 (* 1 = 0.442189 loss)
I1110 23:51:28.575942  2593 sgd_solver.cpp:106] Iteration 2502, lr = 0.0005
I1110 23:51:31.235347  2593 solver.cpp:295] Iteration 2503 (no loss supplied for SingleUpdateStep)
I1110 23:51:31.235472  2593 solver.cpp:310]     Train net output #0: loss = 0.433326 (* 1 = 0.433326 loss)
I1110 23:51:31.235496  2593 sgd_solver.cpp:106] Iteration 2503, lr = 0.0005
I1110 23:51:33.633193  2593 solver.cpp:295] Iteration 2504 (no loss supplied for SingleUpdateStep)
I1110 23:51:33.633312  2593 solver.cpp:310]     Train net output #0: loss = 0.477058 (* 1 = 0.477058 loss)
I1110 23:51:33.633334  2593 sgd_solver.cpp:106] Iteration 2504, lr = 0.0005
I1110 23:51:36.163429  2593 solver.cpp:295] Iteration 2505 (no loss supplied for SingleUpdateStep)
I1110 23:51:36.163524  2593 solver.cpp:310]     Train net output #0: loss = 0.406683 (* 1 = 0.406683 loss)
I1110 23:51:36.163544  2593 sgd_solver.cpp:106] Iteration 2505, lr = 0.0005
I1110 23:51:38.454632  2593 solver.cpp:295] Iteration 2506 (no loss supplied for SingleUpdateStep)
I1110 23:51:38.454696  2593 solver.cpp:310]     Train net output #0: loss = 0.418181 (* 1 = 0.418181 loss)
I1110 23:51:38.454715  2593 sgd_solver.cpp:106] Iteration 2506, lr = 0.0005
I1110 23:51:40.833844  2593 solver.cpp:295] Iteration 2507 (no loss supplied for SingleUpdateStep)
I1110 23:51:40.833914  2593 solver.cpp:310]     Train net output #0: loss = 0.406421 (* 1 = 0.406421 loss)
I1110 23:51:40.833933  2593 sgd_solver.cpp:106] Iteration 2507, lr = 0.0005
I1110 23:51:43.222889  2593 solver.cpp:295] Iteration 2508 (no loss supplied for SingleUpdateStep)
I1110 23:51:43.222970  2593 solver.cpp:310]     Train net output #0: loss = 0.436133 (* 1 = 0.436133 loss)
I1110 23:51:43.222991  2593 sgd_solver.cpp:106] Iteration 2508, lr = 0.0005
I1110 23:51:45.790545  2593 solver.cpp:295] Iteration 2509 (no loss supplied for SingleUpdateStep)
I1110 23:51:45.790666  2593 solver.cpp:310]     Train net output #0: loss = 0.439594 (* 1 = 0.439594 loss)
I1110 23:51:45.790689  2593 sgd_solver.cpp:106] Iteration 2509, lr = 0.0005
I1110 23:51:49.182520  2593 solver.cpp:295] Iteration 2510 (no loss supplied for SingleUpdateStep)
I1110 23:51:49.182627  2593 solver.cpp:310]     Train net output #0: loss = 0.457069 (* 1 = 0.457069 loss)
I1110 23:51:49.182651  2593 sgd_solver.cpp:106] Iteration 2510, lr = 0.0005
I1110 23:51:51.975069  2593 solver.cpp:295] Iteration 2511 (no loss supplied for SingleUpdateStep)
I1110 23:51:51.975193  2593 solver.cpp:310]     Train net output #0: loss = 0.392593 (* 1 = 0.392593 loss)
I1110 23:51:51.975219  2593 sgd_solver.cpp:106] Iteration 2511, lr = 0.0005
I1110 23:51:54.389556  2593 solver.cpp:295] Iteration 2512 (no loss supplied for SingleUpdateStep)
I1110 23:51:54.389683  2593 solver.cpp:310]     Train net output #0: loss = 0.415823 (* 1 = 0.415823 loss)
I1110 23:51:54.389706  2593 sgd_solver.cpp:106] Iteration 2512, lr = 0.0005
I1110 23:51:56.592267  2593 solver.cpp:295] Iteration 2513 (no loss supplied for SingleUpdateStep)
I1110 23:51:56.592417  2593 solver.cpp:310]     Train net output #0: loss = 0.400946 (* 1 = 0.400946 loss)
I1110 23:51:56.592442  2593 sgd_solver.cpp:106] Iteration 2513, lr = 0.0005
I1110 23:51:59.076261  2593 solver.cpp:295] Iteration 2514 (no loss supplied for SingleUpdateStep)
I1110 23:51:59.076357  2593 solver.cpp:310]     Train net output #0: loss = 0.432901 (* 1 = 0.432901 loss)
I1110 23:51:59.076380  2593 sgd_solver.cpp:106] Iteration 2514, lr = 0.0005
I1110 23:52:01.362418  2593 solver.cpp:295] Iteration 2515 (no loss supplied for SingleUpdateStep)
I1110 23:52:01.362506  2593 solver.cpp:310]     Train net output #0: loss = 0.42496 (* 1 = 0.42496 loss)
I1110 23:52:01.362527  2593 sgd_solver.cpp:106] Iteration 2515, lr = 0.0005
I1110 23:52:03.703537  2593 solver.cpp:295] Iteration 2516 (no loss supplied for SingleUpdateStep)
I1110 23:52:03.703660  2593 solver.cpp:310]     Train net output #0: loss = 0.411949 (* 1 = 0.411949 loss)
I1110 23:52:03.703683  2593 sgd_solver.cpp:106] Iteration 2516, lr = 0.0005
I1110 23:52:06.044126  2593 solver.cpp:295] Iteration 2517 (no loss supplied for SingleUpdateStep)
I1110 23:52:06.044183  2593 solver.cpp:310]     Train net output #0: loss = 0.408956 (* 1 = 0.408956 loss)
I1110 23:52:06.044200  2593 sgd_solver.cpp:106] Iteration 2517, lr = 0.0005
I1110 23:52:08.371170  2593 solver.cpp:295] Iteration 2518 (no loss supplied for SingleUpdateStep)
I1110 23:52:08.371237  2593 solver.cpp:310]     Train net output #0: loss = 0.424939 (* 1 = 0.424939 loss)
I1110 23:52:08.371256  2593 sgd_solver.cpp:106] Iteration 2518, lr = 0.0005
I1110 23:52:10.690486  2593 solver.cpp:295] Iteration 2519 (no loss supplied for SingleUpdateStep)
I1110 23:52:10.690546  2593 solver.cpp:310]     Train net output #0: loss = 0.42541 (* 1 = 0.42541 loss)
I1110 23:52:10.690565  2593 sgd_solver.cpp:106] Iteration 2519, lr = 0.0005
I1110 23:52:12.945752  2593 solver.cpp:295] Iteration 2520 (no loss supplied for SingleUpdateStep)
I1110 23:52:12.945807  2593 solver.cpp:310]     Train net output #0: loss = 0.464194 (* 1 = 0.464194 loss)
I1110 23:52:12.945826  2593 sgd_solver.cpp:106] Iteration 2520, lr = 0.0005
I1110 23:52:15.140715  2593 solver.cpp:295] Iteration 2521 (no loss supplied for SingleUpdateStep)
I1110 23:52:15.140830  2593 solver.cpp:310]     Train net output #0: loss = 0.433332 (* 1 = 0.433332 loss)
I1110 23:52:15.140851  2593 sgd_solver.cpp:106] Iteration 2521, lr = 0.0005
I1110 23:52:17.518378  2593 solver.cpp:295] Iteration 2522 (no loss supplied for SingleUpdateStep)
I1110 23:52:17.518498  2593 solver.cpp:310]     Train net output #0: loss = 0.404938 (* 1 = 0.404938 loss)
I1110 23:52:17.518522  2593 sgd_solver.cpp:106] Iteration 2522, lr = 0.0005
I1110 23:52:20.109668  2593 solver.cpp:295] Iteration 2523 (no loss supplied for SingleUpdateStep)
I1110 23:52:20.109732  2593 solver.cpp:310]     Train net output #0: loss = 0.445565 (* 1 = 0.445565 loss)
I1110 23:52:20.109752  2593 sgd_solver.cpp:106] Iteration 2523, lr = 0.0005
I1110 23:52:22.395895  2593 solver.cpp:295] Iteration 2524 (no loss supplied for SingleUpdateStep)
I1110 23:52:22.395951  2593 solver.cpp:310]     Train net output #0: loss = 0.435919 (* 1 = 0.435919 loss)
I1110 23:52:22.395968  2593 sgd_solver.cpp:106] Iteration 2524, lr = 0.0005
I1110 23:52:24.646503  2593 solver.cpp:295] Iteration 2525 (no loss supplied for SingleUpdateStep)
I1110 23:52:24.646662  2593 solver.cpp:310]     Train net output #0: loss = 0.420428 (* 1 = 0.420428 loss)
I1110 23:52:24.646685  2593 sgd_solver.cpp:106] Iteration 2525, lr = 0.0005
I1110 23:52:27.319000  2593 solver.cpp:295] Iteration 2526 (no loss supplied for SingleUpdateStep)
I1110 23:52:27.319114  2593 solver.cpp:310]     Train net output #0: loss = 0.426379 (* 1 = 0.426379 loss)
I1110 23:52:27.319136  2593 sgd_solver.cpp:106] Iteration 2526, lr = 0.0005
I1110 23:52:29.877362  2593 solver.cpp:295] Iteration 2527 (no loss supplied for SingleUpdateStep)
I1110 23:52:29.877439  2593 solver.cpp:310]     Train net output #0: loss = 0.41644 (* 1 = 0.41644 loss)
I1110 23:52:29.877460  2593 sgd_solver.cpp:106] Iteration 2527, lr = 0.0005
I1110 23:52:32.289487  2593 solver.cpp:295] Iteration 2528 (no loss supplied for SingleUpdateStep)
I1110 23:52:32.289597  2593 solver.cpp:310]     Train net output #0: loss = 0.403074 (* 1 = 0.403074 loss)
I1110 23:52:32.289620  2593 sgd_solver.cpp:106] Iteration 2528, lr = 0.0005
I1110 23:52:34.666347  2593 solver.cpp:295] Iteration 2529 (no loss supplied for SingleUpdateStep)
I1110 23:52:34.666447  2593 solver.cpp:310]     Train net output #0: loss = 0.390979 (* 1 = 0.390979 loss)
I1110 23:52:34.666470  2593 sgd_solver.cpp:106] Iteration 2529, lr = 0.0005
I1110 23:52:37.006256  2593 solver.cpp:295] Iteration 2530 (no loss supplied for SingleUpdateStep)
I1110 23:52:37.006358  2593 solver.cpp:310]     Train net output #0: loss = 0.445715 (* 1 = 0.445715 loss)
I1110 23:52:37.006381  2593 sgd_solver.cpp:106] Iteration 2530, lr = 0.0005
I1110 23:52:39.280117  2593 solver.cpp:295] Iteration 2531 (no loss supplied for SingleUpdateStep)
I1110 23:52:39.280275  2593 solver.cpp:310]     Train net output #0: loss = 0.400255 (* 1 = 0.400255 loss)
I1110 23:52:39.280304  2593 sgd_solver.cpp:106] Iteration 2531, lr = 0.0005
I1110 23:52:41.563014  2593 solver.cpp:295] Iteration 2532 (no loss supplied for SingleUpdateStep)
I1110 23:52:41.563112  2593 solver.cpp:310]     Train net output #0: loss = 0.443826 (* 1 = 0.443826 loss)
I1110 23:52:41.563133  2593 sgd_solver.cpp:106] Iteration 2532, lr = 0.0005
I1110 23:52:44.489799  2593 solver.cpp:295] Iteration 2533 (no loss supplied for SingleUpdateStep)
I1110 23:52:44.489902  2593 solver.cpp:310]     Train net output #0: loss = 0.42227 (* 1 = 0.42227 loss)
I1110 23:52:44.489924  2593 sgd_solver.cpp:106] Iteration 2533, lr = 0.0005
I1110 23:52:47.896059  2593 solver.cpp:295] Iteration 2534 (no loss supplied for SingleUpdateStep)
I1110 23:52:47.896190  2593 solver.cpp:310]     Train net output #0: loss = 0.440959 (* 1 = 0.440959 loss)
I1110 23:52:47.896215  2593 sgd_solver.cpp:106] Iteration 2534, lr = 0.0005
I1110 23:52:50.987232  2593 solver.cpp:295] Iteration 2535 (no loss supplied for SingleUpdateStep)
I1110 23:52:50.987337  2593 solver.cpp:310]     Train net output #0: loss = 0.468084 (* 1 = 0.468084 loss)
I1110 23:52:50.987360  2593 sgd_solver.cpp:106] Iteration 2535, lr = 0.0005
I1110 23:52:53.964030  2593 solver.cpp:295] Iteration 2536 (no loss supplied for SingleUpdateStep)
I1110 23:52:53.964159  2593 solver.cpp:310]     Train net output #0: loss = 0.390061 (* 1 = 0.390061 loss)
I1110 23:52:53.964184  2593 sgd_solver.cpp:106] Iteration 2536, lr = 0.0005
I1110 23:52:57.029156  2593 solver.cpp:295] Iteration 2537 (no loss supplied for SingleUpdateStep)
I1110 23:52:57.029288  2593 solver.cpp:310]     Train net output #0: loss = 0.428299 (* 1 = 0.428299 loss)
I1110 23:52:57.029310  2593 sgd_solver.cpp:106] Iteration 2537, lr = 0.0005
I1110 23:53:00.440546  2593 solver.cpp:295] Iteration 2538 (no loss supplied for SingleUpdateStep)
I1110 23:53:00.440647  2593 solver.cpp:310]     Train net output #0: loss = 0.453564 (* 1 = 0.453564 loss)
I1110 23:53:00.440670  2593 sgd_solver.cpp:106] Iteration 2538, lr = 0.0005
I1110 23:53:03.213035  2593 solver.cpp:295] Iteration 2539 (no loss supplied for SingleUpdateStep)
I1110 23:53:03.213248  2593 solver.cpp:310]     Train net output #0: loss = 0.434604 (* 1 = 0.434604 loss)
I1110 23:53:03.213280  2593 sgd_solver.cpp:106] Iteration 2539, lr = 0.0005
I1110 23:53:05.767443  2593 solver.cpp:295] Iteration 2540 (no loss supplied for SingleUpdateStep)
I1110 23:53:05.767529  2593 solver.cpp:310]     Train net output #0: loss = 0.418627 (* 1 = 0.418627 loss)
I1110 23:53:05.767551  2593 sgd_solver.cpp:106] Iteration 2540, lr = 0.0005
I1110 23:53:08.113409  2593 solver.cpp:295] Iteration 2541 (no loss supplied for SingleUpdateStep)
I1110 23:53:08.113595  2593 solver.cpp:310]     Train net output #0: loss = 0.405579 (* 1 = 0.405579 loss)
I1110 23:53:08.113620  2593 sgd_solver.cpp:106] Iteration 2541, lr = 0.0005
I1110 23:53:10.463084  2593 solver.cpp:295] Iteration 2542 (no loss supplied for SingleUpdateStep)
I1110 23:53:10.463156  2593 solver.cpp:310]     Train net output #0: loss = 0.458278 (* 1 = 0.458278 loss)
I1110 23:53:10.463176  2593 sgd_solver.cpp:106] Iteration 2542, lr = 0.0005
I1110 23:53:12.762712  2593 solver.cpp:295] Iteration 2543 (no loss supplied for SingleUpdateStep)
I1110 23:53:12.762819  2593 solver.cpp:310]     Train net output #0: loss = 0.413021 (* 1 = 0.413021 loss)
I1110 23:53:12.762840  2593 sgd_solver.cpp:106] Iteration 2543, lr = 0.0005
I1110 23:53:15.476006  2593 solver.cpp:295] Iteration 2544 (no loss supplied for SingleUpdateStep)
I1110 23:53:15.476061  2593 solver.cpp:310]     Train net output #0: loss = 0.40925 (* 1 = 0.40925 loss)
I1110 23:53:15.476080  2593 sgd_solver.cpp:106] Iteration 2544, lr = 0.0005
I1110 23:53:18.543009  2593 solver.cpp:295] Iteration 2545 (no loss supplied for SingleUpdateStep)
I1110 23:53:18.543069  2593 solver.cpp:310]     Train net output #0: loss = 0.429236 (* 1 = 0.429236 loss)
I1110 23:53:18.543087  2593 sgd_solver.cpp:106] Iteration 2545, lr = 0.0005
I1110 23:53:21.458106  2593 solver.cpp:295] Iteration 2546 (no loss supplied for SingleUpdateStep)
I1110 23:53:21.458189  2593 solver.cpp:310]     Train net output #0: loss = 0.421671 (* 1 = 0.421671 loss)
I1110 23:53:21.458209  2593 sgd_solver.cpp:106] Iteration 2546, lr = 0.0005
I1110 23:53:24.240593  2593 solver.cpp:295] Iteration 2547 (no loss supplied for SingleUpdateStep)
I1110 23:53:24.240718  2593 solver.cpp:310]     Train net output #0: loss = 0.392458 (* 1 = 0.392458 loss)
I1110 23:53:24.240741  2593 sgd_solver.cpp:106] Iteration 2547, lr = 0.0005
I1110 23:53:26.646404  2593 solver.cpp:295] Iteration 2548 (no loss supplied for SingleUpdateStep)
I1110 23:53:26.646461  2593 solver.cpp:310]     Train net output #0: loss = 0.414942 (* 1 = 0.414942 loss)
I1110 23:53:26.646481  2593 sgd_solver.cpp:106] Iteration 2548, lr = 0.0005
I1110 23:53:29.099436  2593 solver.cpp:295] Iteration 2549 (no loss supplied for SingleUpdateStep)
I1110 23:53:29.099547  2593 solver.cpp:310]     Train net output #0: loss = 0.405496 (* 1 = 0.405496 loss)
I1110 23:53:29.099586  2593 sgd_solver.cpp:106] Iteration 2549, lr = 0.0005
I1110 23:53:31.463414  2593 solver.cpp:295] Iteration 2550 (no loss supplied for SingleUpdateStep)
I1110 23:53:31.463529  2593 solver.cpp:310]     Train net output #0: loss = 0.411122 (* 1 = 0.411122 loss)
I1110 23:53:31.463553  2593 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I1110 23:53:33.678843  2593 solver.cpp:295] Iteration 2551 (no loss supplied for SingleUpdateStep)
I1110 23:53:33.678984  2593 solver.cpp:310]     Train net output #0: loss = 0.417319 (* 1 = 0.417319 loss)
I1110 23:53:33.679008  2593 sgd_solver.cpp:106] Iteration 2551, lr = 0.0005
I1110 23:53:36.039033  2593 solver.cpp:295] Iteration 2552 (no loss supplied for SingleUpdateStep)
I1110 23:53:36.039119  2593 solver.cpp:310]     Train net output #0: loss = 0.375634 (* 1 = 0.375634 loss)
I1110 23:53:36.039139  2593 sgd_solver.cpp:106] Iteration 2552, lr = 0.0005
I1110 23:53:38.299228  2593 solver.cpp:295] Iteration 2553 (no loss supplied for SingleUpdateStep)
I1110 23:53:38.299362  2593 solver.cpp:310]     Train net output #0: loss = 0.452796 (* 1 = 0.452796 loss)
I1110 23:53:38.299412  2593 sgd_solver.cpp:106] Iteration 2553, lr = 0.0005
I1110 23:53:40.918902  2593 solver.cpp:295] Iteration 2554 (no loss supplied for SingleUpdateStep)
I1110 23:53:40.919001  2593 solver.cpp:310]     Train net output #0: loss = 0.410204 (* 1 = 0.410204 loss)
I1110 23:53:40.919023  2593 sgd_solver.cpp:106] Iteration 2554, lr = 0.0005
I1110 23:53:43.433987  2593 solver.cpp:295] Iteration 2555 (no loss supplied for SingleUpdateStep)
I1110 23:53:43.434053  2593 solver.cpp:310]     Train net output #0: loss = 0.430901 (* 1 = 0.430901 loss)
I1110 23:53:43.434072  2593 sgd_solver.cpp:106] Iteration 2555, lr = 0.0005
I1110 23:53:46.121647  2593 solver.cpp:295] Iteration 2556 (no loss supplied for SingleUpdateStep)
I1110 23:53:46.121820  2593 solver.cpp:310]     Train net output #0: loss = 0.392663 (* 1 = 0.392663 loss)
I1110 23:53:46.121858  2593 sgd_solver.cpp:106] Iteration 2556, lr = 0.0005
I1110 23:53:49.616345  2593 solver.cpp:295] Iteration 2557 (no loss supplied for SingleUpdateStep)
I1110 23:53:49.616462  2593 solver.cpp:310]     Train net output #0: loss = 0.418863 (* 1 = 0.418863 loss)
I1110 23:53:49.616483  2593 sgd_solver.cpp:106] Iteration 2557, lr = 0.0005
I1110 23:53:54.546432  2593 solver.cpp:295] Iteration 2558 (no loss supplied for SingleUpdateStep)
I1110 23:53:54.546541  2593 solver.cpp:310]     Train net output #0: loss = 0.431728 (* 1 = 0.431728 loss)
I1110 23:53:54.546564  2593 sgd_solver.cpp:106] Iteration 2558, lr = 0.0005
I1110 23:53:59.675209  2593 solver.cpp:295] Iteration 2559 (no loss supplied for SingleUpdateStep)
I1110 23:53:59.675312  2593 solver.cpp:310]     Train net output #0: loss = 0.38246 (* 1 = 0.38246 loss)
I1110 23:53:59.675334  2593 sgd_solver.cpp:106] Iteration 2559, lr = 0.0005
I1110 23:54:04.124516  2593 solver.cpp:295] Iteration 2560 (no loss supplied for SingleUpdateStep)
I1110 23:54:04.124583  2593 solver.cpp:310]     Train net output #0: loss = 0.440008 (* 1 = 0.440008 loss)
I1110 23:54:04.124603  2593 sgd_solver.cpp:106] Iteration 2560, lr = 0.0005
I1110 23:54:08.014132  2593 solver.cpp:295] Iteration 2561 (no loss supplied for SingleUpdateStep)
I1110 23:54:08.014231  2593 solver.cpp:310]     Train net output #0: loss = 0.43736 (* 1 = 0.43736 loss)
I1110 23:54:08.014252  2593 sgd_solver.cpp:106] Iteration 2561, lr = 0.0005
I1110 23:54:12.022327  2593 solver.cpp:295] Iteration 2562 (no loss supplied for SingleUpdateStep)
I1110 23:54:12.022430  2593 solver.cpp:310]     Train net output #0: loss = 0.418987 (* 1 = 0.418987 loss)
I1110 23:54:12.022450  2593 sgd_solver.cpp:106] Iteration 2562, lr = 0.0005
I1110 23:54:15.916823  2593 solver.cpp:295] Iteration 2563 (no loss supplied for SingleUpdateStep)
I1110 23:54:15.916951  2593 solver.cpp:310]     Train net output #0: loss = 0.40811 (* 1 = 0.40811 loss)
I1110 23:54:15.916973  2593 sgd_solver.cpp:106] Iteration 2563, lr = 0.0005
I1110 23:54:22.858969  2593 solver.cpp:295] Iteration 2564 (no loss supplied for SingleUpdateStep)
I1110 23:54:22.859027  2593 solver.cpp:310]     Train net output #0: loss = 0.438146 (* 1 = 0.438146 loss)
I1110 23:54:22.859046  2593 sgd_solver.cpp:106] Iteration 2564, lr = 0.0005
I1110 23:54:25.984184  2593 solver.cpp:295] Iteration 2565 (no loss supplied for SingleUpdateStep)
I1110 23:54:25.984324  2593 solver.cpp:310]     Train net output #0: loss = 0.398073 (* 1 = 0.398073 loss)
I1110 23:54:25.984346  2593 sgd_solver.cpp:106] Iteration 2565, lr = 0.0005
I1110 23:54:28.633395  2593 solver.cpp:295] Iteration 2566 (no loss supplied for SingleUpdateStep)
I1110 23:54:28.633515  2593 solver.cpp:310]     Train net output #0: loss = 0.419704 (* 1 = 0.419704 loss)
I1110 23:54:28.633536  2593 sgd_solver.cpp:106] Iteration 2566, lr = 0.0005
I1110 23:54:31.326112  2593 solver.cpp:295] Iteration 2567 (no loss supplied for SingleUpdateStep)
I1110 23:54:31.326251  2593 solver.cpp:310]     Train net output #0: loss = 0.397325 (* 1 = 0.397325 loss)
I1110 23:54:31.326282  2593 sgd_solver.cpp:106] Iteration 2567, lr = 0.0005
I1110 23:54:34.202041  2593 solver.cpp:295] Iteration 2568 (no loss supplied for SingleUpdateStep)
I1110 23:54:34.202147  2593 solver.cpp:310]     Train net output #0: loss = 0.42247 (* 1 = 0.42247 loss)
I1110 23:54:34.202172  2593 sgd_solver.cpp:106] Iteration 2568, lr = 0.0005
I1110 23:54:37.206706  2593 solver.cpp:295] Iteration 2569 (no loss supplied for SingleUpdateStep)
I1110 23:54:37.206823  2593 solver.cpp:310]     Train net output #0: loss = 0.409412 (* 1 = 0.409412 loss)
I1110 23:54:37.206846  2593 sgd_solver.cpp:106] Iteration 2569, lr = 0.0005
I1110 23:54:40.331058  2593 solver.cpp:295] Iteration 2570 (no loss supplied for SingleUpdateStep)
I1110 23:54:40.331122  2593 solver.cpp:310]     Train net output #0: loss = 0.402109 (* 1 = 0.402109 loss)
I1110 23:54:40.331141  2593 sgd_solver.cpp:106] Iteration 2570, lr = 0.0005
I1110 23:54:43.073907  2593 solver.cpp:295] Iteration 2571 (no loss supplied for SingleUpdateStep)
I1110 23:54:43.074033  2593 solver.cpp:310]     Train net output #0: loss = 0.436692 (* 1 = 0.436692 loss)
I1110 23:54:43.074060  2593 sgd_solver.cpp:106] Iteration 2571, lr = 0.0005
I1110 23:54:45.862773  2593 solver.cpp:295] Iteration 2572 (no loss supplied for SingleUpdateStep)
I1110 23:54:45.862879  2593 solver.cpp:310]     Train net output #0: loss = 0.439875 (* 1 = 0.439875 loss)
I1110 23:54:45.862898  2593 sgd_solver.cpp:106] Iteration 2572, lr = 0.0005
I1110 23:54:48.552858  2593 solver.cpp:295] Iteration 2573 (no loss supplied for SingleUpdateStep)
I1110 23:54:48.553061  2593 solver.cpp:310]     Train net output #0: loss = 0.422209 (* 1 = 0.422209 loss)
I1110 23:54:48.553095  2593 sgd_solver.cpp:106] Iteration 2573, lr = 0.0005
I1110 23:54:51.021185  2593 solver.cpp:295] Iteration 2574 (no loss supplied for SingleUpdateStep)
I1110 23:54:51.021297  2593 solver.cpp:310]     Train net output #0: loss = 0.402802 (* 1 = 0.402802 loss)
I1110 23:54:51.021322  2593 sgd_solver.cpp:106] Iteration 2574, lr = 0.0005
I1110 23:54:53.690407  2593 solver.cpp:295] Iteration 2575 (no loss supplied for SingleUpdateStep)
I1110 23:54:53.690465  2593 solver.cpp:310]     Train net output #0: loss = 0.425399 (* 1 = 0.425399 loss)
I1110 23:54:53.690485  2593 sgd_solver.cpp:106] Iteration 2575, lr = 0.0005
I1110 23:54:56.134472  2593 solver.cpp:295] Iteration 2576 (no loss supplied for SingleUpdateStep)
I1110 23:54:56.134630  2593 solver.cpp:310]     Train net output #0: loss = 0.400809 (* 1 = 0.400809 loss)
I1110 23:54:56.134657  2593 sgd_solver.cpp:106] Iteration 2576, lr = 0.0005
I1110 23:54:58.410590  2593 solver.cpp:295] Iteration 2577 (no loss supplied for SingleUpdateStep)
I1110 23:54:58.410703  2593 solver.cpp:310]     Train net output #0: loss = 0.419482 (* 1 = 0.419482 loss)
I1110 23:54:58.410727  2593 sgd_solver.cpp:106] Iteration 2577, lr = 0.0005
I1110 23:55:00.822288  2593 solver.cpp:295] Iteration 2578 (no loss supplied for SingleUpdateStep)
I1110 23:55:00.822367  2593 solver.cpp:310]     Train net output #0: loss = 0.416124 (* 1 = 0.416124 loss)
I1110 23:55:00.822389  2593 sgd_solver.cpp:106] Iteration 2578, lr = 0.0005
I1110 23:55:03.165585  2593 solver.cpp:295] Iteration 2579 (no loss supplied for SingleUpdateStep)
I1110 23:55:03.165698  2593 solver.cpp:310]     Train net output #0: loss = 0.449317 (* 1 = 0.449317 loss)
I1110 23:55:03.165720  2593 sgd_solver.cpp:106] Iteration 2579, lr = 0.0005
I1110 23:55:05.498901  2593 solver.cpp:295] Iteration 2580 (no loss supplied for SingleUpdateStep)
I1110 23:55:05.498999  2593 solver.cpp:310]     Train net output #0: loss = 0.410364 (* 1 = 0.410364 loss)
I1110 23:55:05.499019  2593 sgd_solver.cpp:106] Iteration 2580, lr = 0.0005
I1110 23:55:07.840878  2593 solver.cpp:295] Iteration 2581 (no loss supplied for SingleUpdateStep)
I1110 23:55:07.840975  2593 solver.cpp:310]     Train net output #0: loss = 0.400671 (* 1 = 0.400671 loss)
I1110 23:55:07.840996  2593 sgd_solver.cpp:106] Iteration 2581, lr = 0.0005
I1110 23:55:10.185446  2593 solver.cpp:295] Iteration 2582 (no loss supplied for SingleUpdateStep)
I1110 23:55:10.185571  2593 solver.cpp:310]     Train net output #0: loss = 0.406171 (* 1 = 0.406171 loss)
I1110 23:55:10.185595  2593 sgd_solver.cpp:106] Iteration 2582, lr = 0.0005
I1110 23:55:12.500442  2593 solver.cpp:295] Iteration 2583 (no loss supplied for SingleUpdateStep)
I1110 23:55:12.500531  2593 solver.cpp:310]     Train net output #0: loss = 0.458589 (* 1 = 0.458589 loss)
I1110 23:55:12.500552  2593 sgd_solver.cpp:106] Iteration 2583, lr = 0.0005
I1110 23:55:14.992439  2593 solver.cpp:295] Iteration 2584 (no loss supplied for SingleUpdateStep)
I1110 23:55:14.992529  2593 solver.cpp:310]     Train net output #0: loss = 0.436414 (* 1 = 0.436414 loss)
I1110 23:55:14.992553  2593 sgd_solver.cpp:106] Iteration 2584, lr = 0.0005
I1110 23:55:17.404548  2593 solver.cpp:295] Iteration 2585 (no loss supplied for SingleUpdateStep)
I1110 23:55:17.404638  2593 solver.cpp:310]     Train net output #0: loss = 0.419186 (* 1 = 0.419186 loss)
I1110 23:55:17.404659  2593 sgd_solver.cpp:106] Iteration 2585, lr = 0.0005
I1110 23:55:19.675789  2593 solver.cpp:295] Iteration 2586 (no loss supplied for SingleUpdateStep)
I1110 23:55:19.675851  2593 solver.cpp:310]     Train net output #0: loss = 0.418815 (* 1 = 0.418815 loss)
I1110 23:55:19.675870  2593 sgd_solver.cpp:106] Iteration 2586, lr = 0.0005
I1110 23:55:22.186069  2593 solver.cpp:295] Iteration 2587 (no loss supplied for SingleUpdateStep)
I1110 23:55:22.186168  2593 solver.cpp:310]     Train net output #0: loss = 0.416507 (* 1 = 0.416507 loss)
I1110 23:55:22.186188  2593 sgd_solver.cpp:106] Iteration 2587, lr = 0.0005
I1110 23:55:24.648393  2593 solver.cpp:295] Iteration 2588 (no loss supplied for SingleUpdateStep)
I1110 23:55:24.648566  2593 solver.cpp:310]     Train net output #0: loss = 0.4287 (* 1 = 0.4287 loss)
I1110 23:55:24.648598  2593 sgd_solver.cpp:106] Iteration 2588, lr = 0.0005
I1110 23:55:27.072954  2593 solver.cpp:295] Iteration 2589 (no loss supplied for SingleUpdateStep)
I1110 23:55:27.073168  2593 solver.cpp:310]     Train net output #0: loss = 0.409799 (* 1 = 0.409799 loss)
I1110 23:55:27.073197  2593 sgd_solver.cpp:106] Iteration 2589, lr = 0.0005
I1110 23:55:29.768859  2593 solver.cpp:295] Iteration 2590 (no loss supplied for SingleUpdateStep)
I1110 23:55:29.768995  2593 solver.cpp:310]     Train net output #0: loss = 0.457965 (* 1 = 0.457965 loss)
I1110 23:55:29.769021  2593 sgd_solver.cpp:106] Iteration 2590, lr = 0.0005
I1110 23:55:32.175678  2593 solver.cpp:295] Iteration 2591 (no loss supplied for SingleUpdateStep)
I1110 23:55:32.175819  2593 solver.cpp:310]     Train net output #0: loss = 0.439848 (* 1 = 0.439848 loss)
I1110 23:55:32.175842  2593 sgd_solver.cpp:106] Iteration 2591, lr = 0.0005
I1110 23:55:34.548689  2593 solver.cpp:295] Iteration 2592 (no loss supplied for SingleUpdateStep)
I1110 23:55:34.548820  2593 solver.cpp:310]     Train net output #0: loss = 0.447028 (* 1 = 0.447028 loss)
I1110 23:55:34.548843  2593 sgd_solver.cpp:106] Iteration 2592, lr = 0.0005
I1110 23:55:36.988808  2593 solver.cpp:295] Iteration 2593 (no loss supplied for SingleUpdateStep)
I1110 23:55:36.988945  2593 solver.cpp:310]     Train net output #0: loss = 0.426475 (* 1 = 0.426475 loss)
I1110 23:55:36.988972  2593 sgd_solver.cpp:106] Iteration 2593, lr = 0.0005
I1110 23:55:39.477897  2593 solver.cpp:295] Iteration 2594 (no loss supplied for SingleUpdateStep)
I1110 23:55:39.478020  2593 solver.cpp:310]     Train net output #0: loss = 0.426698 (* 1 = 0.426698 loss)
I1110 23:55:39.478045  2593 sgd_solver.cpp:106] Iteration 2594, lr = 0.0005
I1110 23:55:41.796725  2593 solver.cpp:295] Iteration 2595 (no loss supplied for SingleUpdateStep)
I1110 23:55:41.796836  2593 solver.cpp:310]     Train net output #0: loss = 0.424837 (* 1 = 0.424837 loss)
I1110 23:55:41.796857  2593 sgd_solver.cpp:106] Iteration 2595, lr = 0.0005
I1110 23:55:44.337474  2593 solver.cpp:295] Iteration 2596 (no loss supplied for SingleUpdateStep)
I1110 23:55:44.337541  2593 solver.cpp:310]     Train net output #0: loss = 0.401421 (* 1 = 0.401421 loss)
I1110 23:55:44.337560  2593 sgd_solver.cpp:106] Iteration 2596, lr = 0.0005
I1110 23:55:46.693873  2593 solver.cpp:295] Iteration 2597 (no loss supplied for SingleUpdateStep)
I1110 23:55:46.693974  2593 solver.cpp:310]     Train net output #0: loss = 0.443303 (* 1 = 0.443303 loss)
I1110 23:55:46.693996  2593 sgd_solver.cpp:106] Iteration 2597, lr = 0.0005
I1110 23:55:49.240844  2593 solver.cpp:295] Iteration 2598 (no loss supplied for SingleUpdateStep)
I1110 23:55:49.240947  2593 solver.cpp:310]     Train net output #0: loss = 0.417701 (* 1 = 0.417701 loss)
I1110 23:55:49.240969  2593 sgd_solver.cpp:106] Iteration 2598, lr = 0.0005
I1110 23:55:51.681030  2593 solver.cpp:295] Iteration 2599 (no loss supplied for SingleUpdateStep)
I1110 23:55:51.681165  2593 solver.cpp:310]     Train net output #0: loss = 0.40539 (* 1 = 0.40539 loss)
I1110 23:55:51.681187  2593 sgd_solver.cpp:106] Iteration 2599, lr = 0.0005
I1110 23:55:53.933020  2593 solver.cpp:295] Iteration 2600 (no loss supplied for SingleUpdateStep)
I1110 23:55:53.933127  2593 solver.cpp:310]     Train net output #0: loss = 0.422902 (* 1 = 0.422902 loss)
I1110 23:55:53.933150  2593 sgd_solver.cpp:106] Iteration 2600, lr = 0.0005
I1110 23:55:56.332850  2593 solver.cpp:295] Iteration 2601 (no loss supplied for SingleUpdateStep)
I1110 23:55:56.332906  2593 solver.cpp:310]     Train net output #0: loss = 0.40259 (* 1 = 0.40259 loss)
I1110 23:55:56.332924  2593 sgd_solver.cpp:106] Iteration 2601, lr = 0.0005
I1110 23:55:58.756896  2593 solver.cpp:295] Iteration 2602 (no loss supplied for SingleUpdateStep)
I1110 23:55:58.757025  2593 solver.cpp:310]     Train net output #0: loss = 0.43764 (* 1 = 0.43764 loss)
I1110 23:55:58.757051  2593 sgd_solver.cpp:106] Iteration 2602, lr = 0.0005
I1110 23:56:01.297111  2593 solver.cpp:295] Iteration 2603 (no loss supplied for SingleUpdateStep)
I1110 23:56:01.297164  2593 solver.cpp:310]     Train net output #0: loss = 0.414683 (* 1 = 0.414683 loss)
I1110 23:56:01.297183  2593 sgd_solver.cpp:106] Iteration 2603, lr = 0.0005
I1110 23:56:03.806673  2593 solver.cpp:295] Iteration 2604 (no loss supplied for SingleUpdateStep)
I1110 23:56:03.806778  2593 solver.cpp:310]     Train net output #0: loss = 0.432062 (* 1 = 0.432062 loss)
I1110 23:56:03.806804  2593 sgd_solver.cpp:106] Iteration 2604, lr = 0.0005
I1110 23:56:06.674060  2593 solver.cpp:295] Iteration 2605 (no loss supplied for SingleUpdateStep)
I1110 23:56:06.674186  2593 solver.cpp:310]     Train net output #0: loss = 0.464272 (* 1 = 0.464272 loss)
I1110 23:56:06.674211  2593 sgd_solver.cpp:106] Iteration 2605, lr = 0.0005
I1110 23:56:09.112422  2593 solver.cpp:295] Iteration 2606 (no loss supplied for SingleUpdateStep)
I1110 23:56:09.112537  2593 solver.cpp:310]     Train net output #0: loss = 0.46319 (* 1 = 0.46319 loss)
I1110 23:56:09.112565  2593 sgd_solver.cpp:106] Iteration 2606, lr = 0.0005
I1110 23:56:11.417702  2593 solver.cpp:295] Iteration 2607 (no loss supplied for SingleUpdateStep)
I1110 23:56:11.417773  2593 solver.cpp:310]     Train net output #0: loss = 0.385803 (* 1 = 0.385803 loss)
I1110 23:56:11.417794  2593 sgd_solver.cpp:106] Iteration 2607, lr = 0.0005
I1110 23:56:13.760082  2593 solver.cpp:295] Iteration 2608 (no loss supplied for SingleUpdateStep)
I1110 23:56:13.760202  2593 solver.cpp:310]     Train net output #0: loss = 0.443048 (* 1 = 0.443048 loss)
I1110 23:56:13.760224  2593 sgd_solver.cpp:106] Iteration 2608, lr = 0.0005
I1110 23:56:16.069696  2593 solver.cpp:295] Iteration 2609 (no loss supplied for SingleUpdateStep)
I1110 23:56:16.069766  2593 solver.cpp:310]     Train net output #0: loss = 0.420588 (* 1 = 0.420588 loss)
I1110 23:56:16.069785  2593 sgd_solver.cpp:106] Iteration 2609, lr = 0.0005
I1110 23:56:18.458333  2593 solver.cpp:295] Iteration 2610 (no loss supplied for SingleUpdateStep)
I1110 23:56:18.458458  2593 solver.cpp:310]     Train net output #0: loss = 0.443492 (* 1 = 0.443492 loss)
I1110 23:56:18.458479  2593 sgd_solver.cpp:106] Iteration 2610, lr = 0.0005
I1110 23:56:20.793485  2593 solver.cpp:295] Iteration 2611 (no loss supplied for SingleUpdateStep)
I1110 23:56:20.793623  2593 solver.cpp:310]     Train net output #0: loss = 0.437178 (* 1 = 0.437178 loss)
I1110 23:56:20.793653  2593 sgd_solver.cpp:106] Iteration 2611, lr = 0.0005
I1110 23:56:23.292317  2593 solver.cpp:295] Iteration 2612 (no loss supplied for SingleUpdateStep)
I1110 23:56:23.292446  2593 solver.cpp:310]     Train net output #0: loss = 0.414975 (* 1 = 0.414975 loss)
I1110 23:56:23.292470  2593 sgd_solver.cpp:106] Iteration 2612, lr = 0.0005
I1110 23:56:26.081135  2593 solver.cpp:295] Iteration 2613 (no loss supplied for SingleUpdateStep)
I1110 23:56:26.081220  2593 solver.cpp:310]     Train net output #0: loss = 0.411077 (* 1 = 0.411077 loss)
I1110 23:56:26.081240  2593 sgd_solver.cpp:106] Iteration 2613, lr = 0.0005
I1110 23:56:28.379587  2593 solver.cpp:295] Iteration 2614 (no loss supplied for SingleUpdateStep)
I1110 23:56:28.379683  2593 solver.cpp:310]     Train net output #0: loss = 0.408513 (* 1 = 0.408513 loss)
I1110 23:56:28.379703  2593 sgd_solver.cpp:106] Iteration 2614, lr = 0.0005
I1110 23:56:30.788990  2593 solver.cpp:295] Iteration 2615 (no loss supplied for SingleUpdateStep)
I1110 23:56:30.789044  2593 solver.cpp:310]     Train net output #0: loss = 0.401701 (* 1 = 0.401701 loss)
I1110 23:56:30.789063  2593 sgd_solver.cpp:106] Iteration 2615, lr = 0.0005
I1110 23:56:33.165912  2593 solver.cpp:295] Iteration 2616 (no loss supplied for SingleUpdateStep)
I1110 23:56:33.165989  2593 solver.cpp:310]     Train net output #0: loss = 0.409197 (* 1 = 0.409197 loss)
I1110 23:56:33.166009  2593 sgd_solver.cpp:106] Iteration 2616, lr = 0.0005
I1110 23:56:35.594097  2593 solver.cpp:295] Iteration 2617 (no loss supplied for SingleUpdateStep)
I1110 23:56:35.594198  2593 solver.cpp:310]     Train net output #0: loss = 0.428506 (* 1 = 0.428506 loss)
I1110 23:56:35.594220  2593 sgd_solver.cpp:106] Iteration 2617, lr = 0.0005
I1110 23:56:38.022733  2593 solver.cpp:295] Iteration 2618 (no loss supplied for SingleUpdateStep)
I1110 23:56:38.022817  2593 solver.cpp:310]     Train net output #0: loss = 0.437428 (* 1 = 0.437428 loss)
I1110 23:56:38.022837  2593 sgd_solver.cpp:106] Iteration 2618, lr = 0.0005
I1110 23:56:40.373982  2593 solver.cpp:295] Iteration 2619 (no loss supplied for SingleUpdateStep)
I1110 23:56:40.374101  2593 solver.cpp:310]     Train net output #0: loss = 0.401691 (* 1 = 0.401691 loss)
I1110 23:56:40.374125  2593 sgd_solver.cpp:106] Iteration 2619, lr = 0.0005
I1110 23:56:42.771237  2593 solver.cpp:295] Iteration 2620 (no loss supplied for SingleUpdateStep)
I1110 23:56:42.771333  2593 solver.cpp:310]     Train net output #0: loss = 0.417497 (* 1 = 0.417497 loss)
I1110 23:56:42.771354  2593 sgd_solver.cpp:106] Iteration 2620, lr = 0.0005
I1110 23:56:44.935837  2593 solver.cpp:295] Iteration 2621 (no loss supplied for SingleUpdateStep)
I1110 23:56:44.935936  2593 solver.cpp:310]     Train net output #0: loss = 0.412554 (* 1 = 0.412554 loss)
I1110 23:56:44.935957  2593 sgd_solver.cpp:106] Iteration 2621, lr = 0.0005
I1110 23:56:47.334854  2593 solver.cpp:295] Iteration 2622 (no loss supplied for SingleUpdateStep)
I1110 23:56:47.334985  2593 solver.cpp:310]     Train net output #0: loss = 0.42326 (* 1 = 0.42326 loss)
I1110 23:56:47.335007  2593 sgd_solver.cpp:106] Iteration 2622, lr = 0.0005
I1110 23:56:49.900225  2593 solver.cpp:295] Iteration 2623 (no loss supplied for SingleUpdateStep)
I1110 23:56:49.900349  2593 solver.cpp:310]     Train net output #0: loss = 0.422644 (* 1 = 0.422644 loss)
I1110 23:56:49.900377  2593 sgd_solver.cpp:106] Iteration 2623, lr = 0.0005
I1110 23:56:52.411568  2593 solver.cpp:295] Iteration 2624 (no loss supplied for SingleUpdateStep)
I1110 23:56:52.411654  2593 solver.cpp:310]     Train net output #0: loss = 0.452115 (* 1 = 0.452115 loss)
I1110 23:56:52.411674  2593 sgd_solver.cpp:106] Iteration 2624, lr = 0.0005
I1110 23:56:54.639915  2593 solver.cpp:295] Iteration 2625 (no loss supplied for SingleUpdateStep)
I1110 23:56:54.640063  2593 solver.cpp:310]     Train net output #0: loss = 0.412307 (* 1 = 0.412307 loss)
I1110 23:56:54.640091  2593 sgd_solver.cpp:106] Iteration 2625, lr = 0.0005
I1110 23:56:56.889156  2593 solver.cpp:295] Iteration 2626 (no loss supplied for SingleUpdateStep)
I1110 23:56:56.889222  2593 solver.cpp:310]     Train net output #0: loss = 0.417519 (* 1 = 0.417519 loss)
I1110 23:56:56.889241  2593 sgd_solver.cpp:106] Iteration 2626, lr = 0.0005
I1110 23:56:59.475294  2593 solver.cpp:295] Iteration 2627 (no loss supplied for SingleUpdateStep)
I1110 23:56:59.475399  2593 solver.cpp:310]     Train net output #0: loss = 0.425741 (* 1 = 0.425741 loss)
I1110 23:56:59.475421  2593 sgd_solver.cpp:106] Iteration 2627, lr = 0.0005
I1110 23:57:01.817876  2593 solver.cpp:295] Iteration 2628 (no loss supplied for SingleUpdateStep)
I1110 23:57:01.818006  2593 solver.cpp:310]     Train net output #0: loss = 0.415049 (* 1 = 0.415049 loss)
I1110 23:57:01.818027  2593 sgd_solver.cpp:106] Iteration 2628, lr = 0.0005
I1110 23:57:04.208819  2593 solver.cpp:295] Iteration 2629 (no loss supplied for SingleUpdateStep)
I1110 23:57:04.208912  2593 solver.cpp:310]     Train net output #0: loss = 0.436768 (* 1 = 0.436768 loss)
I1110 23:57:04.208935  2593 sgd_solver.cpp:106] Iteration 2629, lr = 0.0005
I1110 23:57:06.454867  2593 solver.cpp:295] Iteration 2630 (no loss supplied for SingleUpdateStep)
I1110 23:57:06.454954  2593 solver.cpp:310]     Train net output #0: loss = 0.399778 (* 1 = 0.399778 loss)
I1110 23:57:06.454974  2593 sgd_solver.cpp:106] Iteration 2630, lr = 0.0005
I1110 23:57:09.369655  2593 solver.cpp:295] Iteration 2631 (no loss supplied for SingleUpdateStep)
I1110 23:57:09.369768  2593 solver.cpp:310]     Train net output #0: loss = 0.437623 (* 1 = 0.437623 loss)
I1110 23:57:09.369791  2593 sgd_solver.cpp:106] Iteration 2631, lr = 0.0005
I1110 23:57:13.035866  2593 solver.cpp:295] Iteration 2632 (no loss supplied for SingleUpdateStep)
I1110 23:57:13.035979  2593 solver.cpp:310]     Train net output #0: loss = 0.423957 (* 1 = 0.423957 loss)
I1110 23:57:13.036002  2593 sgd_solver.cpp:106] Iteration 2632, lr = 0.0005
I1110 23:57:15.627365  2593 solver.cpp:295] Iteration 2633 (no loss supplied for SingleUpdateStep)
I1110 23:57:15.627480  2593 solver.cpp:310]     Train net output #0: loss = 0.402291 (* 1 = 0.402291 loss)
I1110 23:57:15.627502  2593 sgd_solver.cpp:106] Iteration 2633, lr = 0.0005
I1110 23:57:17.892942  2593 solver.cpp:295] Iteration 2634 (no loss supplied for SingleUpdateStep)
I1110 23:57:17.893026  2593 solver.cpp:310]     Train net output #0: loss = 0.421012 (* 1 = 0.421012 loss)
I1110 23:57:17.893048  2593 sgd_solver.cpp:106] Iteration 2634, lr = 0.0005
I1110 23:57:20.401162  2593 solver.cpp:295] Iteration 2635 (no loss supplied for SingleUpdateStep)
I1110 23:57:20.401267  2593 solver.cpp:310]     Train net output #0: loss = 0.43373 (* 1 = 0.43373 loss)
I1110 23:57:20.401290  2593 sgd_solver.cpp:106] Iteration 2635, lr = 0.0005
I1110 23:57:23.166597  2593 solver.cpp:295] Iteration 2636 (no loss supplied for SingleUpdateStep)
I1110 23:57:23.166692  2593 solver.cpp:310]     Train net output #0: loss = 0.427043 (* 1 = 0.427043 loss)
I1110 23:57:23.166714  2593 sgd_solver.cpp:106] Iteration 2636, lr = 0.0005
I1110 23:57:26.038012  2593 solver.cpp:295] Iteration 2637 (no loss supplied for SingleUpdateStep)
I1110 23:57:26.038067  2593 solver.cpp:310]     Train net output #0: loss = 0.436104 (* 1 = 0.436104 loss)
I1110 23:57:26.038085  2593 sgd_solver.cpp:106] Iteration 2637, lr = 0.0005
I1110 23:57:29.582432  2593 solver.cpp:295] Iteration 2638 (no loss supplied for SingleUpdateStep)
I1110 23:57:29.582485  2593 solver.cpp:310]     Train net output #0: loss = 0.456693 (* 1 = 0.456693 loss)
I1110 23:57:29.582504  2593 sgd_solver.cpp:106] Iteration 2638, lr = 0.0005
I1110 23:57:32.784581  2593 solver.cpp:295] Iteration 2639 (no loss supplied for SingleUpdateStep)
I1110 23:57:32.784684  2593 solver.cpp:310]     Train net output #0: loss = 0.418071 (* 1 = 0.418071 loss)
I1110 23:57:32.784706  2593 sgd_solver.cpp:106] Iteration 2639, lr = 0.0005
I1110 23:57:36.730330  2593 solver.cpp:295] Iteration 2640 (no loss supplied for SingleUpdateStep)
I1110 23:57:36.730450  2593 solver.cpp:310]     Train net output #0: loss = 0.401772 (* 1 = 0.401772 loss)
I1110 23:57:36.730470  2593 sgd_solver.cpp:106] Iteration 2640, lr = 0.0005
I1110 23:57:41.566961  2593 solver.cpp:295] Iteration 2641 (no loss supplied for SingleUpdateStep)
I1110 23:57:41.567086  2593 solver.cpp:310]     Train net output #0: loss = 0.425024 (* 1 = 0.425024 loss)
I1110 23:57:41.567108  2593 sgd_solver.cpp:106] Iteration 2641, lr = 0.0005
I1110 23:57:45.054215  2593 solver.cpp:295] Iteration 2642 (no loss supplied for SingleUpdateStep)
I1110 23:57:45.054275  2593 solver.cpp:310]     Train net output #0: loss = 0.408144 (* 1 = 0.408144 loss)
I1110 23:57:45.054292  2593 sgd_solver.cpp:106] Iteration 2642, lr = 0.0005
I1110 23:57:48.233676  2593 solver.cpp:295] Iteration 2643 (no loss supplied for SingleUpdateStep)
I1110 23:57:48.233796  2593 solver.cpp:310]     Train net output #0: loss = 0.426969 (* 1 = 0.426969 loss)
I1110 23:57:48.233819  2593 sgd_solver.cpp:106] Iteration 2643, lr = 0.0005
I1110 23:57:51.293145  2593 solver.cpp:295] Iteration 2644 (no loss supplied for SingleUpdateStep)
I1110 23:57:51.293263  2593 solver.cpp:310]     Train net output #0: loss = 0.412955 (* 1 = 0.412955 loss)
I1110 23:57:51.293289  2593 sgd_solver.cpp:106] Iteration 2644, lr = 0.0005
I1110 23:57:53.830507  2593 solver.cpp:295] Iteration 2645 (no loss supplied for SingleUpdateStep)
I1110 23:57:53.830605  2593 solver.cpp:310]     Train net output #0: loss = 0.433038 (* 1 = 0.433038 loss)
I1110 23:57:53.830633  2593 sgd_solver.cpp:106] Iteration 2645, lr = 0.0005
I1110 23:57:56.925514  2593 solver.cpp:295] Iteration 2646 (no loss supplied for SingleUpdateStep)
I1110 23:57:56.925639  2593 solver.cpp:310]     Train net output #0: loss = 0.4585 (* 1 = 0.4585 loss)
I1110 23:57:56.925662  2593 sgd_solver.cpp:106] Iteration 2646, lr = 0.0005
I1110 23:57:59.538008  2593 solver.cpp:295] Iteration 2647 (no loss supplied for SingleUpdateStep)
I1110 23:57:59.538202  2593 solver.cpp:310]     Train net output #0: loss = 0.414775 (* 1 = 0.414775 loss)
I1110 23:57:59.538228  2593 sgd_solver.cpp:106] Iteration 2647, lr = 0.0005
I1110 23:58:01.822213  2593 solver.cpp:295] Iteration 2648 (no loss supplied for SingleUpdateStep)
I1110 23:58:01.822301  2593 solver.cpp:310]     Train net output #0: loss = 0.430418 (* 1 = 0.430418 loss)
I1110 23:58:01.822321  2593 sgd_solver.cpp:106] Iteration 2648, lr = 0.0005
I1110 23:58:04.353902  2593 solver.cpp:295] Iteration 2649 (no loss supplied for SingleUpdateStep)
I1110 23:58:04.354039  2593 solver.cpp:310]     Train net output #0: loss = 0.415817 (* 1 = 0.415817 loss)
I1110 23:58:04.354063  2593 sgd_solver.cpp:106] Iteration 2649, lr = 0.0005
I1110 23:58:06.897642  2593 solver.cpp:295] Iteration 2650 (no loss supplied for SingleUpdateStep)
I1110 23:58:06.897722  2593 solver.cpp:310]     Train net output #0: loss = 0.437189 (* 1 = 0.437189 loss)
I1110 23:58:06.897743  2593 sgd_solver.cpp:106] Iteration 2650, lr = 0.0005
I1110 23:58:09.736166  2593 solver.cpp:295] Iteration 2651 (no loss supplied for SingleUpdateStep)
I1110 23:58:09.736243  2593 solver.cpp:310]     Train net output #0: loss = 0.422304 (* 1 = 0.422304 loss)
I1110 23:58:09.736263  2593 sgd_solver.cpp:106] Iteration 2651, lr = 0.0005
I1110 23:58:12.206658  2593 solver.cpp:295] Iteration 2652 (no loss supplied for SingleUpdateStep)
I1110 23:58:12.206761  2593 solver.cpp:310]     Train net output #0: loss = 0.476789 (* 1 = 0.476789 loss)
I1110 23:58:12.206784  2593 sgd_solver.cpp:106] Iteration 2652, lr = 0.0005
I1110 23:58:14.545897  2593 solver.cpp:295] Iteration 2653 (no loss supplied for SingleUpdateStep)
I1110 23:58:14.545960  2593 solver.cpp:310]     Train net output #0: loss = 0.407145 (* 1 = 0.407145 loss)
I1110 23:58:14.545980  2593 sgd_solver.cpp:106] Iteration 2653, lr = 0.0005
I1110 23:58:17.024211  2593 solver.cpp:295] Iteration 2654 (no loss supplied for SingleUpdateStep)
I1110 23:58:17.024266  2593 solver.cpp:310]     Train net output #0: loss = 0.417827 (* 1 = 0.417827 loss)
I1110 23:58:17.024286  2593 sgd_solver.cpp:106] Iteration 2654, lr = 0.0005
I1110 23:58:19.677244  2593 solver.cpp:295] Iteration 2655 (no loss supplied for SingleUpdateStep)
I1110 23:58:19.677367  2593 solver.cpp:310]     Train net output #0: loss = 0.41838 (* 1 = 0.41838 loss)
I1110 23:58:19.677392  2593 sgd_solver.cpp:106] Iteration 2655, lr = 0.0005
I1110 23:58:22.382364  2593 solver.cpp:295] Iteration 2656 (no loss supplied for SingleUpdateStep)
I1110 23:58:22.382491  2593 solver.cpp:310]     Train net output #0: loss = 0.432571 (* 1 = 0.432571 loss)
I1110 23:58:22.382522  2593 sgd_solver.cpp:106] Iteration 2656, lr = 0.0005
I1110 23:58:24.951428  2593 solver.cpp:295] Iteration 2657 (no loss supplied for SingleUpdateStep)
I1110 23:58:24.951560  2593 solver.cpp:310]     Train net output #0: loss = 0.395475 (* 1 = 0.395475 loss)
I1110 23:58:24.951582  2593 sgd_solver.cpp:106] Iteration 2657, lr = 0.0005
I1110 23:58:27.511051  2593 solver.cpp:295] Iteration 2658 (no loss supplied for SingleUpdateStep)
I1110 23:58:27.511167  2593 solver.cpp:310]     Train net output #0: loss = 0.441414 (* 1 = 0.441414 loss)
I1110 23:58:27.511188  2593 sgd_solver.cpp:106] Iteration 2658, lr = 0.0005
I1110 23:58:30.078444  2593 solver.cpp:295] Iteration 2659 (no loss supplied for SingleUpdateStep)
I1110 23:58:30.078546  2593 solver.cpp:310]     Train net output #0: loss = 0.415335 (* 1 = 0.415335 loss)
I1110 23:58:30.078567  2593 sgd_solver.cpp:106] Iteration 2659, lr = 0.0005
I1110 23:58:32.640671  2593 solver.cpp:295] Iteration 2660 (no loss supplied for SingleUpdateStep)
I1110 23:58:32.640808  2593 solver.cpp:310]     Train net output #0: loss = 0.390818 (* 1 = 0.390818 loss)
I1110 23:58:32.640830  2593 sgd_solver.cpp:106] Iteration 2660, lr = 0.0005
I1110 23:58:34.978078  2593 solver.cpp:295] Iteration 2661 (no loss supplied for SingleUpdateStep)
I1110 23:58:34.978225  2593 solver.cpp:310]     Train net output #0: loss = 0.412405 (* 1 = 0.412405 loss)
I1110 23:58:34.978252  2593 sgd_solver.cpp:106] Iteration 2661, lr = 0.0005
I1110 23:58:37.269209  2593 solver.cpp:295] Iteration 2662 (no loss supplied for SingleUpdateStep)
I1110 23:58:37.269337  2593 solver.cpp:310]     Train net output #0: loss = 0.424145 (* 1 = 0.424145 loss)
I1110 23:58:37.269361  2593 sgd_solver.cpp:106] Iteration 2662, lr = 0.0005
I1110 23:58:39.549607  2593 solver.cpp:295] Iteration 2663 (no loss supplied for SingleUpdateStep)
I1110 23:58:39.549736  2593 solver.cpp:310]     Train net output #0: loss = 0.373592 (* 1 = 0.373592 loss)
I1110 23:58:39.549773  2593 sgd_solver.cpp:106] Iteration 2663, lr = 0.0005
I1110 23:58:41.818783  2593 solver.cpp:295] Iteration 2664 (no loss supplied for SingleUpdateStep)
I1110 23:58:41.818892  2593 solver.cpp:310]     Train net output #0: loss = 0.450935 (* 1 = 0.450935 loss)
I1110 23:58:41.818917  2593 sgd_solver.cpp:106] Iteration 2664, lr = 0.0005
I1110 23:58:44.110335  2593 solver.cpp:295] Iteration 2665 (no loss supplied for SingleUpdateStep)
I1110 23:58:44.110452  2593 solver.cpp:310]     Train net output #0: loss = 0.424593 (* 1 = 0.424593 loss)
I1110 23:58:44.110476  2593 sgd_solver.cpp:106] Iteration 2665, lr = 0.0005
I1110 23:58:46.490968  2593 solver.cpp:295] Iteration 2666 (no loss supplied for SingleUpdateStep)
I1110 23:58:46.491061  2593 solver.cpp:310]     Train net output #0: loss = 0.412588 (* 1 = 0.412588 loss)
I1110 23:58:46.491083  2593 sgd_solver.cpp:106] Iteration 2666, lr = 0.0005
I1110 23:58:49.268476  2593 solver.cpp:295] Iteration 2667 (no loss supplied for SingleUpdateStep)
I1110 23:58:49.268532  2593 solver.cpp:310]     Train net output #0: loss = 0.435894 (* 1 = 0.435894 loss)
I1110 23:58:49.268556  2593 sgd_solver.cpp:106] Iteration 2667, lr = 0.0005
I1110 23:58:51.832598  2593 solver.cpp:295] Iteration 2668 (no loss supplied for SingleUpdateStep)
I1110 23:58:51.832655  2593 solver.cpp:310]     Train net output #0: loss = 0.423612 (* 1 = 0.423612 loss)
I1110 23:58:51.832674  2593 sgd_solver.cpp:106] Iteration 2668, lr = 0.0005
I1110 23:58:54.314946  2593 solver.cpp:295] Iteration 2669 (no loss supplied for SingleUpdateStep)
I1110 23:58:54.315057  2593 solver.cpp:310]     Train net output #0: loss = 0.44632 (* 1 = 0.44632 loss)
I1110 23:58:54.315083  2593 sgd_solver.cpp:106] Iteration 2669, lr = 0.0005
I1110 23:58:56.574120  2593 solver.cpp:295] Iteration 2670 (no loss supplied for SingleUpdateStep)
I1110 23:58:56.574196  2593 solver.cpp:310]     Train net output #0: loss = 0.392926 (* 1 = 0.392926 loss)
I1110 23:58:56.574216  2593 sgd_solver.cpp:106] Iteration 2670, lr = 0.0005
I1110 23:58:59.108343  2593 solver.cpp:295] Iteration 2671 (no loss supplied for SingleUpdateStep)
I1110 23:58:59.108525  2593 solver.cpp:310]     Train net output #0: loss = 0.402003 (* 1 = 0.402003 loss)
I1110 23:58:59.108559  2593 sgd_solver.cpp:106] Iteration 2671, lr = 0.0005
I1110 23:59:01.713630  2593 solver.cpp:295] Iteration 2672 (no loss supplied for SingleUpdateStep)
I1110 23:59:01.713753  2593 solver.cpp:310]     Train net output #0: loss = 0.427955 (* 1 = 0.427955 loss)
I1110 23:59:01.713778  2593 sgd_solver.cpp:106] Iteration 2672, lr = 0.0005
I1110 23:59:04.092741  2593 solver.cpp:295] Iteration 2673 (no loss supplied for SingleUpdateStep)
I1110 23:59:04.092869  2593 solver.cpp:310]     Train net output #0: loss = 0.419916 (* 1 = 0.419916 loss)
I1110 23:59:04.092895  2593 sgd_solver.cpp:106] Iteration 2673, lr = 0.0005
I1110 23:59:06.676811  2593 solver.cpp:295] Iteration 2674 (no loss supplied for SingleUpdateStep)
I1110 23:59:06.676930  2593 solver.cpp:310]     Train net output #0: loss = 0.459854 (* 1 = 0.459854 loss)
I1110 23:59:06.676952  2593 sgd_solver.cpp:106] Iteration 2674, lr = 0.0005
I1110 23:59:08.952575  2593 solver.cpp:295] Iteration 2675 (no loss supplied for SingleUpdateStep)
I1110 23:59:08.952666  2593 solver.cpp:310]     Train net output #0: loss = 0.45839 (* 1 = 0.45839 loss)
I1110 23:59:08.952685  2593 sgd_solver.cpp:106] Iteration 2675, lr = 0.0005
I1110 23:59:11.469285  2593 solver.cpp:295] Iteration 2676 (no loss supplied for SingleUpdateStep)
I1110 23:59:11.469364  2593 solver.cpp:310]     Train net output #0: loss = 0.4469 (* 1 = 0.4469 loss)
I1110 23:59:11.469384  2593 sgd_solver.cpp:106] Iteration 2676, lr = 0.0005
I1110 23:59:13.768569  2593 solver.cpp:295] Iteration 2677 (no loss supplied for SingleUpdateStep)
I1110 23:59:13.768710  2593 solver.cpp:310]     Train net output #0: loss = 0.423012 (* 1 = 0.423012 loss)
I1110 23:59:13.768733  2593 sgd_solver.cpp:106] Iteration 2677, lr = 0.0005
I1110 23:59:16.129096  2593 solver.cpp:295] Iteration 2678 (no loss supplied for SingleUpdateStep)
I1110 23:59:16.129161  2593 solver.cpp:310]     Train net output #0: loss = 0.45046 (* 1 = 0.45046 loss)
I1110 23:59:16.129179  2593 sgd_solver.cpp:106] Iteration 2678, lr = 0.0005
I1110 23:59:18.529554  2593 solver.cpp:295] Iteration 2679 (no loss supplied for SingleUpdateStep)
I1110 23:59:18.529695  2593 solver.cpp:310]     Train net output #0: loss = 0.400711 (* 1 = 0.400711 loss)
I1110 23:59:18.529721  2593 sgd_solver.cpp:106] Iteration 2679, lr = 0.0005
I1110 23:59:20.797505  2593 solver.cpp:295] Iteration 2680 (no loss supplied for SingleUpdateStep)
I1110 23:59:20.797657  2593 solver.cpp:310]     Train net output #0: loss = 0.406381 (* 1 = 0.406381 loss)
I1110 23:59:20.797682  2593 sgd_solver.cpp:106] Iteration 2680, lr = 0.0005
I1110 23:59:23.426515  2593 solver.cpp:295] Iteration 2681 (no loss supplied for SingleUpdateStep)
I1110 23:59:23.426646  2593 solver.cpp:310]     Train net output #0: loss = 0.459238 (* 1 = 0.459238 loss)
I1110 23:59:23.426667  2593 sgd_solver.cpp:106] Iteration 2681, lr = 0.0005
I1110 23:59:25.922991  2593 solver.cpp:295] Iteration 2682 (no loss supplied for SingleUpdateStep)
I1110 23:59:25.923069  2593 solver.cpp:310]     Train net output #0: loss = 0.412323 (* 1 = 0.412323 loss)
I1110 23:59:25.923089  2593 sgd_solver.cpp:106] Iteration 2682, lr = 0.0005
I1110 23:59:29.170943  2593 solver.cpp:295] Iteration 2683 (no loss supplied for SingleUpdateStep)
I1110 23:59:29.171077  2593 solver.cpp:310]     Train net output #0: loss = 0.374278 (* 1 = 0.374278 loss)
I1110 23:59:29.171098  2593 sgd_solver.cpp:106] Iteration 2683, lr = 0.0005
I1110 23:59:32.674439  2593 solver.cpp:295] Iteration 2684 (no loss supplied for SingleUpdateStep)
I1110 23:59:32.674578  2593 solver.cpp:310]     Train net output #0: loss = 0.381877 (* 1 = 0.381877 loss)
I1110 23:59:32.674603  2593 sgd_solver.cpp:106] Iteration 2684, lr = 0.0005
I1110 23:59:35.078667  2593 solver.cpp:295] Iteration 2685 (no loss supplied for SingleUpdateStep)
I1110 23:59:35.078749  2593 solver.cpp:310]     Train net output #0: loss = 0.425154 (* 1 = 0.425154 loss)
I1110 23:59:35.078770  2593 sgd_solver.cpp:106] Iteration 2685, lr = 0.0005
I1110 23:59:37.534888  2593 solver.cpp:295] Iteration 2686 (no loss supplied for SingleUpdateStep)
I1110 23:59:37.535024  2593 solver.cpp:310]     Train net output #0: loss = 0.406931 (* 1 = 0.406931 loss)
I1110 23:59:37.535046  2593 sgd_solver.cpp:106] Iteration 2686, lr = 0.0005
I1110 23:59:40.047916  2593 solver.cpp:295] Iteration 2687 (no loss supplied for SingleUpdateStep)
I1110 23:59:40.047977  2593 solver.cpp:310]     Train net output #0: loss = 0.456643 (* 1 = 0.456643 loss)
I1110 23:59:40.047996  2593 sgd_solver.cpp:106] Iteration 2687, lr = 0.0005
I1110 23:59:42.259320  2593 solver.cpp:295] Iteration 2688 (no loss supplied for SingleUpdateStep)
I1110 23:59:42.259400  2593 solver.cpp:310]     Train net output #0: loss = 0.421666 (* 1 = 0.421666 loss)
I1110 23:59:42.259421  2593 sgd_solver.cpp:106] Iteration 2688, lr = 0.0005
I1110 23:59:44.704509  2593 solver.cpp:295] Iteration 2689 (no loss supplied for SingleUpdateStep)
I1110 23:59:44.704596  2593 solver.cpp:310]     Train net output #0: loss = 0.423479 (* 1 = 0.423479 loss)
I1110 23:59:44.704615  2593 sgd_solver.cpp:106] Iteration 2689, lr = 0.0005
I1110 23:59:46.985466  2593 solver.cpp:295] Iteration 2690 (no loss supplied for SingleUpdateStep)
I1110 23:59:46.985594  2593 solver.cpp:310]     Train net output #0: loss = 0.398067 (* 1 = 0.398067 loss)
I1110 23:59:46.985617  2593 sgd_solver.cpp:106] Iteration 2690, lr = 0.0005
I1110 23:59:49.643677  2593 solver.cpp:295] Iteration 2691 (no loss supplied for SingleUpdateStep)
I1110 23:59:49.643786  2593 solver.cpp:310]     Train net output #0: loss = 0.451623 (* 1 = 0.451623 loss)
I1110 23:59:49.643808  2593 sgd_solver.cpp:106] Iteration 2691, lr = 0.0005
I1110 23:59:52.143414  2593 solver.cpp:295] Iteration 2692 (no loss supplied for SingleUpdateStep)
I1110 23:59:52.143527  2593 solver.cpp:310]     Train net output #0: loss = 0.430638 (* 1 = 0.430638 loss)
I1110 23:59:52.143549  2593 sgd_solver.cpp:106] Iteration 2692, lr = 0.0005
I1110 23:59:54.760849  2593 solver.cpp:295] Iteration 2693 (no loss supplied for SingleUpdateStep)
I1110 23:59:54.760949  2593 solver.cpp:310]     Train net output #0: loss = 0.412976 (* 1 = 0.412976 loss)
I1110 23:59:54.760972  2593 sgd_solver.cpp:106] Iteration 2693, lr = 0.0005
I1110 23:59:57.251993  2593 solver.cpp:295] Iteration 2694 (no loss supplied for SingleUpdateStep)
I1110 23:59:57.252113  2593 solver.cpp:310]     Train net output #0: loss = 0.422455 (* 1 = 0.422455 loss)
I1110 23:59:57.252141  2593 sgd_solver.cpp:106] Iteration 2694, lr = 0.0005
I1110 23:59:59.671355  2593 solver.cpp:295] Iteration 2695 (no loss supplied for SingleUpdateStep)
I1110 23:59:59.671439  2593 solver.cpp:310]     Train net output #0: loss = 0.425694 (* 1 = 0.425694 loss)
I1110 23:59:59.671460  2593 sgd_solver.cpp:106] Iteration 2695, lr = 0.0005
I1111 00:00:02.318106  2593 solver.cpp:295] Iteration 2696 (no loss supplied for SingleUpdateStep)
I1111 00:00:02.318167  2593 solver.cpp:310]     Train net output #0: loss = 0.452057 (* 1 = 0.452057 loss)
I1111 00:00:02.318186  2593 sgd_solver.cpp:106] Iteration 2696, lr = 0.0005
I1111 00:00:04.877308  2593 solver.cpp:295] Iteration 2697 (no loss supplied for SingleUpdateStep)
I1111 00:00:04.877416  2593 solver.cpp:310]     Train net output #0: loss = 0.442232 (* 1 = 0.442232 loss)
I1111 00:00:04.877439  2593 sgd_solver.cpp:106] Iteration 2697, lr = 0.0005
I1111 00:00:07.254253  2593 solver.cpp:295] Iteration 2698 (no loss supplied for SingleUpdateStep)
I1111 00:00:07.254367  2593 solver.cpp:310]     Train net output #0: loss = 0.413526 (* 1 = 0.413526 loss)
I1111 00:00:07.254390  2593 sgd_solver.cpp:106] Iteration 2698, lr = 0.0005
I1111 00:00:09.616708  2593 solver.cpp:295] Iteration 2699 (no loss supplied for SingleUpdateStep)
I1111 00:00:09.616788  2593 solver.cpp:310]     Train net output #0: loss = 0.386861 (* 1 = 0.386861 loss)
I1111 00:00:09.616808  2593 sgd_solver.cpp:106] Iteration 2699, lr = 0.0005
I1111 00:00:11.996628  2593 solver.cpp:295] Iteration 2700 (no loss supplied for SingleUpdateStep)
I1111 00:00:11.996708  2593 solver.cpp:310]     Train net output #0: loss = 0.408285 (* 1 = 0.408285 loss)
I1111 00:00:11.996728  2593 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I1111 00:00:14.222862  2593 solver.cpp:295] Iteration 2701 (no loss supplied for SingleUpdateStep)
I1111 00:00:14.222955  2593 solver.cpp:310]     Train net output #0: loss = 0.426832 (* 1 = 0.426832 loss)
I1111 00:00:14.222975  2593 sgd_solver.cpp:106] Iteration 2701, lr = 0.0005
I1111 00:00:16.743363  2593 solver.cpp:295] Iteration 2702 (no loss supplied for SingleUpdateStep)
I1111 00:00:16.743463  2593 solver.cpp:310]     Train net output #0: loss = 0.420505 (* 1 = 0.420505 loss)
I1111 00:00:16.743484  2593 sgd_solver.cpp:106] Iteration 2702, lr = 0.0005
I1111 00:00:19.011716  2593 solver.cpp:295] Iteration 2703 (no loss supplied for SingleUpdateStep)
I1111 00:00:19.011775  2593 solver.cpp:310]     Train net output #0: loss = 0.429827 (* 1 = 0.429827 loss)
I1111 00:00:19.011793  2593 sgd_solver.cpp:106] Iteration 2703, lr = 0.0005
I1111 00:00:21.469177  2593 solver.cpp:295] Iteration 2704 (no loss supplied for SingleUpdateStep)
I1111 00:00:21.469306  2593 solver.cpp:310]     Train net output #0: loss = 0.419798 (* 1 = 0.419798 loss)
I1111 00:00:21.469328  2593 sgd_solver.cpp:106] Iteration 2704, lr = 0.0005
I1111 00:00:23.695482  2593 solver.cpp:295] Iteration 2705 (no loss supplied for SingleUpdateStep)
I1111 00:00:23.695610  2593 solver.cpp:310]     Train net output #0: loss = 0.407115 (* 1 = 0.407115 loss)
I1111 00:00:23.695641  2593 sgd_solver.cpp:106] Iteration 2705, lr = 0.0005
I1111 00:00:26.159185  2593 solver.cpp:295] Iteration 2706 (no loss supplied for SingleUpdateStep)
I1111 00:00:26.159252  2593 solver.cpp:310]     Train net output #0: loss = 0.386478 (* 1 = 0.386478 loss)
I1111 00:00:26.159272  2593 sgd_solver.cpp:106] Iteration 2706, lr = 0.0005
I1111 00:00:28.401713  2593 solver.cpp:295] Iteration 2707 (no loss supplied for SingleUpdateStep)
I1111 00:00:28.401849  2593 solver.cpp:310]     Train net output #0: loss = 0.433156 (* 1 = 0.433156 loss)
I1111 00:00:28.401875  2593 sgd_solver.cpp:106] Iteration 2707, lr = 0.0005
I1111 00:00:30.621644  2593 solver.cpp:295] Iteration 2708 (no loss supplied for SingleUpdateStep)
I1111 00:00:30.621752  2593 solver.cpp:310]     Train net output #0: loss = 0.393116 (* 1 = 0.393116 loss)
I1111 00:00:30.621775  2593 sgd_solver.cpp:106] Iteration 2708, lr = 0.0005
I1111 00:00:32.908478  2593 solver.cpp:295] Iteration 2709 (no loss supplied for SingleUpdateStep)
I1111 00:00:32.908597  2593 solver.cpp:310]     Train net output #0: loss = 0.443205 (* 1 = 0.443205 loss)
I1111 00:00:32.908619  2593 sgd_solver.cpp:106] Iteration 2709, lr = 0.0005
I1111 00:00:35.178807  2593 solver.cpp:295] Iteration 2710 (no loss supplied for SingleUpdateStep)
I1111 00:00:35.178864  2593 solver.cpp:310]     Train net output #0: loss = 0.411399 (* 1 = 0.411399 loss)
I1111 00:00:35.178884  2593 sgd_solver.cpp:106] Iteration 2710, lr = 0.0005
I1111 00:00:37.489045  2593 solver.cpp:295] Iteration 2711 (no loss supplied for SingleUpdateStep)
I1111 00:00:37.489114  2593 solver.cpp:310]     Train net output #0: loss = 0.391336 (* 1 = 0.391336 loss)
I1111 00:00:37.489135  2593 sgd_solver.cpp:106] Iteration 2711, lr = 0.0005
I1111 00:00:39.840306  2593 solver.cpp:295] Iteration 2712 (no loss supplied for SingleUpdateStep)
I1111 00:00:39.840471  2593 solver.cpp:310]     Train net output #0: loss = 0.442788 (* 1 = 0.442788 loss)
I1111 00:00:39.840498  2593 sgd_solver.cpp:106] Iteration 2712, lr = 0.0005
I1111 00:00:42.150269  2593 solver.cpp:295] Iteration 2713 (no loss supplied for SingleUpdateStep)
I1111 00:00:42.150398  2593 solver.cpp:310]     Train net output #0: loss = 0.395687 (* 1 = 0.395687 loss)
I1111 00:00:42.150421  2593 sgd_solver.cpp:106] Iteration 2713, lr = 0.0005
I1111 00:00:44.571452  2593 solver.cpp:295] Iteration 2714 (no loss supplied for SingleUpdateStep)
I1111 00:00:44.571586  2593 solver.cpp:310]     Train net output #0: loss = 0.396713 (* 1 = 0.396713 loss)
I1111 00:00:44.571609  2593 sgd_solver.cpp:106] Iteration 2714, lr = 0.0005
I1111 00:00:47.122164  2593 solver.cpp:295] Iteration 2715 (no loss supplied for SingleUpdateStep)
I1111 00:00:47.122223  2593 solver.cpp:310]     Train net output #0: loss = 0.411492 (* 1 = 0.411492 loss)
I1111 00:00:47.122241  2593 sgd_solver.cpp:106] Iteration 2715, lr = 0.0005
I1111 00:00:49.717499  2593 solver.cpp:295] Iteration 2716 (no loss supplied for SingleUpdateStep)
I1111 00:00:49.717633  2593 solver.cpp:310]     Train net output #0: loss = 0.41633 (* 1 = 0.41633 loss)
I1111 00:00:49.717663  2593 sgd_solver.cpp:106] Iteration 2716, lr = 0.0005
I1111 00:00:52.148615  2593 solver.cpp:295] Iteration 2717 (no loss supplied for SingleUpdateStep)
I1111 00:00:52.148680  2593 solver.cpp:310]     Train net output #0: loss = 0.42434 (* 1 = 0.42434 loss)
I1111 00:00:52.148700  2593 sgd_solver.cpp:106] Iteration 2717, lr = 0.0005
I1111 00:00:54.556767  2593 solver.cpp:295] Iteration 2718 (no loss supplied for SingleUpdateStep)
I1111 00:00:54.556851  2593 solver.cpp:310]     Train net output #0: loss = 0.445279 (* 1 = 0.445279 loss)
I1111 00:00:54.556872  2593 sgd_solver.cpp:106] Iteration 2718, lr = 0.0005
I1111 00:00:56.875080  2593 solver.cpp:295] Iteration 2719 (no loss supplied for SingleUpdateStep)
I1111 00:00:56.875190  2593 solver.cpp:310]     Train net output #0: loss = 0.433622 (* 1 = 0.433622 loss)
I1111 00:00:56.875215  2593 sgd_solver.cpp:106] Iteration 2719, lr = 0.0005
I1111 00:00:59.266641  2593 solver.cpp:295] Iteration 2720 (no loss supplied for SingleUpdateStep)
I1111 00:00:59.266701  2593 solver.cpp:310]     Train net output #0: loss = 0.398828 (* 1 = 0.398828 loss)
I1111 00:00:59.266721  2593 sgd_solver.cpp:106] Iteration 2720, lr = 0.0005
I1111 00:01:01.482626  2593 solver.cpp:295] Iteration 2721 (no loss supplied for SingleUpdateStep)
I1111 00:01:01.482728  2593 solver.cpp:310]     Train net output #0: loss = 0.425523 (* 1 = 0.425523 loss)
I1111 00:01:01.482748  2593 sgd_solver.cpp:106] Iteration 2721, lr = 0.0005
I1111 00:01:03.927889  2593 solver.cpp:295] Iteration 2722 (no loss supplied for SingleUpdateStep)
I1111 00:01:03.928055  2593 solver.cpp:310]     Train net output #0: loss = 0.413737 (* 1 = 0.413737 loss)
I1111 00:01:03.928086  2593 sgd_solver.cpp:106] Iteration 2722, lr = 0.0005
I1111 00:01:06.737236  2593 solver.cpp:295] Iteration 2723 (no loss supplied for SingleUpdateStep)
I1111 00:01:06.737375  2593 solver.cpp:310]     Train net output #0: loss = 0.411669 (* 1 = 0.411669 loss)
I1111 00:01:06.737399  2593 sgd_solver.cpp:106] Iteration 2723, lr = 0.0005
I1111 00:01:09.170596  2593 solver.cpp:295] Iteration 2724 (no loss supplied for SingleUpdateStep)
I1111 00:01:09.170694  2593 solver.cpp:310]     Train net output #0: loss = 0.412171 (* 1 = 0.412171 loss)
I1111 00:01:09.170716  2593 sgd_solver.cpp:106] Iteration 2724, lr = 0.0005
I1111 00:01:11.432312  2593 solver.cpp:295] Iteration 2725 (no loss supplied for SingleUpdateStep)
I1111 00:01:11.432482  2593 solver.cpp:310]     Train net output #0: loss = 0.412498 (* 1 = 0.412498 loss)
I1111 00:01:11.432518  2593 sgd_solver.cpp:106] Iteration 2725, lr = 0.0005
I1111 00:01:13.825538  2593 solver.cpp:295] Iteration 2726 (no loss supplied for SingleUpdateStep)
I1111 00:01:13.825616  2593 solver.cpp:310]     Train net output #0: loss = 0.402363 (* 1 = 0.402363 loss)
I1111 00:01:13.825639  2593 sgd_solver.cpp:106] Iteration 2726, lr = 0.0005
I1111 00:01:16.046710  2593 solver.cpp:295] Iteration 2727 (no loss supplied for SingleUpdateStep)
I1111 00:01:16.046820  2593 solver.cpp:310]     Train net output #0: loss = 0.388325 (* 1 = 0.388325 loss)
I1111 00:01:16.046843  2593 sgd_solver.cpp:106] Iteration 2727, lr = 0.0005
I1111 00:01:18.303066  2593 solver.cpp:295] Iteration 2728 (no loss supplied for SingleUpdateStep)
I1111 00:01:18.303145  2593 solver.cpp:310]     Train net output #0: loss = 0.414288 (* 1 = 0.414288 loss)
I1111 00:01:18.303167  2593 sgd_solver.cpp:106] Iteration 2728, lr = 0.0005
I1111 00:01:20.952356  2593 solver.cpp:295] Iteration 2729 (no loss supplied for SingleUpdateStep)
I1111 00:01:20.952504  2593 solver.cpp:310]     Train net output #0: loss = 0.398533 (* 1 = 0.398533 loss)
I1111 00:01:20.952533  2593 sgd_solver.cpp:106] Iteration 2729, lr = 0.0005
I1111 00:01:23.498003  2593 solver.cpp:295] Iteration 2730 (no loss supplied for SingleUpdateStep)
I1111 00:01:23.498114  2593 solver.cpp:310]     Train net output #0: loss = 0.414241 (* 1 = 0.414241 loss)
I1111 00:01:23.498136  2593 sgd_solver.cpp:106] Iteration 2730, lr = 0.0005
I1111 00:01:25.712468  2593 solver.cpp:295] Iteration 2731 (no loss supplied for SingleUpdateStep)
I1111 00:01:25.712574  2593 solver.cpp:310]     Train net output #0: loss = 0.392438 (* 1 = 0.392438 loss)
I1111 00:01:25.712595  2593 sgd_solver.cpp:106] Iteration 2731, lr = 0.0005
I1111 00:01:28.177814  2593 solver.cpp:295] Iteration 2732 (no loss supplied for SingleUpdateStep)
I1111 00:01:28.178032  2593 solver.cpp:310]     Train net output #0: loss = 0.419074 (* 1 = 0.419074 loss)
I1111 00:01:28.178078  2593 sgd_solver.cpp:106] Iteration 2732, lr = 0.0005
I1111 00:01:30.659942  2593 solver.cpp:295] Iteration 2733 (no loss supplied for SingleUpdateStep)
I1111 00:01:30.660099  2593 solver.cpp:310]     Train net output #0: loss = 0.430243 (* 1 = 0.430243 loss)
I1111 00:01:30.660120  2593 sgd_solver.cpp:106] Iteration 2733, lr = 0.0005
I1111 00:01:33.075487  2593 solver.cpp:295] Iteration 2734 (no loss supplied for SingleUpdateStep)
I1111 00:01:33.075584  2593 solver.cpp:310]     Train net output #0: loss = 0.421662 (* 1 = 0.421662 loss)
I1111 00:01:33.075606  2593 sgd_solver.cpp:106] Iteration 2734, lr = 0.0005
I1111 00:01:35.900920  2593 solver.cpp:295] Iteration 2735 (no loss supplied for SingleUpdateStep)
I1111 00:01:35.900980  2593 solver.cpp:310]     Train net output #0: loss = 0.376307 (* 1 = 0.376307 loss)
I1111 00:01:35.901000  2593 sgd_solver.cpp:106] Iteration 2735, lr = 0.0005
I1111 00:01:39.249778  2593 solver.cpp:295] Iteration 2736 (no loss supplied for SingleUpdateStep)
I1111 00:01:39.249897  2593 solver.cpp:310]     Train net output #0: loss = 0.432509 (* 1 = 0.432509 loss)
I1111 00:01:39.249923  2593 sgd_solver.cpp:106] Iteration 2736, lr = 0.0005
I1111 00:01:42.712024  2593 solver.cpp:295] Iteration 2737 (no loss supplied for SingleUpdateStep)
I1111 00:01:42.712121  2593 solver.cpp:310]     Train net output #0: loss = 0.414636 (* 1 = 0.414636 loss)
I1111 00:01:42.712142  2593 sgd_solver.cpp:106] Iteration 2737, lr = 0.0005
I1111 00:01:45.954270  2593 solver.cpp:295] Iteration 2738 (no loss supplied for SingleUpdateStep)
I1111 00:01:45.954329  2593 solver.cpp:310]     Train net output #0: loss = 0.418289 (* 1 = 0.418289 loss)
I1111 00:01:45.954347  2593 sgd_solver.cpp:106] Iteration 2738, lr = 0.0005
I1111 00:01:49.143767  2593 solver.cpp:295] Iteration 2739 (no loss supplied for SingleUpdateStep)
I1111 00:01:49.143863  2593 solver.cpp:310]     Train net output #0: loss = 0.39723 (* 1 = 0.39723 loss)
I1111 00:01:49.143887  2593 sgd_solver.cpp:106] Iteration 2739, lr = 0.0005
I1111 00:01:51.739037  2593 solver.cpp:295] Iteration 2740 (no loss supplied for SingleUpdateStep)
I1111 00:01:51.739154  2593 solver.cpp:310]     Train net output #0: loss = 0.400148 (* 1 = 0.400148 loss)
I1111 00:01:51.739178  2593 sgd_solver.cpp:106] Iteration 2740, lr = 0.0005
I1111 00:01:54.329001  2593 solver.cpp:295] Iteration 2741 (no loss supplied for SingleUpdateStep)
I1111 00:01:54.329082  2593 solver.cpp:310]     Train net output #0: loss = 0.434771 (* 1 = 0.434771 loss)
I1111 00:01:54.329102  2593 sgd_solver.cpp:106] Iteration 2741, lr = 0.0005
I1111 00:01:56.611680  2593 solver.cpp:295] Iteration 2742 (no loss supplied for SingleUpdateStep)
I1111 00:01:56.611814  2593 solver.cpp:310]     Train net output #0: loss = 0.416898 (* 1 = 0.416898 loss)
I1111 00:01:56.611841  2593 sgd_solver.cpp:106] Iteration 2742, lr = 0.0005
I1111 00:01:59.038421  2593 solver.cpp:295] Iteration 2743 (no loss supplied for SingleUpdateStep)
I1111 00:01:59.038559  2593 solver.cpp:310]     Train net output #0: loss = 0.415874 (* 1 = 0.415874 loss)
I1111 00:01:59.038590  2593 sgd_solver.cpp:106] Iteration 2743, lr = 0.0005
I1111 00:02:01.665045  2593 solver.cpp:295] Iteration 2744 (no loss supplied for SingleUpdateStep)
I1111 00:02:01.665123  2593 solver.cpp:310]     Train net output #0: loss = 0.432675 (* 1 = 0.432675 loss)
I1111 00:02:01.665143  2593 sgd_solver.cpp:106] Iteration 2744, lr = 0.0005
I1111 00:02:04.211815  2593 solver.cpp:295] Iteration 2745 (no loss supplied for SingleUpdateStep)
I1111 00:02:04.211943  2593 solver.cpp:310]     Train net output #0: loss = 0.397878 (* 1 = 0.397878 loss)
I1111 00:02:04.211966  2593 sgd_solver.cpp:106] Iteration 2745, lr = 0.0005
I1111 00:02:06.430639  2593 solver.cpp:295] Iteration 2746 (no loss supplied for SingleUpdateStep)
I1111 00:02:06.430732  2593 solver.cpp:310]     Train net output #0: loss = 0.420986 (* 1 = 0.420986 loss)
I1111 00:02:06.430757  2593 sgd_solver.cpp:106] Iteration 2746, lr = 0.0005
I1111 00:02:08.740661  2593 solver.cpp:295] Iteration 2747 (no loss supplied for SingleUpdateStep)
I1111 00:02:08.740725  2593 solver.cpp:310]     Train net output #0: loss = 0.42873 (* 1 = 0.42873 loss)
I1111 00:02:08.740746  2593 sgd_solver.cpp:106] Iteration 2747, lr = 0.0005
I1111 00:02:11.009035  2593 solver.cpp:295] Iteration 2748 (no loss supplied for SingleUpdateStep)
I1111 00:02:11.009102  2593 solver.cpp:310]     Train net output #0: loss = 0.399092 (* 1 = 0.399092 loss)
I1111 00:02:11.009121  2593 sgd_solver.cpp:106] Iteration 2748, lr = 0.0005
I1111 00:02:13.650503  2593 solver.cpp:295] Iteration 2749 (no loss supplied for SingleUpdateStep)
I1111 00:02:13.650691  2593 solver.cpp:310]     Train net output #0: loss = 0.417316 (* 1 = 0.417316 loss)
I1111 00:02:13.650718  2593 sgd_solver.cpp:106] Iteration 2749, lr = 0.0005
I1111 00:02:15.934135  2593 solver.cpp:295] Iteration 2750 (no loss supplied for SingleUpdateStep)
I1111 00:02:15.934350  2593 solver.cpp:310]     Train net output #0: loss = 0.408969 (* 1 = 0.408969 loss)
I1111 00:02:15.934378  2593 sgd_solver.cpp:106] Iteration 2750, lr = 0.0005
I1111 00:02:18.192402  2593 solver.cpp:295] Iteration 2751 (no loss supplied for SingleUpdateStep)
I1111 00:02:18.192500  2593 solver.cpp:310]     Train net output #0: loss = 0.421458 (* 1 = 0.421458 loss)
I1111 00:02:18.192526  2593 sgd_solver.cpp:106] Iteration 2751, lr = 0.0005
I1111 00:02:20.392902  2593 solver.cpp:295] Iteration 2752 (no loss supplied for SingleUpdateStep)
I1111 00:02:20.393043  2593 solver.cpp:310]     Train net output #0: loss = 0.433731 (* 1 = 0.433731 loss)
I1111 00:02:20.393067  2593 sgd_solver.cpp:106] Iteration 2752, lr = 0.0005
I1111 00:02:22.868909  2593 solver.cpp:295] Iteration 2753 (no loss supplied for SingleUpdateStep)
I1111 00:02:22.869061  2593 solver.cpp:310]     Train net output #0: loss = 0.404877 (* 1 = 0.404877 loss)
I1111 00:02:22.869086  2593 sgd_solver.cpp:106] Iteration 2753, lr = 0.0005
I1111 00:02:25.363492  2593 solver.cpp:295] Iteration 2754 (no loss supplied for SingleUpdateStep)
I1111 00:02:25.363615  2593 solver.cpp:310]     Train net output #0: loss = 0.440803 (* 1 = 0.440803 loss)
I1111 00:02:25.363639  2593 sgd_solver.cpp:106] Iteration 2754, lr = 0.0005
I1111 00:02:27.656728  2593 solver.cpp:295] Iteration 2755 (no loss supplied for SingleUpdateStep)
I1111 00:02:27.656848  2593 solver.cpp:310]     Train net output #0: loss = 0.420954 (* 1 = 0.420954 loss)
I1111 00:02:27.656869  2593 sgd_solver.cpp:106] Iteration 2755, lr = 0.0005
I1111 00:02:29.951355  2593 solver.cpp:295] Iteration 2756 (no loss supplied for SingleUpdateStep)
I1111 00:02:29.951426  2593 solver.cpp:310]     Train net output #0: loss = 0.387851 (* 1 = 0.387851 loss)
I1111 00:02:29.951447  2593 sgd_solver.cpp:106] Iteration 2756, lr = 0.0005
I1111 00:02:32.221143  2593 solver.cpp:295] Iteration 2757 (no loss supplied for SingleUpdateStep)
I1111 00:02:32.221254  2593 solver.cpp:310]     Train net output #0: loss = 0.403486 (* 1 = 0.403486 loss)
I1111 00:02:32.221276  2593 sgd_solver.cpp:106] Iteration 2757, lr = 0.0005
I1111 00:02:34.589974  2593 solver.cpp:295] Iteration 2758 (no loss supplied for SingleUpdateStep)
I1111 00:02:34.590090  2593 solver.cpp:310]     Train net output #0: loss = 0.428695 (* 1 = 0.428695 loss)
I1111 00:02:34.590112  2593 sgd_solver.cpp:106] Iteration 2758, lr = 0.0005
I1111 00:02:38.119130  2593 solver.cpp:295] Iteration 2759 (no loss supplied for SingleUpdateStep)
I1111 00:02:38.119290  2593 solver.cpp:310]     Train net output #0: loss = 0.404193 (* 1 = 0.404193 loss)
I1111 00:02:38.119316  2593 sgd_solver.cpp:106] Iteration 2759, lr = 0.0005
I1111 00:02:41.883816  2593 solver.cpp:295] Iteration 2760 (no loss supplied for SingleUpdateStep)
I1111 00:02:41.883867  2593 solver.cpp:310]     Train net output #0: loss = 0.397985 (* 1 = 0.397985 loss)
I1111 00:02:41.883884  2593 sgd_solver.cpp:106] Iteration 2760, lr = 0.0005
I1111 00:02:46.612175  2593 solver.cpp:295] Iteration 2761 (no loss supplied for SingleUpdateStep)
I1111 00:02:46.612295  2593 solver.cpp:310]     Train net output #0: loss = 0.421094 (* 1 = 0.421094 loss)
I1111 00:02:46.612318  2593 sgd_solver.cpp:106] Iteration 2761, lr = 0.0005
I1111 00:02:50.041817  2593 solver.cpp:295] Iteration 2762 (no loss supplied for SingleUpdateStep)
I1111 00:02:50.041955  2593 solver.cpp:310]     Train net output #0: loss = 0.382179 (* 1 = 0.382179 loss)
I1111 00:02:50.041981  2593 sgd_solver.cpp:106] Iteration 2762, lr = 0.0005
I1111 00:02:53.531441  2593 solver.cpp:295] Iteration 2763 (no loss supplied for SingleUpdateStep)
I1111 00:02:53.531558  2593 solver.cpp:310]     Train net output #0: loss = 0.422274 (* 1 = 0.422274 loss)
I1111 00:02:53.531579  2593 sgd_solver.cpp:106] Iteration 2763, lr = 0.0005
I1111 00:02:57.302742  2593 solver.cpp:295] Iteration 2764 (no loss supplied for SingleUpdateStep)
I1111 00:02:57.302896  2593 solver.cpp:310]     Train net output #0: loss = 0.421502 (* 1 = 0.421502 loss)
I1111 00:02:57.302922  2593 sgd_solver.cpp:106] Iteration 2764, lr = 0.0005
I1111 00:03:00.305881  2593 solver.cpp:295] Iteration 2765 (no loss supplied for SingleUpdateStep)
I1111 00:03:00.305958  2593 solver.cpp:310]     Train net output #0: loss = 0.414375 (* 1 = 0.414375 loss)
I1111 00:03:00.305980  2593 sgd_solver.cpp:106] Iteration 2765, lr = 0.0005
I1111 00:03:03.202009  2593 solver.cpp:295] Iteration 2766 (no loss supplied for SingleUpdateStep)
I1111 00:03:03.202111  2593 solver.cpp:310]     Train net output #0: loss = 0.387698 (* 1 = 0.387698 loss)
I1111 00:03:03.202132  2593 sgd_solver.cpp:106] Iteration 2766, lr = 0.0005
I1111 00:03:05.557211  2593 solver.cpp:295] Iteration 2767 (no loss supplied for SingleUpdateStep)
I1111 00:03:05.557270  2593 solver.cpp:310]     Train net output #0: loss = 0.432923 (* 1 = 0.432923 loss)
I1111 00:03:05.557288  2593 sgd_solver.cpp:106] Iteration 2767, lr = 0.0005
I1111 00:03:07.709678  2593 solver.cpp:295] Iteration 2768 (no loss supplied for SingleUpdateStep)
I1111 00:03:07.709813  2593 solver.cpp:310]     Train net output #0: loss = 0.425918 (* 1 = 0.425918 loss)
I1111 00:03:07.709853  2593 sgd_solver.cpp:106] Iteration 2768, lr = 0.0005
I1111 00:03:09.995894  2593 solver.cpp:295] Iteration 2769 (no loss supplied for SingleUpdateStep)
I1111 00:03:09.995998  2593 solver.cpp:310]     Train net output #0: loss = 0.413763 (* 1 = 0.413763 loss)
I1111 00:03:09.996021  2593 sgd_solver.cpp:106] Iteration 2769, lr = 0.0005
I1111 00:03:12.308044  2593 solver.cpp:295] Iteration 2770 (no loss supplied for SingleUpdateStep)
I1111 00:03:12.308162  2593 solver.cpp:310]     Train net output #0: loss = 0.400092 (* 1 = 0.400092 loss)
I1111 00:03:12.308190  2593 sgd_solver.cpp:106] Iteration 2770, lr = 0.0005
I1111 00:03:14.725435  2593 solver.cpp:295] Iteration 2771 (no loss supplied for SingleUpdateStep)
I1111 00:03:14.725592  2593 solver.cpp:310]     Train net output #0: loss = 0.437677 (* 1 = 0.437677 loss)
I1111 00:03:14.725626  2593 sgd_solver.cpp:106] Iteration 2771, lr = 0.0005
I1111 00:03:16.977643  2593 solver.cpp:295] Iteration 2772 (no loss supplied for SingleUpdateStep)
I1111 00:03:16.977814  2593 solver.cpp:310]     Train net output #0: loss = 0.417124 (* 1 = 0.417124 loss)
I1111 00:03:16.977852  2593 sgd_solver.cpp:106] Iteration 2772, lr = 0.0005
I1111 00:03:19.300606  2593 solver.cpp:295] Iteration 2773 (no loss supplied for SingleUpdateStep)
I1111 00:03:19.300772  2593 solver.cpp:310]     Train net output #0: loss = 0.402533 (* 1 = 0.402533 loss)
I1111 00:03:19.300798  2593 sgd_solver.cpp:106] Iteration 2773, lr = 0.0005
I1111 00:03:21.665500  2593 solver.cpp:295] Iteration 2774 (no loss supplied for SingleUpdateStep)
I1111 00:03:21.665576  2593 solver.cpp:310]     Train net output #0: loss = 0.429109 (* 1 = 0.429109 loss)
I1111 00:03:21.665596  2593 sgd_solver.cpp:106] Iteration 2774, lr = 0.0005
I1111 00:03:24.288702  2593 solver.cpp:295] Iteration 2775 (no loss supplied for SingleUpdateStep)
I1111 00:03:24.288816  2593 solver.cpp:310]     Train net output #0: loss = 0.458602 (* 1 = 0.458602 loss)
I1111 00:03:24.288838  2593 sgd_solver.cpp:106] Iteration 2775, lr = 0.0005
I1111 00:03:27.003298  2593 solver.cpp:295] Iteration 2776 (no loss supplied for SingleUpdateStep)
I1111 00:03:27.003427  2593 solver.cpp:310]     Train net output #0: loss = 0.411995 (* 1 = 0.411995 loss)
I1111 00:03:27.003458  2593 sgd_solver.cpp:106] Iteration 2776, lr = 0.0005
I1111 00:03:29.687711  2593 solver.cpp:295] Iteration 2777 (no loss supplied for SingleUpdateStep)
I1111 00:03:29.687789  2593 solver.cpp:310]     Train net output #0: loss = 0.390818 (* 1 = 0.390818 loss)
I1111 00:03:29.687811  2593 sgd_solver.cpp:106] Iteration 2777, lr = 0.0005
I1111 00:03:32.022935  2593 solver.cpp:295] Iteration 2778 (no loss supplied for SingleUpdateStep)
I1111 00:03:32.023049  2593 solver.cpp:310]     Train net output #0: loss = 0.396511 (* 1 = 0.396511 loss)
I1111 00:03:32.023072  2593 sgd_solver.cpp:106] Iteration 2778, lr = 0.0005
I1111 00:03:34.234557  2593 solver.cpp:295] Iteration 2779 (no loss supplied for SingleUpdateStep)
I1111 00:03:34.234711  2593 solver.cpp:310]     Train net output #0: loss = 0.432681 (* 1 = 0.432681 loss)
I1111 00:03:34.234737  2593 sgd_solver.cpp:106] Iteration 2779, lr = 0.0005
I1111 00:03:36.544205  2593 solver.cpp:295] Iteration 2780 (no loss supplied for SingleUpdateStep)
I1111 00:03:36.544275  2593 solver.cpp:310]     Train net output #0: loss = 0.418904 (* 1 = 0.418904 loss)
I1111 00:03:36.544296  2593 sgd_solver.cpp:106] Iteration 2780, lr = 0.0005
I1111 00:03:38.826010  2593 solver.cpp:295] Iteration 2781 (no loss supplied for SingleUpdateStep)
I1111 00:03:38.826130  2593 solver.cpp:310]     Train net output #0: loss = 0.442243 (* 1 = 0.442243 loss)
I1111 00:03:38.826151  2593 sgd_solver.cpp:106] Iteration 2781, lr = 0.0005
I1111 00:03:41.150188  2593 solver.cpp:295] Iteration 2782 (no loss supplied for SingleUpdateStep)
I1111 00:03:41.150326  2593 solver.cpp:310]     Train net output #0: loss = 0.401107 (* 1 = 0.401107 loss)
I1111 00:03:41.150349  2593 sgd_solver.cpp:106] Iteration 2782, lr = 0.0005
I1111 00:03:43.364430  2593 solver.cpp:295] Iteration 2783 (no loss supplied for SingleUpdateStep)
I1111 00:03:43.364554  2593 solver.cpp:310]     Train net output #0: loss = 0.386506 (* 1 = 0.386506 loss)
I1111 00:03:43.364575  2593 sgd_solver.cpp:106] Iteration 2783, lr = 0.0005
I1111 00:03:45.719352  2593 solver.cpp:295] Iteration 2784 (no loss supplied for SingleUpdateStep)
I1111 00:03:45.719437  2593 solver.cpp:310]     Train net output #0: loss = 0.413514 (* 1 = 0.413514 loss)
I1111 00:03:45.719458  2593 sgd_solver.cpp:106] Iteration 2784, lr = 0.0005
I1111 00:03:48.176558  2593 solver.cpp:295] Iteration 2785 (no loss supplied for SingleUpdateStep)
I1111 00:03:48.176668  2593 solver.cpp:310]     Train net output #0: loss = 0.410643 (* 1 = 0.410643 loss)
I1111 00:03:48.176689  2593 sgd_solver.cpp:106] Iteration 2785, lr = 0.0005
I1111 00:03:50.994921  2593 solver.cpp:295] Iteration 2786 (no loss supplied for SingleUpdateStep)
I1111 00:03:50.995003  2593 solver.cpp:310]     Train net output #0: loss = 0.419006 (* 1 = 0.419006 loss)
I1111 00:03:50.995025  2593 sgd_solver.cpp:106] Iteration 2786, lr = 0.0005
I1111 00:03:53.765677  2593 solver.cpp:295] Iteration 2787 (no loss supplied for SingleUpdateStep)
I1111 00:03:53.765823  2593 solver.cpp:310]     Train net output #0: loss = 0.414446 (* 1 = 0.414446 loss)
I1111 00:03:53.765847  2593 sgd_solver.cpp:106] Iteration 2787, lr = 0.0005
I1111 00:03:56.239853  2593 solver.cpp:295] Iteration 2788 (no loss supplied for SingleUpdateStep)
I1111 00:03:56.239941  2593 solver.cpp:310]     Train net output #0: loss = 0.420513 (* 1 = 0.420513 loss)
I1111 00:03:56.239962  2593 sgd_solver.cpp:106] Iteration 2788, lr = 0.0005
I1111 00:03:58.731288  2593 solver.cpp:295] Iteration 2789 (no loss supplied for SingleUpdateStep)
I1111 00:03:58.731348  2593 solver.cpp:310]     Train net output #0: loss = 0.413415 (* 1 = 0.413415 loss)
I1111 00:03:58.731370  2593 sgd_solver.cpp:106] Iteration 2789, lr = 0.0005
I1111 00:04:01.098431  2593 solver.cpp:295] Iteration 2790 (no loss supplied for SingleUpdateStep)
I1111 00:04:01.098546  2593 solver.cpp:310]     Train net output #0: loss = 0.448593 (* 1 = 0.448593 loss)
I1111 00:04:01.098565  2593 sgd_solver.cpp:106] Iteration 2790, lr = 0.0005
I1111 00:04:03.501639  2593 solver.cpp:295] Iteration 2791 (no loss supplied for SingleUpdateStep)
I1111 00:04:03.501775  2593 solver.cpp:310]     Train net output #0: loss = 0.417428 (* 1 = 0.417428 loss)
I1111 00:04:03.501798  2593 sgd_solver.cpp:106] Iteration 2791, lr = 0.0005
I1111 00:04:05.831135  2593 solver.cpp:295] Iteration 2792 (no loss supplied for SingleUpdateStep)
I1111 00:04:05.831274  2593 solver.cpp:310]     Train net output #0: loss = 0.39577 (* 1 = 0.39577 loss)
I1111 00:04:05.831305  2593 sgd_solver.cpp:106] Iteration 2792, lr = 0.0005
I1111 00:04:07.985332  2593 solver.cpp:295] Iteration 2793 (no loss supplied for SingleUpdateStep)
I1111 00:04:07.985440  2593 solver.cpp:310]     Train net output #0: loss = 0.433727 (* 1 = 0.433727 loss)
I1111 00:04:07.985461  2593 sgd_solver.cpp:106] Iteration 2793, lr = 0.0005
I1111 00:04:10.248077  2593 solver.cpp:295] Iteration 2794 (no loss supplied for SingleUpdateStep)
I1111 00:04:10.248132  2593 solver.cpp:310]     Train net output #0: loss = 0.394096 (* 1 = 0.394096 loss)
I1111 00:04:10.248150  2593 sgd_solver.cpp:106] Iteration 2794, lr = 0.0005
I1111 00:04:12.498436  2593 solver.cpp:295] Iteration 2795 (no loss supplied for SingleUpdateStep)
I1111 00:04:12.498500  2593 solver.cpp:310]     Train net output #0: loss = 0.40295 (* 1 = 0.40295 loss)
I1111 00:04:12.498519  2593 sgd_solver.cpp:106] Iteration 2795, lr = 0.0005
I1111 00:04:15.031199  2593 solver.cpp:295] Iteration 2796 (no loss supplied for SingleUpdateStep)
I1111 00:04:15.031316  2593 solver.cpp:310]     Train net output #0: loss = 0.432483 (* 1 = 0.432483 loss)
I1111 00:04:15.031337  2593 sgd_solver.cpp:106] Iteration 2796, lr = 0.0005
I1111 00:04:17.205160  2593 solver.cpp:295] Iteration 2797 (no loss supplied for SingleUpdateStep)
I1111 00:04:17.205270  2593 solver.cpp:310]     Train net output #0: loss = 0.407953 (* 1 = 0.407953 loss)
I1111 00:04:17.205289  2593 sgd_solver.cpp:106] Iteration 2797, lr = 0.0005
I1111 00:04:19.452250  2593 solver.cpp:295] Iteration 2798 (no loss supplied for SingleUpdateStep)
I1111 00:04:19.452312  2593 solver.cpp:310]     Train net output #0: loss = 0.420766 (* 1 = 0.420766 loss)
I1111 00:04:19.452330  2593 sgd_solver.cpp:106] Iteration 2798, lr = 0.0005
I1111 00:04:21.776108  2593 solver.cpp:295] Iteration 2799 (no loss supplied for SingleUpdateStep)
I1111 00:04:21.776226  2593 solver.cpp:310]     Train net output #0: loss = 0.41204 (* 1 = 0.41204 loss)
I1111 00:04:21.776247  2593 sgd_solver.cpp:106] Iteration 2799, lr = 0.0005
I1111 00:04:23.973101  2593 solver.cpp:295] Iteration 2800 (no loss supplied for SingleUpdateStep)
I1111 00:04:23.973238  2593 solver.cpp:310]     Train net output #0: loss = 0.40639 (* 1 = 0.40639 loss)
I1111 00:04:23.973260  2593 sgd_solver.cpp:106] Iteration 2800, lr = 0.0005
I1111 00:04:26.231621  2593 solver.cpp:295] Iteration 2801 (no loss supplied for SingleUpdateStep)
I1111 00:04:26.231717  2593 solver.cpp:310]     Train net output #0: loss = 0.40325 (* 1 = 0.40325 loss)
I1111 00:04:26.231739  2593 sgd_solver.cpp:106] Iteration 2801, lr = 0.0005
I1111 00:04:28.410781  2593 solver.cpp:295] Iteration 2802 (no loss supplied for SingleUpdateStep)
I1111 00:04:28.410858  2593 solver.cpp:310]     Train net output #0: loss = 0.410582 (* 1 = 0.410582 loss)
I1111 00:04:28.410878  2593 sgd_solver.cpp:106] Iteration 2802, lr = 0.0005
I1111 00:04:30.647439  2593 solver.cpp:295] Iteration 2803 (no loss supplied for SingleUpdateStep)
I1111 00:04:30.647550  2593 solver.cpp:310]     Train net output #0: loss = 0.432327 (* 1 = 0.432327 loss)
I1111 00:04:30.647572  2593 sgd_solver.cpp:106] Iteration 2803, lr = 0.0005
I1111 00:04:32.995988  2593 solver.cpp:295] Iteration 2804 (no loss supplied for SingleUpdateStep)
I1111 00:04:32.996127  2593 solver.cpp:310]     Train net output #0: loss = 0.409761 (* 1 = 0.409761 loss)
I1111 00:04:32.996153  2593 sgd_solver.cpp:106] Iteration 2804, lr = 0.0005
I1111 00:04:35.364100  2593 solver.cpp:295] Iteration 2805 (no loss supplied for SingleUpdateStep)
I1111 00:04:35.364202  2593 solver.cpp:310]     Train net output #0: loss = 0.412211 (* 1 = 0.412211 loss)
I1111 00:04:35.364223  2593 sgd_solver.cpp:106] Iteration 2805, lr = 0.0005
I1111 00:04:37.699847  2593 solver.cpp:295] Iteration 2806 (no loss supplied for SingleUpdateStep)
I1111 00:04:37.699976  2593 solver.cpp:310]     Train net output #0: loss = 0.438328 (* 1 = 0.438328 loss)
I1111 00:04:37.700000  2593 sgd_solver.cpp:106] Iteration 2806, lr = 0.0005
I1111 00:04:40.087363  2593 solver.cpp:295] Iteration 2807 (no loss supplied for SingleUpdateStep)
I1111 00:04:40.087460  2593 solver.cpp:310]     Train net output #0: loss = 0.42005 (* 1 = 0.42005 loss)
I1111 00:04:40.087481  2593 sgd_solver.cpp:106] Iteration 2807, lr = 0.0005
I1111 00:04:42.538990  2593 solver.cpp:295] Iteration 2808 (no loss supplied for SingleUpdateStep)
I1111 00:04:42.539106  2593 solver.cpp:310]     Train net output #0: loss = 0.400283 (* 1 = 0.400283 loss)
I1111 00:04:42.539129  2593 sgd_solver.cpp:106] Iteration 2808, lr = 0.0005
I1111 00:04:44.936318  2593 solver.cpp:295] Iteration 2809 (no loss supplied for SingleUpdateStep)
I1111 00:04:44.936415  2593 solver.cpp:310]     Train net output #0: loss = 0.424783 (* 1 = 0.424783 loss)
I1111 00:04:44.936436  2593 sgd_solver.cpp:106] Iteration 2809, lr = 0.0005
I1111 00:04:47.236584  2593 solver.cpp:295] Iteration 2810 (no loss supplied for SingleUpdateStep)
I1111 00:04:47.236654  2593 solver.cpp:310]     Train net output #0: loss = 0.395811 (* 1 = 0.395811 loss)
I1111 00:04:47.236672  2593 sgd_solver.cpp:106] Iteration 2810, lr = 0.0005
I1111 00:04:49.497442  2593 solver.cpp:295] Iteration 2811 (no loss supplied for SingleUpdateStep)
I1111 00:04:49.497539  2593 solver.cpp:310]     Train net output #0: loss = 0.418303 (* 1 = 0.418303 loss)
I1111 00:04:49.497565  2593 sgd_solver.cpp:106] Iteration 2811, lr = 0.0005
I1111 00:04:51.725793  2593 solver.cpp:295] Iteration 2812 (no loss supplied for SingleUpdateStep)
I1111 00:04:51.725927  2593 solver.cpp:310]     Train net output #0: loss = 0.441517 (* 1 = 0.441517 loss)
I1111 00:04:51.725953  2593 sgd_solver.cpp:106] Iteration 2812, lr = 0.0005
I1111 00:04:53.987922  2593 solver.cpp:295] Iteration 2813 (no loss supplied for SingleUpdateStep)
I1111 00:04:53.988003  2593 solver.cpp:310]     Train net output #0: loss = 0.461987 (* 1 = 0.461987 loss)
I1111 00:04:53.988026  2593 sgd_solver.cpp:106] Iteration 2813, lr = 0.0005
I1111 00:04:56.360896  2593 solver.cpp:295] Iteration 2814 (no loss supplied for SingleUpdateStep)
I1111 00:04:56.360975  2593 solver.cpp:310]     Train net output #0: loss = 0.39985 (* 1 = 0.39985 loss)
I1111 00:04:56.360994  2593 sgd_solver.cpp:106] Iteration 2814, lr = 0.0005
I1111 00:04:58.774545  2593 solver.cpp:295] Iteration 2815 (no loss supplied for SingleUpdateStep)
I1111 00:04:58.774684  2593 solver.cpp:310]     Train net output #0: loss = 0.417865 (* 1 = 0.417865 loss)
I1111 00:04:58.774711  2593 sgd_solver.cpp:106] Iteration 2815, lr = 0.0005
I1111 00:05:01.177150  2593 solver.cpp:295] Iteration 2816 (no loss supplied for SingleUpdateStep)
I1111 00:05:01.177251  2593 solver.cpp:310]     Train net output #0: loss = 0.408995 (* 1 = 0.408995 loss)
I1111 00:05:01.177273  2593 sgd_solver.cpp:106] Iteration 2816, lr = 0.0005
I1111 00:05:03.719833  2593 solver.cpp:295] Iteration 2817 (no loss supplied for SingleUpdateStep)
I1111 00:05:03.719924  2593 solver.cpp:310]     Train net output #0: loss = 0.401595 (* 1 = 0.401595 loss)
I1111 00:05:03.719948  2593 sgd_solver.cpp:106] Iteration 2817, lr = 0.0005
I1111 00:05:06.378540  2593 solver.cpp:295] Iteration 2818 (no loss supplied for SingleUpdateStep)
I1111 00:05:06.378682  2593 solver.cpp:310]     Train net output #0: loss = 0.411434 (* 1 = 0.411434 loss)
I1111 00:05:06.378707  2593 sgd_solver.cpp:106] Iteration 2818, lr = 0.0005
I1111 00:05:08.833959  2593 solver.cpp:295] Iteration 2819 (no loss supplied for SingleUpdateStep)
I1111 00:05:08.834014  2593 solver.cpp:310]     Train net output #0: loss = 0.399542 (* 1 = 0.399542 loss)
I1111 00:05:08.834033  2593 sgd_solver.cpp:106] Iteration 2819, lr = 0.0005
I1111 00:05:11.412657  2593 solver.cpp:295] Iteration 2820 (no loss supplied for SingleUpdateStep)
I1111 00:05:11.412775  2593 solver.cpp:310]     Train net output #0: loss = 0.390892 (* 1 = 0.390892 loss)
I1111 00:05:11.412811  2593 sgd_solver.cpp:106] Iteration 2820, lr = 0.0005
I1111 00:05:13.969137  2593 solver.cpp:295] Iteration 2821 (no loss supplied for SingleUpdateStep)
I1111 00:05:13.969244  2593 solver.cpp:310]     Train net output #0: loss = 0.424948 (* 1 = 0.424948 loss)
I1111 00:05:13.969269  2593 sgd_solver.cpp:106] Iteration 2821, lr = 0.0005
I1111 00:05:16.347839  2593 solver.cpp:295] Iteration 2822 (no loss supplied for SingleUpdateStep)
I1111 00:05:16.347949  2593 solver.cpp:310]     Train net output #0: loss = 0.386827 (* 1 = 0.386827 loss)
I1111 00:05:16.347972  2593 sgd_solver.cpp:106] Iteration 2822, lr = 0.0005
I1111 00:05:18.775492  2593 solver.cpp:295] Iteration 2823 (no loss supplied for SingleUpdateStep)
I1111 00:05:18.775615  2593 solver.cpp:310]     Train net output #0: loss = 0.411961 (* 1 = 0.411961 loss)
I1111 00:05:18.775640  2593 sgd_solver.cpp:106] Iteration 2823, lr = 0.0005
I1111 00:05:21.235304  2593 solver.cpp:295] Iteration 2824 (no loss supplied for SingleUpdateStep)
I1111 00:05:21.235441  2593 solver.cpp:310]     Train net output #0: loss = 0.385765 (* 1 = 0.385765 loss)
I1111 00:05:21.235465  2593 sgd_solver.cpp:106] Iteration 2824, lr = 0.0005
I1111 00:05:23.691169  2593 solver.cpp:295] Iteration 2825 (no loss supplied for SingleUpdateStep)
I1111 00:05:23.691292  2593 solver.cpp:310]     Train net output #0: loss = 0.417545 (* 1 = 0.417545 loss)
I1111 00:05:23.691313  2593 sgd_solver.cpp:106] Iteration 2825, lr = 0.0005
I1111 00:05:26.105931  2593 solver.cpp:295] Iteration 2826 (no loss supplied for SingleUpdateStep)
I1111 00:05:26.106051  2593 solver.cpp:310]     Train net output #0: loss = 0.429869 (* 1 = 0.429869 loss)
I1111 00:05:26.106075  2593 sgd_solver.cpp:106] Iteration 2826, lr = 0.0005
I1111 00:05:28.409631  2593 solver.cpp:295] Iteration 2827 (no loss supplied for SingleUpdateStep)
I1111 00:05:28.409739  2593 solver.cpp:310]     Train net output #0: loss = 0.421151 (* 1 = 0.421151 loss)
I1111 00:05:28.409761  2593 sgd_solver.cpp:106] Iteration 2827, lr = 0.0005
I1111 00:05:30.727249  2593 solver.cpp:295] Iteration 2828 (no loss supplied for SingleUpdateStep)
I1111 00:05:30.727442  2593 solver.cpp:310]     Train net output #0: loss = 0.406021 (* 1 = 0.406021 loss)
I1111 00:05:30.727465  2593 sgd_solver.cpp:106] Iteration 2828, lr = 0.0005
I1111 00:05:33.299422  2593 solver.cpp:295] Iteration 2829 (no loss supplied for SingleUpdateStep)
I1111 00:05:33.299571  2593 solver.cpp:310]     Train net output #0: loss = 0.430236 (* 1 = 0.430236 loss)
I1111 00:05:33.299595  2593 sgd_solver.cpp:106] Iteration 2829, lr = 0.0005
I1111 00:05:35.966724  2593 solver.cpp:295] Iteration 2830 (no loss supplied for SingleUpdateStep)
I1111 00:05:35.966840  2593 solver.cpp:310]     Train net output #0: loss = 0.396942 (* 1 = 0.396942 loss)
I1111 00:05:35.966862  2593 sgd_solver.cpp:106] Iteration 2830, lr = 0.0005
I1111 00:05:39.003314  2593 solver.cpp:295] Iteration 2831 (no loss supplied for SingleUpdateStep)
I1111 00:05:39.003437  2593 solver.cpp:310]     Train net output #0: loss = 0.380203 (* 1 = 0.380203 loss)
I1111 00:05:39.003458  2593 sgd_solver.cpp:106] Iteration 2831, lr = 0.0005
I1111 00:05:41.834465  2593 solver.cpp:295] Iteration 2832 (no loss supplied for SingleUpdateStep)
I1111 00:05:41.834585  2593 solver.cpp:310]     Train net output #0: loss = 0.417926 (* 1 = 0.417926 loss)
I1111 00:05:41.834615  2593 sgd_solver.cpp:106] Iteration 2832, lr = 0.0005
I1111 00:05:44.029009  2593 solver.cpp:295] Iteration 2833 (no loss supplied for SingleUpdateStep)
I1111 00:05:44.029130  2593 solver.cpp:310]     Train net output #0: loss = 0.402221 (* 1 = 0.402221 loss)
I1111 00:05:44.029151  2593 sgd_solver.cpp:106] Iteration 2833, lr = 0.0005
I1111 00:05:46.329426  2593 solver.cpp:295] Iteration 2834 (no loss supplied for SingleUpdateStep)
I1111 00:05:46.329532  2593 solver.cpp:310]     Train net output #0: loss = 0.398646 (* 1 = 0.398646 loss)
I1111 00:05:46.329555  2593 sgd_solver.cpp:106] Iteration 2834, lr = 0.0005
I1111 00:05:48.601032  2593 solver.cpp:295] Iteration 2835 (no loss supplied for SingleUpdateStep)
I1111 00:05:48.601157  2593 solver.cpp:310]     Train net output #0: loss = 0.39016 (* 1 = 0.39016 loss)
I1111 00:05:48.601182  2593 sgd_solver.cpp:106] Iteration 2835, lr = 0.0005
I1111 00:05:50.844779  2593 solver.cpp:295] Iteration 2836 (no loss supplied for SingleUpdateStep)
I1111 00:05:50.844851  2593 solver.cpp:310]     Train net output #0: loss = 0.415705 (* 1 = 0.415705 loss)
I1111 00:05:50.844871  2593 sgd_solver.cpp:106] Iteration 2836, lr = 0.0005
I1111 00:05:53.068821  2593 solver.cpp:295] Iteration 2837 (no loss supplied for SingleUpdateStep)
I1111 00:05:53.068918  2593 solver.cpp:310]     Train net output #0: loss = 0.414508 (* 1 = 0.414508 loss)
I1111 00:05:53.068940  2593 sgd_solver.cpp:106] Iteration 2837, lr = 0.0005
I1111 00:05:55.351563  2593 solver.cpp:295] Iteration 2838 (no loss supplied for SingleUpdateStep)
I1111 00:05:55.351688  2593 solver.cpp:310]     Train net output #0: loss = 0.380007 (* 1 = 0.380007 loss)
I1111 00:05:55.351711  2593 sgd_solver.cpp:106] Iteration 2838, lr = 0.0005
I1111 00:05:57.695060  2593 solver.cpp:295] Iteration 2839 (no loss supplied for SingleUpdateStep)
I1111 00:05:57.695248  2593 solver.cpp:310]     Train net output #0: loss = 0.410684 (* 1 = 0.410684 loss)
I1111 00:05:57.695276  2593 sgd_solver.cpp:106] Iteration 2839, lr = 0.0005
I1111 00:06:00.094079  2593 solver.cpp:295] Iteration 2840 (no loss supplied for SingleUpdateStep)
I1111 00:06:00.094182  2593 solver.cpp:310]     Train net output #0: loss = 0.414221 (* 1 = 0.414221 loss)
I1111 00:06:00.094202  2593 sgd_solver.cpp:106] Iteration 2840, lr = 0.0005
I1111 00:06:02.594296  2593 solver.cpp:295] Iteration 2841 (no loss supplied for SingleUpdateStep)
I1111 00:06:02.594456  2593 solver.cpp:310]     Train net output #0: loss = 0.404265 (* 1 = 0.404265 loss)
I1111 00:06:02.594480  2593 sgd_solver.cpp:106] Iteration 2841, lr = 0.0005
I1111 00:06:04.964195  2593 solver.cpp:295] Iteration 2842 (no loss supplied for SingleUpdateStep)
I1111 00:06:04.964318  2593 solver.cpp:310]     Train net output #0: loss = 0.41324 (* 1 = 0.41324 loss)
I1111 00:06:04.964342  2593 sgd_solver.cpp:106] Iteration 2842, lr = 0.0005
I1111 00:06:07.324854  2593 solver.cpp:295] Iteration 2843 (no loss supplied for SingleUpdateStep)
I1111 00:06:07.324959  2593 solver.cpp:310]     Train net output #0: loss = 0.408214 (* 1 = 0.408214 loss)
I1111 00:06:07.324982  2593 sgd_solver.cpp:106] Iteration 2843, lr = 0.0005
I1111 00:06:09.693888  2593 solver.cpp:295] Iteration 2844 (no loss supplied for SingleUpdateStep)
I1111 00:06:09.694041  2593 solver.cpp:310]     Train net output #0: loss = 0.388988 (* 1 = 0.388988 loss)
I1111 00:06:09.694066  2593 sgd_solver.cpp:106] Iteration 2844, lr = 0.0005
I1111 00:06:12.146647  2593 solver.cpp:295] Iteration 2845 (no loss supplied for SingleUpdateStep)
I1111 00:06:12.146774  2593 solver.cpp:310]     Train net output #0: loss = 0.401026 (* 1 = 0.401026 loss)
I1111 00:06:12.146795  2593 sgd_solver.cpp:106] Iteration 2845, lr = 0.0005
I1111 00:06:14.637890  2593 solver.cpp:295] Iteration 2846 (no loss supplied for SingleUpdateStep)
I1111 00:06:14.638058  2593 solver.cpp:310]     Train net output #0: loss = 0.402624 (* 1 = 0.402624 loss)
I1111 00:06:14.638084  2593 sgd_solver.cpp:106] Iteration 2846, lr = 0.0005
I1111 00:06:17.001812  2593 solver.cpp:295] Iteration 2847 (no loss supplied for SingleUpdateStep)
I1111 00:06:17.001945  2593 solver.cpp:310]     Train net output #0: loss = 0.398805 (* 1 = 0.398805 loss)
I1111 00:06:17.001966  2593 sgd_solver.cpp:106] Iteration 2847, lr = 0.0005
I1111 00:06:20.001641  2593 solver.cpp:295] Iteration 2848 (no loss supplied for SingleUpdateStep)
I1111 00:06:20.001726  2593 solver.cpp:310]     Train net output #0: loss = 0.449893 (* 1 = 0.449893 loss)
I1111 00:06:20.001749  2593 sgd_solver.cpp:106] Iteration 2848, lr = 0.0005
I1111 00:06:22.563586  2593 solver.cpp:295] Iteration 2849 (no loss supplied for SingleUpdateStep)
I1111 00:06:22.563643  2593 solver.cpp:310]     Train net output #0: loss = 0.423496 (* 1 = 0.423496 loss)
I1111 00:06:22.563662  2593 sgd_solver.cpp:106] Iteration 2849, lr = 0.0005
I1111 00:06:25.485123  2593 solver.cpp:295] Iteration 2850 (no loss supplied for SingleUpdateStep)
I1111 00:06:25.485254  2593 solver.cpp:310]     Train net output #0: loss = 0.39176 (* 1 = 0.39176 loss)
I1111 00:06:25.485277  2593 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I1111 00:06:28.284188  2593 solver.cpp:295] Iteration 2851 (no loss supplied for SingleUpdateStep)
I1111 00:06:28.284288  2593 solver.cpp:310]     Train net output #0: loss = 0.421377 (* 1 = 0.421377 loss)
I1111 00:06:28.284307  2593 sgd_solver.cpp:106] Iteration 2851, lr = 0.0005
I1111 00:06:31.308199  2593 solver.cpp:295] Iteration 2852 (no loss supplied for SingleUpdateStep)
I1111 00:06:31.308264  2593 solver.cpp:310]     Train net output #0: loss = 0.409295 (* 1 = 0.409295 loss)
I1111 00:06:31.308284  2593 sgd_solver.cpp:106] Iteration 2852, lr = 0.0005
I1111 00:06:34.324596  2593 solver.cpp:295] Iteration 2853 (no loss supplied for SingleUpdateStep)
I1111 00:06:34.324697  2593 solver.cpp:310]     Train net output #0: loss = 0.408348 (* 1 = 0.408348 loss)
I1111 00:06:34.324720  2593 sgd_solver.cpp:106] Iteration 2853, lr = 0.0005
I1111 00:06:36.768193  2593 solver.cpp:295] Iteration 2854 (no loss supplied for SingleUpdateStep)
I1111 00:06:36.768326  2593 solver.cpp:310]     Train net output #0: loss = 0.430358 (* 1 = 0.430358 loss)
I1111 00:06:36.768349  2593 sgd_solver.cpp:106] Iteration 2854, lr = 0.0005
I1111 00:06:38.980525  2593 solver.cpp:295] Iteration 2855 (no loss supplied for SingleUpdateStep)
I1111 00:06:38.980635  2593 solver.cpp:310]     Train net output #0: loss = 0.390243 (* 1 = 0.390243 loss)
I1111 00:06:38.980661  2593 sgd_solver.cpp:106] Iteration 2855, lr = 0.0005
I1111 00:06:41.219177  2593 solver.cpp:295] Iteration 2856 (no loss supplied for SingleUpdateStep)
I1111 00:06:41.219326  2593 solver.cpp:310]     Train net output #0: loss = 0.411893 (* 1 = 0.411893 loss)
I1111 00:06:41.219352  2593 sgd_solver.cpp:106] Iteration 2856, lr = 0.0005
I1111 00:06:43.447283  2593 solver.cpp:295] Iteration 2857 (no loss supplied for SingleUpdateStep)
I1111 00:06:43.447350  2593 solver.cpp:310]     Train net output #0: loss = 0.440992 (* 1 = 0.440992 loss)
I1111 00:06:43.447371  2593 sgd_solver.cpp:106] Iteration 2857, lr = 0.0005
I1111 00:06:45.759114  2593 solver.cpp:295] Iteration 2858 (no loss supplied for SingleUpdateStep)
I1111 00:06:45.759179  2593 solver.cpp:310]     Train net output #0: loss = 0.408217 (* 1 = 0.408217 loss)
I1111 00:06:45.759198  2593 sgd_solver.cpp:106] Iteration 2858, lr = 0.0005
I1111 00:06:48.127574  2593 solver.cpp:295] Iteration 2859 (no loss supplied for SingleUpdateStep)
I1111 00:06:48.127702  2593 solver.cpp:310]     Train net output #0: loss = 0.404691 (* 1 = 0.404691 loss)
I1111 00:06:48.127723  2593 sgd_solver.cpp:106] Iteration 2859, lr = 0.0005
I1111 00:06:50.573745  2593 solver.cpp:295] Iteration 2860 (no loss supplied for SingleUpdateStep)
I1111 00:06:50.573853  2593 solver.cpp:310]     Train net output #0: loss = 0.435805 (* 1 = 0.435805 loss)
I1111 00:06:50.573874  2593 sgd_solver.cpp:106] Iteration 2860, lr = 0.0005
I1111 00:06:53.326618  2593 solver.cpp:295] Iteration 2861 (no loss supplied for SingleUpdateStep)
I1111 00:06:53.326751  2593 solver.cpp:310]     Train net output #0: loss = 0.434251 (* 1 = 0.434251 loss)
I1111 00:06:53.326779  2593 sgd_solver.cpp:106] Iteration 2861, lr = 0.0005
I1111 00:06:55.691942  2593 solver.cpp:295] Iteration 2862 (no loss supplied for SingleUpdateStep)
I1111 00:06:55.692015  2593 solver.cpp:310]     Train net output #0: loss = 0.407243 (* 1 = 0.407243 loss)
I1111 00:06:55.692035  2593 sgd_solver.cpp:106] Iteration 2862, lr = 0.0005
I1111 00:06:58.351894  2593 solver.cpp:295] Iteration 2863 (no loss supplied for SingleUpdateStep)
I1111 00:06:58.352035  2593 solver.cpp:310]     Train net output #0: loss = 0.399354 (* 1 = 0.399354 loss)
I1111 00:06:58.352062  2593 sgd_solver.cpp:106] Iteration 2863, lr = 0.0005
I1111 00:07:00.543531  2593 solver.cpp:295] Iteration 2864 (no loss supplied for SingleUpdateStep)
I1111 00:07:00.543635  2593 solver.cpp:310]     Train net output #0: loss = 0.404493 (* 1 = 0.404493 loss)
I1111 00:07:00.543658  2593 sgd_solver.cpp:106] Iteration 2864, lr = 0.0005
I1111 00:07:02.820238  2593 solver.cpp:295] Iteration 2865 (no loss supplied for SingleUpdateStep)
I1111 00:07:02.820302  2593 solver.cpp:310]     Train net output #0: loss = 0.415183 (* 1 = 0.415183 loss)
I1111 00:07:02.820319  2593 sgd_solver.cpp:106] Iteration 2865, lr = 0.0005
I1111 00:07:05.046030  2593 solver.cpp:295] Iteration 2866 (no loss supplied for SingleUpdateStep)
I1111 00:07:05.046129  2593 solver.cpp:310]     Train net output #0: loss = 0.417676 (* 1 = 0.417676 loss)
I1111 00:07:05.046152  2593 sgd_solver.cpp:106] Iteration 2866, lr = 0.0005
I1111 00:07:07.365339  2593 solver.cpp:295] Iteration 2867 (no loss supplied for SingleUpdateStep)
I1111 00:07:07.365432  2593 solver.cpp:310]     Train net output #0: loss = 0.425606 (* 1 = 0.425606 loss)
I1111 00:07:07.365453  2593 sgd_solver.cpp:106] Iteration 2867, lr = 0.0005
I1111 00:07:09.525871  2593 solver.cpp:295] Iteration 2868 (no loss supplied for SingleUpdateStep)
I1111 00:07:09.526038  2593 solver.cpp:310]     Train net output #0: loss = 0.403818 (* 1 = 0.403818 loss)
I1111 00:07:09.526069  2593 sgd_solver.cpp:106] Iteration 2868, lr = 0.0005
I1111 00:07:11.880069  2593 solver.cpp:295] Iteration 2869 (no loss supplied for SingleUpdateStep)
I1111 00:07:11.880179  2593 solver.cpp:310]     Train net output #0: loss = 0.413588 (* 1 = 0.413588 loss)
I1111 00:07:11.880201  2593 sgd_solver.cpp:106] Iteration 2869, lr = 0.0005
I1111 00:07:14.111942  2593 solver.cpp:295] Iteration 2870 (no loss supplied for SingleUpdateStep)
I1111 00:07:14.112054  2593 solver.cpp:310]     Train net output #0: loss = 0.377955 (* 1 = 0.377955 loss)
I1111 00:07:14.112076  2593 sgd_solver.cpp:106] Iteration 2870, lr = 0.0005
I1111 00:07:16.318406  2593 solver.cpp:295] Iteration 2871 (no loss supplied for SingleUpdateStep)
I1111 00:07:16.318549  2593 solver.cpp:310]     Train net output #0: loss = 0.436893 (* 1 = 0.436893 loss)
I1111 00:07:16.318583  2593 sgd_solver.cpp:106] Iteration 2871, lr = 0.0005
I1111 00:07:18.608206  2593 solver.cpp:295] Iteration 2872 (no loss supplied for SingleUpdateStep)
I1111 00:07:18.608304  2593 solver.cpp:310]     Train net output #0: loss = 0.429958 (* 1 = 0.429958 loss)
I1111 00:07:18.608325  2593 sgd_solver.cpp:106] Iteration 2872, lr = 0.0005
I1111 00:07:20.779685  2593 solver.cpp:295] Iteration 2873 (no loss supplied for SingleUpdateStep)
I1111 00:07:20.779875  2593 solver.cpp:310]     Train net output #0: loss = 0.424663 (* 1 = 0.424663 loss)
I1111 00:07:20.779911  2593 sgd_solver.cpp:106] Iteration 2873, lr = 0.0005
I1111 00:07:23.242432  2593 solver.cpp:295] Iteration 2874 (no loss supplied for SingleUpdateStep)
I1111 00:07:23.242497  2593 solver.cpp:310]     Train net output #0: loss = 0.421905 (* 1 = 0.421905 loss)
I1111 00:07:23.242517  2593 sgd_solver.cpp:106] Iteration 2874, lr = 0.0005
I1111 00:07:25.558209  2593 solver.cpp:295] Iteration 2875 (no loss supplied for SingleUpdateStep)
I1111 00:07:25.558364  2593 solver.cpp:310]     Train net output #0: loss = 0.425181 (* 1 = 0.425181 loss)
I1111 00:07:25.558387  2593 sgd_solver.cpp:106] Iteration 2875, lr = 0.0005
I1111 00:07:27.804270  2593 solver.cpp:295] Iteration 2876 (no loss supplied for SingleUpdateStep)
I1111 00:07:27.804451  2593 solver.cpp:310]     Train net output #0: loss = 0.36627 (* 1 = 0.36627 loss)
I1111 00:07:27.804482  2593 sgd_solver.cpp:106] Iteration 2876, lr = 0.0005
I1111 00:07:30.045496  2593 solver.cpp:295] Iteration 2877 (no loss supplied for SingleUpdateStep)
I1111 00:07:30.045620  2593 solver.cpp:310]     Train net output #0: loss = 0.424219 (* 1 = 0.424219 loss)
I1111 00:07:30.045647  2593 sgd_solver.cpp:106] Iteration 2877, lr = 0.0005
I1111 00:07:32.266351  2593 solver.cpp:295] Iteration 2878 (no loss supplied for SingleUpdateStep)
I1111 00:07:32.266482  2593 solver.cpp:310]     Train net output #0: loss = 0.417245 (* 1 = 0.417245 loss)
I1111 00:07:32.266505  2593 sgd_solver.cpp:106] Iteration 2878, lr = 0.0005
I1111 00:07:34.470780  2593 solver.cpp:295] Iteration 2879 (no loss supplied for SingleUpdateStep)
I1111 00:07:34.470840  2593 solver.cpp:310]     Train net output #0: loss = 0.403744 (* 1 = 0.403744 loss)
I1111 00:07:34.470859  2593 sgd_solver.cpp:106] Iteration 2879, lr = 0.0005
I1111 00:07:36.693557  2593 solver.cpp:295] Iteration 2880 (no loss supplied for SingleUpdateStep)
I1111 00:07:36.693650  2593 solver.cpp:310]     Train net output #0: loss = 0.402408 (* 1 = 0.402408 loss)
I1111 00:07:36.693678  2593 sgd_solver.cpp:106] Iteration 2880, lr = 0.0005
I1111 00:07:38.921989  2593 solver.cpp:295] Iteration 2881 (no loss supplied for SingleUpdateStep)
I1111 00:07:38.922047  2593 solver.cpp:310]     Train net output #0: loss = 0.411004 (* 1 = 0.411004 loss)
I1111 00:07:38.922066  2593 sgd_solver.cpp:106] Iteration 2881, lr = 0.0005
I1111 00:07:41.122155  2593 solver.cpp:295] Iteration 2882 (no loss supplied for SingleUpdateStep)
I1111 00:07:41.122230  2593 solver.cpp:310]     Train net output #0: loss = 0.392533 (* 1 = 0.392533 loss)
I1111 00:07:41.122251  2593 sgd_solver.cpp:106] Iteration 2882, lr = 0.0005
I1111 00:07:43.370929  2593 solver.cpp:295] Iteration 2883 (no loss supplied for SingleUpdateStep)
I1111 00:07:43.371052  2593 solver.cpp:310]     Train net output #0: loss = 0.411783 (* 1 = 0.411783 loss)
I1111 00:07:43.371076  2593 sgd_solver.cpp:106] Iteration 2883, lr = 0.0005
I1111 00:07:45.575109  2593 solver.cpp:295] Iteration 2884 (no loss supplied for SingleUpdateStep)
I1111 00:07:45.575187  2593 solver.cpp:310]     Train net output #0: loss = 0.43816 (* 1 = 0.43816 loss)
I1111 00:07:45.575207  2593 sgd_solver.cpp:106] Iteration 2884, lr = 0.0005
I1111 00:07:47.850466  2593 solver.cpp:295] Iteration 2885 (no loss supplied for SingleUpdateStep)
I1111 00:07:47.850587  2593 solver.cpp:310]     Train net output #0: loss = 0.412883 (* 1 = 0.412883 loss)
I1111 00:07:47.850610  2593 sgd_solver.cpp:106] Iteration 2885, lr = 0.0005
I1111 00:07:50.035403  2593 solver.cpp:295] Iteration 2886 (no loss supplied for SingleUpdateStep)
I1111 00:07:50.035482  2593 solver.cpp:310]     Train net output #0: loss = 0.387433 (* 1 = 0.387433 loss)
I1111 00:07:50.035504  2593 sgd_solver.cpp:106] Iteration 2886, lr = 0.0005
I1111 00:07:52.610144  2593 solver.cpp:295] Iteration 2887 (no loss supplied for SingleUpdateStep)
I1111 00:07:52.610220  2593 solver.cpp:310]     Train net output #0: loss = 0.456029 (* 1 = 0.456029 loss)
I1111 00:07:52.610242  2593 sgd_solver.cpp:106] Iteration 2887, lr = 0.0005
I1111 00:07:54.841455  2593 solver.cpp:295] Iteration 2888 (no loss supplied for SingleUpdateStep)
I1111 00:07:54.841542  2593 solver.cpp:310]     Train net output #0: loss = 0.406016 (* 1 = 0.406016 loss)
I1111 00:07:54.841562  2593 sgd_solver.cpp:106] Iteration 2888, lr = 0.0005
I1111 00:07:57.012377  2593 solver.cpp:295] Iteration 2889 (no loss supplied for SingleUpdateStep)
I1111 00:07:57.012457  2593 solver.cpp:310]     Train net output #0: loss = 0.387974 (* 1 = 0.387974 loss)
I1111 00:07:57.012480  2593 sgd_solver.cpp:106] Iteration 2889, lr = 0.0005
I1111 00:07:59.328742  2593 solver.cpp:295] Iteration 2890 (no loss supplied for SingleUpdateStep)
I1111 00:07:59.328804  2593 solver.cpp:310]     Train net output #0: loss = 0.408107 (* 1 = 0.408107 loss)
I1111 00:07:59.328822  2593 sgd_solver.cpp:106] Iteration 2890, lr = 0.0005
I1111 00:08:01.674257  2593 solver.cpp:295] Iteration 2891 (no loss supplied for SingleUpdateStep)
I1111 00:08:01.674399  2593 solver.cpp:310]     Train net output #0: loss = 0.422341 (* 1 = 0.422341 loss)
I1111 00:08:01.674430  2593 sgd_solver.cpp:106] Iteration 2891, lr = 0.0005
I1111 00:08:04.006711  2593 solver.cpp:295] Iteration 2892 (no loss supplied for SingleUpdateStep)
I1111 00:08:04.006845  2593 solver.cpp:310]     Train net output #0: loss = 0.410868 (* 1 = 0.410868 loss)
I1111 00:08:04.006870  2593 sgd_solver.cpp:106] Iteration 2892, lr = 0.0005
I1111 00:08:06.234428  2593 solver.cpp:295] Iteration 2893 (no loss supplied for SingleUpdateStep)
I1111 00:08:06.234493  2593 solver.cpp:310]     Train net output #0: loss = 0.406908 (* 1 = 0.406908 loss)
I1111 00:08:06.234521  2593 sgd_solver.cpp:106] Iteration 2893, lr = 0.0005
I1111 00:08:08.510562  2593 solver.cpp:295] Iteration 2894 (no loss supplied for SingleUpdateStep)
I1111 00:08:08.510704  2593 solver.cpp:310]     Train net output #0: loss = 0.443821 (* 1 = 0.443821 loss)
I1111 00:08:08.510727  2593 sgd_solver.cpp:106] Iteration 2894, lr = 0.0005
I1111 00:08:10.809284  2593 solver.cpp:295] Iteration 2895 (no loss supplied for SingleUpdateStep)
I1111 00:08:10.809401  2593 solver.cpp:310]     Train net output #0: loss = 0.416382 (* 1 = 0.416382 loss)
I1111 00:08:10.809422  2593 sgd_solver.cpp:106] Iteration 2895, lr = 0.0005
I1111 00:08:13.005499  2593 solver.cpp:295] Iteration 2896 (no loss supplied for SingleUpdateStep)
I1111 00:08:13.005605  2593 solver.cpp:310]     Train net output #0: loss = 0.420391 (* 1 = 0.420391 loss)
I1111 00:08:13.005626  2593 sgd_solver.cpp:106] Iteration 2896, lr = 0.0005
I1111 00:08:15.092304  2593 solver.cpp:295] Iteration 2897 (no loss supplied for SingleUpdateStep)
I1111 00:08:15.092432  2593 solver.cpp:310]     Train net output #0: loss = 0.371875 (* 1 = 0.371875 loss)
I1111 00:08:15.092456  2593 sgd_solver.cpp:106] Iteration 2897, lr = 0.0005
I1111 00:08:17.380584  2593 solver.cpp:295] Iteration 2898 (no loss supplied for SingleUpdateStep)
I1111 00:08:17.380723  2593 solver.cpp:310]     Train net output #0: loss = 0.382363 (* 1 = 0.382363 loss)
I1111 00:08:17.380748  2593 sgd_solver.cpp:106] Iteration 2898, lr = 0.0005
I1111 00:08:19.592236  2593 solver.cpp:295] Iteration 2899 (no loss supplied for SingleUpdateStep)
I1111 00:08:19.592329  2593 solver.cpp:310]     Train net output #0: loss = 0.429525 (* 1 = 0.429525 loss)
I1111 00:08:19.592347  2593 sgd_solver.cpp:106] Iteration 2899, lr = 0.0005
I1111 00:08:21.901859  2593 solver.cpp:295] Iteration 2900 (no loss supplied for SingleUpdateStep)
I1111 00:08:21.901964  2593 solver.cpp:310]     Train net output #0: loss = 0.44197 (* 1 = 0.44197 loss)
I1111 00:08:21.901986  2593 sgd_solver.cpp:106] Iteration 2900, lr = 0.0005
I1111 00:08:24.398530  2593 solver.cpp:295] Iteration 2901 (no loss supplied for SingleUpdateStep)
I1111 00:08:24.398674  2593 solver.cpp:310]     Train net output #0: loss = 0.409579 (* 1 = 0.409579 loss)
I1111 00:08:24.398696  2593 sgd_solver.cpp:106] Iteration 2901, lr = 0.0005
I1111 00:08:27.192302  2593 solver.cpp:295] Iteration 2902 (no loss supplied for SingleUpdateStep)
I1111 00:08:27.192442  2593 solver.cpp:310]     Train net output #0: loss = 0.398 (* 1 = 0.398 loss)
I1111 00:08:27.192473  2593 sgd_solver.cpp:106] Iteration 2902, lr = 0.0005
I1111 00:08:29.419456  2593 solver.cpp:295] Iteration 2903 (no loss supplied for SingleUpdateStep)
I1111 00:08:29.419515  2593 solver.cpp:310]     Train net output #0: loss = 0.420943 (* 1 = 0.420943 loss)
I1111 00:08:29.419534  2593 sgd_solver.cpp:106] Iteration 2903, lr = 0.0005
I1111 00:08:31.844689  2593 solver.cpp:295] Iteration 2904 (no loss supplied for SingleUpdateStep)
I1111 00:08:31.844780  2593 solver.cpp:310]     Train net output #0: loss = 0.402228 (* 1 = 0.402228 loss)
I1111 00:08:31.844801  2593 sgd_solver.cpp:106] Iteration 2904, lr = 0.0005
I1111 00:08:34.103451  2593 solver.cpp:295] Iteration 2905 (no loss supplied for SingleUpdateStep)
I1111 00:08:34.103557  2593 solver.cpp:310]     Train net output #0: loss = 0.402813 (* 1 = 0.402813 loss)
I1111 00:08:34.103581  2593 sgd_solver.cpp:106] Iteration 2905, lr = 0.0005
I1111 00:08:36.559365  2593 solver.cpp:295] Iteration 2906 (no loss supplied for SingleUpdateStep)
I1111 00:08:36.559483  2593 solver.cpp:310]     Train net output #0: loss = 0.422479 (* 1 = 0.422479 loss)
I1111 00:08:36.559505  2593 sgd_solver.cpp:106] Iteration 2906, lr = 0.0005
I1111 00:08:38.888656  2593 solver.cpp:295] Iteration 2907 (no loss supplied for SingleUpdateStep)
I1111 00:08:38.888800  2593 solver.cpp:310]     Train net output #0: loss = 0.434666 (* 1 = 0.434666 loss)
I1111 00:08:38.888823  2593 sgd_solver.cpp:106] Iteration 2907, lr = 0.0005
I1111 00:08:41.723630  2593 solver.cpp:295] Iteration 2908 (no loss supplied for SingleUpdateStep)
I1111 00:08:41.723749  2593 solver.cpp:310]     Train net output #0: loss = 0.41453 (* 1 = 0.41453 loss)
I1111 00:08:41.723773  2593 sgd_solver.cpp:106] Iteration 2908, lr = 0.0005
I1111 00:08:44.212815  2593 solver.cpp:295] Iteration 2909 (no loss supplied for SingleUpdateStep)
I1111 00:08:44.212939  2593 solver.cpp:310]     Train net output #0: loss = 0.388018 (* 1 = 0.388018 loss)
I1111 00:08:44.212960  2593 sgd_solver.cpp:106] Iteration 2909, lr = 0.0005
I1111 00:08:46.741297  2593 solver.cpp:295] Iteration 2910 (no loss supplied for SingleUpdateStep)
I1111 00:08:46.741369  2593 solver.cpp:310]     Train net output #0: loss = 0.413565 (* 1 = 0.413565 loss)
I1111 00:08:46.741390  2593 sgd_solver.cpp:106] Iteration 2910, lr = 0.0005
I1111 00:08:49.224591  2593 solver.cpp:295] Iteration 2911 (no loss supplied for SingleUpdateStep)
I1111 00:08:49.224720  2593 solver.cpp:310]     Train net output #0: loss = 0.396519 (* 1 = 0.396519 loss)
I1111 00:08:49.224740  2593 sgd_solver.cpp:106] Iteration 2911, lr = 0.0005
I1111 00:08:51.445405  2593 solver.cpp:295] Iteration 2912 (no loss supplied for SingleUpdateStep)
I1111 00:08:51.445466  2593 solver.cpp:310]     Train net output #0: loss = 0.40348 (* 1 = 0.40348 loss)
I1111 00:08:51.445487  2593 sgd_solver.cpp:106] Iteration 2912, lr = 0.0005
I1111 00:08:53.906889  2593 solver.cpp:295] Iteration 2913 (no loss supplied for SingleUpdateStep)
I1111 00:08:53.906978  2593 solver.cpp:310]     Train net output #0: loss = 0.417272 (* 1 = 0.417272 loss)
I1111 00:08:53.906997  2593 sgd_solver.cpp:106] Iteration 2913, lr = 0.0005
I1111 00:08:56.408164  2593 solver.cpp:295] Iteration 2914 (no loss supplied for SingleUpdateStep)
I1111 00:08:56.408263  2593 solver.cpp:310]     Train net output #0: loss = 0.371664 (* 1 = 0.371664 loss)
I1111 00:08:56.408287  2593 sgd_solver.cpp:106] Iteration 2914, lr = 0.0005
I1111 00:08:58.935314  2593 solver.cpp:295] Iteration 2915 (no loss supplied for SingleUpdateStep)
I1111 00:08:58.935446  2593 solver.cpp:310]     Train net output #0: loss = 0.42615 (* 1 = 0.42615 loss)
I1111 00:08:58.935467  2593 sgd_solver.cpp:106] Iteration 2915, lr = 0.0005
I1111 00:09:01.998234  2593 solver.cpp:295] Iteration 2916 (no loss supplied for SingleUpdateStep)
I1111 00:09:01.998318  2593 solver.cpp:310]     Train net output #0: loss = 0.429426 (* 1 = 0.429426 loss)
I1111 00:09:01.998339  2593 sgd_solver.cpp:106] Iteration 2916, lr = 0.0005
I1111 00:09:05.390372  2593 solver.cpp:295] Iteration 2917 (no loss supplied for SingleUpdateStep)
I1111 00:09:05.390522  2593 solver.cpp:310]     Train net output #0: loss = 0.412428 (* 1 = 0.412428 loss)
I1111 00:09:05.390544  2593 sgd_solver.cpp:106] Iteration 2917, lr = 0.0005
I1111 00:09:07.782348  2593 solver.cpp:295] Iteration 2918 (no loss supplied for SingleUpdateStep)
I1111 00:09:07.782526  2593 solver.cpp:310]     Train net output #0: loss = 0.39077 (* 1 = 0.39077 loss)
I1111 00:09:07.782548  2593 sgd_solver.cpp:106] Iteration 2918, lr = 0.0005
I1111 00:09:10.106744  2593 solver.cpp:295] Iteration 2919 (no loss supplied for SingleUpdateStep)
I1111 00:09:10.106853  2593 solver.cpp:310]     Train net output #0: loss = 0.421219 (* 1 = 0.421219 loss)
I1111 00:09:10.106875  2593 sgd_solver.cpp:106] Iteration 2919, lr = 0.0005
I1111 00:09:12.384405  2593 solver.cpp:295] Iteration 2920 (no loss supplied for SingleUpdateStep)
I1111 00:09:12.384462  2593 solver.cpp:310]     Train net output #0: loss = 0.382937 (* 1 = 0.382937 loss)
I1111 00:09:12.384481  2593 sgd_solver.cpp:106] Iteration 2920, lr = 0.0005
I1111 00:09:14.766162  2593 solver.cpp:295] Iteration 2921 (no loss supplied for SingleUpdateStep)
I1111 00:09:14.766217  2593 solver.cpp:310]     Train net output #0: loss = 0.404729 (* 1 = 0.404729 loss)
I1111 00:09:14.766235  2593 sgd_solver.cpp:106] Iteration 2921, lr = 0.0005
I1111 00:09:17.370759  2593 solver.cpp:295] Iteration 2922 (no loss supplied for SingleUpdateStep)
I1111 00:09:17.370898  2593 solver.cpp:310]     Train net output #0: loss = 0.411185 (* 1 = 0.411185 loss)
I1111 00:09:17.370920  2593 sgd_solver.cpp:106] Iteration 2922, lr = 0.0005
I1111 00:09:19.695420  2593 solver.cpp:295] Iteration 2923 (no loss supplied for SingleUpdateStep)
I1111 00:09:19.695547  2593 solver.cpp:310]     Train net output #0: loss = 0.404071 (* 1 = 0.404071 loss)
I1111 00:09:19.695570  2593 sgd_solver.cpp:106] Iteration 2923, lr = 0.0005
I1111 00:09:22.347874  2593 solver.cpp:295] Iteration 2924 (no loss supplied for SingleUpdateStep)
I1111 00:09:22.347944  2593 solver.cpp:310]     Train net output #0: loss = 0.417112 (* 1 = 0.417112 loss)
I1111 00:09:22.347965  2593 sgd_solver.cpp:106] Iteration 2924, lr = 0.0005
I1111 00:09:24.690289  2593 solver.cpp:295] Iteration 2925 (no loss supplied for SingleUpdateStep)
I1111 00:09:24.690431  2593 solver.cpp:310]     Train net output #0: loss = 0.398531 (* 1 = 0.398531 loss)
I1111 00:09:24.690459  2593 sgd_solver.cpp:106] Iteration 2925, lr = 0.0005
I1111 00:09:27.154752  2593 solver.cpp:295] Iteration 2926 (no loss supplied for SingleUpdateStep)
I1111 00:09:27.154844  2593 solver.cpp:310]     Train net output #0: loss = 0.412482 (* 1 = 0.412482 loss)
I1111 00:09:27.154865  2593 sgd_solver.cpp:106] Iteration 2926, lr = 0.0005
I1111 00:09:29.371388  2593 solver.cpp:295] Iteration 2927 (no loss supplied for SingleUpdateStep)
I1111 00:09:29.371501  2593 solver.cpp:310]     Train net output #0: loss = 0.391652 (* 1 = 0.391652 loss)
I1111 00:09:29.371525  2593 sgd_solver.cpp:106] Iteration 2927, lr = 0.0005
I1111 00:09:31.599557  2593 solver.cpp:295] Iteration 2928 (no loss supplied for SingleUpdateStep)
I1111 00:09:31.599725  2593 solver.cpp:310]     Train net output #0: loss = 0.42312 (* 1 = 0.42312 loss)
I1111 00:09:31.599767  2593 sgd_solver.cpp:106] Iteration 2928, lr = 0.0005
I1111 00:09:33.945607  2593 solver.cpp:295] Iteration 2929 (no loss supplied for SingleUpdateStep)
I1111 00:09:33.945729  2593 solver.cpp:310]     Train net output #0: loss = 0.424246 (* 1 = 0.424246 loss)
I1111 00:09:33.945758  2593 sgd_solver.cpp:106] Iteration 2929, lr = 0.0005
I1111 00:09:36.092319  2593 solver.cpp:295] Iteration 2930 (no loss supplied for SingleUpdateStep)
I1111 00:09:36.092439  2593 solver.cpp:310]     Train net output #0: loss = 0.390234 (* 1 = 0.390234 loss)
I1111 00:09:36.092465  2593 sgd_solver.cpp:106] Iteration 2930, lr = 0.0005
I1111 00:09:38.414686  2593 solver.cpp:295] Iteration 2931 (no loss supplied for SingleUpdateStep)
I1111 00:09:38.414769  2593 solver.cpp:310]     Train net output #0: loss = 0.380641 (* 1 = 0.380641 loss)
I1111 00:09:38.414793  2593 sgd_solver.cpp:106] Iteration 2931, lr = 0.0005
I1111 00:09:40.685492  2593 solver.cpp:295] Iteration 2932 (no loss supplied for SingleUpdateStep)
I1111 00:09:40.685672  2593 solver.cpp:310]     Train net output #0: loss = 0.408485 (* 1 = 0.408485 loss)
I1111 00:09:40.685700  2593 sgd_solver.cpp:106] Iteration 2932, lr = 0.0005
I1111 00:09:42.975061  2593 solver.cpp:295] Iteration 2933 (no loss supplied for SingleUpdateStep)
I1111 00:09:42.975188  2593 solver.cpp:310]     Train net output #0: loss = 0.404579 (* 1 = 0.404579 loss)
I1111 00:09:42.975210  2593 sgd_solver.cpp:106] Iteration 2933, lr = 0.0005
I1111 00:09:45.483958  2593 solver.cpp:295] Iteration 2934 (no loss supplied for SingleUpdateStep)
I1111 00:09:45.484078  2593 solver.cpp:310]     Train net output #0: loss = 0.431369 (* 1 = 0.431369 loss)
I1111 00:09:45.484102  2593 sgd_solver.cpp:106] Iteration 2934, lr = 0.0005
I1111 00:09:49.119704  2593 solver.cpp:295] Iteration 2935 (no loss supplied for SingleUpdateStep)
I1111 00:09:49.119837  2593 solver.cpp:310]     Train net output #0: loss = 0.421256 (* 1 = 0.421256 loss)
I1111 00:09:49.119863  2593 sgd_solver.cpp:106] Iteration 2935, lr = 0.0005
I1111 00:09:53.085000  2593 solver.cpp:295] Iteration 2936 (no loss supplied for SingleUpdateStep)
I1111 00:09:53.085108  2593 solver.cpp:310]     Train net output #0: loss = 0.420358 (* 1 = 0.420358 loss)
I1111 00:09:53.085129  2593 sgd_solver.cpp:106] Iteration 2936, lr = 0.0005
I1111 00:09:55.534319  2593 solver.cpp:295] Iteration 2937 (no loss supplied for SingleUpdateStep)
I1111 00:09:55.534410  2593 solver.cpp:310]     Train net output #0: loss = 0.413375 (* 1 = 0.413375 loss)
I1111 00:09:55.534432  2593 sgd_solver.cpp:106] Iteration 2937, lr = 0.0005
I1111 00:09:58.013113  2593 solver.cpp:295] Iteration 2938 (no loss supplied for SingleUpdateStep)
I1111 00:09:58.013219  2593 solver.cpp:310]     Train net output #0: loss = 0.421221 (* 1 = 0.421221 loss)
I1111 00:09:58.013241  2593 sgd_solver.cpp:106] Iteration 2938, lr = 0.0005
I1111 00:10:00.275446  2593 solver.cpp:295] Iteration 2939 (no loss supplied for SingleUpdateStep)
I1111 00:10:00.275578  2593 solver.cpp:310]     Train net output #0: loss = 0.405847 (* 1 = 0.405847 loss)
I1111 00:10:00.275601  2593 sgd_solver.cpp:106] Iteration 2939, lr = 0.0005
I1111 00:10:02.549846  2593 solver.cpp:295] Iteration 2940 (no loss supplied for SingleUpdateStep)
I1111 00:10:02.549974  2593 solver.cpp:310]     Train net output #0: loss = 0.401952 (* 1 = 0.401952 loss)
I1111 00:10:02.549998  2593 sgd_solver.cpp:106] Iteration 2940, lr = 0.0005
I1111 00:10:04.893213  2593 solver.cpp:295] Iteration 2941 (no loss supplied for SingleUpdateStep)
I1111 00:10:04.893287  2593 solver.cpp:310]     Train net output #0: loss = 0.40338 (* 1 = 0.40338 loss)
I1111 00:10:04.893308  2593 sgd_solver.cpp:106] Iteration 2941, lr = 0.0005
I1111 00:10:07.056633  2593 solver.cpp:295] Iteration 2942 (no loss supplied for SingleUpdateStep)
I1111 00:10:07.056751  2593 solver.cpp:310]     Train net output #0: loss = 0.435619 (* 1 = 0.435619 loss)
I1111 00:10:07.056777  2593 sgd_solver.cpp:106] Iteration 2942, lr = 0.0005
I1111 00:10:09.178851  2593 solver.cpp:295] Iteration 2943 (no loss supplied for SingleUpdateStep)
I1111 00:10:09.178972  2593 solver.cpp:310]     Train net output #0: loss = 0.402943 (* 1 = 0.402943 loss)
I1111 00:10:09.178994  2593 sgd_solver.cpp:106] Iteration 2943, lr = 0.0005
I1111 00:10:11.507019  2593 solver.cpp:295] Iteration 2944 (no loss supplied for SingleUpdateStep)
I1111 00:10:11.507113  2593 solver.cpp:310]     Train net output #0: loss = 0.430506 (* 1 = 0.430506 loss)
I1111 00:10:11.507134  2593 sgd_solver.cpp:106] Iteration 2944, lr = 0.0005
I1111 00:10:13.713910  2593 solver.cpp:295] Iteration 2945 (no loss supplied for SingleUpdateStep)
I1111 00:10:13.714015  2593 solver.cpp:310]     Train net output #0: loss = 0.412496 (* 1 = 0.412496 loss)
I1111 00:10:13.714035  2593 sgd_solver.cpp:106] Iteration 2945, lr = 0.0005
I1111 00:10:15.979758  2593 solver.cpp:295] Iteration 2946 (no loss supplied for SingleUpdateStep)
I1111 00:10:15.979838  2593 solver.cpp:310]     Train net output #0: loss = 0.407326 (* 1 = 0.407326 loss)
I1111 00:10:15.979858  2593 sgd_solver.cpp:106] Iteration 2946, lr = 0.0005
I1111 00:10:18.490443  2593 solver.cpp:295] Iteration 2947 (no loss supplied for SingleUpdateStep)
I1111 00:10:18.490571  2593 solver.cpp:310]     Train net output #0: loss = 0.398604 (* 1 = 0.398604 loss)
I1111 00:10:18.490595  2593 sgd_solver.cpp:106] Iteration 2947, lr = 0.0005
I1111 00:10:21.234525  2593 solver.cpp:295] Iteration 2948 (no loss supplied for SingleUpdateStep)
I1111 00:10:21.234655  2593 solver.cpp:310]     Train net output #0: loss = 0.374557 (* 1 = 0.374557 loss)
I1111 00:10:21.234681  2593 sgd_solver.cpp:106] Iteration 2948, lr = 0.0005
I1111 00:10:24.287268  2593 solver.cpp:295] Iteration 2949 (no loss supplied for SingleUpdateStep)
I1111 00:10:24.287328  2593 solver.cpp:310]     Train net output #0: loss = 0.370303 (* 1 = 0.370303 loss)
I1111 00:10:24.287348  2593 sgd_solver.cpp:106] Iteration 2949, lr = 0.0005
I1111 00:10:27.242712  2593 solver.cpp:295] Iteration 2950 (no loss supplied for SingleUpdateStep)
I1111 00:10:27.242828  2593 solver.cpp:310]     Train net output #0: loss = 0.395214 (* 1 = 0.395214 loss)
I1111 00:10:27.242851  2593 sgd_solver.cpp:106] Iteration 2950, lr = 0.0005
I1111 00:10:30.240754  2593 solver.cpp:295] Iteration 2951 (no loss supplied for SingleUpdateStep)
I1111 00:10:30.240844  2593 solver.cpp:310]     Train net output #0: loss = 0.413983 (* 1 = 0.413983 loss)
I1111 00:10:30.240864  2593 sgd_solver.cpp:106] Iteration 2951, lr = 0.0005
I1111 00:10:32.565068  2593 solver.cpp:295] Iteration 2952 (no loss supplied for SingleUpdateStep)
I1111 00:10:32.565136  2593 solver.cpp:310]     Train net output #0: loss = 0.41085 (* 1 = 0.41085 loss)
I1111 00:10:32.565156  2593 sgd_solver.cpp:106] Iteration 2952, lr = 0.0005
I1111 00:10:35.178154  2593 solver.cpp:295] Iteration 2953 (no loss supplied for SingleUpdateStep)
I1111 00:10:35.178318  2593 solver.cpp:310]     Train net output #0: loss = 0.408358 (* 1 = 0.408358 loss)
I1111 00:10:35.178341  2593 sgd_solver.cpp:106] Iteration 2953, lr = 0.0005
I1111 00:10:37.665037  2593 solver.cpp:295] Iteration 2954 (no loss supplied for SingleUpdateStep)
I1111 00:10:37.665151  2593 solver.cpp:310]     Train net output #0: loss = 0.395406 (* 1 = 0.395406 loss)
I1111 00:10:37.665175  2593 sgd_solver.cpp:106] Iteration 2954, lr = 0.0005
I1111 00:10:40.311414  2593 solver.cpp:295] Iteration 2955 (no loss supplied for SingleUpdateStep)
I1111 00:10:40.311553  2593 solver.cpp:310]     Train net output #0: loss = 0.383045 (* 1 = 0.383045 loss)
I1111 00:10:40.311578  2593 sgd_solver.cpp:106] Iteration 2955, lr = 0.0005
I1111 00:10:42.792176  2593 solver.cpp:295] Iteration 2956 (no loss supplied for SingleUpdateStep)
I1111 00:10:42.792301  2593 solver.cpp:310]     Train net output #0: loss = 0.411115 (* 1 = 0.411115 loss)
I1111 00:10:42.792325  2593 sgd_solver.cpp:106] Iteration 2956, lr = 0.0005
I1111 00:10:45.263123  2593 solver.cpp:295] Iteration 2957 (no loss supplied for SingleUpdateStep)
I1111 00:10:45.263207  2593 solver.cpp:310]     Train net output #0: loss = 0.409682 (* 1 = 0.409682 loss)
I1111 00:10:45.263227  2593 sgd_solver.cpp:106] Iteration 2957, lr = 0.0005
I1111 00:10:47.597167  2593 solver.cpp:295] Iteration 2958 (no loss supplied for SingleUpdateStep)
I1111 00:10:47.597316  2593 solver.cpp:310]     Train net output #0: loss = 0.446079 (* 1 = 0.446079 loss)
I1111 00:10:47.597338  2593 sgd_solver.cpp:106] Iteration 2958, lr = 0.0005
I1111 00:10:49.987769  2593 solver.cpp:295] Iteration 2959 (no loss supplied for SingleUpdateStep)
I1111 00:10:49.987874  2593 solver.cpp:310]     Train net output #0: loss = 0.417518 (* 1 = 0.417518 loss)
I1111 00:10:49.987896  2593 sgd_solver.cpp:106] Iteration 2959, lr = 0.0005
I1111 00:10:52.267319  2593 solver.cpp:295] Iteration 2960 (no loss supplied for SingleUpdateStep)
I1111 00:10:52.267441  2593 solver.cpp:310]     Train net output #0: loss = 0.417011 (* 1 = 0.417011 loss)
I1111 00:10:52.267465  2593 sgd_solver.cpp:106] Iteration 2960, lr = 0.0005
I1111 00:10:54.507879  2593 solver.cpp:295] Iteration 2961 (no loss supplied for SingleUpdateStep)
I1111 00:10:54.507999  2593 solver.cpp:310]     Train net output #0: loss = 0.404572 (* 1 = 0.404572 loss)
I1111 00:10:54.508021  2593 sgd_solver.cpp:106] Iteration 2961, lr = 0.0005
I1111 00:10:56.937840  2593 solver.cpp:295] Iteration 2962 (no loss supplied for SingleUpdateStep)
I1111 00:10:56.937899  2593 solver.cpp:310]     Train net output #0: loss = 0.391186 (* 1 = 0.391186 loss)
I1111 00:10:56.937918  2593 sgd_solver.cpp:106] Iteration 2962, lr = 0.0005
I1111 00:10:59.444412  2593 solver.cpp:295] Iteration 2963 (no loss supplied for SingleUpdateStep)
I1111 00:10:59.444566  2593 solver.cpp:310]     Train net output #0: loss = 0.41111 (* 1 = 0.41111 loss)
I1111 00:10:59.444588  2593 sgd_solver.cpp:106] Iteration 2963, lr = 0.0005
I1111 00:11:01.818331  2593 solver.cpp:295] Iteration 2964 (no loss supplied for SingleUpdateStep)
I1111 00:11:01.818465  2593 solver.cpp:310]     Train net output #0: loss = 0.388236 (* 1 = 0.388236 loss)
I1111 00:11:01.818487  2593 sgd_solver.cpp:106] Iteration 2964, lr = 0.0005
I1111 00:11:04.242467  2593 solver.cpp:295] Iteration 2965 (no loss supplied for SingleUpdateStep)
I1111 00:11:04.242571  2593 solver.cpp:310]     Train net output #0: loss = 0.396721 (* 1 = 0.396721 loss)
I1111 00:11:04.242594  2593 sgd_solver.cpp:106] Iteration 2965, lr = 0.0005
I1111 00:11:06.394250  2593 solver.cpp:295] Iteration 2966 (no loss supplied for SingleUpdateStep)
I1111 00:11:06.394321  2593 solver.cpp:310]     Train net output #0: loss = 0.412361 (* 1 = 0.412361 loss)
I1111 00:11:06.394341  2593 sgd_solver.cpp:106] Iteration 2966, lr = 0.0005
I1111 00:11:08.765743  2593 solver.cpp:295] Iteration 2967 (no loss supplied for SingleUpdateStep)
I1111 00:11:08.765842  2593 solver.cpp:310]     Train net output #0: loss = 0.423996 (* 1 = 0.423996 loss)
I1111 00:11:08.765863  2593 sgd_solver.cpp:106] Iteration 2967, lr = 0.0005
I1111 00:11:11.021512  2593 solver.cpp:295] Iteration 2968 (no loss supplied for SingleUpdateStep)
I1111 00:11:11.021625  2593 solver.cpp:310]     Train net output #0: loss = 0.41426 (* 1 = 0.41426 loss)
I1111 00:11:11.021647  2593 sgd_solver.cpp:106] Iteration 2968, lr = 0.0005
I1111 00:11:13.293622  2593 solver.cpp:295] Iteration 2969 (no loss supplied for SingleUpdateStep)
I1111 00:11:13.293773  2593 solver.cpp:310]     Train net output #0: loss = 0.425478 (* 1 = 0.425478 loss)
I1111 00:11:13.293798  2593 sgd_solver.cpp:106] Iteration 2969, lr = 0.0005
I1111 00:11:15.453043  2593 solver.cpp:295] Iteration 2970 (no loss supplied for SingleUpdateStep)
I1111 00:11:15.453135  2593 solver.cpp:310]     Train net output #0: loss = 0.399027 (* 1 = 0.399027 loss)
I1111 00:11:15.453155  2593 sgd_solver.cpp:106] Iteration 2970, lr = 0.0005
I1111 00:11:17.629446  2593 solver.cpp:295] Iteration 2971 (no loss supplied for SingleUpdateStep)
I1111 00:11:17.629501  2593 solver.cpp:310]     Train net output #0: loss = 0.403309 (* 1 = 0.403309 loss)
I1111 00:11:17.629519  2593 sgd_solver.cpp:106] Iteration 2971, lr = 0.0005
I1111 00:11:20.220224  2593 solver.cpp:295] Iteration 2972 (no loss supplied for SingleUpdateStep)
I1111 00:11:20.220335  2593 solver.cpp:310]     Train net output #0: loss = 0.407833 (* 1 = 0.407833 loss)
I1111 00:11:20.220356  2593 sgd_solver.cpp:106] Iteration 2972, lr = 0.0005
I1111 00:11:22.930810  2593 solver.cpp:295] Iteration 2973 (no loss supplied for SingleUpdateStep)
I1111 00:11:22.930907  2593 solver.cpp:310]     Train net output #0: loss = 0.411975 (* 1 = 0.411975 loss)
I1111 00:11:22.930928  2593 sgd_solver.cpp:106] Iteration 2973, lr = 0.0005
I1111 00:11:26.109107  2593 solver.cpp:295] Iteration 2974 (no loss supplied for SingleUpdateStep)
I1111 00:11:26.109256  2593 solver.cpp:310]     Train net output #0: loss = 0.387764 (* 1 = 0.387764 loss)
I1111 00:11:26.109279  2593 sgd_solver.cpp:106] Iteration 2974, lr = 0.0005
I1111 00:11:29.361151  2593 solver.cpp:295] Iteration 2975 (no loss supplied for SingleUpdateStep)
I1111 00:11:29.361274  2593 solver.cpp:310]     Train net output #0: loss = 0.405987 (* 1 = 0.405987 loss)
I1111 00:11:29.361294  2593 sgd_solver.cpp:106] Iteration 2975, lr = 0.0005
I1111 00:11:32.601663  2593 solver.cpp:295] Iteration 2976 (no loss supplied for SingleUpdateStep)
I1111 00:11:32.601764  2593 solver.cpp:310]     Train net output #0: loss = 0.402802 (* 1 = 0.402802 loss)
I1111 00:11:32.601784  2593 sgd_solver.cpp:106] Iteration 2976, lr = 0.0005
I1111 00:11:35.771430  2593 solver.cpp:295] Iteration 2977 (no loss supplied for SingleUpdateStep)
I1111 00:11:35.771538  2593 solver.cpp:310]     Train net output #0: loss = 0.405831 (* 1 = 0.405831 loss)
I1111 00:11:35.771565  2593 sgd_solver.cpp:106] Iteration 2977, lr = 0.0005
I1111 00:11:39.234555  2593 solver.cpp:295] Iteration 2978 (no loss supplied for SingleUpdateStep)
I1111 00:11:39.234647  2593 solver.cpp:310]     Train net output #0: loss = 0.390232 (* 1 = 0.390232 loss)
I1111 00:11:39.234668  2593 sgd_solver.cpp:106] Iteration 2978, lr = 0.0005
I1111 00:11:42.251950  2593 solver.cpp:295] Iteration 2979 (no loss supplied for SingleUpdateStep)
I1111 00:11:42.252043  2593 solver.cpp:310]     Train net output #0: loss = 0.442689 (* 1 = 0.442689 loss)
I1111 00:11:42.252063  2593 sgd_solver.cpp:106] Iteration 2979, lr = 0.0005
I1111 00:11:45.672164  2593 solver.cpp:295] Iteration 2980 (no loss supplied for SingleUpdateStep)
I1111 00:11:45.672257  2593 solver.cpp:310]     Train net output #0: loss = 0.419015 (* 1 = 0.419015 loss)
I1111 00:11:45.672278  2593 sgd_solver.cpp:106] Iteration 2980, lr = 0.0005
I1111 00:11:50.191613  2593 solver.cpp:295] Iteration 2981 (no loss supplied for SingleUpdateStep)
I1111 00:11:50.191721  2593 solver.cpp:310]     Train net output #0: loss = 0.395505 (* 1 = 0.395505 loss)
I1111 00:11:50.191742  2593 sgd_solver.cpp:106] Iteration 2981, lr = 0.0005
I1111 00:11:53.389842  2593 solver.cpp:295] Iteration 2982 (no loss supplied for SingleUpdateStep)
I1111 00:11:53.389943  2593 solver.cpp:310]     Train net output #0: loss = 0.378318 (* 1 = 0.378318 loss)
I1111 00:11:53.389966  2593 sgd_solver.cpp:106] Iteration 2982, lr = 0.0005
I1111 00:11:56.259626  2593 solver.cpp:295] Iteration 2983 (no loss supplied for SingleUpdateStep)
I1111 00:11:56.259690  2593 solver.cpp:310]     Train net output #0: loss = 0.443169 (* 1 = 0.443169 loss)
I1111 00:11:56.259708  2593 sgd_solver.cpp:106] Iteration 2983, lr = 0.0005
I1111 00:11:58.919020  2593 solver.cpp:295] Iteration 2984 (no loss supplied for SingleUpdateStep)
I1111 00:11:58.919097  2593 solver.cpp:310]     Train net output #0: loss = 0.442723 (* 1 = 0.442723 loss)
I1111 00:11:58.919117  2593 sgd_solver.cpp:106] Iteration 2984, lr = 0.0005
I1111 00:12:01.313359  2593 solver.cpp:295] Iteration 2985 (no loss supplied for SingleUpdateStep)
I1111 00:12:01.313427  2593 solver.cpp:310]     Train net output #0: loss = 0.404374 (* 1 = 0.404374 loss)
I1111 00:12:01.313446  2593 sgd_solver.cpp:106] Iteration 2985, lr = 0.0005
I1111 00:12:03.571328  2593 solver.cpp:295] Iteration 2986 (no loss supplied for SingleUpdateStep)
I1111 00:12:03.571382  2593 solver.cpp:310]     Train net output #0: loss = 0.422357 (* 1 = 0.422357 loss)
I1111 00:12:03.571400  2593 sgd_solver.cpp:106] Iteration 2986, lr = 0.0005
I1111 00:12:05.854276  2593 solver.cpp:295] Iteration 2987 (no loss supplied for SingleUpdateStep)
I1111 00:12:05.854410  2593 solver.cpp:310]     Train net output #0: loss = 0.442527 (* 1 = 0.442527 loss)
I1111 00:12:05.854452  2593 sgd_solver.cpp:106] Iteration 2987, lr = 0.0005
I1111 00:12:08.262733  2593 solver.cpp:295] Iteration 2988 (no loss supplied for SingleUpdateStep)
I1111 00:12:08.262902  2593 solver.cpp:310]     Train net output #0: loss = 0.423842 (* 1 = 0.423842 loss)
I1111 00:12:08.262935  2593 sgd_solver.cpp:106] Iteration 2988, lr = 0.0005
I1111 00:12:10.530232  2593 solver.cpp:295] Iteration 2989 (no loss supplied for SingleUpdateStep)
I1111 00:12:10.530289  2593 solver.cpp:310]     Train net output #0: loss = 0.399529 (* 1 = 0.399529 loss)
I1111 00:12:10.530308  2593 sgd_solver.cpp:106] Iteration 2989, lr = 0.0005
I1111 00:12:13.128077  2593 solver.cpp:295] Iteration 2990 (no loss supplied for SingleUpdateStep)
I1111 00:12:13.128198  2593 solver.cpp:310]     Train net output #0: loss = 0.414673 (* 1 = 0.414673 loss)
I1111 00:12:13.128218  2593 sgd_solver.cpp:106] Iteration 2990, lr = 0.0005
I1111 00:12:15.622377  2593 solver.cpp:295] Iteration 2991 (no loss supplied for SingleUpdateStep)
I1111 00:12:15.622520  2593 solver.cpp:310]     Train net output #0: loss = 0.395033 (* 1 = 0.395033 loss)
I1111 00:12:15.622545  2593 sgd_solver.cpp:106] Iteration 2991, lr = 0.0005
I1111 00:12:18.154024  2593 solver.cpp:295] Iteration 2992 (no loss supplied for SingleUpdateStep)
I1111 00:12:18.154188  2593 solver.cpp:310]     Train net output #0: loss = 0.406065 (* 1 = 0.406065 loss)
I1111 00:12:18.154224  2593 sgd_solver.cpp:106] Iteration 2992, lr = 0.0005
I1111 00:12:20.689859  2593 solver.cpp:295] Iteration 2993 (no loss supplied for SingleUpdateStep)
I1111 00:12:20.689990  2593 solver.cpp:310]     Train net output #0: loss = 0.426067 (* 1 = 0.426067 loss)
I1111 00:12:20.690011  2593 sgd_solver.cpp:106] Iteration 2993, lr = 0.0005
I1111 00:12:23.140836  2593 solver.cpp:295] Iteration 2994 (no loss supplied for SingleUpdateStep)
I1111 00:12:23.140990  2593 solver.cpp:310]     Train net output #0: loss = 0.385602 (* 1 = 0.385602 loss)
I1111 00:12:23.141011  2593 sgd_solver.cpp:106] Iteration 2994, lr = 0.0005
I1111 00:12:25.638897  2593 solver.cpp:295] Iteration 2995 (no loss supplied for SingleUpdateStep)
I1111 00:12:25.638994  2593 solver.cpp:310]     Train net output #0: loss = 0.402392 (* 1 = 0.402392 loss)
I1111 00:12:25.639015  2593 sgd_solver.cpp:106] Iteration 2995, lr = 0.0005
I1111 00:12:27.923501  2593 solver.cpp:295] Iteration 2996 (no loss supplied for SingleUpdateStep)
I1111 00:12:27.923625  2593 solver.cpp:310]     Train net output #0: loss = 0.421433 (* 1 = 0.421433 loss)
I1111 00:12:27.923650  2593 sgd_solver.cpp:106] Iteration 2996, lr = 0.0005
I1111 00:12:30.550617  2593 solver.cpp:295] Iteration 2997 (no loss supplied for SingleUpdateStep)
I1111 00:12:30.550739  2593 solver.cpp:310]     Train net output #0: loss = 0.408357 (* 1 = 0.408357 loss)
I1111 00:12:30.550765  2593 sgd_solver.cpp:106] Iteration 2997, lr = 0.0005
I1111 00:12:33.004575  2593 solver.cpp:295] Iteration 2998 (no loss supplied for SingleUpdateStep)
I1111 00:12:33.004709  2593 solver.cpp:310]     Train net output #0: loss = 0.409339 (* 1 = 0.409339 loss)
I1111 00:12:33.004734  2593 sgd_solver.cpp:106] Iteration 2998, lr = 0.0005
I1111 00:12:35.509544  2593 solver.cpp:295] Iteration 2999 (no loss supplied for SingleUpdateStep)
I1111 00:12:35.509610  2593 solver.cpp:310]     Train net output #0: loss = 0.405817 (* 1 = 0.405817 loss)
I1111 00:12:35.509629  2593 sgd_solver.cpp:106] Iteration 2999, lr = 0.0005
I1111 00:12:35.509769  2593 solver.cpp:534] Snapshotting to binary proto file stitch_iter_3000.caffemodel
I1111 00:12:35.509798  2593 net.cpp:1022] Serializing 2 layers
I1111 00:12:35.515736  2593 sgd_solver.cpp:269] Snapshotting solver state to binary proto file stitch_iter_3000.solverstate
I1111 00:12:37.936517  2593 solver.cpp:295] Iteration 3000 (no loss supplied for SingleUpdateStep)
I1111 00:12:37.936630  2593 solver.cpp:310]     Train net output #0: loss = 0.421902 (* 1 = 0.421902 loss)
I1111 00:12:37.936655  2593 sgd_solver.cpp:106] Iteration 3000, lr = 0.00025
I1111 00:12:40.192730  2593 solver.cpp:295] Iteration 3001 (no loss supplied for SingleUpdateStep)
I1111 00:12:40.192847  2593 solver.cpp:310]     Train net output #0: loss = 0.432416 (* 1 = 0.432416 loss)
I1111 00:12:40.192867  2593 sgd_solver.cpp:106] Iteration 3001, lr = 0.00025
I1111 00:12:42.456743  2593 solver.cpp:295] Iteration 3002 (no loss supplied for SingleUpdateStep)
I1111 00:12:42.456856  2593 solver.cpp:310]     Train net output #0: loss = 0.391889 (* 1 = 0.391889 loss)
I1111 00:12:42.456877  2593 sgd_solver.cpp:106] Iteration 3002, lr = 0.00025
I1111 00:12:44.646703  2593 solver.cpp:295] Iteration 3003 (no loss supplied for SingleUpdateStep)
I1111 00:12:44.646769  2593 solver.cpp:310]     Train net output #0: loss = 0.423087 (* 1 = 0.423087 loss)
I1111 00:12:44.646788  2593 sgd_solver.cpp:106] Iteration 3003, lr = 0.00025
I1111 00:12:46.843611  2593 solver.cpp:295] Iteration 3004 (no loss supplied for SingleUpdateStep)
I1111 00:12:46.843716  2593 solver.cpp:310]     Train net output #0: loss = 0.408482 (* 1 = 0.408482 loss)
I1111 00:12:46.843740  2593 sgd_solver.cpp:106] Iteration 3004, lr = 0.00025
I1111 00:12:49.230473  2593 solver.cpp:295] Iteration 3005 (no loss supplied for SingleUpdateStep)
I1111 00:12:49.230541  2593 solver.cpp:310]     Train net output #0: loss = 0.403501 (* 1 = 0.403501 loss)
I1111 00:12:49.230561  2593 sgd_solver.cpp:106] Iteration 3005, lr = 0.00025
I1111 00:12:51.560894  2593 solver.cpp:295] Iteration 3006 (no loss supplied for SingleUpdateStep)
I1111 00:12:51.561009  2593 solver.cpp:310]     Train net output #0: loss = 0.41001 (* 1 = 0.41001 loss)
I1111 00:12:51.561036  2593 sgd_solver.cpp:106] Iteration 3006, lr = 0.00025
I1111 00:12:53.690788  2593 solver.cpp:295] Iteration 3007 (no loss supplied for SingleUpdateStep)
I1111 00:12:53.690891  2593 solver.cpp:310]     Train net output #0: loss = 0.426912 (* 1 = 0.426912 loss)
I1111 00:12:53.690914  2593 sgd_solver.cpp:106] Iteration 3007, lr = 0.00025
I1111 00:12:55.892469  2593 solver.cpp:295] Iteration 3008 (no loss supplied for SingleUpdateStep)
I1111 00:12:55.892618  2593 solver.cpp:310]     Train net output #0: loss = 0.434527 (* 1 = 0.434527 loss)
I1111 00:12:55.892643  2593 sgd_solver.cpp:106] Iteration 3008, lr = 0.00025
I1111 00:12:58.386734  2593 solver.cpp:295] Iteration 3009 (no loss supplied for SingleUpdateStep)
I1111 00:12:58.386854  2593 solver.cpp:310]     Train net output #0: loss = 0.393515 (* 1 = 0.393515 loss)
I1111 00:12:58.386878  2593 sgd_solver.cpp:106] Iteration 3009, lr = 0.00025
I1111 00:13:00.409548  2593 solver.cpp:295] Iteration 3010 (no loss supplied for SingleUpdateStep)
I1111 00:13:00.409626  2593 solver.cpp:310]     Train net output #0: loss = 0.401813 (* 1 = 0.401813 loss)
I1111 00:13:00.409646  2593 sgd_solver.cpp:106] Iteration 3010, lr = 0.00025
I1111 00:13:02.637069  2593 solver.cpp:295] Iteration 3011 (no loss supplied for SingleUpdateStep)
I1111 00:13:02.637190  2593 solver.cpp:310]     Train net output #0: loss = 0.441676 (* 1 = 0.441676 loss)
I1111 00:13:02.637217  2593 sgd_solver.cpp:106] Iteration 3011, lr = 0.00025
I1111 00:13:05.005414  2593 solver.cpp:295] Iteration 3012 (no loss supplied for SingleUpdateStep)
I1111 00:13:05.005512  2593 solver.cpp:310]     Train net output #0: loss = 0.423325 (* 1 = 0.423325 loss)
I1111 00:13:05.005537  2593 sgd_solver.cpp:106] Iteration 3012, lr = 0.00025
I1111 00:13:07.266650  2593 solver.cpp:295] Iteration 3013 (no loss supplied for SingleUpdateStep)
I1111 00:13:07.266772  2593 solver.cpp:310]     Train net output #0: loss = 0.413483 (* 1 = 0.413483 loss)
I1111 00:13:07.266793  2593 sgd_solver.cpp:106] Iteration 3013, lr = 0.00025
I1111 00:13:09.529512  2593 solver.cpp:295] Iteration 3014 (no loss supplied for SingleUpdateStep)
I1111 00:13:09.529638  2593 solver.cpp:310]     Train net output #0: loss = 0.407667 (* 1 = 0.407667 loss)
I1111 00:13:09.529659  2593 sgd_solver.cpp:106] Iteration 3014, lr = 0.00025
I1111 00:13:11.955565  2593 solver.cpp:295] Iteration 3015 (no loss supplied for SingleUpdateStep)
I1111 00:13:11.955703  2593 solver.cpp:310]     Train net output #0: loss = 0.435981 (* 1 = 0.435981 loss)
I1111 00:13:11.955726  2593 sgd_solver.cpp:106] Iteration 3015, lr = 0.00025
I1111 00:13:14.303673  2593 solver.cpp:295] Iteration 3016 (no loss supplied for SingleUpdateStep)
I1111 00:13:14.303735  2593 solver.cpp:310]     Train net output #0: loss = 0.412254 (* 1 = 0.412254 loss)
I1111 00:13:14.303755  2593 sgd_solver.cpp:106] Iteration 3016, lr = 0.00025
I1111 00:13:16.613692  2593 solver.cpp:295] Iteration 3017 (no loss supplied for SingleUpdateStep)
I1111 00:13:16.613834  2593 solver.cpp:310]     Train net output #0: loss = 0.435752 (* 1 = 0.435752 loss)
I1111 00:13:16.613857  2593 sgd_solver.cpp:106] Iteration 3017, lr = 0.00025
I1111 00:13:18.857362  2593 solver.cpp:295] Iteration 3018 (no loss supplied for SingleUpdateStep)
I1111 00:13:18.857435  2593 solver.cpp:310]     Train net output #0: loss = 0.405211 (* 1 = 0.405211 loss)
I1111 00:13:18.857457  2593 sgd_solver.cpp:106] Iteration 3018, lr = 0.00025
I1111 00:13:20.908013  2593 solver.cpp:295] Iteration 3019 (no loss supplied for SingleUpdateStep)
I1111 00:13:20.908120  2593 solver.cpp:310]     Train net output #0: loss = 0.41282 (* 1 = 0.41282 loss)
I1111 00:13:20.908143  2593 sgd_solver.cpp:106] Iteration 3019, lr = 0.00025
I1111 00:13:23.167146  2593 solver.cpp:295] Iteration 3020 (no loss supplied for SingleUpdateStep)
I1111 00:13:23.167280  2593 solver.cpp:310]     Train net output #0: loss = 0.404982 (* 1 = 0.404982 loss)
I1111 00:13:23.167305  2593 sgd_solver.cpp:106] Iteration 3020, lr = 0.00025
I1111 00:13:25.511831  2593 solver.cpp:295] Iteration 3021 (no loss supplied for SingleUpdateStep)
I1111 00:13:25.511896  2593 solver.cpp:310]     Train net output #0: loss = 0.389624 (* 1 = 0.389624 loss)
I1111 00:13:25.511919  2593 sgd_solver.cpp:106] Iteration 3021, lr = 0.00025
I1111 00:13:27.804298  2593 solver.cpp:295] Iteration 3022 (no loss supplied for SingleUpdateStep)
I1111 00:13:27.804445  2593 solver.cpp:310]     Train net output #0: loss = 0.374972 (* 1 = 0.374972 loss)
I1111 00:13:27.804481  2593 sgd_solver.cpp:106] Iteration 3022, lr = 0.00025
I1111 00:13:30.088390  2593 solver.cpp:295] Iteration 3023 (no loss supplied for SingleUpdateStep)
I1111 00:13:30.088486  2593 solver.cpp:310]     Train net output #0: loss = 0.397884 (* 1 = 0.397884 loss)
I1111 00:13:30.088508  2593 sgd_solver.cpp:106] Iteration 3023, lr = 0.00025
I1111 00:13:32.340121  2593 solver.cpp:295] Iteration 3024 (no loss supplied for SingleUpdateStep)
I1111 00:13:32.340261  2593 solver.cpp:310]     Train net output #0: loss = 0.416333 (* 1 = 0.416333 loss)
I1111 00:13:32.340287  2593 sgd_solver.cpp:106] Iteration 3024, lr = 0.00025
I1111 00:13:34.788911  2593 solver.cpp:295] Iteration 3025 (no loss supplied for SingleUpdateStep)
I1111 00:13:34.789003  2593 solver.cpp:310]     Train net output #0: loss = 0.385655 (* 1 = 0.385655 loss)
I1111 00:13:34.789027  2593 sgd_solver.cpp:106] Iteration 3025, lr = 0.00025
I1111 00:13:37.036234  2593 solver.cpp:295] Iteration 3026 (no loss supplied for SingleUpdateStep)
I1111 00:13:37.036288  2593 solver.cpp:310]     Train net output #0: loss = 0.418501 (* 1 = 0.418501 loss)
I1111 00:13:37.036306  2593 sgd_solver.cpp:106] Iteration 3026, lr = 0.00025
I1111 00:13:39.414276  2593 solver.cpp:295] Iteration 3027 (no loss supplied for SingleUpdateStep)
I1111 00:13:39.414405  2593 solver.cpp:310]     Train net output #0: loss = 0.411644 (* 1 = 0.411644 loss)
I1111 00:13:39.414427  2593 sgd_solver.cpp:106] Iteration 3027, lr = 0.00025
I1111 00:13:41.676172  2593 solver.cpp:295] Iteration 3028 (no loss supplied for SingleUpdateStep)
I1111 00:13:41.676300  2593 solver.cpp:310]     Train net output #0: loss = 0.397015 (* 1 = 0.397015 loss)
I1111 00:13:41.676322  2593 sgd_solver.cpp:106] Iteration 3028, lr = 0.00025
I1111 00:13:43.671481  2593 solver.cpp:295] Iteration 3029 (no loss supplied for SingleUpdateStep)
I1111 00:13:43.671597  2593 solver.cpp:310]     Train net output #0: loss = 0.434976 (* 1 = 0.434976 loss)
I1111 00:13:43.671619  2593 sgd_solver.cpp:106] Iteration 3029, lr = 0.00025
I1111 00:13:45.528712  2593 solver.cpp:295] Iteration 3030 (no loss supplied for SingleUpdateStep)
I1111 00:13:45.528825  2593 solver.cpp:310]     Train net output #0: loss = 0.402015 (* 1 = 0.402015 loss)
I1111 00:13:45.528847  2593 sgd_solver.cpp:106] Iteration 3030, lr = 0.00025
I1111 00:13:47.334849  2593 solver.cpp:295] Iteration 3031 (no loss supplied for SingleUpdateStep)
I1111 00:13:47.334974  2593 solver.cpp:310]     Train net output #0: loss = 0.380929 (* 1 = 0.380929 loss)
I1111 00:13:47.334996  2593 sgd_solver.cpp:106] Iteration 3031, lr = 0.00025
I1111 00:13:49.097311  2593 solver.cpp:295] Iteration 3032 (no loss supplied for SingleUpdateStep)
I1111 00:13:49.097570  2593 solver.cpp:310]     Train net output #0: loss = 0.416615 (* 1 = 0.416615 loss)
I1111 00:13:49.097635  2593 sgd_solver.cpp:106] Iteration 3032, lr = 0.00025
I1111 00:13:50.902235  2593 solver.cpp:295] Iteration 3033 (no loss supplied for SingleUpdateStep)
I1111 00:13:50.902375  2593 solver.cpp:310]     Train net output #0: loss = 0.424944 (* 1 = 0.424944 loss)
I1111 00:13:50.902400  2593 sgd_solver.cpp:106] Iteration 3033, lr = 0.00025
I1111 00:13:52.775810  2593 solver.cpp:295] Iteration 3034 (no loss supplied for SingleUpdateStep)
I1111 00:13:52.775902  2593 solver.cpp:310]     Train net output #0: loss = 0.392236 (* 1 = 0.392236 loss)
I1111 00:13:52.775923  2593 sgd_solver.cpp:106] Iteration 3034, lr = 0.00025
I1111 00:13:54.684669  2593 solver.cpp:295] Iteration 3035 (no loss supplied for SingleUpdateStep)
I1111 00:13:54.684741  2593 solver.cpp:310]     Train net output #0: loss = 0.386919 (* 1 = 0.386919 loss)
I1111 00:13:54.684762  2593 sgd_solver.cpp:106] Iteration 3035, lr = 0.00025
I1111 00:13:56.601270  2593 solver.cpp:295] Iteration 3036 (no loss supplied for SingleUpdateStep)
I1111 00:13:56.601326  2593 solver.cpp:310]     Train net output #0: loss = 0.419304 (* 1 = 0.419304 loss)
I1111 00:13:56.601346  2593 sgd_solver.cpp:106] Iteration 3036, lr = 0.00025
I1111 00:13:58.470891  2593 solver.cpp:295] Iteration 3037 (no loss supplied for SingleUpdateStep)
I1111 00:13:58.471000  2593 solver.cpp:310]     Train net output #0: loss = 0.401299 (* 1 = 0.401299 loss)
I1111 00:13:58.471022  2593 sgd_solver.cpp:106] Iteration 3037, lr = 0.00025
I1111 00:14:00.312917  2593 solver.cpp:295] Iteration 3038 (no loss supplied for SingleUpdateStep)
I1111 00:14:00.313092  2593 solver.cpp:310]     Train net output #0: loss = 0.384724 (* 1 = 0.384724 loss)
I1111 00:14:00.313117  2593 sgd_solver.cpp:106] Iteration 3038, lr = 0.00025
I1111 00:14:02.220572  2593 solver.cpp:295] Iteration 3039 (no loss supplied for SingleUpdateStep)
I1111 00:14:02.220722  2593 solver.cpp:310]     Train net output #0: loss = 0.388773 (* 1 = 0.388773 loss)
I1111 00:14:02.220749  2593 sgd_solver.cpp:106] Iteration 3039, lr = 0.00025
I1111 00:14:04.288336  2593 solver.cpp:295] Iteration 3040 (no loss supplied for SingleUpdateStep)
I1111 00:14:04.288449  2593 solver.cpp:310]     Train net output #0: loss = 0.380812 (* 1 = 0.380812 loss)
I1111 00:14:04.288470  2593 sgd_solver.cpp:106] Iteration 3040, lr = 0.00025
I1111 00:14:06.157627  2593 solver.cpp:295] Iteration 3041 (no loss supplied for SingleUpdateStep)
I1111 00:14:06.157691  2593 solver.cpp:310]     Train net output #0: loss = 0.435716 (* 1 = 0.435716 loss)
I1111 00:14:06.157711  2593 sgd_solver.cpp:106] Iteration 3041, lr = 0.00025
I1111 00:14:08.142065  2593 solver.cpp:295] Iteration 3042 (no loss supplied for SingleUpdateStep)
I1111 00:14:08.142246  2593 solver.cpp:310]     Train net output #0: loss = 0.408231 (* 1 = 0.408231 loss)
I1111 00:14:08.142272  2593 sgd_solver.cpp:106] Iteration 3042, lr = 0.00025
I1111 00:14:10.027783  2593 solver.cpp:295] Iteration 3043 (no loss supplied for SingleUpdateStep)
I1111 00:14:10.027983  2593 solver.cpp:310]     Train net output #0: loss = 0.392599 (* 1 = 0.392599 loss)
I1111 00:14:10.028012  2593 sgd_solver.cpp:106] Iteration 3043, lr = 0.00025
I1111 00:14:11.897280  2593 solver.cpp:295] Iteration 3044 (no loss supplied for SingleUpdateStep)
I1111 00:14:11.897399  2593 solver.cpp:310]     Train net output #0: loss = 0.426999 (* 1 = 0.426999 loss)
I1111 00:14:11.897423  2593 sgd_solver.cpp:106] Iteration 3044, lr = 0.00025
I1111 00:14:13.835638  2593 solver.cpp:295] Iteration 3045 (no loss supplied for SingleUpdateStep)
I1111 00:14:13.835711  2593 solver.cpp:310]     Train net output #0: loss = 0.403396 (* 1 = 0.403396 loss)
I1111 00:14:13.835733  2593 sgd_solver.cpp:106] Iteration 3045, lr = 0.00025
I1111 00:14:15.611790  2593 solver.cpp:295] Iteration 3046 (no loss supplied for SingleUpdateStep)
I1111 00:14:15.611878  2593 solver.cpp:310]     Train net output #0: loss = 0.377617 (* 1 = 0.377617 loss)
I1111 00:14:15.611901  2593 sgd_solver.cpp:106] Iteration 3046, lr = 0.00025
I1111 00:14:17.593538  2593 solver.cpp:295] Iteration 3047 (no loss supplied for SingleUpdateStep)
I1111 00:14:17.593657  2593 solver.cpp:310]     Train net output #0: loss = 0.404928 (* 1 = 0.404928 loss)
I1111 00:14:17.593678  2593 sgd_solver.cpp:106] Iteration 3047, lr = 0.00025
I1111 00:14:19.666452  2593 solver.cpp:295] Iteration 3048 (no loss supplied for SingleUpdateStep)
I1111 00:14:19.666563  2593 solver.cpp:310]     Train net output #0: loss = 0.420979 (* 1 = 0.420979 loss)
I1111 00:14:19.666585  2593 sgd_solver.cpp:106] Iteration 3048, lr = 0.00025
I1111 00:14:21.516485  2593 solver.cpp:295] Iteration 3049 (no loss supplied for SingleUpdateStep)
I1111 00:14:21.516614  2593 solver.cpp:310]     Train net output #0: loss = 0.402215 (* 1 = 0.402215 loss)
I1111 00:14:21.516644  2593 sgd_solver.cpp:106] Iteration 3049, lr = 0.00025
I1111 00:14:23.436923  2593 solver.cpp:295] Iteration 3050 (no loss supplied for SingleUpdateStep)
I1111 00:14:23.437044  2593 solver.cpp:310]     Train net output #0: loss = 0.397179 (* 1 = 0.397179 loss)
I1111 00:14:23.437072  2593 sgd_solver.cpp:106] Iteration 3050, lr = 0.00025
I1111 00:14:25.432847  2593 solver.cpp:295] Iteration 3051 (no loss supplied for SingleUpdateStep)
I1111 00:14:25.432960  2593 solver.cpp:310]     Train net output #0: loss = 0.41298 (* 1 = 0.41298 loss)
I1111 00:14:25.432984  2593 sgd_solver.cpp:106] Iteration 3051, lr = 0.00025
I1111 00:14:27.237540  2593 solver.cpp:295] Iteration 3052 (no loss supplied for SingleUpdateStep)
I1111 00:14:27.237661  2593 solver.cpp:310]     Train net output #0: loss = 0.365535 (* 1 = 0.365535 loss)
I1111 00:14:27.237689  2593 sgd_solver.cpp:106] Iteration 3052, lr = 0.00025
I1111 00:14:28.998942  2593 solver.cpp:295] Iteration 3053 (no loss supplied for SingleUpdateStep)
I1111 00:14:28.999047  2593 solver.cpp:310]     Train net output #0: loss = 0.414231 (* 1 = 0.414231 loss)
I1111 00:14:28.999070  2593 sgd_solver.cpp:106] Iteration 3053, lr = 0.00025
I1111 00:14:30.898428  2593 solver.cpp:295] Iteration 3054 (no loss supplied for SingleUpdateStep)
I1111 00:14:30.898586  2593 solver.cpp:310]     Train net output #0: loss = 0.406014 (* 1 = 0.406014 loss)
I1111 00:14:30.898612  2593 sgd_solver.cpp:106] Iteration 3054, lr = 0.00025
I1111 00:14:32.817509  2593 solver.cpp:295] Iteration 3055 (no loss supplied for SingleUpdateStep)
I1111 00:14:32.817625  2593 solver.cpp:310]     Train net output #0: loss = 0.39621 (* 1 = 0.39621 loss)
I1111 00:14:32.817648  2593 sgd_solver.cpp:106] Iteration 3055, lr = 0.00025
I1111 00:14:34.737663  2593 solver.cpp:295] Iteration 3056 (no loss supplied for SingleUpdateStep)
I1111 00:14:34.737769  2593 solver.cpp:310]     Train net output #0: loss = 0.390993 (* 1 = 0.390993 loss)
I1111 00:14:34.737792  2593 sgd_solver.cpp:106] Iteration 3056, lr = 0.00025
I1111 00:14:36.578038  2593 solver.cpp:295] Iteration 3057 (no loss supplied for SingleUpdateStep)
I1111 00:14:36.578151  2593 solver.cpp:310]     Train net output #0: loss = 0.391763 (* 1 = 0.391763 loss)
I1111 00:14:36.578173  2593 sgd_solver.cpp:106] Iteration 3057, lr = 0.00025
I1111 00:14:38.362632  2593 solver.cpp:295] Iteration 3058 (no loss supplied for SingleUpdateStep)
I1111 00:14:38.362697  2593 solver.cpp:310]     Train net output #0: loss = 0.402324 (* 1 = 0.402324 loss)
I1111 00:14:38.362721  2593 sgd_solver.cpp:106] Iteration 3058, lr = 0.00025
I1111 00:14:40.201777  2593 solver.cpp:295] Iteration 3059 (no loss supplied for SingleUpdateStep)
I1111 00:14:40.201885  2593 solver.cpp:310]     Train net output #0: loss = 0.384688 (* 1 = 0.384688 loss)
I1111 00:14:40.201907  2593 sgd_solver.cpp:106] Iteration 3059, lr = 0.00025
I1111 00:14:42.166740  2593 solver.cpp:295] Iteration 3060 (no loss supplied for SingleUpdateStep)
I1111 00:14:42.166849  2593 solver.cpp:310]     Train net output #0: loss = 0.392169 (* 1 = 0.392169 loss)
I1111 00:14:42.166873  2593 sgd_solver.cpp:106] Iteration 3060, lr = 0.00025
I1111 00:14:43.925004  2593 solver.cpp:295] Iteration 3061 (no loss supplied for SingleUpdateStep)
I1111 00:14:43.925128  2593 solver.cpp:310]     Train net output #0: loss = 0.412764 (* 1 = 0.412764 loss)
I1111 00:14:43.925155  2593 sgd_solver.cpp:106] Iteration 3061, lr = 0.00025
I1111 00:14:45.766077  2593 solver.cpp:295] Iteration 3062 (no loss supplied for SingleUpdateStep)
I1111 00:14:45.766145  2593 solver.cpp:310]     Train net output #0: loss = 0.406004 (* 1 = 0.406004 loss)
I1111 00:14:45.766165  2593 sgd_solver.cpp:106] Iteration 3062, lr = 0.00025
I1111 00:14:48.002804  2593 solver.cpp:295] Iteration 3063 (no loss supplied for SingleUpdateStep)
I1111 00:14:48.002904  2593 solver.cpp:310]     Train net output #0: loss = 0.39911 (* 1 = 0.39911 loss)
I1111 00:14:48.002926  2593 sgd_solver.cpp:106] Iteration 3063, lr = 0.00025
I1111 00:14:49.925714  2593 solver.cpp:295] Iteration 3064 (no loss supplied for SingleUpdateStep)
I1111 00:14:49.925817  2593 solver.cpp:310]     Train net output #0: loss = 0.391039 (* 1 = 0.391039 loss)
I1111 00:14:49.925840  2593 sgd_solver.cpp:106] Iteration 3064, lr = 0.00025
I1111 00:14:52.048931  2593 solver.cpp:295] Iteration 3065 (no loss supplied for SingleUpdateStep)
I1111 00:14:52.049064  2593 solver.cpp:310]     Train net output #0: loss = 0.3859 (* 1 = 0.3859 loss)
I1111 00:14:52.049088  2593 sgd_solver.cpp:106] Iteration 3065, lr = 0.00025
I1111 00:14:55.267526  2593 solver.cpp:295] Iteration 3066 (no loss supplied for SingleUpdateStep)
I1111 00:14:55.267617  2593 solver.cpp:310]     Train net output #0: loss = 0.3762 (* 1 = 0.3762 loss)
I1111 00:14:55.267638  2593 sgd_solver.cpp:106] Iteration 3066, lr = 0.00025
I1111 00:14:57.937614  2593 solver.cpp:295] Iteration 3067 (no loss supplied for SingleUpdateStep)
I1111 00:14:57.937692  2593 solver.cpp:310]     Train net output #0: loss = 0.394622 (* 1 = 0.394622 loss)
I1111 00:14:57.937712  2593 sgd_solver.cpp:106] Iteration 3067, lr = 0.00025
I1111 00:15:00.799587  2593 solver.cpp:295] Iteration 3068 (no loss supplied for SingleUpdateStep)
I1111 00:15:00.799690  2593 solver.cpp:310]     Train net output #0: loss = 0.433636 (* 1 = 0.433636 loss)
I1111 00:15:00.799712  2593 sgd_solver.cpp:106] Iteration 3068, lr = 0.00025
I1111 00:15:03.674360  2593 solver.cpp:295] Iteration 3069 (no loss supplied for SingleUpdateStep)
I1111 00:15:03.674422  2593 solver.cpp:310]     Train net output #0: loss = 0.420442 (* 1 = 0.420442 loss)
I1111 00:15:03.674442  2593 sgd_solver.cpp:106] Iteration 3069, lr = 0.00025
I1111 00:15:05.983472  2593 solver.cpp:295] Iteration 3070 (no loss supplied for SingleUpdateStep)
I1111 00:15:05.983649  2593 solver.cpp:310]     Train net output #0: loss = 0.426349 (* 1 = 0.426349 loss)
I1111 00:15:05.983676  2593 sgd_solver.cpp:106] Iteration 3070, lr = 0.00025
I1111 00:15:08.089522  2593 solver.cpp:295] Iteration 3071 (no loss supplied for SingleUpdateStep)
I1111 00:15:08.089648  2593 solver.cpp:310]     Train net output #0: loss = 0.389656 (* 1 = 0.389656 loss)
I1111 00:15:08.089669  2593 sgd_solver.cpp:106] Iteration 3071, lr = 0.00025
I1111 00:15:10.425499  2593 solver.cpp:295] Iteration 3072 (no loss supplied for SingleUpdateStep)
I1111 00:15:10.425609  2593 solver.cpp:310]     Train net output #0: loss = 0.385162 (* 1 = 0.385162 loss)
I1111 00:15:10.425629  2593 sgd_solver.cpp:106] Iteration 3072, lr = 0.00025
I1111 00:15:12.748565  2593 solver.cpp:295] Iteration 3073 (no loss supplied for SingleUpdateStep)
I1111 00:15:12.748770  2593 solver.cpp:310]     Train net output #0: loss = 0.406559 (* 1 = 0.406559 loss)
I1111 00:15:12.748798  2593 sgd_solver.cpp:106] Iteration 3073, lr = 0.00025
I1111 00:15:15.138898  2593 solver.cpp:295] Iteration 3074 (no loss supplied for SingleUpdateStep)
I1111 00:15:15.139010  2593 solver.cpp:310]     Train net output #0: loss = 0.42295 (* 1 = 0.42295 loss)
I1111 00:15:15.139034  2593 sgd_solver.cpp:106] Iteration 3074, lr = 0.00025
I1111 00:15:17.292170  2593 solver.cpp:295] Iteration 3075 (no loss supplied for SingleUpdateStep)
I1111 00:15:17.292268  2593 solver.cpp:310]     Train net output #0: loss = 0.424557 (* 1 = 0.424557 loss)
I1111 00:15:17.292290  2593 sgd_solver.cpp:106] Iteration 3075, lr = 0.00025
I1111 00:15:19.301412  2593 solver.cpp:295] Iteration 3076 (no loss supplied for SingleUpdateStep)
I1111 00:15:19.301523  2593 solver.cpp:310]     Train net output #0: loss = 0.381279 (* 1 = 0.381279 loss)
I1111 00:15:19.301545  2593 sgd_solver.cpp:106] Iteration 3076, lr = 0.00025
I1111 00:15:21.444062  2593 solver.cpp:295] Iteration 3077 (no loss supplied for SingleUpdateStep)
I1111 00:15:21.444185  2593 solver.cpp:310]     Train net output #0: loss = 0.408332 (* 1 = 0.408332 loss)
I1111 00:15:21.444208  2593 sgd_solver.cpp:106] Iteration 3077, lr = 0.00025
I1111 00:15:23.524109  2593 solver.cpp:295] Iteration 3078 (no loss supplied for SingleUpdateStep)
I1111 00:15:23.524281  2593 solver.cpp:310]     Train net output #0: loss = 0.404947 (* 1 = 0.404947 loss)
I1111 00:15:23.524308  2593 sgd_solver.cpp:106] Iteration 3078, lr = 0.00025
I1111 00:15:25.356583  2593 solver.cpp:295] Iteration 3079 (no loss supplied for SingleUpdateStep)
I1111 00:15:25.356724  2593 solver.cpp:310]     Train net output #0: loss = 0.383663 (* 1 = 0.383663 loss)
I1111 00:15:25.356751  2593 sgd_solver.cpp:106] Iteration 3079, lr = 0.00025
I1111 00:15:27.165905  2593 solver.cpp:295] Iteration 3080 (no loss supplied for SingleUpdateStep)
I1111 00:15:27.165973  2593 solver.cpp:310]     Train net output #0: loss = 0.391407 (* 1 = 0.391407 loss)
I1111 00:15:27.165992  2593 sgd_solver.cpp:106] Iteration 3080, lr = 0.00025
I1111 00:15:28.952466  2593 solver.cpp:295] Iteration 3081 (no loss supplied for SingleUpdateStep)
I1111 00:15:28.952613  2593 solver.cpp:310]     Train net output #0: loss = 0.411129 (* 1 = 0.411129 loss)
I1111 00:15:28.952639  2593 sgd_solver.cpp:106] Iteration 3081, lr = 0.00025
I1111 00:15:30.863072  2593 solver.cpp:295] Iteration 3082 (no loss supplied for SingleUpdateStep)
I1111 00:15:30.863131  2593 solver.cpp:310]     Train net output #0: loss = 0.379998 (* 1 = 0.379998 loss)
I1111 00:15:30.863152  2593 sgd_solver.cpp:106] Iteration 3082, lr = 0.00025
I1111 00:15:32.764999  2593 solver.cpp:295] Iteration 3083 (no loss supplied for SingleUpdateStep)
I1111 00:15:32.765120  2593 solver.cpp:310]     Train net output #0: loss = 0.412888 (* 1 = 0.412888 loss)
I1111 00:15:32.765142  2593 sgd_solver.cpp:106] Iteration 3083, lr = 0.00025
I1111 00:15:34.770268  2593 solver.cpp:295] Iteration 3084 (no loss supplied for SingleUpdateStep)
I1111 00:15:34.770431  2593 solver.cpp:310]     Train net output #0: loss = 0.406126 (* 1 = 0.406126 loss)
I1111 00:15:34.770457  2593 sgd_solver.cpp:106] Iteration 3084, lr = 0.00025
I1111 00:15:36.741477  2593 solver.cpp:295] Iteration 3085 (no loss supplied for SingleUpdateStep)
I1111 00:15:36.741583  2593 solver.cpp:310]     Train net output #0: loss = 0.428966 (* 1 = 0.428966 loss)
I1111 00:15:36.741607  2593 sgd_solver.cpp:106] Iteration 3085, lr = 0.00025
I1111 00:15:38.625460  2593 solver.cpp:295] Iteration 3086 (no loss supplied for SingleUpdateStep)
I1111 00:15:38.625581  2593 solver.cpp:310]     Train net output #0: loss = 0.391659 (* 1 = 0.391659 loss)
I1111 00:15:38.625605  2593 sgd_solver.cpp:106] Iteration 3086, lr = 0.00025
I1111 00:15:40.533185  2593 solver.cpp:295] Iteration 3087 (no loss supplied for SingleUpdateStep)
I1111 00:15:40.533305  2593 solver.cpp:310]     Train net output #0: loss = 0.421372 (* 1 = 0.421372 loss)
I1111 00:15:40.533329  2593 sgd_solver.cpp:106] Iteration 3087, lr = 0.00025
I1111 00:15:42.302866  2593 solver.cpp:295] Iteration 3088 (no loss supplied for SingleUpdateStep)
I1111 00:15:42.302988  2593 solver.cpp:310]     Train net output #0: loss = 0.410995 (* 1 = 0.410995 loss)
I1111 00:15:42.303014  2593 sgd_solver.cpp:106] Iteration 3088, lr = 0.00025
I1111 00:15:44.199589  2593 solver.cpp:295] Iteration 3089 (no loss supplied for SingleUpdateStep)
I1111 00:15:44.199718  2593 solver.cpp:310]     Train net output #0: loss = 0.36793 (* 1 = 0.36793 loss)
I1111 00:15:44.199743  2593 sgd_solver.cpp:106] Iteration 3089, lr = 0.00025
I1111 00:15:46.666887  2593 solver.cpp:295] Iteration 3090 (no loss supplied for SingleUpdateStep)
I1111 00:15:46.667004  2593 solver.cpp:310]     Train net output #0: loss = 0.403036 (* 1 = 0.403036 loss)
I1111 00:15:46.667031  2593 sgd_solver.cpp:106] Iteration 3090, lr = 0.00025
I1111 00:15:49.315635  2593 solver.cpp:295] Iteration 3091 (no loss supplied for SingleUpdateStep)
I1111 00:15:49.315781  2593 solver.cpp:310]     Train net output #0: loss = 0.403513 (* 1 = 0.403513 loss)
I1111 00:15:49.315805  2593 sgd_solver.cpp:106] Iteration 3091, lr = 0.00025
I1111 00:15:51.957685  2593 solver.cpp:295] Iteration 3092 (no loss supplied for SingleUpdateStep)
I1111 00:15:51.957772  2593 solver.cpp:310]     Train net output #0: loss = 0.38601 (* 1 = 0.38601 loss)
I1111 00:15:51.957793  2593 sgd_solver.cpp:106] Iteration 3092, lr = 0.00025
I1111 00:15:54.036860  2593 solver.cpp:295] Iteration 3093 (no loss supplied for SingleUpdateStep)
I1111 00:15:54.037012  2593 solver.cpp:310]     Train net output #0: loss = 0.387656 (* 1 = 0.387656 loss)
I1111 00:15:54.037046  2593 sgd_solver.cpp:106] Iteration 3093, lr = 0.00025
I1111 00:15:56.129199  2593 solver.cpp:295] Iteration 3094 (no loss supplied for SingleUpdateStep)
I1111 00:15:56.129385  2593 solver.cpp:310]     Train net output #0: loss = 0.392999 (* 1 = 0.392999 loss)
I1111 00:15:56.129421  2593 sgd_solver.cpp:106] Iteration 3094, lr = 0.00025
I1111 00:15:58.139389  2593 solver.cpp:295] Iteration 3095 (no loss supplied for SingleUpdateStep)
I1111 00:15:58.139495  2593 solver.cpp:310]     Train net output #0: loss = 0.372461 (* 1 = 0.372461 loss)
I1111 00:15:58.139520  2593 sgd_solver.cpp:106] Iteration 3095, lr = 0.00025
I1111 00:16:00.112758  2593 solver.cpp:295] Iteration 3096 (no loss supplied for SingleUpdateStep)
I1111 00:16:00.112859  2593 solver.cpp:310]     Train net output #0: loss = 0.392466 (* 1 = 0.392466 loss)
I1111 00:16:00.112879  2593 sgd_solver.cpp:106] Iteration 3096, lr = 0.00025
I1111 00:16:02.063460  2593 solver.cpp:295] Iteration 3097 (no loss supplied for SingleUpdateStep)
I1111 00:16:02.063555  2593 solver.cpp:310]     Train net output #0: loss = 0.382954 (* 1 = 0.382954 loss)
I1111 00:16:02.063576  2593 sgd_solver.cpp:106] Iteration 3097, lr = 0.00025
I1111 00:16:04.103227  2593 solver.cpp:295] Iteration 3098 (no loss supplied for SingleUpdateStep)
I1111 00:16:04.103282  2593 solver.cpp:310]     Train net output #0: loss = 0.377002 (* 1 = 0.377002 loss)
I1111 00:16:04.103301  2593 sgd_solver.cpp:106] Iteration 3098, lr = 0.00025
I1111 00:16:05.977035  2593 solver.cpp:295] Iteration 3099 (no loss supplied for SingleUpdateStep)
I1111 00:16:05.977139  2593 solver.cpp:310]     Train net output #0: loss = 0.418761 (* 1 = 0.418761 loss)
I1111 00:16:05.977160  2593 sgd_solver.cpp:106] Iteration 3099, lr = 0.00025
I1111 00:16:07.865864  2593 solver.cpp:295] Iteration 3100 (no loss supplied for SingleUpdateStep)
I1111 00:16:07.865936  2593 solver.cpp:310]     Train net output #0: loss = 0.410418 (* 1 = 0.410418 loss)
I1111 00:16:07.865957  2593 sgd_solver.cpp:106] Iteration 3100, lr = 0.00025
I1111 00:16:09.909768  2593 solver.cpp:295] Iteration 3101 (no loss supplied for SingleUpdateStep)
I1111 00:16:09.909919  2593 solver.cpp:310]     Train net output #0: loss = 0.398835 (* 1 = 0.398835 loss)
I1111 00:16:09.909945  2593 sgd_solver.cpp:106] Iteration 3101, lr = 0.00025
I1111 00:16:11.863791  2593 solver.cpp:295] Iteration 3102 (no loss supplied for SingleUpdateStep)
I1111 00:16:11.863909  2593 solver.cpp:310]     Train net output #0: loss = 0.395549 (* 1 = 0.395549 loss)
I1111 00:16:11.863934  2593 sgd_solver.cpp:106] Iteration 3102, lr = 0.00025
I1111 00:16:13.804602  2593 solver.cpp:295] Iteration 3103 (no loss supplied for SingleUpdateStep)
I1111 00:16:13.804750  2593 solver.cpp:310]     Train net output #0: loss = 0.418964 (* 1 = 0.418964 loss)
I1111 00:16:13.804779  2593 sgd_solver.cpp:106] Iteration 3103, lr = 0.00025
I1111 00:16:15.767138  2593 solver.cpp:295] Iteration 3104 (no loss supplied for SingleUpdateStep)
I1111 00:16:15.767343  2593 solver.cpp:310]     Train net output #0: loss = 0.431369 (* 1 = 0.431369 loss)
I1111 00:16:15.767369  2593 sgd_solver.cpp:106] Iteration 3104, lr = 0.00025
I1111 00:16:17.612998  2593 solver.cpp:295] Iteration 3105 (no loss supplied for SingleUpdateStep)
I1111 00:16:17.613118  2593 solver.cpp:310]     Train net output #0: loss = 0.415179 (* 1 = 0.415179 loss)
I1111 00:16:17.613147  2593 sgd_solver.cpp:106] Iteration 3105, lr = 0.00025
I1111 00:16:19.443686  2593 solver.cpp:295] Iteration 3106 (no loss supplied for SingleUpdateStep)
I1111 00:16:19.443800  2593 solver.cpp:310]     Train net output #0: loss = 0.396941 (* 1 = 0.396941 loss)
I1111 00:16:19.443822  2593 sgd_solver.cpp:106] Iteration 3106, lr = 0.00025
I1111 00:16:21.528995  2593 solver.cpp:295] Iteration 3107 (no loss supplied for SingleUpdateStep)
I1111 00:16:21.529053  2593 solver.cpp:310]     Train net output #0: loss = 0.391619 (* 1 = 0.391619 loss)
I1111 00:16:21.529072  2593 sgd_solver.cpp:106] Iteration 3107, lr = 0.00025
I1111 00:16:23.397379  2593 solver.cpp:295] Iteration 3108 (no loss supplied for SingleUpdateStep)
I1111 00:16:23.397531  2593 solver.cpp:310]     Train net output #0: loss = 0.399771 (* 1 = 0.399771 loss)
I1111 00:16:23.397555  2593 sgd_solver.cpp:106] Iteration 3108, lr = 0.00025
I1111 00:16:25.281307  2593 solver.cpp:295] Iteration 3109 (no loss supplied for SingleUpdateStep)
I1111 00:16:25.281383  2593 solver.cpp:310]     Train net output #0: loss = 0.399459 (* 1 = 0.399459 loss)
I1111 00:16:25.281405  2593 sgd_solver.cpp:106] Iteration 3109, lr = 0.00025
I1111 00:16:26.985221  2593 solver.cpp:295] Iteration 3110 (no loss supplied for SingleUpdateStep)
I1111 00:16:26.985373  2593 solver.cpp:310]     Train net output #0: loss = 0.384629 (* 1 = 0.384629 loss)
I1111 00:16:26.985401  2593 sgd_solver.cpp:106] Iteration 3110, lr = 0.00025
I1111 00:16:28.764477  2593 solver.cpp:295] Iteration 3111 (no loss supplied for SingleUpdateStep)
I1111 00:16:28.764649  2593 solver.cpp:310]     Train net output #0: loss = 0.381061 (* 1 = 0.381061 loss)
I1111 00:16:28.764674  2593 sgd_solver.cpp:106] Iteration 3111, lr = 0.00025
I1111 00:16:30.548787  2593 solver.cpp:295] Iteration 3112 (no loss supplied for SingleUpdateStep)
I1111 00:16:30.548905  2593 solver.cpp:310]     Train net output #0: loss = 0.35436 (* 1 = 0.35436 loss)
I1111 00:16:30.548926  2593 sgd_solver.cpp:106] Iteration 3112, lr = 0.00025
I1111 00:16:32.353551  2593 solver.cpp:295] Iteration 3113 (no loss supplied for SingleUpdateStep)
I1111 00:16:32.353679  2593 solver.cpp:310]     Train net output #0: loss = 0.429871 (* 1 = 0.429871 loss)
I1111 00:16:32.353708  2593 sgd_solver.cpp:106] Iteration 3113, lr = 0.00025
I1111 00:16:34.183526  2593 solver.cpp:295] Iteration 3114 (no loss supplied for SingleUpdateStep)
I1111 00:16:34.183634  2593 solver.cpp:310]     Train net output #0: loss = 0.39741 (* 1 = 0.39741 loss)
I1111 00:16:34.183653  2593 sgd_solver.cpp:106] Iteration 3114, lr = 0.00025
I1111 00:16:36.117321  2593 solver.cpp:295] Iteration 3115 (no loss supplied for SingleUpdateStep)
I1111 00:16:36.117422  2593 solver.cpp:310]     Train net output #0: loss = 0.399455 (* 1 = 0.399455 loss)
I1111 00:16:36.117444  2593 sgd_solver.cpp:106] Iteration 3115, lr = 0.00025
I1111 00:16:38.289369  2593 solver.cpp:295] Iteration 3116 (no loss supplied for SingleUpdateStep)
I1111 00:16:38.289482  2593 solver.cpp:310]     Train net output #0: loss = 0.391899 (* 1 = 0.391899 loss)
I1111 00:16:38.289505  2593 sgd_solver.cpp:106] Iteration 3116, lr = 0.00025
I1111 00:16:40.512828  2593 solver.cpp:295] Iteration 3117 (no loss supplied for SingleUpdateStep)
I1111 00:16:40.512936  2593 solver.cpp:310]     Train net output #0: loss = 0.43041 (* 1 = 0.43041 loss)
I1111 00:16:40.512960  2593 sgd_solver.cpp:106] Iteration 3117, lr = 0.00025
I1111 00:16:42.830723  2593 solver.cpp:295] Iteration 3118 (no loss supplied for SingleUpdateStep)
I1111 00:16:42.830903  2593 solver.cpp:310]     Train net output #0: loss = 0.407444 (* 1 = 0.407444 loss)
I1111 00:16:42.830935  2593 sgd_solver.cpp:106] Iteration 3118, lr = 0.00025
I1111 00:16:45.271998  2593 solver.cpp:295] Iteration 3119 (no loss supplied for SingleUpdateStep)
I1111 00:16:45.272132  2593 solver.cpp:310]     Train net output #0: loss = 0.385279 (* 1 = 0.385279 loss)
I1111 00:16:45.272161  2593 sgd_solver.cpp:106] Iteration 3119, lr = 0.00025
I1111 00:16:47.604378  2593 solver.cpp:295] Iteration 3120 (no loss supplied for SingleUpdateStep)
I1111 00:16:47.604498  2593 solver.cpp:310]     Train net output #0: loss = 0.365855 (* 1 = 0.365855 loss)
I1111 00:16:47.604521  2593 sgd_solver.cpp:106] Iteration 3120, lr = 0.00025
I1111 00:16:49.977681  2593 solver.cpp:295] Iteration 3121 (no loss supplied for SingleUpdateStep)
I1111 00:16:49.977736  2593 solver.cpp:310]     Train net output #0: loss = 0.38345 (* 1 = 0.38345 loss)
I1111 00:16:49.977754  2593 sgd_solver.cpp:106] Iteration 3121, lr = 0.00025
I1111 00:16:52.314045  2593 solver.cpp:295] Iteration 3122 (no loss supplied for SingleUpdateStep)
I1111 00:16:52.314134  2593 solver.cpp:310]     Train net output #0: loss = 0.36872 (* 1 = 0.36872 loss)
I1111 00:16:52.314155  2593 sgd_solver.cpp:106] Iteration 3122, lr = 0.00025
I1111 00:16:54.867383  2593 solver.cpp:295] Iteration 3123 (no loss supplied for SingleUpdateStep)
I1111 00:16:54.867445  2593 solver.cpp:310]     Train net output #0: loss = 0.424887 (* 1 = 0.424887 loss)
I1111 00:16:54.867465  2593 sgd_solver.cpp:106] Iteration 3123, lr = 0.00025
I1111 00:16:57.303520  2593 solver.cpp:295] Iteration 3124 (no loss supplied for SingleUpdateStep)
I1111 00:16:57.303676  2593 solver.cpp:310]     Train net output #0: loss = 0.377437 (* 1 = 0.377437 loss)
I1111 00:16:57.303701  2593 sgd_solver.cpp:106] Iteration 3124, lr = 0.00025
I1111 00:16:59.599043  2593 solver.cpp:295] Iteration 3125 (no loss supplied for SingleUpdateStep)
I1111 00:16:59.599113  2593 solver.cpp:310]     Train net output #0: loss = 0.401001 (* 1 = 0.401001 loss)
I1111 00:16:59.599133  2593 sgd_solver.cpp:106] Iteration 3125, lr = 0.00025
I1111 00:17:01.943219  2593 solver.cpp:295] Iteration 3126 (no loss supplied for SingleUpdateStep)
I1111 00:17:01.943353  2593 solver.cpp:310]     Train net output #0: loss = 0.410683 (* 1 = 0.410683 loss)
I1111 00:17:01.943377  2593 sgd_solver.cpp:106] Iteration 3126, lr = 0.00025
I1111 00:17:04.148378  2593 solver.cpp:295] Iteration 3127 (no loss supplied for SingleUpdateStep)
I1111 00:17:04.148504  2593 solver.cpp:310]     Train net output #0: loss = 0.3892 (* 1 = 0.3892 loss)
I1111 00:17:04.148525  2593 sgd_solver.cpp:106] Iteration 3127, lr = 0.00025
I1111 00:17:06.394343  2593 solver.cpp:295] Iteration 3128 (no loss supplied for SingleUpdateStep)
I1111 00:17:06.394475  2593 solver.cpp:310]     Train net output #0: loss = 0.390997 (* 1 = 0.390997 loss)
I1111 00:17:06.394501  2593 sgd_solver.cpp:106] Iteration 3128, lr = 0.00025
I1111 00:17:08.650619  2593 solver.cpp:295] Iteration 3129 (no loss supplied for SingleUpdateStep)
I1111 00:17:08.650701  2593 solver.cpp:310]     Train net output #0: loss = 0.43334 (* 1 = 0.43334 loss)
I1111 00:17:08.650722  2593 sgd_solver.cpp:106] Iteration 3129, lr = 0.00025
I1111 00:17:10.966105  2593 solver.cpp:295] Iteration 3130 (no loss supplied for SingleUpdateStep)
I1111 00:17:10.966226  2593 solver.cpp:310]     Train net output #0: loss = 0.396515 (* 1 = 0.396515 loss)
I1111 00:17:10.966260  2593 sgd_solver.cpp:106] Iteration 3130, lr = 0.00025
I1111 00:17:13.119055  2593 solver.cpp:295] Iteration 3131 (no loss supplied for SingleUpdateStep)
I1111 00:17:13.119184  2593 solver.cpp:310]     Train net output #0: loss = 0.396694 (* 1 = 0.396694 loss)
I1111 00:17:13.119205  2593 sgd_solver.cpp:106] Iteration 3131, lr = 0.00025
I1111 00:17:15.460729  2593 solver.cpp:295] Iteration 3132 (no loss supplied for SingleUpdateStep)
I1111 00:17:15.460799  2593 solver.cpp:310]     Train net output #0: loss = 0.384799 (* 1 = 0.384799 loss)
I1111 00:17:15.460820  2593 sgd_solver.cpp:106] Iteration 3132, lr = 0.00025
I1111 00:17:17.824852  2593 solver.cpp:295] Iteration 3133 (no loss supplied for SingleUpdateStep)
I1111 00:17:17.825002  2593 solver.cpp:310]     Train net output #0: loss = 0.390916 (* 1 = 0.390916 loss)
I1111 00:17:17.825024  2593 sgd_solver.cpp:106] Iteration 3133, lr = 0.00025
I1111 00:17:20.197594  2593 solver.cpp:295] Iteration 3134 (no loss supplied for SingleUpdateStep)
I1111 00:17:20.197688  2593 solver.cpp:310]     Train net output #0: loss = 0.374607 (* 1 = 0.374607 loss)
I1111 00:17:20.197713  2593 sgd_solver.cpp:106] Iteration 3134, lr = 0.00025
I1111 00:17:22.894460  2593 solver.cpp:295] Iteration 3135 (no loss supplied for SingleUpdateStep)
I1111 00:17:22.894589  2593 solver.cpp:310]     Train net output #0: loss = 0.403312 (* 1 = 0.403312 loss)
I1111 00:17:22.894616  2593 sgd_solver.cpp:106] Iteration 3135, lr = 0.00025
I1111 00:17:25.332006  2593 solver.cpp:295] Iteration 3136 (no loss supplied for SingleUpdateStep)
I1111 00:17:25.332128  2593 solver.cpp:310]     Train net output #0: loss = 0.401866 (* 1 = 0.401866 loss)
I1111 00:17:25.332154  2593 sgd_solver.cpp:106] Iteration 3136, lr = 0.00025
I1111 00:17:27.830518  2593 solver.cpp:295] Iteration 3137 (no loss supplied for SingleUpdateStep)
I1111 00:17:27.830618  2593 solver.cpp:310]     Train net output #0: loss = 0.369284 (* 1 = 0.369284 loss)
I1111 00:17:27.830641  2593 sgd_solver.cpp:106] Iteration 3137, lr = 0.00025
I1111 00:17:30.371134  2593 solver.cpp:295] Iteration 3138 (no loss supplied for SingleUpdateStep)
I1111 00:17:30.371340  2593 solver.cpp:310]     Train net output #0: loss = 0.398106 (* 1 = 0.398106 loss)
I1111 00:17:30.371386  2593 sgd_solver.cpp:106] Iteration 3138, lr = 0.00025
I1111 00:17:33.206362  2593 solver.cpp:295] Iteration 3139 (no loss supplied for SingleUpdateStep)
I1111 00:17:33.206504  2593 solver.cpp:310]     Train net output #0: loss = 0.427259 (* 1 = 0.427259 loss)
I1111 00:17:33.206531  2593 sgd_solver.cpp:106] Iteration 3139, lr = 0.00025
I1111 00:17:35.692322  2593 solver.cpp:295] Iteration 3140 (no loss supplied for SingleUpdateStep)
I1111 00:17:35.692435  2593 solver.cpp:310]     Train net output #0: loss = 0.407226 (* 1 = 0.407226 loss)
I1111 00:17:35.692461  2593 sgd_solver.cpp:106] Iteration 3140, lr = 0.00025
I1111 00:17:38.311938  2593 solver.cpp:295] Iteration 3141 (no loss supplied for SingleUpdateStep)
I1111 00:17:38.312024  2593 solver.cpp:310]     Train net output #0: loss = 0.38747 (* 1 = 0.38747 loss)
I1111 00:17:38.312044  2593 sgd_solver.cpp:106] Iteration 3141, lr = 0.00025
I1111 00:17:40.680214  2593 solver.cpp:295] Iteration 3142 (no loss supplied for SingleUpdateStep)
I1111 00:17:40.680330  2593 solver.cpp:310]     Train net output #0: loss = 0.412957 (* 1 = 0.412957 loss)
I1111 00:17:40.680352  2593 sgd_solver.cpp:106] Iteration 3142, lr = 0.00025
I1111 00:17:43.099652  2593 solver.cpp:295] Iteration 3143 (no loss supplied for SingleUpdateStep)
I1111 00:17:43.099805  2593 solver.cpp:310]     Train net output #0: loss = 0.378484 (* 1 = 0.378484 loss)
I1111 00:17:43.099833  2593 sgd_solver.cpp:106] Iteration 3143, lr = 0.00025
I1111 00:17:45.458896  2593 solver.cpp:295] Iteration 3144 (no loss supplied for SingleUpdateStep)
I1111 00:17:45.459040  2593 solver.cpp:310]     Train net output #0: loss = 0.387685 (* 1 = 0.387685 loss)
I1111 00:17:45.459064  2593 sgd_solver.cpp:106] Iteration 3144, lr = 0.00025
I1111 00:17:47.798981  2593 solver.cpp:295] Iteration 3145 (no loss supplied for SingleUpdateStep)
I1111 00:17:47.799139  2593 solver.cpp:310]     Train net output #0: loss = 0.41118 (* 1 = 0.41118 loss)
I1111 00:17:47.799170  2593 sgd_solver.cpp:106] Iteration 3145, lr = 0.00025
I1111 00:17:50.373518  2593 solver.cpp:295] Iteration 3146 (no loss supplied for SingleUpdateStep)
I1111 00:17:50.373625  2593 solver.cpp:310]     Train net output #0: loss = 0.378685 (* 1 = 0.378685 loss)
I1111 00:17:50.373648  2593 sgd_solver.cpp:106] Iteration 3146, lr = 0.00025
I1111 00:17:52.727409  2593 solver.cpp:295] Iteration 3147 (no loss supplied for SingleUpdateStep)
I1111 00:17:52.727535  2593 solver.cpp:310]     Train net output #0: loss = 0.398143 (* 1 = 0.398143 loss)
I1111 00:17:52.727558  2593 sgd_solver.cpp:106] Iteration 3147, lr = 0.00025
I1111 00:17:55.326720  2593 solver.cpp:295] Iteration 3148 (no loss supplied for SingleUpdateStep)
I1111 00:17:55.326875  2593 solver.cpp:310]     Train net output #0: loss = 0.420586 (* 1 = 0.420586 loss)
I1111 00:17:55.326905  2593 sgd_solver.cpp:106] Iteration 3148, lr = 0.00025
I1111 00:17:57.654759  2593 solver.cpp:295] Iteration 3149 (no loss supplied for SingleUpdateStep)
I1111 00:17:57.817358  2593 solver.cpp:310]     Train net output #0: loss = 0.399748 (* 1 = 0.399748 loss)
I1111 00:17:57.817420  2593 sgd_solver.cpp:106] Iteration 3149, lr = 0.00025
I1111 00:17:59.853050  2593 solver.cpp:295] Iteration 3150 (no loss supplied for SingleUpdateStep)
I1111 00:17:59.853159  2593 solver.cpp:310]     Train net output #0: loss = 0.403366 (* 1 = 0.403366 loss)
I1111 00:17:59.853183  2593 sgd_solver.cpp:106] Iteration 3150, lr = 0.00025
I1111 00:18:02.335360  2593 solver.cpp:295] Iteration 3151 (no loss supplied for SingleUpdateStep)
I1111 00:18:02.335541  2593 solver.cpp:310]     Train net output #0: loss = 0.404599 (* 1 = 0.404599 loss)
I1111 00:18:02.335573  2593 sgd_solver.cpp:106] Iteration 3151, lr = 0.00025
I1111 00:18:04.663588  2593 solver.cpp:295] Iteration 3152 (no loss supplied for SingleUpdateStep)
I1111 00:18:04.663738  2593 solver.cpp:310]     Train net output #0: loss = 0.388387 (* 1 = 0.388387 loss)
I1111 00:18:04.663764  2593 sgd_solver.cpp:106] Iteration 3152, lr = 0.00025
I1111 00:18:07.194768  2593 solver.cpp:295] Iteration 3153 (no loss supplied for SingleUpdateStep)
I1111 00:18:07.194831  2593 solver.cpp:310]     Train net output #0: loss = 0.430279 (* 1 = 0.430279 loss)
I1111 00:18:07.194851  2593 sgd_solver.cpp:106] Iteration 3153, lr = 0.00025
I1111 00:18:09.789538  2593 solver.cpp:295] Iteration 3154 (no loss supplied for SingleUpdateStep)
I1111 00:18:09.789644  2593 solver.cpp:310]     Train net output #0: loss = 0.424621 (* 1 = 0.424621 loss)
I1111 00:18:09.789665  2593 sgd_solver.cpp:106] Iteration 3154, lr = 0.00025
I1111 00:18:12.152860  2593 solver.cpp:295] Iteration 3155 (no loss supplied for SingleUpdateStep)
I1111 00:18:12.152993  2593 solver.cpp:310]     Train net output #0: loss = 0.36382 (* 1 = 0.36382 loss)
I1111 00:18:12.153017  2593 sgd_solver.cpp:106] Iteration 3155, lr = 0.00025
I1111 00:18:14.495235  2593 solver.cpp:295] Iteration 3156 (no loss supplied for SingleUpdateStep)
I1111 00:18:14.495375  2593 solver.cpp:310]     Train net output #0: loss = 0.374376 (* 1 = 0.374376 loss)
I1111 00:18:14.495401  2593 sgd_solver.cpp:106] Iteration 3156, lr = 0.00025
I1111 00:18:16.792723  2593 solver.cpp:295] Iteration 3157 (no loss supplied for SingleUpdateStep)
I1111 00:18:16.792830  2593 solver.cpp:310]     Train net output #0: loss = 0.38404 (* 1 = 0.38404 loss)
I1111 00:18:16.792852  2593 sgd_solver.cpp:106] Iteration 3157, lr = 0.00025
I1111 00:18:18.953948  2593 solver.cpp:295] Iteration 3158 (no loss supplied for SingleUpdateStep)
I1111 00:18:18.954056  2593 solver.cpp:310]     Train net output #0: loss = 0.41782 (* 1 = 0.41782 loss)
I1111 00:18:18.954077  2593 sgd_solver.cpp:106] Iteration 3158, lr = 0.00025
I1111 00:18:21.194968  2593 solver.cpp:295] Iteration 3159 (no loss supplied for SingleUpdateStep)
I1111 00:18:21.195102  2593 solver.cpp:310]     Train net output #0: loss = 0.443351 (* 1 = 0.443351 loss)
I1111 00:18:21.195125  2593 sgd_solver.cpp:106] Iteration 3159, lr = 0.00025
I1111 00:18:23.512459  2593 solver.cpp:295] Iteration 3160 (no loss supplied for SingleUpdateStep)
I1111 00:18:23.512609  2593 solver.cpp:310]     Train net output #0: loss = 0.410175 (* 1 = 0.410175 loss)
I1111 00:18:23.512635  2593 sgd_solver.cpp:106] Iteration 3160, lr = 0.00025
I1111 00:18:25.790309  2593 solver.cpp:295] Iteration 3161 (no loss supplied for SingleUpdateStep)
I1111 00:18:25.790442  2593 solver.cpp:310]     Train net output #0: loss = 0.426368 (* 1 = 0.426368 loss)
I1111 00:18:25.790464  2593 sgd_solver.cpp:106] Iteration 3161, lr = 0.00025
I1111 00:18:28.080982  2593 solver.cpp:295] Iteration 3162 (no loss supplied for SingleUpdateStep)
I1111 00:18:28.081043  2593 solver.cpp:310]     Train net output #0: loss = 0.381101 (* 1 = 0.381101 loss)
I1111 00:18:28.081061  2593 sgd_solver.cpp:106] Iteration 3162, lr = 0.00025
I1111 00:18:30.365906  2593 solver.cpp:295] Iteration 3163 (no loss supplied for SingleUpdateStep)
I1111 00:18:30.366030  2593 solver.cpp:310]     Train net output #0: loss = 0.391323 (* 1 = 0.391323 loss)
I1111 00:18:30.366055  2593 sgd_solver.cpp:106] Iteration 3163, lr = 0.00025
I1111 00:18:32.887070  2593 solver.cpp:295] Iteration 3164 (no loss supplied for SingleUpdateStep)
I1111 00:18:32.887233  2593 solver.cpp:310]     Train net output #0: loss = 0.40286 (* 1 = 0.40286 loss)
I1111 00:18:32.887259  2593 sgd_solver.cpp:106] Iteration 3164, lr = 0.00025
I1111 00:18:35.358296  2593 solver.cpp:295] Iteration 3165 (no loss supplied for SingleUpdateStep)
I1111 00:18:35.358417  2593 solver.cpp:310]     Train net output #0: loss = 0.380839 (* 1 = 0.380839 loss)
I1111 00:18:35.358443  2593 sgd_solver.cpp:106] Iteration 3165, lr = 0.00025
I1111 00:18:37.600777  2593 solver.cpp:295] Iteration 3166 (no loss supplied for SingleUpdateStep)
I1111 00:18:37.600831  2593 solver.cpp:310]     Train net output #0: loss = 0.398924 (* 1 = 0.398924 loss)
I1111 00:18:37.600852  2593 sgd_solver.cpp:106] Iteration 3166, lr = 0.00025
I1111 00:18:39.854918  2593 solver.cpp:295] Iteration 3167 (no loss supplied for SingleUpdateStep)
I1111 00:18:39.855062  2593 solver.cpp:310]     Train net output #0: loss = 0.391412 (* 1 = 0.391412 loss)
I1111 00:18:39.855087  2593 sgd_solver.cpp:106] Iteration 3167, lr = 0.00025
I1111 00:18:42.082447  2593 solver.cpp:295] Iteration 3168 (no loss supplied for SingleUpdateStep)
I1111 00:18:42.082566  2593 solver.cpp:310]     Train net output #0: loss = 0.400871 (* 1 = 0.400871 loss)
I1111 00:18:42.082586  2593 sgd_solver.cpp:106] Iteration 3168, lr = 0.00025
I1111 00:18:44.367635  2593 solver.cpp:295] Iteration 3169 (no loss supplied for SingleUpdateStep)
I1111 00:18:44.367815  2593 solver.cpp:310]     Train net output #0: loss = 0.380412 (* 1 = 0.380412 loss)
I1111 00:18:44.367846  2593 sgd_solver.cpp:106] Iteration 3169, lr = 0.00025
I1111 00:18:46.657165  2593 solver.cpp:295] Iteration 3170 (no loss supplied for SingleUpdateStep)
I1111 00:18:46.657248  2593 solver.cpp:310]     Train net output #0: loss = 0.37378 (* 1 = 0.37378 loss)
I1111 00:18:46.657269  2593 sgd_solver.cpp:106] Iteration 3170, lr = 0.00025
I1111 00:18:48.897864  2593 solver.cpp:295] Iteration 3171 (no loss supplied for SingleUpdateStep)
I1111 00:18:48.897975  2593 solver.cpp:310]     Train net output #0: loss = 0.390613 (* 1 = 0.390613 loss)
I1111 00:18:48.897997  2593 sgd_solver.cpp:106] Iteration 3171, lr = 0.00025
I1111 00:18:51.893960  2593 solver.cpp:295] Iteration 3172 (no loss supplied for SingleUpdateStep)
I1111 00:18:51.894026  2593 solver.cpp:310]     Train net output #0: loss = 0.378106 (* 1 = 0.378106 loss)
I1111 00:18:51.894044  2593 sgd_solver.cpp:106] Iteration 3172, lr = 0.00025
I1111 00:18:56.063688  2593 solver.cpp:295] Iteration 3173 (no loss supplied for SingleUpdateStep)
I1111 00:18:56.063797  2593 solver.cpp:310]     Train net output #0: loss = 0.360631 (* 1 = 0.360631 loss)
I1111 00:18:56.063819  2593 sgd_solver.cpp:106] Iteration 3173, lr = 0.00025
I1111 00:19:00.766559  2593 solver.cpp:295] Iteration 3174 (no loss supplied for SingleUpdateStep)
I1111 00:19:00.766659  2593 solver.cpp:310]     Train net output #0: loss = 0.420768 (* 1 = 0.420768 loss)
I1111 00:19:00.766682  2593 sgd_solver.cpp:106] Iteration 3174, lr = 0.00025
I1111 00:19:04.020175  2593 solver.cpp:295] Iteration 3175 (no loss supplied for SingleUpdateStep)
I1111 00:19:04.020287  2593 solver.cpp:310]     Train net output #0: loss = 0.415503 (* 1 = 0.415503 loss)
I1111 00:19:04.020309  2593 sgd_solver.cpp:106] Iteration 3175, lr = 0.00025
I1111 00:19:07.165500  2593 solver.cpp:295] Iteration 3176 (no loss supplied for SingleUpdateStep)
I1111 00:19:07.165573  2593 solver.cpp:310]     Train net output #0: loss = 0.367693 (* 1 = 0.367693 loss)
I1111 00:19:07.165594  2593 sgd_solver.cpp:106] Iteration 3176, lr = 0.00025
I1111 00:19:09.576905  2593 solver.cpp:295] Iteration 3177 (no loss supplied for SingleUpdateStep)
I1111 00:19:09.577013  2593 solver.cpp:310]     Train net output #0: loss = 0.371965 (* 1 = 0.371965 loss)
I1111 00:19:09.577035  2593 sgd_solver.cpp:106] Iteration 3177, lr = 0.00025
I1111 00:19:11.977913  2593 solver.cpp:295] Iteration 3178 (no loss supplied for SingleUpdateStep)
I1111 00:19:11.978015  2593 solver.cpp:310]     Train net output #0: loss = 0.410699 (* 1 = 0.410699 loss)
I1111 00:19:11.978046  2593 sgd_solver.cpp:106] Iteration 3178, lr = 0.00025
I1111 00:19:14.498268  2593 solver.cpp:295] Iteration 3179 (no loss supplied for SingleUpdateStep)
I1111 00:19:14.498356  2593 solver.cpp:310]     Train net output #0: loss = 0.410397 (* 1 = 0.410397 loss)
I1111 00:19:14.498375  2593 sgd_solver.cpp:106] Iteration 3179, lr = 0.00025
I1111 00:19:17.405637  2593 solver.cpp:295] Iteration 3180 (no loss supplied for SingleUpdateStep)
I1111 00:19:17.405736  2593 solver.cpp:310]     Train net output #0: loss = 0.37699 (* 1 = 0.37699 loss)
I1111 00:19:17.405757  2593 sgd_solver.cpp:106] Iteration 3180, lr = 0.00025
I1111 00:19:20.525979  2593 solver.cpp:295] Iteration 3181 (no loss supplied for SingleUpdateStep)
I1111 00:19:20.526093  2593 solver.cpp:310]     Train net output #0: loss = 0.368846 (* 1 = 0.368846 loss)
I1111 00:19:20.526115  2593 sgd_solver.cpp:106] Iteration 3181, lr = 0.00025
I1111 00:19:23.618630  2593 solver.cpp:295] Iteration 3182 (no loss supplied for SingleUpdateStep)
I1111 00:19:23.618696  2593 solver.cpp:310]     Train net output #0: loss = 0.390618 (* 1 = 0.390618 loss)
I1111 00:19:23.618716  2593 sgd_solver.cpp:106] Iteration 3182, lr = 0.00025
I1111 00:19:26.148265  2593 solver.cpp:295] Iteration 3183 (no loss supplied for SingleUpdateStep)
I1111 00:19:26.148350  2593 solver.cpp:310]     Train net output #0: loss = 0.390501 (* 1 = 0.390501 loss)
I1111 00:19:26.148368  2593 sgd_solver.cpp:106] Iteration 3183, lr = 0.00025
I1111 00:19:28.918972  2593 solver.cpp:295] Iteration 3184 (no loss supplied for SingleUpdateStep)
I1111 00:19:28.919072  2593 solver.cpp:310]     Train net output #0: loss = 0.424743 (* 1 = 0.424743 loss)
I1111 00:19:28.919092  2593 sgd_solver.cpp:106] Iteration 3184, lr = 0.00025
I1111 00:19:31.690883  2593 solver.cpp:295] Iteration 3185 (no loss supplied for SingleUpdateStep)
I1111 00:19:31.690932  2593 solver.cpp:310]     Train net output #0: loss = 0.388584 (* 1 = 0.388584 loss)
I1111 00:19:31.690948  2593 sgd_solver.cpp:106] Iteration 3185, lr = 0.00025
I1111 00:19:34.153427  2593 solver.cpp:295] Iteration 3186 (no loss supplied for SingleUpdateStep)
I1111 00:19:34.153540  2593 solver.cpp:310]     Train net output #0: loss = 0.431289 (* 1 = 0.431289 loss)
I1111 00:19:34.153563  2593 sgd_solver.cpp:106] Iteration 3186, lr = 0.00025
I1111 00:19:36.612944  2593 solver.cpp:295] Iteration 3187 (no loss supplied for SingleUpdateStep)
I1111 00:19:36.613039  2593 solver.cpp:310]     Train net output #0: loss = 0.422899 (* 1 = 0.422899 loss)
I1111 00:19:36.613061  2593 sgd_solver.cpp:106] Iteration 3187, lr = 0.00025
I1111 00:19:39.053261  2593 solver.cpp:295] Iteration 3188 (no loss supplied for SingleUpdateStep)
I1111 00:19:39.053377  2593 solver.cpp:310]     Train net output #0: loss = 0.383427 (* 1 = 0.383427 loss)
I1111 00:19:39.053400  2593 sgd_solver.cpp:106] Iteration 3188, lr = 0.00025
I1111 00:19:41.313848  2593 solver.cpp:295] Iteration 3189 (no loss supplied for SingleUpdateStep)
I1111 00:19:41.313976  2593 solver.cpp:310]     Train net output #0: loss = 0.407117 (* 1 = 0.407117 loss)
I1111 00:19:41.314000  2593 sgd_solver.cpp:106] Iteration 3189, lr = 0.00025
I1111 00:19:43.519999  2593 solver.cpp:295] Iteration 3190 (no loss supplied for SingleUpdateStep)
I1111 00:19:43.520124  2593 solver.cpp:310]     Train net output #0: loss = 0.354606 (* 1 = 0.354606 loss)
I1111 00:19:43.520153  2593 sgd_solver.cpp:106] Iteration 3190, lr = 0.00025
I1111 00:19:45.823966  2593 solver.cpp:295] Iteration 3191 (no loss supplied for SingleUpdateStep)
I1111 00:19:45.824044  2593 solver.cpp:310]     Train net output #0: loss = 0.386626 (* 1 = 0.386626 loss)
I1111 00:19:45.824064  2593 sgd_solver.cpp:106] Iteration 3191, lr = 0.00025
I1111 00:19:48.110767  2593 solver.cpp:295] Iteration 3192 (no loss supplied for SingleUpdateStep)
I1111 00:19:48.110874  2593 solver.cpp:310]     Train net output #0: loss = 0.390024 (* 1 = 0.390024 loss)
I1111 00:19:48.110901  2593 sgd_solver.cpp:106] Iteration 3192, lr = 0.00025
I1111 00:19:50.542752  2593 solver.cpp:295] Iteration 3193 (no loss supplied for SingleUpdateStep)
I1111 00:19:50.542902  2593 solver.cpp:310]     Train net output #0: loss = 0.391549 (* 1 = 0.391549 loss)
I1111 00:19:50.542927  2593 sgd_solver.cpp:106] Iteration 3193, lr = 0.00025
I1111 00:19:53.410799  2593 solver.cpp:295] Iteration 3194 (no loss supplied for SingleUpdateStep)
I1111 00:19:53.410856  2593 solver.cpp:310]     Train net output #0: loss = 0.403718 (* 1 = 0.403718 loss)
I1111 00:19:53.410874  2593 sgd_solver.cpp:106] Iteration 3194, lr = 0.00025
I1111 00:19:56.992071  2593 solver.cpp:295] Iteration 3195 (no loss supplied for SingleUpdateStep)
I1111 00:19:56.992135  2593 solver.cpp:310]     Train net output #0: loss = 0.388656 (* 1 = 0.388656 loss)
I1111 00:19:56.992153  2593 sgd_solver.cpp:106] Iteration 3195, lr = 0.00025
I1111 00:20:00.661689  2593 solver.cpp:295] Iteration 3196 (no loss supplied for SingleUpdateStep)
I1111 00:20:00.661795  2593 solver.cpp:310]     Train net output #0: loss = 0.359785 (* 1 = 0.359785 loss)
I1111 00:20:00.661815  2593 sgd_solver.cpp:106] Iteration 3196, lr = 0.00025
I1111 00:20:03.785892  2593 solver.cpp:295] Iteration 3197 (no loss supplied for SingleUpdateStep)
I1111 00:20:03.785981  2593 solver.cpp:310]     Train net output #0: loss = 0.409133 (* 1 = 0.409133 loss)
I1111 00:20:03.786002  2593 sgd_solver.cpp:106] Iteration 3197, lr = 0.00025
I1111 00:20:06.791077  2593 solver.cpp:295] Iteration 3198 (no loss supplied for SingleUpdateStep)
I1111 00:20:06.791129  2593 solver.cpp:310]     Train net output #0: loss = 0.4021 (* 1 = 0.4021 loss)
I1111 00:20:06.791147  2593 sgd_solver.cpp:106] Iteration 3198, lr = 0.00025
I1111 00:20:10.063587  2593 solver.cpp:295] Iteration 3199 (no loss supplied for SingleUpdateStep)
I1111 00:20:10.063693  2593 solver.cpp:310]     Train net output #0: loss = 0.397938 (* 1 = 0.397938 loss)
I1111 00:20:10.063714  2593 sgd_solver.cpp:106] Iteration 3199, lr = 0.00025
I1111 00:20:13.204277  2593 solver.cpp:295] Iteration 3200 (no loss supplied for SingleUpdateStep)
I1111 00:20:13.204407  2593 solver.cpp:310]     Train net output #0: loss = 0.401241 (* 1 = 0.401241 loss)
I1111 00:20:13.204430  2593 sgd_solver.cpp:106] Iteration 3200, lr = 0.00025
I1111 00:20:15.954898  2593 solver.cpp:295] Iteration 3201 (no loss supplied for SingleUpdateStep)
I1111 00:20:15.954980  2593 solver.cpp:310]     Train net output #0: loss = 0.43773 (* 1 = 0.43773 loss)
I1111 00:20:15.955001  2593 sgd_solver.cpp:106] Iteration 3201, lr = 0.00025
I1111 00:20:18.203325  2593 solver.cpp:295] Iteration 3202 (no loss supplied for SingleUpdateStep)
I1111 00:20:18.203444  2593 solver.cpp:310]     Train net output #0: loss = 0.382631 (* 1 = 0.382631 loss)
I1111 00:20:18.203464  2593 sgd_solver.cpp:106] Iteration 3202, lr = 0.00025
I1111 00:20:20.426367  2593 solver.cpp:295] Iteration 3203 (no loss supplied for SingleUpdateStep)
I1111 00:20:20.426448  2593 solver.cpp:310]     Train net output #0: loss = 0.404113 (* 1 = 0.404113 loss)
I1111 00:20:20.426471  2593 sgd_solver.cpp:106] Iteration 3203, lr = 0.00025
I1111 00:20:22.811133  2593 solver.cpp:295] Iteration 3204 (no loss supplied for SingleUpdateStep)
I1111 00:20:22.811265  2593 solver.cpp:310]     Train net output #0: loss = 0.384206 (* 1 = 0.384206 loss)
I1111 00:20:22.811290  2593 sgd_solver.cpp:106] Iteration 3204, lr = 0.00025
I1111 00:20:25.274526  2593 solver.cpp:295] Iteration 3205 (no loss supplied for SingleUpdateStep)
I1111 00:20:25.274749  2593 solver.cpp:310]     Train net output #0: loss = 0.405051 (* 1 = 0.405051 loss)
I1111 00:20:25.274778  2593 sgd_solver.cpp:106] Iteration 3205, lr = 0.00025
I1111 00:20:27.636236  2593 solver.cpp:295] Iteration 3206 (no loss supplied for SingleUpdateStep)
I1111 00:20:27.636339  2593 solver.cpp:310]     Train net output #0: loss = 0.388501 (* 1 = 0.388501 loss)
I1111 00:20:27.636361  2593 sgd_solver.cpp:106] Iteration 3206, lr = 0.00025
I1111 00:20:29.951045  2593 solver.cpp:295] Iteration 3207 (no loss supplied for SingleUpdateStep)
I1111 00:20:29.951123  2593 solver.cpp:310]     Train net output #0: loss = 0.424246 (* 1 = 0.424246 loss)
I1111 00:20:29.951143  2593 sgd_solver.cpp:106] Iteration 3207, lr = 0.00025
I1111 00:20:32.417155  2593 solver.cpp:295] Iteration 3208 (no loss supplied for SingleUpdateStep)
I1111 00:20:32.417330  2593 solver.cpp:310]     Train net output #0: loss = 0.396658 (* 1 = 0.396658 loss)
I1111 00:20:32.417357  2593 sgd_solver.cpp:106] Iteration 3208, lr = 0.00025
I1111 00:20:34.794975  2593 solver.cpp:295] Iteration 3209 (no loss supplied for SingleUpdateStep)
I1111 00:20:34.795042  2593 solver.cpp:310]     Train net output #0: loss = 0.380304 (* 1 = 0.380304 loss)
I1111 00:20:34.795061  2593 sgd_solver.cpp:106] Iteration 3209, lr = 0.00025
I1111 00:20:37.229723  2593 solver.cpp:295] Iteration 3210 (no loss supplied for SingleUpdateStep)
I1111 00:20:37.229871  2593 solver.cpp:310]     Train net output #0: loss = 0.435444 (* 1 = 0.435444 loss)
I1111 00:20:37.229895  2593 sgd_solver.cpp:106] Iteration 3210, lr = 0.00025
I1111 00:20:39.521860  2593 solver.cpp:295] Iteration 3211 (no loss supplied for SingleUpdateStep)
I1111 00:20:39.521952  2593 solver.cpp:310]     Train net output #0: loss = 0.411589 (* 1 = 0.411589 loss)
I1111 00:20:39.521975  2593 sgd_solver.cpp:106] Iteration 3211, lr = 0.00025
I1111 00:20:41.968950  2593 solver.cpp:295] Iteration 3212 (no loss supplied for SingleUpdateStep)
I1111 00:20:41.969106  2593 solver.cpp:310]     Train net output #0: loss = 0.410461 (* 1 = 0.410461 loss)
I1111 00:20:41.969130  2593 sgd_solver.cpp:106] Iteration 3212, lr = 0.00025
I1111 00:20:44.368166  2593 solver.cpp:295] Iteration 3213 (no loss supplied for SingleUpdateStep)
I1111 00:20:44.368260  2593 solver.cpp:310]     Train net output #0: loss = 0.396311 (* 1 = 0.396311 loss)
I1111 00:20:44.368283  2593 sgd_solver.cpp:106] Iteration 3213, lr = 0.00025
I1111 00:20:46.879178  2593 solver.cpp:295] Iteration 3214 (no loss supplied for SingleUpdateStep)
I1111 00:20:46.879299  2593 solver.cpp:310]     Train net output #0: loss = 0.415181 (* 1 = 0.415181 loss)
I1111 00:20:46.879320  2593 sgd_solver.cpp:106] Iteration 3214, lr = 0.00025
I1111 00:20:49.227924  2593 solver.cpp:295] Iteration 3215 (no loss supplied for SingleUpdateStep)
I1111 00:20:49.228026  2593 solver.cpp:310]     Train net output #0: loss = 0.36941 (* 1 = 0.36941 loss)
I1111 00:20:49.228045  2593 sgd_solver.cpp:106] Iteration 3215, lr = 0.00025
I1111 00:20:51.954977  2593 solver.cpp:295] Iteration 3216 (no loss supplied for SingleUpdateStep)
I1111 00:20:51.955042  2593 solver.cpp:310]     Train net output #0: loss = 0.373431 (* 1 = 0.373431 loss)
I1111 00:20:51.955062  2593 sgd_solver.cpp:106] Iteration 3216, lr = 0.00025
I1111 00:20:54.288653  2593 solver.cpp:295] Iteration 3217 (no loss supplied for SingleUpdateStep)
I1111 00:20:54.288754  2593 solver.cpp:310]     Train net output #0: loss = 0.419367 (* 1 = 0.419367 loss)
I1111 00:20:54.288775  2593 sgd_solver.cpp:106] Iteration 3217, lr = 0.00025
I1111 00:20:56.544541  2593 solver.cpp:295] Iteration 3218 (no loss supplied for SingleUpdateStep)
I1111 00:20:56.544697  2593 solver.cpp:310]     Train net output #0: loss = 0.42674 (* 1 = 0.42674 loss)
I1111 00:20:56.544723  2593 sgd_solver.cpp:106] Iteration 3218, lr = 0.00025
I1111 00:20:59.146041  2593 solver.cpp:295] Iteration 3219 (no loss supplied for SingleUpdateStep)
I1111 00:20:59.146186  2593 solver.cpp:310]     Train net output #0: loss = 0.398447 (* 1 = 0.398447 loss)
I1111 00:20:59.146209  2593 sgd_solver.cpp:106] Iteration 3219, lr = 0.00025
I1111 00:21:01.624434  2593 solver.cpp:295] Iteration 3220 (no loss supplied for SingleUpdateStep)
I1111 00:21:01.624552  2593 solver.cpp:310]     Train net output #0: loss = 0.417749 (* 1 = 0.417749 loss)
I1111 00:21:01.624575  2593 sgd_solver.cpp:106] Iteration 3220, lr = 0.00025
I1111 00:21:03.991770  2593 solver.cpp:295] Iteration 3221 (no loss supplied for SingleUpdateStep)
I1111 00:21:03.991876  2593 solver.cpp:310]     Train net output #0: loss = 0.429573 (* 1 = 0.429573 loss)
I1111 00:21:03.991899  2593 sgd_solver.cpp:106] Iteration 3221, lr = 0.00025
I1111 00:21:06.414782  2593 solver.cpp:295] Iteration 3222 (no loss supplied for SingleUpdateStep)
I1111 00:21:06.414868  2593 solver.cpp:310]     Train net output #0: loss = 0.374507 (* 1 = 0.374507 loss)
I1111 00:21:06.414888  2593 sgd_solver.cpp:106] Iteration 3222, lr = 0.00025
I1111 00:21:09.013659  2593 solver.cpp:295] Iteration 3223 (no loss supplied for SingleUpdateStep)
I1111 00:21:09.013766  2593 solver.cpp:310]     Train net output #0: loss = 0.406819 (* 1 = 0.406819 loss)
I1111 00:21:09.013788  2593 sgd_solver.cpp:106] Iteration 3223, lr = 0.00025
I1111 00:21:11.520987  2593 solver.cpp:295] Iteration 3224 (no loss supplied for SingleUpdateStep)
I1111 00:21:11.521098  2593 solver.cpp:310]     Train net output #0: loss = 0.401037 (* 1 = 0.401037 loss)
I1111 00:21:11.521118  2593 sgd_solver.cpp:106] Iteration 3224, lr = 0.00025
I1111 00:21:14.062119  2593 solver.cpp:295] Iteration 3225 (no loss supplied for SingleUpdateStep)
I1111 00:21:14.062180  2593 solver.cpp:310]     Train net output #0: loss = 0.393705 (* 1 = 0.393705 loss)
I1111 00:21:14.062199  2593 sgd_solver.cpp:106] Iteration 3225, lr = 0.00025
I1111 00:21:16.482306  2593 solver.cpp:295] Iteration 3226 (no loss supplied for SingleUpdateStep)
I1111 00:21:16.482403  2593 solver.cpp:310]     Train net output #0: loss = 0.394407 (* 1 = 0.394407 loss)
I1111 00:21:16.482425  2593 sgd_solver.cpp:106] Iteration 3226, lr = 0.00025
I1111 00:21:18.750500  2593 solver.cpp:295] Iteration 3227 (no loss supplied for SingleUpdateStep)
I1111 00:21:18.750581  2593 solver.cpp:310]     Train net output #0: loss = 0.381172 (* 1 = 0.381172 loss)
I1111 00:21:18.750602  2593 sgd_solver.cpp:106] Iteration 3227, lr = 0.00025
I1111 00:21:21.201793  2593 solver.cpp:295] Iteration 3228 (no loss supplied for SingleUpdateStep)
I1111 00:21:21.201870  2593 solver.cpp:310]     Train net output #0: loss = 0.358596 (* 1 = 0.358596 loss)
I1111 00:21:21.201890  2593 sgd_solver.cpp:106] Iteration 3228, lr = 0.00025
I1111 00:21:23.607916  2593 solver.cpp:295] Iteration 3229 (no loss supplied for SingleUpdateStep)
I1111 00:21:23.608044  2593 solver.cpp:310]     Train net output #0: loss = 0.390367 (* 1 = 0.390367 loss)
I1111 00:21:23.608068  2593 sgd_solver.cpp:106] Iteration 3229, lr = 0.00025
I1111 00:21:26.205070  2593 solver.cpp:295] Iteration 3230 (no loss supplied for SingleUpdateStep)
I1111 00:21:26.205190  2593 solver.cpp:310]     Train net output #0: loss = 0.395191 (* 1 = 0.395191 loss)
I1111 00:21:26.205212  2593 sgd_solver.cpp:106] Iteration 3230, lr = 0.00025
I1111 00:21:28.600090  2593 solver.cpp:295] Iteration 3231 (no loss supplied for SingleUpdateStep)
I1111 00:21:28.600194  2593 solver.cpp:310]     Train net output #0: loss = 0.391831 (* 1 = 0.391831 loss)
I1111 00:21:28.600215  2593 sgd_solver.cpp:106] Iteration 3231, lr = 0.00025
I1111 00:21:31.037268  2593 solver.cpp:295] Iteration 3232 (no loss supplied for SingleUpdateStep)
I1111 00:21:31.037402  2593 solver.cpp:310]     Train net output #0: loss = 0.421723 (* 1 = 0.421723 loss)
I1111 00:21:31.037425  2593 sgd_solver.cpp:106] Iteration 3232, lr = 0.00025
I1111 00:21:33.349736  2593 solver.cpp:295] Iteration 3233 (no loss supplied for SingleUpdateStep)
I1111 00:21:33.349797  2593 solver.cpp:310]     Train net output #0: loss = 0.418101 (* 1 = 0.418101 loss)
I1111 00:21:33.349817  2593 sgd_solver.cpp:106] Iteration 3233, lr = 0.00025
I1111 00:21:36.025429  2593 solver.cpp:295] Iteration 3234 (no loss supplied for SingleUpdateStep)
I1111 00:21:36.025542  2593 solver.cpp:310]     Train net output #0: loss = 0.377732 (* 1 = 0.377732 loss)
I1111 00:21:36.025563  2593 sgd_solver.cpp:106] Iteration 3234, lr = 0.00025
I1111 00:21:38.405756  2593 solver.cpp:295] Iteration 3235 (no loss supplied for SingleUpdateStep)
I1111 00:21:38.405818  2593 solver.cpp:310]     Train net output #0: loss = 0.38013 (* 1 = 0.38013 loss)
I1111 00:21:38.405836  2593 sgd_solver.cpp:106] Iteration 3235, lr = 0.00025
I1111 00:21:40.788934  2593 solver.cpp:295] Iteration 3236 (no loss supplied for SingleUpdateStep)
I1111 00:21:40.789017  2593 solver.cpp:310]     Train net output #0: loss = 0.404253 (* 1 = 0.404253 loss)
I1111 00:21:40.789038  2593 sgd_solver.cpp:106] Iteration 3236, lr = 0.00025
I1111 00:21:43.104549  2593 solver.cpp:295] Iteration 3237 (no loss supplied for SingleUpdateStep)
I1111 00:21:43.104656  2593 solver.cpp:310]     Train net output #0: loss = 0.398068 (* 1 = 0.398068 loss)
I1111 00:21:43.104679  2593 sgd_solver.cpp:106] Iteration 3237, lr = 0.00025
I1111 00:21:45.335878  2593 solver.cpp:295] Iteration 3238 (no loss supplied for SingleUpdateStep)
I1111 00:21:45.336006  2593 solver.cpp:310]     Train net output #0: loss = 0.382848 (* 1 = 0.382848 loss)
I1111 00:21:45.336031  2593 sgd_solver.cpp:106] Iteration 3238, lr = 0.00025
I1111 00:21:47.709369  2593 solver.cpp:295] Iteration 3239 (no loss supplied for SingleUpdateStep)
I1111 00:21:47.709477  2593 solver.cpp:310]     Train net output #0: loss = 0.392649 (* 1 = 0.392649 loss)
I1111 00:21:47.709497  2593 sgd_solver.cpp:106] Iteration 3239, lr = 0.00025
I1111 00:21:50.117772  2593 solver.cpp:295] Iteration 3240 (no loss supplied for SingleUpdateStep)
I1111 00:21:50.117913  2593 solver.cpp:310]     Train net output #0: loss = 0.389541 (* 1 = 0.389541 loss)
I1111 00:21:50.117944  2593 sgd_solver.cpp:106] Iteration 3240, lr = 0.00025
I1111 00:21:52.622558  2593 solver.cpp:295] Iteration 3241 (no loss supplied for SingleUpdateStep)
I1111 00:21:52.622740  2593 solver.cpp:310]     Train net output #0: loss = 0.392 (* 1 = 0.392 loss)
I1111 00:21:52.622766  2593 sgd_solver.cpp:106] Iteration 3241, lr = 0.00025
I1111 00:21:54.820492  2593 solver.cpp:295] Iteration 3242 (no loss supplied for SingleUpdateStep)
I1111 00:21:54.820622  2593 solver.cpp:310]     Train net output #0: loss = 0.385935 (* 1 = 0.385935 loss)
I1111 00:21:54.820647  2593 sgd_solver.cpp:106] Iteration 3242, lr = 0.00025
I1111 00:21:57.068476  2593 solver.cpp:295] Iteration 3243 (no loss supplied for SingleUpdateStep)
I1111 00:21:57.068603  2593 solver.cpp:310]     Train net output #0: loss = 0.419339 (* 1 = 0.419339 loss)
I1111 00:21:57.068630  2593 sgd_solver.cpp:106] Iteration 3243, lr = 0.00025
I1111 00:21:59.386859  2593 solver.cpp:295] Iteration 3244 (no loss supplied for SingleUpdateStep)
I1111 00:21:59.386981  2593 solver.cpp:310]     Train net output #0: loss = 0.399875 (* 1 = 0.399875 loss)
I1111 00:21:59.387004  2593 sgd_solver.cpp:106] Iteration 3244, lr = 0.00025
I1111 00:22:01.822973  2593 solver.cpp:295] Iteration 3245 (no loss supplied for SingleUpdateStep)
I1111 00:22:01.823130  2593 solver.cpp:310]     Train net output #0: loss = 0.404835 (* 1 = 0.404835 loss)
I1111 00:22:01.823156  2593 sgd_solver.cpp:106] Iteration 3245, lr = 0.00025
I1111 00:22:04.068979  2593 solver.cpp:295] Iteration 3246 (no loss supplied for SingleUpdateStep)
I1111 00:22:04.069124  2593 solver.cpp:310]     Train net output #0: loss = 0.410566 (* 1 = 0.410566 loss)
I1111 00:22:04.069147  2593 sgd_solver.cpp:106] Iteration 3246, lr = 0.00025
I1111 00:22:06.456506  2593 solver.cpp:295] Iteration 3247 (no loss supplied for SingleUpdateStep)
I1111 00:22:06.456749  2593 solver.cpp:310]     Train net output #0: loss = 0.392138 (* 1 = 0.392138 loss)
I1111 00:22:06.456795  2593 sgd_solver.cpp:106] Iteration 3247, lr = 0.00025
I1111 00:22:08.931574  2593 solver.cpp:295] Iteration 3248 (no loss supplied for SingleUpdateStep)
I1111 00:22:08.931661  2593 solver.cpp:310]     Train net output #0: loss = 0.410091 (* 1 = 0.410091 loss)
I1111 00:22:08.931682  2593 sgd_solver.cpp:106] Iteration 3248, lr = 0.00025
I1111 00:22:11.292659  2593 solver.cpp:295] Iteration 3249 (no loss supplied for SingleUpdateStep)
I1111 00:22:11.292752  2593 solver.cpp:310]     Train net output #0: loss = 0.396605 (* 1 = 0.396605 loss)
I1111 00:22:11.292773  2593 sgd_solver.cpp:106] Iteration 3249, lr = 0.00025
I1111 00:22:13.669641  2593 solver.cpp:295] Iteration 3250 (no loss supplied for SingleUpdateStep)
I1111 00:22:13.669699  2593 solver.cpp:310]     Train net output #0: loss = 0.430095 (* 1 = 0.430095 loss)
I1111 00:22:13.669718  2593 sgd_solver.cpp:106] Iteration 3250, lr = 0.00025
I1111 00:22:15.914288  2593 solver.cpp:295] Iteration 3251 (no loss supplied for SingleUpdateStep)
I1111 00:22:15.914420  2593 solver.cpp:310]     Train net output #0: loss = 0.406747 (* 1 = 0.406747 loss)
I1111 00:22:15.914446  2593 sgd_solver.cpp:106] Iteration 3251, lr = 0.00025
I1111 00:22:18.330834  2593 solver.cpp:295] Iteration 3252 (no loss supplied for SingleUpdateStep)
I1111 00:22:18.330945  2593 solver.cpp:310]     Train net output #0: loss = 0.389657 (* 1 = 0.389657 loss)
I1111 00:22:18.330966  2593 sgd_solver.cpp:106] Iteration 3252, lr = 0.00025
I1111 00:22:21.331776  2593 solver.cpp:295] Iteration 3253 (no loss supplied for SingleUpdateStep)
I1111 00:22:21.331850  2593 solver.cpp:310]     Train net output #0: loss = 0.427914 (* 1 = 0.427914 loss)
I1111 00:22:21.331869  2593 sgd_solver.cpp:106] Iteration 3253, lr = 0.00025
I1111 00:22:24.110651  2593 solver.cpp:295] Iteration 3254 (no loss supplied for SingleUpdateStep)
I1111 00:22:24.110770  2593 solver.cpp:310]     Train net output #0: loss = 0.397607 (* 1 = 0.397607 loss)
I1111 00:22:24.110795  2593 sgd_solver.cpp:106] Iteration 3254, lr = 0.00025
I1111 00:22:26.819778  2593 solver.cpp:295] Iteration 3255 (no loss supplied for SingleUpdateStep)
I1111 00:22:26.836216  2593 solver.cpp:310]     Train net output #0: loss = 0.409589 (* 1 = 0.409589 loss)
I1111 00:22:26.836277  2593 sgd_solver.cpp:106] Iteration 3255, lr = 0.00025
I1111 00:22:29.218421  2593 solver.cpp:295] Iteration 3256 (no loss supplied for SingleUpdateStep)
I1111 00:22:29.218499  2593 solver.cpp:310]     Train net output #0: loss = 0.390227 (* 1 = 0.390227 loss)
I1111 00:22:29.218523  2593 sgd_solver.cpp:106] Iteration 3256, lr = 0.00025
I1111 00:22:31.504736  2593 solver.cpp:295] Iteration 3257 (no loss supplied for SingleUpdateStep)
I1111 00:22:31.504791  2593 solver.cpp:310]     Train net output #0: loss = 0.399927 (* 1 = 0.399927 loss)
I1111 00:22:31.504809  2593 sgd_solver.cpp:106] Iteration 3257, lr = 0.00025
I1111 00:22:34.000368  2593 solver.cpp:295] Iteration 3258 (no loss supplied for SingleUpdateStep)
I1111 00:22:34.000496  2593 solver.cpp:310]     Train net output #0: loss = 0.397756 (* 1 = 0.397756 loss)
I1111 00:22:34.000521  2593 sgd_solver.cpp:106] Iteration 3258, lr = 0.00025
I1111 00:22:36.484138  2593 solver.cpp:295] Iteration 3259 (no loss supplied for SingleUpdateStep)
I1111 00:22:36.484249  2593 solver.cpp:310]     Train net output #0: loss = 0.404243 (* 1 = 0.404243 loss)
I1111 00:22:36.484273  2593 sgd_solver.cpp:106] Iteration 3259, lr = 0.00025
I1111 00:22:38.871290  2593 solver.cpp:295] Iteration 3260 (no loss supplied for SingleUpdateStep)
I1111 00:22:38.871409  2593 solver.cpp:310]     Train net output #0: loss = 0.380097 (* 1 = 0.380097 loss)
I1111 00:22:38.871431  2593 sgd_solver.cpp:106] Iteration 3260, lr = 0.00025
I1111 00:22:41.578691  2593 solver.cpp:295] Iteration 3261 (no loss supplied for SingleUpdateStep)
I1111 00:22:41.578809  2593 solver.cpp:310]     Train net output #0: loss = 0.378989 (* 1 = 0.378989 loss)
I1111 00:22:41.578833  2593 sgd_solver.cpp:106] Iteration 3261, lr = 0.00025
I1111 00:22:44.109393  2593 solver.cpp:295] Iteration 3262 (no loss supplied for SingleUpdateStep)
I1111 00:22:44.109505  2593 solver.cpp:310]     Train net output #0: loss = 0.398475 (* 1 = 0.398475 loss)
I1111 00:22:44.109531  2593 sgd_solver.cpp:106] Iteration 3262, lr = 0.00025
I1111 00:22:46.831681  2593 solver.cpp:295] Iteration 3263 (no loss supplied for SingleUpdateStep)
I1111 00:22:46.831801  2593 solver.cpp:310]     Train net output #0: loss = 0.398976 (* 1 = 0.398976 loss)
I1111 00:22:46.831822  2593 sgd_solver.cpp:106] Iteration 3263, lr = 0.00025
I1111 00:22:49.646642  2593 solver.cpp:295] Iteration 3264 (no loss supplied for SingleUpdateStep)
I1111 00:22:49.646772  2593 solver.cpp:310]     Train net output #0: loss = 0.394722 (* 1 = 0.394722 loss)
I1111 00:22:49.646795  2593 sgd_solver.cpp:106] Iteration 3264, lr = 0.00025
I1111 00:22:52.241410  2593 solver.cpp:295] Iteration 3265 (no loss supplied for SingleUpdateStep)
I1111 00:22:52.241523  2593 solver.cpp:310]     Train net output #0: loss = 0.412341 (* 1 = 0.412341 loss)
I1111 00:22:52.241549  2593 sgd_solver.cpp:106] Iteration 3265, lr = 0.00025
I1111 00:22:55.162752  2593 solver.cpp:295] Iteration 3266 (no loss supplied for SingleUpdateStep)
I1111 00:22:55.162950  2593 solver.cpp:310]     Train net output #0: loss = 0.400893 (* 1 = 0.400893 loss)
I1111 00:22:55.162984  2593 sgd_solver.cpp:106] Iteration 3266, lr = 0.00025
I1111 00:22:59.557322  2593 solver.cpp:295] Iteration 3267 (no loss supplied for SingleUpdateStep)
I1111 00:22:59.557448  2593 solver.cpp:310]     Train net output #0: loss = 0.393815 (* 1 = 0.393815 loss)
I1111 00:22:59.557471  2593 sgd_solver.cpp:106] Iteration 3267, lr = 0.00025
I1111 00:23:03.038483  2593 solver.cpp:295] Iteration 3268 (no loss supplied for SingleUpdateStep)
I1111 00:23:03.038599  2593 solver.cpp:310]     Train net output #0: loss = 0.375528 (* 1 = 0.375528 loss)
I1111 00:23:03.038624  2593 sgd_solver.cpp:106] Iteration 3268, lr = 0.00025
I1111 00:23:07.638949  2593 solver.cpp:295] Iteration 3269 (no loss supplied for SingleUpdateStep)
I1111 00:23:07.639056  2593 solver.cpp:310]     Train net output #0: loss = 0.375594 (* 1 = 0.375594 loss)
I1111 00:23:07.639078  2593 sgd_solver.cpp:106] Iteration 3269, lr = 0.00025
I1111 00:23:10.995072  2593 solver.cpp:295] Iteration 3270 (no loss supplied for SingleUpdateStep)
I1111 00:23:10.995193  2593 solver.cpp:310]     Train net output #0: loss = 0.385939 (* 1 = 0.385939 loss)
I1111 00:23:10.995215  2593 sgd_solver.cpp:106] Iteration 3270, lr = 0.00025
I1111 00:23:15.242096  2593 solver.cpp:295] Iteration 3271 (no loss supplied for SingleUpdateStep)
I1111 00:23:15.242224  2593 solver.cpp:310]     Train net output #0: loss = 0.393407 (* 1 = 0.393407 loss)
I1111 00:23:15.242250  2593 sgd_solver.cpp:106] Iteration 3271, lr = 0.00025
I1111 00:23:18.526048  2593 solver.cpp:295] Iteration 3272 (no loss supplied for SingleUpdateStep)
I1111 00:23:18.526125  2593 solver.cpp:310]     Train net output #0: loss = 0.40524 (* 1 = 0.40524 loss)
I1111 00:23:18.526145  2593 sgd_solver.cpp:106] Iteration 3272, lr = 0.00025
I1111 00:23:22.339757  2593 solver.cpp:295] Iteration 3273 (no loss supplied for SingleUpdateStep)
I1111 00:23:22.339890  2593 solver.cpp:310]     Train net output #0: loss = 0.39413 (* 1 = 0.39413 loss)
I1111 00:23:22.339920  2593 sgd_solver.cpp:106] Iteration 3273, lr = 0.00025
I1111 00:23:25.772009  2593 solver.cpp:295] Iteration 3274 (no loss supplied for SingleUpdateStep)
I1111 00:23:25.772156  2593 solver.cpp:310]     Train net output #0: loss = 0.386259 (* 1 = 0.386259 loss)
I1111 00:23:25.772181  2593 sgd_solver.cpp:106] Iteration 3274, lr = 0.00025
I1111 00:23:29.207051  2593 solver.cpp:295] Iteration 3275 (no loss supplied for SingleUpdateStep)
I1111 00:23:29.207134  2593 solver.cpp:310]     Train net output #0: loss = 0.377209 (* 1 = 0.377209 loss)
I1111 00:23:29.207154  2593 sgd_solver.cpp:106] Iteration 3275, lr = 0.00025
I1111 00:23:32.747591  2593 solver.cpp:295] Iteration 3276 (no loss supplied for SingleUpdateStep)
I1111 00:23:32.747728  2593 solver.cpp:310]     Train net output #0: loss = 0.379807 (* 1 = 0.379807 loss)
I1111 00:23:32.747757  2593 sgd_solver.cpp:106] Iteration 3276, lr = 0.00025
I1111 00:23:36.087680  2593 solver.cpp:295] Iteration 3277 (no loss supplied for SingleUpdateStep)
I1111 00:23:36.087802  2593 solver.cpp:310]     Train net output #0: loss = 0.41217 (* 1 = 0.41217 loss)
I1111 00:23:36.087826  2593 sgd_solver.cpp:106] Iteration 3277, lr = 0.00025
I1111 00:23:39.584056  2593 solver.cpp:295] Iteration 3278 (no loss supplied for SingleUpdateStep)
I1111 00:23:39.584178  2593 solver.cpp:310]     Train net output #0: loss = 0.400135 (* 1 = 0.400135 loss)
I1111 00:23:39.584204  2593 sgd_solver.cpp:106] Iteration 3278, lr = 0.00025
I1111 00:23:43.087313  2593 solver.cpp:295] Iteration 3279 (no loss supplied for SingleUpdateStep)
I1111 00:23:43.087436  2593 solver.cpp:310]     Train net output #0: loss = 0.388031 (* 1 = 0.388031 loss)
I1111 00:23:43.087457  2593 sgd_solver.cpp:106] Iteration 3279, lr = 0.00025
I1111 00:23:45.498785  2593 solver.cpp:295] Iteration 3280 (no loss supplied for SingleUpdateStep)
I1111 00:23:45.498870  2593 solver.cpp:310]     Train net output #0: loss = 0.375928 (* 1 = 0.375928 loss)
I1111 00:23:45.498893  2593 sgd_solver.cpp:106] Iteration 3280, lr = 0.00025
I1111 00:23:48.373561  2593 solver.cpp:295] Iteration 3281 (no loss supplied for SingleUpdateStep)
I1111 00:23:48.373628  2593 solver.cpp:310]     Train net output #0: loss = 0.379972 (* 1 = 0.379972 loss)
I1111 00:23:48.373651  2593 sgd_solver.cpp:106] Iteration 3281, lr = 0.00025
I1111 00:23:52.125229  2593 solver.cpp:295] Iteration 3282 (no loss supplied for SingleUpdateStep)
I1111 00:23:52.125341  2593 solver.cpp:310]     Train net output #0: loss = 0.374217 (* 1 = 0.374217 loss)
I1111 00:23:52.125365  2593 sgd_solver.cpp:106] Iteration 3282, lr = 0.00025
I1111 00:23:54.659414  2593 solver.cpp:295] Iteration 3283 (no loss supplied for SingleUpdateStep)
I1111 00:23:54.659500  2593 solver.cpp:310]     Train net output #0: loss = 0.413259 (* 1 = 0.413259 loss)
I1111 00:23:54.659523  2593 sgd_solver.cpp:106] Iteration 3283, lr = 0.00025
I1111 00:23:57.035920  2593 solver.cpp:295] Iteration 3284 (no loss supplied for SingleUpdateStep)
I1111 00:23:57.036053  2593 solver.cpp:310]     Train net output #0: loss = 0.405984 (* 1 = 0.405984 loss)
I1111 00:23:57.036079  2593 sgd_solver.cpp:106] Iteration 3284, lr = 0.00025
I1111 00:23:59.804962  2593 solver.cpp:295] Iteration 3285 (no loss supplied for SingleUpdateStep)
I1111 00:23:59.805106  2593 solver.cpp:310]     Train net output #0: loss = 0.396489 (* 1 = 0.396489 loss)
I1111 00:23:59.805132  2593 sgd_solver.cpp:106] Iteration 3285, lr = 0.00025
I1111 00:24:02.482031  2593 solver.cpp:295] Iteration 3286 (no loss supplied for SingleUpdateStep)
I1111 00:24:02.482153  2593 solver.cpp:310]     Train net output #0: loss = 0.387349 (* 1 = 0.387349 loss)
I1111 00:24:02.482175  2593 sgd_solver.cpp:106] Iteration 3286, lr = 0.00025
I1111 00:24:04.871379  2593 solver.cpp:295] Iteration 3287 (no loss supplied for SingleUpdateStep)
I1111 00:24:04.871445  2593 solver.cpp:310]     Train net output #0: loss = 0.422807 (* 1 = 0.422807 loss)
I1111 00:24:04.871466  2593 sgd_solver.cpp:106] Iteration 3287, lr = 0.00025
I1111 00:24:07.159852  2593 solver.cpp:295] Iteration 3288 (no loss supplied for SingleUpdateStep)
I1111 00:24:07.160022  2593 solver.cpp:310]     Train net output #0: loss = 0.399353 (* 1 = 0.399353 loss)
I1111 00:24:07.160056  2593 sgd_solver.cpp:106] Iteration 3288, lr = 0.00025
I1111 00:24:09.530351  2593 solver.cpp:295] Iteration 3289 (no loss supplied for SingleUpdateStep)
I1111 00:24:09.530472  2593 solver.cpp:310]     Train net output #0: loss = 0.389736 (* 1 = 0.389736 loss)
I1111 00:24:09.530500  2593 sgd_solver.cpp:106] Iteration 3289, lr = 0.00025
I1111 00:24:11.766937  2593 solver.cpp:295] Iteration 3290 (no loss supplied for SingleUpdateStep)
I1111 00:24:11.766991  2593 solver.cpp:310]     Train net output #0: loss = 0.409173 (* 1 = 0.409173 loss)
I1111 00:24:11.767011  2593 sgd_solver.cpp:106] Iteration 3290, lr = 0.00025
I1111 00:24:14.421751  2593 solver.cpp:295] Iteration 3291 (no loss supplied for SingleUpdateStep)
I1111 00:24:14.421820  2593 solver.cpp:310]     Train net output #0: loss = 0.417167 (* 1 = 0.417167 loss)
I1111 00:24:14.421839  2593 sgd_solver.cpp:106] Iteration 3291, lr = 0.00025
I1111 00:24:16.848109  2593 solver.cpp:295] Iteration 3292 (no loss supplied for SingleUpdateStep)
I1111 00:24:16.848202  2593 solver.cpp:310]     Train net output #0: loss = 0.364589 (* 1 = 0.364589 loss)
I1111 00:24:16.848224  2593 sgd_solver.cpp:106] Iteration 3292, lr = 0.00025
I1111 00:24:19.798177  2593 solver.cpp:295] Iteration 3293 (no loss supplied for SingleUpdateStep)
I1111 00:24:19.798301  2593 solver.cpp:310]     Train net output #0: loss = 0.395112 (* 1 = 0.395112 loss)
I1111 00:24:19.798327  2593 sgd_solver.cpp:106] Iteration 3293, lr = 0.00025
I1111 00:24:22.116499  2593 solver.cpp:295] Iteration 3294 (no loss supplied for SingleUpdateStep)
I1111 00:24:22.116559  2593 solver.cpp:310]     Train net output #0: loss = 0.381274 (* 1 = 0.381274 loss)
I1111 00:24:22.116577  2593 sgd_solver.cpp:106] Iteration 3294, lr = 0.00025
I1111 00:24:24.589020  2593 solver.cpp:295] Iteration 3295 (no loss supplied for SingleUpdateStep)
I1111 00:24:24.589151  2593 solver.cpp:310]     Train net output #0: loss = 0.394799 (* 1 = 0.394799 loss)
I1111 00:24:24.589174  2593 sgd_solver.cpp:106] Iteration 3295, lr = 0.00025
I1111 00:24:27.387673  2593 solver.cpp:295] Iteration 3296 (no loss supplied for SingleUpdateStep)
I1111 00:24:27.387817  2593 solver.cpp:310]     Train net output #0: loss = 0.398587 (* 1 = 0.398587 loss)
I1111 00:24:27.387840  2593 sgd_solver.cpp:106] Iteration 3296, lr = 0.00025
I1111 00:24:30.009091  2593 solver.cpp:295] Iteration 3297 (no loss supplied for SingleUpdateStep)
I1111 00:24:30.009212  2593 solver.cpp:310]     Train net output #0: loss = 0.361798 (* 1 = 0.361798 loss)
I1111 00:24:30.009237  2593 sgd_solver.cpp:106] Iteration 3297, lr = 0.00025
I1111 00:24:32.401095  2593 solver.cpp:295] Iteration 3298 (no loss supplied for SingleUpdateStep)
I1111 00:24:32.401185  2593 solver.cpp:310]     Train net output #0: loss = 0.369666 (* 1 = 0.369666 loss)
I1111 00:24:32.401206  2593 sgd_solver.cpp:106] Iteration 3298, lr = 0.00025
I1111 00:24:35.204460  2593 solver.cpp:295] Iteration 3299 (no loss supplied for SingleUpdateStep)
I1111 00:24:35.204577  2593 solver.cpp:310]     Train net output #0: loss = 0.385234 (* 1 = 0.385234 loss)
I1111 00:24:35.204601  2593 sgd_solver.cpp:106] Iteration 3299, lr = 0.00025
I1111 00:24:37.530825  2593 solver.cpp:295] Iteration 3300 (no loss supplied for SingleUpdateStep)
I1111 00:24:37.530936  2593 solver.cpp:310]     Train net output #0: loss = 0.362961 (* 1 = 0.362961 loss)
I1111 00:24:37.530958  2593 sgd_solver.cpp:106] Iteration 3300, lr = 0.00025
I1111 00:24:40.418411  2593 solver.cpp:295] Iteration 3301 (no loss supplied for SingleUpdateStep)
I1111 00:24:40.418493  2593 solver.cpp:310]     Train net output #0: loss = 0.374582 (* 1 = 0.374582 loss)
I1111 00:24:40.418514  2593 sgd_solver.cpp:106] Iteration 3301, lr = 0.00025
I1111 00:24:43.081343  2593 solver.cpp:295] Iteration 3302 (no loss supplied for SingleUpdateStep)
I1111 00:24:43.081496  2593 solver.cpp:310]     Train net output #0: loss = 0.374583 (* 1 = 0.374583 loss)
I1111 00:24:43.081519  2593 sgd_solver.cpp:106] Iteration 3302, lr = 0.00025
I1111 00:24:45.786396  2593 solver.cpp:295] Iteration 3303 (no loss supplied for SingleUpdateStep)
I1111 00:24:45.786500  2593 solver.cpp:310]     Train net output #0: loss = 0.389555 (* 1 = 0.389555 loss)
I1111 00:24:45.786522  2593 sgd_solver.cpp:106] Iteration 3303, lr = 0.00025
I1111 00:24:48.120105  2593 solver.cpp:295] Iteration 3304 (no loss supplied for SingleUpdateStep)
I1111 00:24:48.120188  2593 solver.cpp:310]     Train net output #0: loss = 0.385948 (* 1 = 0.385948 loss)
I1111 00:24:48.120210  2593 sgd_solver.cpp:106] Iteration 3304, lr = 0.00025
I1111 00:24:50.638789  2593 solver.cpp:295] Iteration 3305 (no loss supplied for SingleUpdateStep)
I1111 00:24:50.638859  2593 solver.cpp:310]     Train net output #0: loss = 0.357475 (* 1 = 0.357475 loss)
I1111 00:24:50.638878  2593 sgd_solver.cpp:106] Iteration 3305, lr = 0.00025
I1111 00:24:52.940001  2593 solver.cpp:295] Iteration 3306 (no loss supplied for SingleUpdateStep)
I1111 00:24:52.940162  2593 solver.cpp:310]     Train net output #0: loss = 0.396858 (* 1 = 0.396858 loss)
I1111 00:24:52.940186  2593 sgd_solver.cpp:106] Iteration 3306, lr = 0.00025
I1111 00:24:55.358381  2593 solver.cpp:295] Iteration 3307 (no loss supplied for SingleUpdateStep)
I1111 00:24:55.358507  2593 solver.cpp:310]     Train net output #0: loss = 0.409203 (* 1 = 0.409203 loss)
I1111 00:24:55.358535  2593 sgd_solver.cpp:106] Iteration 3307, lr = 0.00025
I1111 00:24:57.947798  2593 solver.cpp:295] Iteration 3308 (no loss supplied for SingleUpdateStep)
I1111 00:24:57.947899  2593 solver.cpp:310]     Train net output #0: loss = 0.405585 (* 1 = 0.405585 loss)
I1111 00:24:57.947922  2593 sgd_solver.cpp:106] Iteration 3308, lr = 0.00025
I1111 00:25:00.300146  2593 solver.cpp:295] Iteration 3309 (no loss supplied for SingleUpdateStep)
I1111 00:25:00.300262  2593 solver.cpp:310]     Train net output #0: loss = 0.405488 (* 1 = 0.405488 loss)
I1111 00:25:00.300283  2593 sgd_solver.cpp:106] Iteration 3309, lr = 0.00025
I1111 00:25:02.673419  2593 solver.cpp:295] Iteration 3310 (no loss supplied for SingleUpdateStep)
I1111 00:25:02.673476  2593 solver.cpp:310]     Train net output #0: loss = 0.411125 (* 1 = 0.411125 loss)
I1111 00:25:02.673496  2593 sgd_solver.cpp:106] Iteration 3310, lr = 0.00025
I1111 00:25:05.072917  2593 solver.cpp:295] Iteration 3311 (no loss supplied for SingleUpdateStep)
I1111 00:25:05.073019  2593 solver.cpp:310]     Train net output #0: loss = 0.406299 (* 1 = 0.406299 loss)
I1111 00:25:05.073040  2593 sgd_solver.cpp:106] Iteration 3311, lr = 0.00025
I1111 00:25:07.672842  2593 solver.cpp:295] Iteration 3312 (no loss supplied for SingleUpdateStep)
I1111 00:25:07.672981  2593 solver.cpp:310]     Train net output #0: loss = 0.389757 (* 1 = 0.389757 loss)
I1111 00:25:07.673002  2593 sgd_solver.cpp:106] Iteration 3312, lr = 0.00025
I1111 00:25:10.293166  2593 solver.cpp:295] Iteration 3313 (no loss supplied for SingleUpdateStep)
I1111 00:25:10.293225  2593 solver.cpp:310]     Train net output #0: loss = 0.403142 (* 1 = 0.403142 loss)
I1111 00:25:10.293242  2593 sgd_solver.cpp:106] Iteration 3313, lr = 0.00025
I1111 00:25:12.761284  2593 solver.cpp:295] Iteration 3314 (no loss supplied for SingleUpdateStep)
I1111 00:25:12.761410  2593 solver.cpp:310]     Train net output #0: loss = 0.384267 (* 1 = 0.384267 loss)
I1111 00:25:12.761432  2593 sgd_solver.cpp:106] Iteration 3314, lr = 0.00025
I1111 00:25:15.131597  2593 solver.cpp:295] Iteration 3315 (no loss supplied for SingleUpdateStep)
I1111 00:25:15.131705  2593 solver.cpp:310]     Train net output #0: loss = 0.41128 (* 1 = 0.41128 loss)
I1111 00:25:15.131727  2593 sgd_solver.cpp:106] Iteration 3315, lr = 0.00025
I1111 00:25:17.537906  2593 solver.cpp:295] Iteration 3316 (no loss supplied for SingleUpdateStep)
I1111 00:25:17.537986  2593 solver.cpp:310]     Train net output #0: loss = 0.373082 (* 1 = 0.373082 loss)
I1111 00:25:17.538007  2593 sgd_solver.cpp:106] Iteration 3316, lr = 0.00025
I1111 00:25:19.772366  2593 solver.cpp:295] Iteration 3317 (no loss supplied for SingleUpdateStep)
I1111 00:25:19.772503  2593 solver.cpp:310]     Train net output #0: loss = 0.417679 (* 1 = 0.417679 loss)
I1111 00:25:19.772526  2593 sgd_solver.cpp:106] Iteration 3317, lr = 0.00025
I1111 00:25:22.217105  2593 solver.cpp:295] Iteration 3318 (no loss supplied for SingleUpdateStep)
I1111 00:25:22.217183  2593 solver.cpp:310]     Train net output #0: loss = 0.37142 (* 1 = 0.37142 loss)
I1111 00:25:22.217203  2593 sgd_solver.cpp:106] Iteration 3318, lr = 0.00025
I1111 00:25:24.558049  2593 solver.cpp:295] Iteration 3319 (no loss supplied for SingleUpdateStep)
I1111 00:25:24.558145  2593 solver.cpp:310]     Train net output #0: loss = 0.403861 (* 1 = 0.403861 loss)
I1111 00:25:24.558166  2593 sgd_solver.cpp:106] Iteration 3319, lr = 0.00025
I1111 00:25:27.307281  2593 solver.cpp:295] Iteration 3320 (no loss supplied for SingleUpdateStep)
I1111 00:25:27.307374  2593 solver.cpp:310]     Train net output #0: loss = 0.396534 (* 1 = 0.396534 loss)
I1111 00:25:27.307396  2593 sgd_solver.cpp:106] Iteration 3320, lr = 0.00025
I1111 00:25:29.912664  2593 solver.cpp:295] Iteration 3321 (no loss supplied for SingleUpdateStep)
I1111 00:25:29.912775  2593 solver.cpp:310]     Train net output #0: loss = 0.37956 (* 1 = 0.37956 loss)
I1111 00:25:29.912797  2593 sgd_solver.cpp:106] Iteration 3321, lr = 0.00025
I1111 00:25:32.133461  2593 solver.cpp:295] Iteration 3322 (no loss supplied for SingleUpdateStep)
I1111 00:25:32.133519  2593 solver.cpp:310]     Train net output #0: loss = 0.395236 (* 1 = 0.395236 loss)
I1111 00:25:32.133538  2593 sgd_solver.cpp:106] Iteration 3322, lr = 0.00025
I1111 00:25:34.456895  2593 solver.cpp:295] Iteration 3323 (no loss supplied for SingleUpdateStep)
I1111 00:25:34.456990  2593 solver.cpp:310]     Train net output #0: loss = 0.384365 (* 1 = 0.384365 loss)
I1111 00:25:34.457011  2593 sgd_solver.cpp:106] Iteration 3323, lr = 0.00025
I1111 00:25:36.631250  2593 solver.cpp:295] Iteration 3324 (no loss supplied for SingleUpdateStep)
I1111 00:25:36.631361  2593 solver.cpp:310]     Train net output #0: loss = 0.382269 (* 1 = 0.382269 loss)
I1111 00:25:36.631384  2593 sgd_solver.cpp:106] Iteration 3324, lr = 0.00025
I1111 00:25:38.922546  2593 solver.cpp:295] Iteration 3325 (no loss supplied for SingleUpdateStep)
I1111 00:25:38.922626  2593 solver.cpp:310]     Train net output #0: loss = 0.373485 (* 1 = 0.373485 loss)
I1111 00:25:38.922647  2593 sgd_solver.cpp:106] Iteration 3325, lr = 0.00025
I1111 00:25:41.245489  2593 solver.cpp:295] Iteration 3326 (no loss supplied for SingleUpdateStep)
I1111 00:25:41.245584  2593 solver.cpp:310]     Train net output #0: loss = 0.403097 (* 1 = 0.403097 loss)
I1111 00:25:41.245606  2593 sgd_solver.cpp:106] Iteration 3326, lr = 0.00025
I1111 00:25:43.497020  2593 solver.cpp:295] Iteration 3327 (no loss supplied for SingleUpdateStep)
I1111 00:25:43.497114  2593 solver.cpp:310]     Train net output #0: loss = 0.408686 (* 1 = 0.408686 loss)
I1111 00:25:43.497134  2593 sgd_solver.cpp:106] Iteration 3327, lr = 0.00025
I1111 00:25:45.905148  2593 solver.cpp:295] Iteration 3328 (no loss supplied for SingleUpdateStep)
I1111 00:25:45.905274  2593 solver.cpp:310]     Train net output #0: loss = 0.429412 (* 1 = 0.429412 loss)
I1111 00:25:45.905300  2593 sgd_solver.cpp:106] Iteration 3328, lr = 0.00025
I1111 00:25:48.207633  2593 solver.cpp:295] Iteration 3329 (no loss supplied for SingleUpdateStep)
I1111 00:25:48.207731  2593 solver.cpp:310]     Train net output #0: loss = 0.4025 (* 1 = 0.4025 loss)
I1111 00:25:48.207751  2593 sgd_solver.cpp:106] Iteration 3329, lr = 0.00025
I1111 00:25:50.615255  2593 solver.cpp:295] Iteration 3330 (no loss supplied for SingleUpdateStep)
I1111 00:25:50.615392  2593 solver.cpp:310]     Train net output #0: loss = 0.398686 (* 1 = 0.398686 loss)
I1111 00:25:50.615414  2593 sgd_solver.cpp:106] Iteration 3330, lr = 0.00025
I1111 00:25:53.148351  2593 solver.cpp:295] Iteration 3331 (no loss supplied for SingleUpdateStep)
I1111 00:25:53.148439  2593 solver.cpp:310]     Train net output #0: loss = 0.38933 (* 1 = 0.38933 loss)
I1111 00:25:53.148461  2593 sgd_solver.cpp:106] Iteration 3331, lr = 0.00025
I1111 00:25:55.767741  2593 solver.cpp:295] Iteration 3332 (no loss supplied for SingleUpdateStep)
I1111 00:25:55.767801  2593 solver.cpp:310]     Train net output #0: loss = 0.368431 (* 1 = 0.368431 loss)
I1111 00:25:55.767818  2593 sgd_solver.cpp:106] Iteration 3332, lr = 0.00025
I1111 00:25:58.199481  2593 solver.cpp:295] Iteration 3333 (no loss supplied for SingleUpdateStep)
I1111 00:25:58.199592  2593 solver.cpp:310]     Train net output #0: loss = 0.406843 (* 1 = 0.406843 loss)
I1111 00:25:58.199631  2593 sgd_solver.cpp:106] Iteration 3333, lr = 0.00025
I1111 00:26:00.566844  2593 solver.cpp:295] Iteration 3334 (no loss supplied for SingleUpdateStep)
I1111 00:26:00.566979  2593 solver.cpp:310]     Train net output #0: loss = 0.400312 (* 1 = 0.400312 loss)
I1111 00:26:00.567008  2593 sgd_solver.cpp:106] Iteration 3334, lr = 0.00025
I1111 00:26:03.020217  2593 solver.cpp:295] Iteration 3335 (no loss supplied for SingleUpdateStep)
I1111 00:26:03.020346  2593 solver.cpp:310]     Train net output #0: loss = 0.365131 (* 1 = 0.365131 loss)
I1111 00:26:03.020376  2593 sgd_solver.cpp:106] Iteration 3335, lr = 0.00025
I1111 00:26:05.686018  2593 solver.cpp:295] Iteration 3336 (no loss supplied for SingleUpdateStep)
I1111 00:26:05.686099  2593 solver.cpp:310]     Train net output #0: loss = 0.425773 (* 1 = 0.425773 loss)
I1111 00:26:05.686121  2593 sgd_solver.cpp:106] Iteration 3336, lr = 0.00025
I1111 00:26:08.983132  2593 solver.cpp:295] Iteration 3337 (no loss supplied for SingleUpdateStep)
I1111 00:26:08.983222  2593 solver.cpp:310]     Train net output #0: loss = 0.397892 (* 1 = 0.397892 loss)
I1111 00:26:08.983242  2593 sgd_solver.cpp:106] Iteration 3337, lr = 0.00025
I1111 00:26:11.951680  2593 solver.cpp:295] Iteration 3338 (no loss supplied for SingleUpdateStep)
I1111 00:26:11.951762  2593 solver.cpp:310]     Train net output #0: loss = 0.355134 (* 1 = 0.355134 loss)
I1111 00:26:11.951782  2593 sgd_solver.cpp:106] Iteration 3338, lr = 0.00025
I1111 00:26:14.373860  2593 solver.cpp:295] Iteration 3339 (no loss supplied for SingleUpdateStep)
I1111 00:26:14.373939  2593 solver.cpp:310]     Train net output #0: loss = 0.400251 (* 1 = 0.400251 loss)
I1111 00:26:14.373960  2593 sgd_solver.cpp:106] Iteration 3339, lr = 0.00025
I1111 00:26:16.669760  2593 solver.cpp:295] Iteration 3340 (no loss supplied for SingleUpdateStep)
I1111 00:26:16.669947  2593 solver.cpp:310]     Train net output #0: loss = 0.40707 (* 1 = 0.40707 loss)
I1111 00:26:16.669982  2593 sgd_solver.cpp:106] Iteration 3340, lr = 0.00025
I1111 00:26:19.092167  2593 solver.cpp:295] Iteration 3341 (no loss supplied for SingleUpdateStep)
I1111 00:26:19.092285  2593 solver.cpp:310]     Train net output #0: loss = 0.395157 (* 1 = 0.395157 loss)
I1111 00:26:19.092321  2593 sgd_solver.cpp:106] Iteration 3341, lr = 0.00025
I1111 00:26:21.528205  2593 solver.cpp:295] Iteration 3342 (no loss supplied for SingleUpdateStep)
I1111 00:26:21.528347  2593 solver.cpp:310]     Train net output #0: loss = 0.396257 (* 1 = 0.396257 loss)
I1111 00:26:21.528383  2593 sgd_solver.cpp:106] Iteration 3342, lr = 0.00025
I1111 00:26:24.009152  2593 solver.cpp:295] Iteration 3343 (no loss supplied for SingleUpdateStep)
I1111 00:26:24.009248  2593 solver.cpp:310]     Train net output #0: loss = 0.399683 (* 1 = 0.399683 loss)
I1111 00:26:24.009270  2593 sgd_solver.cpp:106] Iteration 3343, lr = 0.00025
I1111 00:26:26.556376  2593 solver.cpp:295] Iteration 3344 (no loss supplied for SingleUpdateStep)
I1111 00:26:26.556520  2593 solver.cpp:310]     Train net output #0: loss = 0.411831 (* 1 = 0.411831 loss)
I1111 00:26:26.556555  2593 sgd_solver.cpp:106] Iteration 3344, lr = 0.00025
I1111 00:26:29.345091  2593 solver.cpp:295] Iteration 3345 (no loss supplied for SingleUpdateStep)
I1111 00:26:29.345227  2593 solver.cpp:310]     Train net output #0: loss = 0.420681 (* 1 = 0.420681 loss)
I1111 00:26:29.345252  2593 sgd_solver.cpp:106] Iteration 3345, lr = 0.00025
I1111 00:26:31.775987  2593 solver.cpp:295] Iteration 3346 (no loss supplied for SingleUpdateStep)
I1111 00:26:31.776116  2593 solver.cpp:310]     Train net output #0: loss = 0.388216 (* 1 = 0.388216 loss)
I1111 00:26:31.776139  2593 sgd_solver.cpp:106] Iteration 3346, lr = 0.00025
I1111 00:26:34.372128  2593 solver.cpp:295] Iteration 3347 (no loss supplied for SingleUpdateStep)
I1111 00:26:34.372261  2593 solver.cpp:310]     Train net output #0: loss = 0.378317 (* 1 = 0.378317 loss)
I1111 00:26:34.372282  2593 sgd_solver.cpp:106] Iteration 3347, lr = 0.00025
I1111 00:26:36.717785  2593 solver.cpp:295] Iteration 3348 (no loss supplied for SingleUpdateStep)
I1111 00:26:36.717900  2593 solver.cpp:310]     Train net output #0: loss = 0.386561 (* 1 = 0.386561 loss)
I1111 00:26:36.717921  2593 sgd_solver.cpp:106] Iteration 3348, lr = 0.00025
I1111 00:26:39.184384  2593 solver.cpp:295] Iteration 3349 (no loss supplied for SingleUpdateStep)
I1111 00:26:39.184444  2593 solver.cpp:310]     Train net output #0: loss = 0.403043 (* 1 = 0.403043 loss)
I1111 00:26:39.184465  2593 sgd_solver.cpp:106] Iteration 3349, lr = 0.00025
I1111 00:26:41.580219  2593 solver.cpp:295] Iteration 3350 (no loss supplied for SingleUpdateStep)
I1111 00:26:41.580338  2593 solver.cpp:310]     Train net output #0: loss = 0.402125 (* 1 = 0.402125 loss)
I1111 00:26:41.580363  2593 sgd_solver.cpp:106] Iteration 3350, lr = 0.00025
I1111 00:26:44.157059  2593 solver.cpp:295] Iteration 3351 (no loss supplied for SingleUpdateStep)
I1111 00:26:44.157177  2593 solver.cpp:310]     Train net output #0: loss = 0.383753 (* 1 = 0.383753 loss)
I1111 00:26:44.157202  2593 sgd_solver.cpp:106] Iteration 3351, lr = 0.00025
I1111 00:26:46.586153  2593 solver.cpp:295] Iteration 3352 (no loss supplied for SingleUpdateStep)
I1111 00:26:46.586292  2593 solver.cpp:310]     Train net output #0: loss = 0.355819 (* 1 = 0.355819 loss)
I1111 00:26:46.586318  2593 sgd_solver.cpp:106] Iteration 3352, lr = 0.00025
I1111 00:26:49.184041  2593 solver.cpp:295] Iteration 3353 (no loss supplied for SingleUpdateStep)
I1111 00:26:49.184186  2593 solver.cpp:310]     Train net output #0: loss = 0.414813 (* 1 = 0.414813 loss)
I1111 00:26:49.184207  2593 sgd_solver.cpp:106] Iteration 3353, lr = 0.00025
I1111 00:26:51.743985  2593 solver.cpp:295] Iteration 3354 (no loss supplied for SingleUpdateStep)
I1111 00:26:51.744112  2593 solver.cpp:310]     Train net output #0: loss = 0.383722 (* 1 = 0.383722 loss)
I1111 00:26:51.744135  2593 sgd_solver.cpp:106] Iteration 3354, lr = 0.00025
I1111 00:26:54.199942  2593 solver.cpp:295] Iteration 3355 (no loss supplied for SingleUpdateStep)
I1111 00:26:54.200001  2593 solver.cpp:310]     Train net output #0: loss = 0.398273 (* 1 = 0.398273 loss)
I1111 00:26:54.200019  2593 sgd_solver.cpp:106] Iteration 3355, lr = 0.00025
I1111 00:26:57.090678  2593 solver.cpp:295] Iteration 3356 (no loss supplied for SingleUpdateStep)
I1111 00:26:57.090808  2593 solver.cpp:310]     Train net output #0: loss = 0.404297 (* 1 = 0.404297 loss)
I1111 00:26:57.090836  2593 sgd_solver.cpp:106] Iteration 3356, lr = 0.00025
I1111 00:26:59.914397  2593 solver.cpp:295] Iteration 3357 (no loss supplied for SingleUpdateStep)
I1111 00:26:59.914559  2593 solver.cpp:310]     Train net output #0: loss = 0.379948 (* 1 = 0.379948 loss)
I1111 00:26:59.914592  2593 sgd_solver.cpp:106] Iteration 3357, lr = 0.00025
I1111 00:27:02.565644  2593 solver.cpp:295] Iteration 3358 (no loss supplied for SingleUpdateStep)
I1111 00:27:02.565729  2593 solver.cpp:310]     Train net output #0: loss = 0.395986 (* 1 = 0.395986 loss)
I1111 00:27:02.565752  2593 sgd_solver.cpp:106] Iteration 3358, lr = 0.00025
I1111 00:27:05.181161  2593 solver.cpp:295] Iteration 3359 (no loss supplied for SingleUpdateStep)
I1111 00:27:05.181236  2593 solver.cpp:310]     Train net output #0: loss = 0.382351 (* 1 = 0.382351 loss)
I1111 00:27:05.181255  2593 sgd_solver.cpp:106] Iteration 3359, lr = 0.00025
I1111 00:27:07.767585  2593 solver.cpp:295] Iteration 3360 (no loss supplied for SingleUpdateStep)
I1111 00:27:07.767748  2593 solver.cpp:310]     Train net output #0: loss = 0.403777 (* 1 = 0.403777 loss)
I1111 00:27:07.767776  2593 sgd_solver.cpp:106] Iteration 3360, lr = 0.00025
I1111 00:27:10.243084  2593 solver.cpp:295] Iteration 3361 (no loss supplied for SingleUpdateStep)
I1111 00:27:10.243170  2593 solver.cpp:310]     Train net output #0: loss = 0.386908 (* 1 = 0.386908 loss)
I1111 00:27:10.243190  2593 sgd_solver.cpp:106] Iteration 3361, lr = 0.00025
I1111 00:27:12.715647  2593 solver.cpp:295] Iteration 3362 (no loss supplied for SingleUpdateStep)
I1111 00:27:12.715739  2593 solver.cpp:310]     Train net output #0: loss = 0.414398 (* 1 = 0.414398 loss)
I1111 00:27:12.715765  2593 sgd_solver.cpp:106] Iteration 3362, lr = 0.00025
I1111 00:27:16.037428  2593 solver.cpp:295] Iteration 3363 (no loss supplied for SingleUpdateStep)
I1111 00:27:16.037544  2593 solver.cpp:310]     Train net output #0: loss = 0.397445 (* 1 = 0.397445 loss)
I1111 00:27:16.037565  2593 sgd_solver.cpp:106] Iteration 3363, lr = 0.00025
I1111 00:27:18.847445  2593 solver.cpp:295] Iteration 3364 (no loss supplied for SingleUpdateStep)
I1111 00:27:18.847587  2593 solver.cpp:310]     Train net output #0: loss = 0.412047 (* 1 = 0.412047 loss)
I1111 00:27:18.847618  2593 sgd_solver.cpp:106] Iteration 3364, lr = 0.00025
I1111 00:27:21.239389  2593 solver.cpp:295] Iteration 3365 (no loss supplied for SingleUpdateStep)
I1111 00:27:21.239462  2593 solver.cpp:310]     Train net output #0: loss = 0.387415 (* 1 = 0.387415 loss)
I1111 00:27:21.239485  2593 sgd_solver.cpp:106] Iteration 3365, lr = 0.00025
I1111 00:27:23.534562  2593 solver.cpp:295] Iteration 3366 (no loss supplied for SingleUpdateStep)
I1111 00:27:23.534632  2593 solver.cpp:310]     Train net output #0: loss = 0.383748 (* 1 = 0.383748 loss)
I1111 00:27:23.534653  2593 sgd_solver.cpp:106] Iteration 3366, lr = 0.00025
I1111 00:27:25.901139  2593 solver.cpp:295] Iteration 3367 (no loss supplied for SingleUpdateStep)
I1111 00:27:25.901238  2593 solver.cpp:310]     Train net output #0: loss = 0.376499 (* 1 = 0.376499 loss)
I1111 00:27:25.901258  2593 sgd_solver.cpp:106] Iteration 3367, lr = 0.00025
I1111 00:27:28.466639  2593 solver.cpp:295] Iteration 3368 (no loss supplied for SingleUpdateStep)
I1111 00:27:28.466747  2593 solver.cpp:310]     Train net output #0: loss = 0.397666 (* 1 = 0.397666 loss)
I1111 00:27:28.466769  2593 sgd_solver.cpp:106] Iteration 3368, lr = 0.00025
I1111 00:27:30.830778  2593 solver.cpp:295] Iteration 3369 (no loss supplied for SingleUpdateStep)
I1111 00:27:30.830883  2593 solver.cpp:310]     Train net output #0: loss = 0.41254 (* 1 = 0.41254 loss)
I1111 00:27:30.830903  2593 sgd_solver.cpp:106] Iteration 3369, lr = 0.00025
I1111 00:27:33.215430  2593 solver.cpp:295] Iteration 3370 (no loss supplied for SingleUpdateStep)
I1111 00:27:33.215519  2593 solver.cpp:310]     Train net output #0: loss = 0.373476 (* 1 = 0.373476 loss)
I1111 00:27:33.215540  2593 sgd_solver.cpp:106] Iteration 3370, lr = 0.00025
I1111 00:27:36.833595  2593 solver.cpp:295] Iteration 3371 (no loss supplied for SingleUpdateStep)
I1111 00:27:36.833735  2593 solver.cpp:310]     Train net output #0: loss = 0.382388 (* 1 = 0.382388 loss)
I1111 00:27:36.833765  2593 sgd_solver.cpp:106] Iteration 3371, lr = 0.00025
I1111 00:27:41.141248  2593 solver.cpp:295] Iteration 3372 (no loss supplied for SingleUpdateStep)
I1111 00:27:41.141371  2593 solver.cpp:310]     Train net output #0: loss = 0.400702 (* 1 = 0.400702 loss)
I1111 00:27:41.141391  2593 sgd_solver.cpp:106] Iteration 3372, lr = 0.00025
I1111 00:27:44.889953  2593 solver.cpp:295] Iteration 3373 (no loss supplied for SingleUpdateStep)
I1111 00:27:44.890113  2593 solver.cpp:310]     Train net output #0: loss = 0.414389 (* 1 = 0.414389 loss)
I1111 00:27:44.890142  2593 sgd_solver.cpp:106] Iteration 3373, lr = 0.00025
I1111 00:27:48.510167  2593 solver.cpp:295] Iteration 3374 (no loss supplied for SingleUpdateStep)
I1111 00:27:48.510222  2593 solver.cpp:310]     Train net output #0: loss = 0.415235 (* 1 = 0.415235 loss)
I1111 00:27:48.510241  2593 sgd_solver.cpp:106] Iteration 3374, lr = 0.00025
I1111 00:27:51.098399  2593 solver.cpp:295] Iteration 3375 (no loss supplied for SingleUpdateStep)
I1111 00:27:51.098495  2593 solver.cpp:310]     Train net output #0: loss = 0.406556 (* 1 = 0.406556 loss)
I1111 00:27:51.098517  2593 sgd_solver.cpp:106] Iteration 3375, lr = 0.00025
I1111 00:27:53.503367  2593 solver.cpp:295] Iteration 3376 (no loss supplied for SingleUpdateStep)
I1111 00:27:53.503484  2593 solver.cpp:310]     Train net output #0: loss = 0.420056 (* 1 = 0.420056 loss)
I1111 00:27:53.503509  2593 sgd_solver.cpp:106] Iteration 3376, lr = 0.00025
I1111 00:27:55.931047  2593 solver.cpp:295] Iteration 3377 (no loss supplied for SingleUpdateStep)
I1111 00:27:55.931179  2593 solver.cpp:310]     Train net output #0: loss = 0.39264 (* 1 = 0.39264 loss)
I1111 00:27:55.931203  2593 sgd_solver.cpp:106] Iteration 3377, lr = 0.00025
I1111 00:27:58.236754  2593 solver.cpp:295] Iteration 3378 (no loss supplied for SingleUpdateStep)
I1111 00:27:58.236825  2593 solver.cpp:310]     Train net output #0: loss = 0.393447 (* 1 = 0.393447 loss)
I1111 00:27:58.236845  2593 sgd_solver.cpp:106] Iteration 3378, lr = 0.00025
I1111 00:28:00.536558  2593 solver.cpp:295] Iteration 3379 (no loss supplied for SingleUpdateStep)
I1111 00:28:00.536636  2593 solver.cpp:310]     Train net output #0: loss = 0.389245 (* 1 = 0.389245 loss)
I1111 00:28:00.536659  2593 sgd_solver.cpp:106] Iteration 3379, lr = 0.00025
I1111 00:28:02.962266  2593 solver.cpp:295] Iteration 3380 (no loss supplied for SingleUpdateStep)
I1111 00:28:02.962381  2593 solver.cpp:310]     Train net output #0: loss = 0.395138 (* 1 = 0.395138 loss)
I1111 00:28:02.962405  2593 sgd_solver.cpp:106] Iteration 3380, lr = 0.00025
I1111 00:28:05.241590  2593 solver.cpp:295] Iteration 3381 (no loss supplied for SingleUpdateStep)
I1111 00:28:05.241685  2593 solver.cpp:310]     Train net output #0: loss = 0.411113 (* 1 = 0.411113 loss)
I1111 00:28:05.241706  2593 sgd_solver.cpp:106] Iteration 3381, lr = 0.00025
I1111 00:28:07.742558  2593 solver.cpp:295] Iteration 3382 (no loss supplied for SingleUpdateStep)
I1111 00:28:07.742779  2593 solver.cpp:310]     Train net output #0: loss = 0.379939 (* 1 = 0.379939 loss)
I1111 00:28:07.742815  2593 sgd_solver.cpp:106] Iteration 3382, lr = 0.00025
I1111 00:28:10.099825  2593 solver.cpp:295] Iteration 3383 (no loss supplied for SingleUpdateStep)
I1111 00:28:10.099946  2593 solver.cpp:310]     Train net output #0: loss = 0.364968 (* 1 = 0.364968 loss)
I1111 00:28:10.099967  2593 sgd_solver.cpp:106] Iteration 3383, lr = 0.00025
I1111 00:28:12.372315  2593 solver.cpp:295] Iteration 3384 (no loss supplied for SingleUpdateStep)
I1111 00:28:12.372422  2593 solver.cpp:310]     Train net output #0: loss = 0.414135 (* 1 = 0.414135 loss)
I1111 00:28:12.372442  2593 sgd_solver.cpp:106] Iteration 3384, lr = 0.00025
I1111 00:28:14.559855  2593 solver.cpp:295] Iteration 3385 (no loss supplied for SingleUpdateStep)
I1111 00:28:14.560096  2593 solver.cpp:310]     Train net output #0: loss = 0.370603 (* 1 = 0.370603 loss)
I1111 00:28:14.560123  2593 sgd_solver.cpp:106] Iteration 3385, lr = 0.00025
I1111 00:28:16.891273  2593 solver.cpp:295] Iteration 3386 (no loss supplied for SingleUpdateStep)
I1111 00:28:16.891437  2593 solver.cpp:310]     Train net output #0: loss = 0.379007 (* 1 = 0.379007 loss)
I1111 00:28:16.891469  2593 sgd_solver.cpp:106] Iteration 3386, lr = 0.00025
I1111 00:28:19.222527  2593 solver.cpp:295] Iteration 3387 (no loss supplied for SingleUpdateStep)
I1111 00:28:19.222579  2593 solver.cpp:310]     Train net output #0: loss = 0.39302 (* 1 = 0.39302 loss)
I1111 00:28:19.222599  2593 sgd_solver.cpp:106] Iteration 3387, lr = 0.00025
I1111 00:28:21.684732  2593 solver.cpp:295] Iteration 3388 (no loss supplied for SingleUpdateStep)
I1111 00:28:21.684866  2593 solver.cpp:310]     Train net output #0: loss = 0.38718 (* 1 = 0.38718 loss)
I1111 00:28:21.684896  2593 sgd_solver.cpp:106] Iteration 3388, lr = 0.00025
I1111 00:28:24.045080  2593 solver.cpp:295] Iteration 3389 (no loss supplied for SingleUpdateStep)
I1111 00:28:24.045194  2593 solver.cpp:310]     Train net output #0: loss = 0.422084 (* 1 = 0.422084 loss)
I1111 00:28:24.045217  2593 sgd_solver.cpp:106] Iteration 3389, lr = 0.00025
I1111 00:28:26.754276  2593 solver.cpp:295] Iteration 3390 (no loss supplied for SingleUpdateStep)
I1111 00:28:26.754403  2593 solver.cpp:310]     Train net output #0: loss = 0.414501 (* 1 = 0.414501 loss)
I1111 00:28:26.754426  2593 sgd_solver.cpp:106] Iteration 3390, lr = 0.00025
I1111 00:28:28.892786  2593 solver.cpp:295] Iteration 3391 (no loss supplied for SingleUpdateStep)
I1111 00:28:28.892864  2593 solver.cpp:310]     Train net output #0: loss = 0.387527 (* 1 = 0.387527 loss)
I1111 00:28:28.892884  2593 sgd_solver.cpp:106] Iteration 3391, lr = 0.00025
I1111 00:28:31.298099  2593 solver.cpp:295] Iteration 3392 (no loss supplied for SingleUpdateStep)
I1111 00:28:31.298251  2593 solver.cpp:310]     Train net output #0: loss = 0.389911 (* 1 = 0.389911 loss)
I1111 00:28:31.298274  2593 sgd_solver.cpp:106] Iteration 3392, lr = 0.00025
I1111 00:28:33.750867  2593 solver.cpp:295] Iteration 3393 (no loss supplied for SingleUpdateStep)
I1111 00:28:33.751013  2593 solver.cpp:310]     Train net output #0: loss = 0.38994 (* 1 = 0.38994 loss)
I1111 00:28:33.751047  2593 sgd_solver.cpp:106] Iteration 3393, lr = 0.00025
I1111 00:28:36.429296  2593 solver.cpp:295] Iteration 3394 (no loss supplied for SingleUpdateStep)
I1111 00:28:36.429411  2593 solver.cpp:310]     Train net output #0: loss = 0.383492 (* 1 = 0.383492 loss)
I1111 00:28:36.429431  2593 sgd_solver.cpp:106] Iteration 3394, lr = 0.00025
I1111 00:28:39.892431  2593 solver.cpp:295] Iteration 3395 (no loss supplied for SingleUpdateStep)
I1111 00:28:39.892557  2593 solver.cpp:310]     Train net output #0: loss = 0.437331 (* 1 = 0.437331 loss)
I1111 00:28:39.892580  2593 sgd_solver.cpp:106] Iteration 3395, lr = 0.00025
I1111 00:28:43.450233  2593 solver.cpp:295] Iteration 3396 (no loss supplied for SingleUpdateStep)
I1111 00:28:43.450374  2593 solver.cpp:310]     Train net output #0: loss = 0.38285 (* 1 = 0.38285 loss)
I1111 00:28:43.450397  2593 sgd_solver.cpp:106] Iteration 3396, lr = 0.00025
I1111 00:28:46.044198  2593 solver.cpp:295] Iteration 3397 (no loss supplied for SingleUpdateStep)
I1111 00:28:46.044320  2593 solver.cpp:310]     Train net output #0: loss = 0.384789 (* 1 = 0.384789 loss)
I1111 00:28:46.044347  2593 sgd_solver.cpp:106] Iteration 3397, lr = 0.00025
I1111 00:28:48.325791  2593 solver.cpp:295] Iteration 3398 (no loss supplied for SingleUpdateStep)
I1111 00:28:48.325896  2593 solver.cpp:310]     Train net output #0: loss = 0.391737 (* 1 = 0.391737 loss)
I1111 00:28:48.325920  2593 sgd_solver.cpp:106] Iteration 3398, lr = 0.00025
I1111 00:28:50.755625  2593 solver.cpp:295] Iteration 3399 (no loss supplied for SingleUpdateStep)
I1111 00:28:50.755748  2593 solver.cpp:310]     Train net output #0: loss = 0.390094 (* 1 = 0.390094 loss)
I1111 00:28:50.755772  2593 sgd_solver.cpp:106] Iteration 3399, lr = 0.00025
I1111 00:28:53.069686  2593 solver.cpp:295] Iteration 3400 (no loss supplied for SingleUpdateStep)
I1111 00:28:53.069797  2593 solver.cpp:310]     Train net output #0: loss = 0.401496 (* 1 = 0.401496 loss)
I1111 00:28:53.069820  2593 sgd_solver.cpp:106] Iteration 3400, lr = 0.00025
I1111 00:28:55.557946  2593 solver.cpp:295] Iteration 3401 (no loss supplied for SingleUpdateStep)
I1111 00:28:55.558061  2593 solver.cpp:310]     Train net output #0: loss = 0.401295 (* 1 = 0.401295 loss)
I1111 00:28:55.558084  2593 sgd_solver.cpp:106] Iteration 3401, lr = 0.00025
I1111 00:28:57.957640  2593 solver.cpp:295] Iteration 3402 (no loss supplied for SingleUpdateStep)
I1111 00:28:57.957748  2593 solver.cpp:310]     Train net output #0: loss = 0.383691 (* 1 = 0.383691 loss)
I1111 00:28:57.957775  2593 sgd_solver.cpp:106] Iteration 3402, lr = 0.00025
I1111 00:29:00.430157  2593 solver.cpp:295] Iteration 3403 (no loss supplied for SingleUpdateStep)
I1111 00:29:00.430266  2593 solver.cpp:310]     Train net output #0: loss = 0.424187 (* 1 = 0.424187 loss)
I1111 00:29:00.430290  2593 sgd_solver.cpp:106] Iteration 3403, lr = 0.00025
I1111 00:29:02.747444  2593 solver.cpp:295] Iteration 3404 (no loss supplied for SingleUpdateStep)
I1111 00:29:02.747522  2593 solver.cpp:310]     Train net output #0: loss = 0.390156 (* 1 = 0.390156 loss)
I1111 00:29:02.747542  2593 sgd_solver.cpp:106] Iteration 3404, lr = 0.00025
I1111 00:29:05.167193  2593 solver.cpp:295] Iteration 3405 (no loss supplied for SingleUpdateStep)
I1111 00:29:05.167333  2593 solver.cpp:310]     Train net output #0: loss = 0.376889 (* 1 = 0.376889 loss)
I1111 00:29:05.167356  2593 sgd_solver.cpp:106] Iteration 3405, lr = 0.00025
I1111 00:29:07.413745  2593 solver.cpp:295] Iteration 3406 (no loss supplied for SingleUpdateStep)
I1111 00:29:07.413847  2593 solver.cpp:310]     Train net output #0: loss = 0.404998 (* 1 = 0.404998 loss)
I1111 00:29:07.413868  2593 sgd_solver.cpp:106] Iteration 3406, lr = 0.00025
I1111 00:29:09.589984  2593 solver.cpp:295] Iteration 3407 (no loss supplied for SingleUpdateStep)
I1111 00:29:09.590096  2593 solver.cpp:310]     Train net output #0: loss = 0.395902 (* 1 = 0.395902 loss)
I1111 00:29:09.590121  2593 sgd_solver.cpp:106] Iteration 3407, lr = 0.00025
I1111 00:29:11.921967  2593 solver.cpp:295] Iteration 3408 (no loss supplied for SingleUpdateStep)
I1111 00:29:11.922027  2593 solver.cpp:310]     Train net output #0: loss = 0.39253 (* 1 = 0.39253 loss)
I1111 00:29:11.922045  2593 sgd_solver.cpp:106] Iteration 3408, lr = 0.00025
I1111 00:29:14.286507  2593 solver.cpp:295] Iteration 3409 (no loss supplied for SingleUpdateStep)
I1111 00:29:14.286641  2593 solver.cpp:310]     Train net output #0: loss = 0.372179 (* 1 = 0.372179 loss)
I1111 00:29:14.286667  2593 sgd_solver.cpp:106] Iteration 3409, lr = 0.00025
I1111 00:29:16.662370  2593 solver.cpp:295] Iteration 3410 (no loss supplied for SingleUpdateStep)
I1111 00:29:16.662475  2593 solver.cpp:310]     Train net output #0: loss = 0.352395 (* 1 = 0.352395 loss)
I1111 00:29:16.662499  2593 sgd_solver.cpp:106] Iteration 3410, lr = 0.00025
I1111 00:29:18.889639  2593 solver.cpp:295] Iteration 3411 (no loss supplied for SingleUpdateStep)
I1111 00:29:18.889696  2593 solver.cpp:310]     Train net output #0: loss = 0.35493 (* 1 = 0.35493 loss)
I1111 00:29:18.889715  2593 sgd_solver.cpp:106] Iteration 3411, lr = 0.00025
I1111 00:29:21.030709  2593 solver.cpp:295] Iteration 3412 (no loss supplied for SingleUpdateStep)
I1111 00:29:21.030833  2593 solver.cpp:310]     Train net output #0: loss = 0.401091 (* 1 = 0.401091 loss)
I1111 00:29:21.030855  2593 sgd_solver.cpp:106] Iteration 3412, lr = 0.00025
I1111 00:29:23.381902  2593 solver.cpp:295] Iteration 3413 (no loss supplied for SingleUpdateStep)
I1111 00:29:23.382010  2593 solver.cpp:310]     Train net output #0: loss = 0.372512 (* 1 = 0.372512 loss)
I1111 00:29:23.382032  2593 sgd_solver.cpp:106] Iteration 3413, lr = 0.00025
I1111 00:29:25.480896  2593 solver.cpp:295] Iteration 3414 (no loss supplied for SingleUpdateStep)
I1111 00:29:25.481003  2593 solver.cpp:310]     Train net output #0: loss = 0.391413 (* 1 = 0.391413 loss)
I1111 00:29:25.481025  2593 sgd_solver.cpp:106] Iteration 3414, lr = 0.00025
I1111 00:29:27.713886  2593 solver.cpp:295] Iteration 3415 (no loss supplied for SingleUpdateStep)
I1111 00:29:27.714009  2593 solver.cpp:310]     Train net output #0: loss = 0.396848 (* 1 = 0.396848 loss)
I1111 00:29:27.714031  2593 sgd_solver.cpp:106] Iteration 3415, lr = 0.00025
I1111 00:29:29.957113  2593 solver.cpp:295] Iteration 3416 (no loss supplied for SingleUpdateStep)
I1111 00:29:29.957211  2593 solver.cpp:310]     Train net output #0: loss = 0.40444 (* 1 = 0.40444 loss)
I1111 00:29:29.957231  2593 sgd_solver.cpp:106] Iteration 3416, lr = 0.00025
I1111 00:29:32.027650  2593 solver.cpp:295] Iteration 3417 (no loss supplied for SingleUpdateStep)
I1111 00:29:32.027731  2593 solver.cpp:310]     Train net output #0: loss = 0.375327 (* 1 = 0.375327 loss)
I1111 00:29:32.027751  2593 sgd_solver.cpp:106] Iteration 3417, lr = 0.00025
I1111 00:29:34.459125  2593 solver.cpp:295] Iteration 3418 (no loss supplied for SingleUpdateStep)
I1111 00:29:34.459189  2593 solver.cpp:310]     Train net output #0: loss = 0.391952 (* 1 = 0.391952 loss)
I1111 00:29:34.459208  2593 sgd_solver.cpp:106] Iteration 3418, lr = 0.00025
I1111 00:29:36.702106  2593 solver.cpp:295] Iteration 3419 (no loss supplied for SingleUpdateStep)
I1111 00:29:36.702239  2593 solver.cpp:310]     Train net output #0: loss = 0.406787 (* 1 = 0.406787 loss)
I1111 00:29:36.702266  2593 sgd_solver.cpp:106] Iteration 3419, lr = 0.00025
I1111 00:29:38.909843  2593 solver.cpp:295] Iteration 3420 (no loss supplied for SingleUpdateStep)
I1111 00:29:38.909977  2593 solver.cpp:310]     Train net output #0: loss = 0.388027 (* 1 = 0.388027 loss)
I1111 00:29:38.910003  2593 sgd_solver.cpp:106] Iteration 3420, lr = 0.00025
I1111 00:29:41.204948  2593 solver.cpp:295] Iteration 3421 (no loss supplied for SingleUpdateStep)
I1111 00:29:41.205085  2593 solver.cpp:310]     Train net output #0: loss = 0.406392 (* 1 = 0.406392 loss)
I1111 00:29:41.205111  2593 sgd_solver.cpp:106] Iteration 3421, lr = 0.00025
I1111 00:29:43.437150  2593 solver.cpp:295] Iteration 3422 (no loss supplied for SingleUpdateStep)
I1111 00:29:43.437218  2593 solver.cpp:310]     Train net output #0: loss = 0.401557 (* 1 = 0.401557 loss)
I1111 00:29:43.437238  2593 sgd_solver.cpp:106] Iteration 3422, lr = 0.00025
I1111 00:29:45.951107  2593 solver.cpp:295] Iteration 3423 (no loss supplied for SingleUpdateStep)
I1111 00:29:45.951202  2593 solver.cpp:310]     Train net output #0: loss = 0.355438 (* 1 = 0.355438 loss)
I1111 00:29:45.951223  2593 sgd_solver.cpp:106] Iteration 3423, lr = 0.00025
I1111 00:29:48.483341  2593 solver.cpp:295] Iteration 3424 (no loss supplied for SingleUpdateStep)
I1111 00:29:48.483448  2593 solver.cpp:310]     Train net output #0: loss = 0.391086 (* 1 = 0.391086 loss)
I1111 00:29:48.483471  2593 sgd_solver.cpp:106] Iteration 3424, lr = 0.00025
I1111 00:29:51.249094  2593 solver.cpp:295] Iteration 3425 (no loss supplied for SingleUpdateStep)
I1111 00:29:51.249161  2593 solver.cpp:310]     Train net output #0: loss = 0.418798 (* 1 = 0.418798 loss)
I1111 00:29:51.249178  2593 sgd_solver.cpp:106] Iteration 3425, lr = 0.00025
I1111 00:29:53.572468  2593 solver.cpp:295] Iteration 3426 (no loss supplied for SingleUpdateStep)
I1111 00:29:53.572592  2593 solver.cpp:310]     Train net output #0: loss = 0.390698 (* 1 = 0.390698 loss)
I1111 00:29:53.572619  2593 sgd_solver.cpp:106] Iteration 3426, lr = 0.00025
I1111 00:29:56.064849  2593 solver.cpp:295] Iteration 3427 (no loss supplied for SingleUpdateStep)
I1111 00:29:56.064967  2593 solver.cpp:310]     Train net output #0: loss = 0.371429 (* 1 = 0.371429 loss)
I1111 00:29:56.064991  2593 sgd_solver.cpp:106] Iteration 3427, lr = 0.00025
I1111 00:29:58.531608  2593 solver.cpp:295] Iteration 3428 (no loss supplied for SingleUpdateStep)
I1111 00:29:58.531685  2593 solver.cpp:310]     Train net output #0: loss = 0.402517 (* 1 = 0.402517 loss)
I1111 00:29:58.531705  2593 sgd_solver.cpp:106] Iteration 3428, lr = 0.00025
I1111 00:30:00.954944  2593 solver.cpp:295] Iteration 3429 (no loss supplied for SingleUpdateStep)
I1111 00:30:00.955034  2593 solver.cpp:310]     Train net output #0: loss = 0.406466 (* 1 = 0.406466 loss)
I1111 00:30:00.955055  2593 sgd_solver.cpp:106] Iteration 3429, lr = 0.00025
I1111 00:30:03.470757  2593 solver.cpp:295] Iteration 3430 (no loss supplied for SingleUpdateStep)
I1111 00:30:03.470877  2593 solver.cpp:310]     Train net output #0: loss = 0.397807 (* 1 = 0.397807 loss)
I1111 00:30:03.470901  2593 sgd_solver.cpp:106] Iteration 3430, lr = 0.00025
I1111 00:30:05.828032  2593 solver.cpp:295] Iteration 3431 (no loss supplied for SingleUpdateStep)
I1111 00:30:05.828086  2593 solver.cpp:310]     Train net output #0: loss = 0.400991 (* 1 = 0.400991 loss)
I1111 00:30:05.828104  2593 sgd_solver.cpp:106] Iteration 3431, lr = 0.00025
I1111 00:30:08.686310  2593 solver.cpp:295] Iteration 3432 (no loss supplied for SingleUpdateStep)
I1111 00:30:08.686399  2593 solver.cpp:310]     Train net output #0: loss = 0.391654 (* 1 = 0.391654 loss)
I1111 00:30:08.686421  2593 sgd_solver.cpp:106] Iteration 3432, lr = 0.00025
I1111 00:30:11.478005  2593 solver.cpp:295] Iteration 3433 (no loss supplied for SingleUpdateStep)
I1111 00:30:11.478139  2593 solver.cpp:310]     Train net output #0: loss = 0.383018 (* 1 = 0.383018 loss)
I1111 00:30:11.478162  2593 sgd_solver.cpp:106] Iteration 3433, lr = 0.00025
I1111 00:30:13.848455  2593 solver.cpp:295] Iteration 3434 (no loss supplied for SingleUpdateStep)
I1111 00:30:13.848553  2593 solver.cpp:310]     Train net output #0: loss = 0.388465 (* 1 = 0.388465 loss)
I1111 00:30:13.848577  2593 sgd_solver.cpp:106] Iteration 3434, lr = 0.00025
I1111 00:30:16.248679  2593 solver.cpp:295] Iteration 3435 (no loss supplied for SingleUpdateStep)
I1111 00:30:16.248759  2593 solver.cpp:310]     Train net output #0: loss = 0.394888 (* 1 = 0.394888 loss)
I1111 00:30:16.248778  2593 sgd_solver.cpp:106] Iteration 3435, lr = 0.00025
I1111 00:30:18.811467  2593 solver.cpp:295] Iteration 3436 (no loss supplied for SingleUpdateStep)
I1111 00:30:18.811545  2593 solver.cpp:310]     Train net output #0: loss = 0.411457 (* 1 = 0.411457 loss)
I1111 00:30:18.811566  2593 sgd_solver.cpp:106] Iteration 3436, lr = 0.00025
I1111 00:30:21.243948  2593 solver.cpp:295] Iteration 3437 (no loss supplied for SingleUpdateStep)
I1111 00:30:21.244112  2593 solver.cpp:310]     Train net output #0: loss = 0.397274 (* 1 = 0.397274 loss)
I1111 00:30:21.244137  2593 sgd_solver.cpp:106] Iteration 3437, lr = 0.00025
I1111 00:30:23.805802  2593 solver.cpp:295] Iteration 3438 (no loss supplied for SingleUpdateStep)
I1111 00:30:23.805923  2593 solver.cpp:310]     Train net output #0: loss = 0.38292 (* 1 = 0.38292 loss)
I1111 00:30:23.805948  2593 sgd_solver.cpp:106] Iteration 3438, lr = 0.00025
I1111 00:30:26.159499  2593 solver.cpp:295] Iteration 3439 (no loss supplied for SingleUpdateStep)
I1111 00:30:26.159607  2593 solver.cpp:310]     Train net output #0: loss = 0.386264 (* 1 = 0.386264 loss)
I1111 00:30:26.159631  2593 sgd_solver.cpp:106] Iteration 3439, lr = 0.00025
I1111 00:30:28.702461  2593 solver.cpp:295] Iteration 3440 (no loss supplied for SingleUpdateStep)
I1111 00:30:28.702560  2593 solver.cpp:310]     Train net output #0: loss = 0.394943 (* 1 = 0.394943 loss)
I1111 00:30:28.702581  2593 sgd_solver.cpp:106] Iteration 3440, lr = 0.00025
I1111 00:30:31.340020  2593 solver.cpp:295] Iteration 3441 (no loss supplied for SingleUpdateStep)
I1111 00:30:31.340157  2593 solver.cpp:310]     Train net output #0: loss = 0.416984 (* 1 = 0.416984 loss)
I1111 00:30:31.340184  2593 sgd_solver.cpp:106] Iteration 3441, lr = 0.00025
I1111 00:30:33.832471  2593 solver.cpp:295] Iteration 3442 (no loss supplied for SingleUpdateStep)
I1111 00:30:33.832561  2593 solver.cpp:310]     Train net output #0: loss = 0.443691 (* 1 = 0.443691 loss)
I1111 00:30:33.832581  2593 sgd_solver.cpp:106] Iteration 3442, lr = 0.00025
I1111 00:30:36.328644  2593 solver.cpp:295] Iteration 3443 (no loss supplied for SingleUpdateStep)
I1111 00:30:36.328760  2593 solver.cpp:310]     Train net output #0: loss = 0.418025 (* 1 = 0.418025 loss)
I1111 00:30:36.328786  2593 sgd_solver.cpp:106] Iteration 3443, lr = 0.00025
I1111 00:30:38.845320  2593 solver.cpp:295] Iteration 3444 (no loss supplied for SingleUpdateStep)
I1111 00:30:38.845441  2593 solver.cpp:310]     Train net output #0: loss = 0.441332 (* 1 = 0.441332 loss)
I1111 00:30:38.845471  2593 sgd_solver.cpp:106] Iteration 3444, lr = 0.00025
I1111 00:30:41.306974  2593 solver.cpp:295] Iteration 3445 (no loss supplied for SingleUpdateStep)
I1111 00:30:41.307030  2593 solver.cpp:310]     Train net output #0: loss = 0.39945 (* 1 = 0.39945 loss)
I1111 00:30:41.307049  2593 sgd_solver.cpp:106] Iteration 3445, lr = 0.00025
I1111 00:30:43.789633  2593 solver.cpp:295] Iteration 3446 (no loss supplied for SingleUpdateStep)
I1111 00:30:43.789685  2593 solver.cpp:310]     Train net output #0: loss = 0.388759 (* 1 = 0.388759 loss)
I1111 00:30:43.789711  2593 sgd_solver.cpp:106] Iteration 3446, lr = 0.00025
I1111 00:30:46.396905  2593 solver.cpp:295] Iteration 3447 (no loss supplied for SingleUpdateStep)
I1111 00:30:46.396971  2593 solver.cpp:310]     Train net output #0: loss = 0.388221 (* 1 = 0.388221 loss)
I1111 00:30:46.396989  2593 sgd_solver.cpp:106] Iteration 3447, lr = 0.00025
I1111 00:30:48.853811  2593 solver.cpp:295] Iteration 3448 (no loss supplied for SingleUpdateStep)
I1111 00:30:48.853952  2593 solver.cpp:310]     Train net output #0: loss = 0.388769 (* 1 = 0.388769 loss)
I1111 00:30:48.853983  2593 sgd_solver.cpp:106] Iteration 3448, lr = 0.00025
I1111 00:30:51.244736  2593 solver.cpp:295] Iteration 3449 (no loss supplied for SingleUpdateStep)
I1111 00:30:51.244868  2593 solver.cpp:310]     Train net output #0: loss = 0.430871 (* 1 = 0.430871 loss)
I1111 00:30:51.244894  2593 sgd_solver.cpp:106] Iteration 3449, lr = 0.00025
I1111 00:30:53.537482  2593 solver.cpp:295] Iteration 3450 (no loss supplied for SingleUpdateStep)
I1111 00:30:53.537549  2593 solver.cpp:310]     Train net output #0: loss = 0.401608 (* 1 = 0.401608 loss)
I1111 00:30:53.537567  2593 sgd_solver.cpp:106] Iteration 3450, lr = 0.00025
I1111 00:30:55.828027  2593 solver.cpp:295] Iteration 3451 (no loss supplied for SingleUpdateStep)
I1111 00:30:55.828151  2593 solver.cpp:310]     Train net output #0: loss = 0.390533 (* 1 = 0.390533 loss)
I1111 00:30:55.828177  2593 sgd_solver.cpp:106] Iteration 3451, lr = 0.00025
I1111 00:30:58.209424  2593 solver.cpp:295] Iteration 3452 (no loss supplied for SingleUpdateStep)
I1111 00:30:58.209534  2593 solver.cpp:310]     Train net output #0: loss = 0.378552 (* 1 = 0.378552 loss)
I1111 00:30:58.209558  2593 sgd_solver.cpp:106] Iteration 3452, lr = 0.00025
I1111 00:31:00.507771  2593 solver.cpp:295] Iteration 3453 (no loss supplied for SingleUpdateStep)
I1111 00:31:00.508364  2593 solver.cpp:310]     Train net output #0: loss = 0.395322 (* 1 = 0.395322 loss)
I1111 00:31:00.508390  2593 sgd_solver.cpp:106] Iteration 3453, lr = 0.00025
I1111 00:31:02.936672  2593 solver.cpp:295] Iteration 3454 (no loss supplied for SingleUpdateStep)
I1111 00:31:02.936799  2593 solver.cpp:310]     Train net output #0: loss = 0.398 (* 1 = 0.398 loss)
I1111 00:31:02.936821  2593 sgd_solver.cpp:106] Iteration 3454, lr = 0.00025
I1111 00:31:05.287272  2593 solver.cpp:295] Iteration 3455 (no loss supplied for SingleUpdateStep)
I1111 00:31:05.287395  2593 solver.cpp:310]     Train net output #0: loss = 0.387403 (* 1 = 0.387403 loss)
I1111 00:31:05.287418  2593 sgd_solver.cpp:106] Iteration 3455, lr = 0.00025
I1111 00:31:07.432961  2593 solver.cpp:295] Iteration 3456 (no loss supplied for SingleUpdateStep)
I1111 00:31:07.433158  2593 solver.cpp:310]     Train net output #0: loss = 0.398078 (* 1 = 0.398078 loss)
I1111 00:31:07.433192  2593 sgd_solver.cpp:106] Iteration 3456, lr = 0.00025
I1111 00:31:09.641487  2593 solver.cpp:295] Iteration 3457 (no loss supplied for SingleUpdateStep)
I1111 00:31:09.641609  2593 solver.cpp:310]     Train net output #0: loss = 0.373306 (* 1 = 0.373306 loss)
I1111 00:31:09.641640  2593 sgd_solver.cpp:106] Iteration 3457, lr = 0.00025
I1111 00:31:12.042089  2593 solver.cpp:295] Iteration 3458 (no loss supplied for SingleUpdateStep)
I1111 00:31:12.042199  2593 solver.cpp:310]     Train net output #0: loss = 0.405014 (* 1 = 0.405014 loss)
I1111 00:31:12.042227  2593 sgd_solver.cpp:106] Iteration 3458, lr = 0.00025
I1111 00:31:14.553926  2593 solver.cpp:295] Iteration 3459 (no loss supplied for SingleUpdateStep)
I1111 00:31:14.554050  2593 solver.cpp:310]     Train net output #0: loss = 0.39757 (* 1 = 0.39757 loss)
I1111 00:31:14.554080  2593 sgd_solver.cpp:106] Iteration 3459, lr = 0.00025
I1111 00:31:16.817049  2593 solver.cpp:295] Iteration 3460 (no loss supplied for SingleUpdateStep)
I1111 00:31:16.817152  2593 solver.cpp:310]     Train net output #0: loss = 0.383421 (* 1 = 0.383421 loss)
I1111 00:31:16.817173  2593 sgd_solver.cpp:106] Iteration 3460, lr = 0.00025
I1111 00:31:19.005403  2593 solver.cpp:295] Iteration 3461 (no loss supplied for SingleUpdateStep)
I1111 00:31:19.005514  2593 solver.cpp:310]     Train net output #0: loss = 0.402297 (* 1 = 0.402297 loss)
I1111 00:31:19.005537  2593 sgd_solver.cpp:106] Iteration 3461, lr = 0.00025
I1111 00:31:21.329479  2593 solver.cpp:295] Iteration 3462 (no loss supplied for SingleUpdateStep)
I1111 00:31:21.329620  2593 solver.cpp:310]     Train net output #0: loss = 0.391713 (* 1 = 0.391713 loss)
I1111 00:31:21.329648  2593 sgd_solver.cpp:106] Iteration 3462, lr = 0.00025
I1111 00:31:23.562811  2593 solver.cpp:295] Iteration 3463 (no loss supplied for SingleUpdateStep)
I1111 00:31:23.562971  2593 solver.cpp:310]     Train net output #0: loss = 0.383306 (* 1 = 0.383306 loss)
I1111 00:31:23.562999  2593 sgd_solver.cpp:106] Iteration 3463, lr = 0.00025
I1111 00:31:25.891717  2593 solver.cpp:295] Iteration 3464 (no loss supplied for SingleUpdateStep)
I1111 00:31:25.891839  2593 solver.cpp:310]     Train net output #0: loss = 0.375491 (* 1 = 0.375491 loss)
I1111 00:31:25.891860  2593 sgd_solver.cpp:106] Iteration 3464, lr = 0.00025
I1111 00:31:28.109295  2593 solver.cpp:295] Iteration 3465 (no loss supplied for SingleUpdateStep)
I1111 00:31:28.109465  2593 solver.cpp:310]     Train net output #0: loss = 0.385641 (* 1 = 0.385641 loss)
I1111 00:31:28.109495  2593 sgd_solver.cpp:106] Iteration 3465, lr = 0.00025
I1111 00:31:30.962785  2593 solver.cpp:295] Iteration 3466 (no loss supplied for SingleUpdateStep)
I1111 00:31:30.962983  2593 solver.cpp:310]     Train net output #0: loss = 0.406339 (* 1 = 0.406339 loss)
I1111 00:31:30.963008  2593 sgd_solver.cpp:106] Iteration 3466, lr = 0.00025
I1111 00:31:33.530797  2593 solver.cpp:295] Iteration 3467 (no loss supplied for SingleUpdateStep)
I1111 00:31:33.530935  2593 solver.cpp:310]     Train net output #0: loss = 0.418766 (* 1 = 0.418766 loss)
I1111 00:31:33.530964  2593 sgd_solver.cpp:106] Iteration 3467, lr = 0.00025
I1111 00:31:35.959620  2593 solver.cpp:295] Iteration 3468 (no loss supplied for SingleUpdateStep)
I1111 00:31:35.959714  2593 solver.cpp:310]     Train net output #0: loss = 0.379991 (* 1 = 0.379991 loss)
I1111 00:31:35.959738  2593 sgd_solver.cpp:106] Iteration 3468, lr = 0.00025
I1111 00:31:38.271935  2593 solver.cpp:295] Iteration 3469 (no loss supplied for SingleUpdateStep)
I1111 00:31:38.272030  2593 solver.cpp:310]     Train net output #0: loss = 0.397767 (* 1 = 0.397767 loss)
I1111 00:31:38.272053  2593 sgd_solver.cpp:106] Iteration 3469, lr = 0.00025
I1111 00:31:40.553710  2593 solver.cpp:295] Iteration 3470 (no loss supplied for SingleUpdateStep)
I1111 00:31:40.553864  2593 solver.cpp:310]     Train net output #0: loss = 0.379584 (* 1 = 0.379584 loss)
I1111 00:31:40.553890  2593 sgd_solver.cpp:106] Iteration 3470, lr = 0.00025
I1111 00:31:42.871564  2593 solver.cpp:295] Iteration 3471 (no loss supplied for SingleUpdateStep)
I1111 00:31:42.871649  2593 solver.cpp:310]     Train net output #0: loss = 0.379573 (* 1 = 0.379573 loss)
I1111 00:31:42.871670  2593 sgd_solver.cpp:106] Iteration 3471, lr = 0.00025
I1111 00:31:45.225826  2593 solver.cpp:295] Iteration 3472 (no loss supplied for SingleUpdateStep)
I1111 00:31:45.225919  2593 solver.cpp:310]     Train net output #0: loss = 0.385921 (* 1 = 0.385921 loss)
I1111 00:31:45.225939  2593 sgd_solver.cpp:106] Iteration 3472, lr = 0.00025
I1111 00:31:47.630722  2593 solver.cpp:295] Iteration 3473 (no loss supplied for SingleUpdateStep)
I1111 00:31:47.630897  2593 solver.cpp:310]     Train net output #0: loss = 0.38509 (* 1 = 0.38509 loss)
I1111 00:31:47.630923  2593 sgd_solver.cpp:106] Iteration 3473, lr = 0.00025
I1111 00:31:50.157099  2593 solver.cpp:295] Iteration 3474 (no loss supplied for SingleUpdateStep)
I1111 00:31:50.157199  2593 solver.cpp:310]     Train net output #0: loss = 0.392815 (* 1 = 0.392815 loss)
I1111 00:31:50.157219  2593 sgd_solver.cpp:106] Iteration 3474, lr = 0.00025
I1111 00:31:52.588668  2593 solver.cpp:295] Iteration 3475 (no loss supplied for SingleUpdateStep)
I1111 00:31:52.588769  2593 solver.cpp:310]     Train net output #0: loss = 0.398989 (* 1 = 0.398989 loss)
I1111 00:31:52.588793  2593 sgd_solver.cpp:106] Iteration 3475, lr = 0.00025
I1111 00:31:54.946030  2593 solver.cpp:295] Iteration 3476 (no loss supplied for SingleUpdateStep)
I1111 00:31:54.946151  2593 solver.cpp:310]     Train net output #0: loss = 0.358936 (* 1 = 0.358936 loss)
I1111 00:31:54.946177  2593 sgd_solver.cpp:106] Iteration 3476, lr = 0.00025
I1111 00:31:57.496544  2593 solver.cpp:295] Iteration 3477 (no loss supplied for SingleUpdateStep)
I1111 00:31:57.496695  2593 solver.cpp:310]     Train net output #0: loss = 0.400251 (* 1 = 0.400251 loss)
I1111 00:31:57.496719  2593 sgd_solver.cpp:106] Iteration 3477, lr = 0.00025
I1111 00:32:00.009968  2593 solver.cpp:295] Iteration 3478 (no loss supplied for SingleUpdateStep)
I1111 00:32:00.010136  2593 solver.cpp:310]     Train net output #0: loss = 0.409101 (* 1 = 0.409101 loss)
I1111 00:32:00.010164  2593 sgd_solver.cpp:106] Iteration 3478, lr = 0.00025
I1111 00:32:02.441928  2593 solver.cpp:295] Iteration 3479 (no loss supplied for SingleUpdateStep)
I1111 00:32:02.442111  2593 solver.cpp:310]     Train net output #0: loss = 0.424109 (* 1 = 0.424109 loss)
I1111 00:32:02.442144  2593 sgd_solver.cpp:106] Iteration 3479, lr = 0.00025
I1111 00:32:05.031453  2593 solver.cpp:295] Iteration 3480 (no loss supplied for SingleUpdateStep)
I1111 00:32:05.031626  2593 solver.cpp:310]     Train net output #0: loss = 0.408747 (* 1 = 0.408747 loss)
I1111 00:32:05.031656  2593 sgd_solver.cpp:106] Iteration 3480, lr = 0.00025
I1111 00:32:08.068388  2593 solver.cpp:295] Iteration 3481 (no loss supplied for SingleUpdateStep)
I1111 00:32:08.068543  2593 solver.cpp:310]     Train net output #0: loss = 0.386547 (* 1 = 0.386547 loss)
I1111 00:32:08.068569  2593 sgd_solver.cpp:106] Iteration 3481, lr = 0.00025
I1111 00:32:11.318351  2593 solver.cpp:295] Iteration 3482 (no loss supplied for SingleUpdateStep)
I1111 00:32:11.318442  2593 solver.cpp:310]     Train net output #0: loss = 0.359534 (* 1 = 0.359534 loss)
I1111 00:32:11.318462  2593 sgd_solver.cpp:106] Iteration 3482, lr = 0.00025
I1111 00:32:14.966830  2593 solver.cpp:295] Iteration 3483 (no loss supplied for SingleUpdateStep)
I1111 00:32:14.966969  2593 solver.cpp:310]     Train net output #0: loss = 0.427682 (* 1 = 0.427682 loss)
I1111 00:32:14.966991  2593 sgd_solver.cpp:106] Iteration 3483, lr = 0.00025
I1111 00:32:17.908187  2593 solver.cpp:295] Iteration 3484 (no loss supplied for SingleUpdateStep)
I1111 00:32:17.908321  2593 solver.cpp:310]     Train net output #0: loss = 0.408662 (* 1 = 0.408662 loss)
I1111 00:32:17.908344  2593 sgd_solver.cpp:106] Iteration 3484, lr = 0.00025
I1111 00:32:20.607681  2593 solver.cpp:295] Iteration 3485 (no loss supplied for SingleUpdateStep)
I1111 00:32:20.607745  2593 solver.cpp:310]     Train net output #0: loss = 0.418728 (* 1 = 0.418728 loss)
I1111 00:32:20.607764  2593 sgd_solver.cpp:106] Iteration 3485, lr = 0.00025
I1111 00:32:23.276856  2593 solver.cpp:295] Iteration 3486 (no loss supplied for SingleUpdateStep)
I1111 00:32:23.277014  2593 solver.cpp:310]     Train net output #0: loss = 0.393663 (* 1 = 0.393663 loss)
I1111 00:32:23.277036  2593 sgd_solver.cpp:106] Iteration 3486, lr = 0.00025
I1111 00:32:26.018523  2593 solver.cpp:295] Iteration 3487 (no loss supplied for SingleUpdateStep)
I1111 00:32:26.018595  2593 solver.cpp:310]     Train net output #0: loss = 0.362557 (* 1 = 0.362557 loss)
I1111 00:32:26.018616  2593 sgd_solver.cpp:106] Iteration 3487, lr = 0.00025
I1111 00:32:28.989235  2593 solver.cpp:295] Iteration 3488 (no loss supplied for SingleUpdateStep)
I1111 00:32:28.989344  2593 solver.cpp:310]     Train net output #0: loss = 0.374777 (* 1 = 0.374777 loss)
I1111 00:32:28.989367  2593 sgd_solver.cpp:106] Iteration 3488, lr = 0.00025
I1111 00:32:31.623896  2593 solver.cpp:295] Iteration 3489 (no loss supplied for SingleUpdateStep)
I1111 00:32:31.623952  2593 solver.cpp:310]     Train net output #0: loss = 0.389073 (* 1 = 0.389073 loss)
I1111 00:32:31.623971  2593 sgd_solver.cpp:106] Iteration 3489, lr = 0.00025
I1111 00:32:34.334661  2593 solver.cpp:295] Iteration 3490 (no loss supplied for SingleUpdateStep)
I1111 00:32:34.334760  2593 solver.cpp:310]     Train net output #0: loss = 0.387093 (* 1 = 0.387093 loss)
I1111 00:32:34.334782  2593 sgd_solver.cpp:106] Iteration 3490, lr = 0.00025
I1111 00:32:36.661967  2593 solver.cpp:295] Iteration 3491 (no loss supplied for SingleUpdateStep)
I1111 00:32:36.662021  2593 solver.cpp:310]     Train net output #0: loss = 0.384203 (* 1 = 0.384203 loss)
I1111 00:32:36.662040  2593 sgd_solver.cpp:106] Iteration 3491, lr = 0.00025
I1111 00:32:39.013769  2593 solver.cpp:295] Iteration 3492 (no loss supplied for SingleUpdateStep)
I1111 00:32:39.013953  2593 solver.cpp:310]     Train net output #0: loss = 0.415582 (* 1 = 0.415582 loss)
I1111 00:32:39.013978  2593 sgd_solver.cpp:106] Iteration 3492, lr = 0.00025
I1111 00:32:41.342712  2593 solver.cpp:295] Iteration 3493 (no loss supplied for SingleUpdateStep)
I1111 00:32:41.342836  2593 solver.cpp:310]     Train net output #0: loss = 0.40028 (* 1 = 0.40028 loss)
I1111 00:32:41.342859  2593 sgd_solver.cpp:106] Iteration 3493, lr = 0.00025
I1111 00:32:43.545358  2593 solver.cpp:295] Iteration 3494 (no loss supplied for SingleUpdateStep)
I1111 00:32:43.545545  2593 solver.cpp:310]     Train net output #0: loss = 0.370285 (* 1 = 0.370285 loss)
I1111 00:32:43.545572  2593 sgd_solver.cpp:106] Iteration 3494, lr = 0.00025
I1111 00:32:45.686640  2593 solver.cpp:295] Iteration 3495 (no loss supplied for SingleUpdateStep)
I1111 00:32:45.686759  2593 solver.cpp:310]     Train net output #0: loss = 0.411329 (* 1 = 0.411329 loss)
I1111 00:32:45.686789  2593 sgd_solver.cpp:106] Iteration 3495, lr = 0.00025
I1111 00:32:48.032737  2593 solver.cpp:295] Iteration 3496 (no loss supplied for SingleUpdateStep)
I1111 00:32:48.032865  2593 solver.cpp:310]     Train net output #0: loss = 0.35329 (* 1 = 0.35329 loss)
I1111 00:32:48.032886  2593 sgd_solver.cpp:106] Iteration 3496, lr = 0.00025
I1111 00:32:50.972597  2593 solver.cpp:295] Iteration 3497 (no loss supplied for SingleUpdateStep)
I1111 00:32:50.972694  2593 solver.cpp:310]     Train net output #0: loss = 0.386076 (* 1 = 0.386076 loss)
I1111 00:32:50.972717  2593 sgd_solver.cpp:106] Iteration 3497, lr = 0.00025
I1111 00:32:53.558969  2593 solver.cpp:295] Iteration 3498 (no loss supplied for SingleUpdateStep)
I1111 00:32:53.559077  2593 solver.cpp:310]     Train net output #0: loss = 0.369199 (* 1 = 0.369199 loss)
I1111 00:32:53.559098  2593 sgd_solver.cpp:106] Iteration 3498, lr = 0.00025
I1111 00:32:55.890714  2593 solver.cpp:295] Iteration 3499 (no loss supplied for SingleUpdateStep)
I1111 00:32:55.890840  2593 solver.cpp:310]     Train net output #0: loss = 0.382762 (* 1 = 0.382762 loss)
I1111 00:32:55.890862  2593 sgd_solver.cpp:106] Iteration 3499, lr = 0.00025
I1111 00:32:58.167409  2593 solver.cpp:295] Iteration 3500 (no loss supplied for SingleUpdateStep)
I1111 00:32:58.167522  2593 solver.cpp:310]     Train net output #0: loss = 0.361447 (* 1 = 0.361447 loss)
I1111 00:32:58.167542  2593 sgd_solver.cpp:106] Iteration 3500, lr = 0.00025
I1111 00:33:00.318565  2593 solver.cpp:295] Iteration 3501 (no loss supplied for SingleUpdateStep)
I1111 00:33:00.318649  2593 solver.cpp:310]     Train net output #0: loss = 0.361961 (* 1 = 0.361961 loss)
I1111 00:33:00.318672  2593 sgd_solver.cpp:106] Iteration 3501, lr = 0.00025
I1111 00:33:02.656731  2593 solver.cpp:295] Iteration 3502 (no loss supplied for SingleUpdateStep)
I1111 00:33:02.656879  2593 solver.cpp:310]     Train net output #0: loss = 0.395307 (* 1 = 0.395307 loss)
I1111 00:33:02.656905  2593 sgd_solver.cpp:106] Iteration 3502, lr = 0.00025
I1111 00:33:04.924823  2593 solver.cpp:295] Iteration 3503 (no loss supplied for SingleUpdateStep)
I1111 00:33:04.924906  2593 solver.cpp:310]     Train net output #0: loss = 0.398962 (* 1 = 0.398962 loss)
I1111 00:33:04.924927  2593 sgd_solver.cpp:106] Iteration 3503, lr = 0.00025
I1111 00:33:07.289894  2593 solver.cpp:295] Iteration 3504 (no loss supplied for SingleUpdateStep)
I1111 00:33:07.289983  2593 solver.cpp:310]     Train net output #0: loss = 0.363188 (* 1 = 0.363188 loss)
I1111 00:33:07.290006  2593 sgd_solver.cpp:106] Iteration 3504, lr = 0.00025
I1111 00:33:09.817472  2593 solver.cpp:295] Iteration 3505 (no loss supplied for SingleUpdateStep)
I1111 00:33:09.817556  2593 solver.cpp:310]     Train net output #0: loss = 0.4084 (* 1 = 0.4084 loss)
I1111 00:33:09.817579  2593 sgd_solver.cpp:106] Iteration 3505, lr = 0.00025
I1111 00:33:12.333736  2593 solver.cpp:295] Iteration 3506 (no loss supplied for SingleUpdateStep)
I1111 00:33:12.333837  2593 solver.cpp:310]     Train net output #0: loss = 0.394617 (* 1 = 0.394617 loss)
I1111 00:33:12.333858  2593 sgd_solver.cpp:106] Iteration 3506, lr = 0.00025
I1111 00:33:14.490488  2593 solver.cpp:295] Iteration 3507 (no loss supplied for SingleUpdateStep)
I1111 00:33:14.490617  2593 solver.cpp:310]     Train net output #0: loss = 0.396944 (* 1 = 0.396944 loss)
I1111 00:33:14.490646  2593 sgd_solver.cpp:106] Iteration 3507, lr = 0.00025
I1111 00:33:16.834391  2593 solver.cpp:295] Iteration 3508 (no loss supplied for SingleUpdateStep)
I1111 00:33:16.834457  2593 solver.cpp:310]     Train net output #0: loss = 0.378934 (* 1 = 0.378934 loss)
I1111 00:33:16.834477  2593 sgd_solver.cpp:106] Iteration 3508, lr = 0.00025
I1111 00:33:19.038655  2593 solver.cpp:295] Iteration 3509 (no loss supplied for SingleUpdateStep)
I1111 00:33:19.038827  2593 solver.cpp:310]     Train net output #0: loss = 0.362558 (* 1 = 0.362558 loss)
I1111 00:33:19.038856  2593 sgd_solver.cpp:106] Iteration 3509, lr = 0.00025
I1111 00:33:21.204560  2593 solver.cpp:295] Iteration 3510 (no loss supplied for SingleUpdateStep)
I1111 00:33:21.204624  2593 solver.cpp:310]     Train net output #0: loss = 0.37302 (* 1 = 0.37302 loss)
I1111 00:33:21.204644  2593 sgd_solver.cpp:106] Iteration 3510, lr = 0.00025
I1111 00:33:23.544565  2593 solver.cpp:295] Iteration 3511 (no loss supplied for SingleUpdateStep)
I1111 00:33:23.544675  2593 solver.cpp:310]     Train net output #0: loss = 0.349235 (* 1 = 0.349235 loss)
I1111 00:33:23.544695  2593 sgd_solver.cpp:106] Iteration 3511, lr = 0.00025
I1111 00:33:25.784260  2593 solver.cpp:295] Iteration 3512 (no loss supplied for SingleUpdateStep)
I1111 00:33:25.784368  2593 solver.cpp:310]     Train net output #0: loss = 0.386873 (* 1 = 0.386873 loss)
I1111 00:33:25.784394  2593 sgd_solver.cpp:106] Iteration 3512, lr = 0.00025
I1111 00:33:28.033357  2593 solver.cpp:295] Iteration 3513 (no loss supplied for SingleUpdateStep)
I1111 00:33:28.033469  2593 solver.cpp:310]     Train net output #0: loss = 0.389684 (* 1 = 0.389684 loss)
I1111 00:33:28.033493  2593 sgd_solver.cpp:106] Iteration 3513, lr = 0.00025
I1111 00:33:30.314512  2593 solver.cpp:295] Iteration 3514 (no loss supplied for SingleUpdateStep)
I1111 00:33:30.314586  2593 solver.cpp:310]     Train net output #0: loss = 0.384127 (* 1 = 0.384127 loss)
I1111 00:33:30.314607  2593 sgd_solver.cpp:106] Iteration 3514, lr = 0.00025
I1111 00:33:32.408458  2593 solver.cpp:295] Iteration 3515 (no loss supplied for SingleUpdateStep)
I1111 00:33:32.408587  2593 solver.cpp:310]     Train net output #0: loss = 0.385915 (* 1 = 0.385915 loss)
I1111 00:33:32.408612  2593 sgd_solver.cpp:106] Iteration 3515, lr = 0.00025
I1111 00:33:35.277642  2593 solver.cpp:295] Iteration 3516 (no loss supplied for SingleUpdateStep)
I1111 00:33:35.277750  2593 solver.cpp:310]     Train net output #0: loss = 0.390468 (* 1 = 0.390468 loss)
I1111 00:33:35.277772  2593 sgd_solver.cpp:106] Iteration 3516, lr = 0.00025
I1111 00:33:37.648183  2593 solver.cpp:295] Iteration 3517 (no loss supplied for SingleUpdateStep)
I1111 00:33:37.648291  2593 solver.cpp:310]     Train net output #0: loss = 0.410169 (* 1 = 0.410169 loss)
I1111 00:33:37.648314  2593 sgd_solver.cpp:106] Iteration 3517, lr = 0.00025
I1111 00:33:40.323045  2593 solver.cpp:295] Iteration 3518 (no loss supplied for SingleUpdateStep)
I1111 00:33:40.323108  2593 solver.cpp:310]     Train net output #0: loss = 0.424477 (* 1 = 0.424477 loss)
I1111 00:33:40.323128  2593 sgd_solver.cpp:106] Iteration 3518, lr = 0.00025
I1111 00:33:42.935961  2593 solver.cpp:295] Iteration 3519 (no loss supplied for SingleUpdateStep)
I1111 00:33:42.936050  2593 solver.cpp:310]     Train net output #0: loss = 0.407532 (* 1 = 0.407532 loss)
I1111 00:33:42.936074  2593 sgd_solver.cpp:106] Iteration 3519, lr = 0.00025
I1111 00:33:45.379161  2593 solver.cpp:295] Iteration 3520 (no loss supplied for SingleUpdateStep)
I1111 00:33:45.379274  2593 solver.cpp:310]     Train net output #0: loss = 0.361182 (* 1 = 0.361182 loss)
I1111 00:33:45.379299  2593 sgd_solver.cpp:106] Iteration 3520, lr = 0.00025
I1111 00:33:47.929445  2593 solver.cpp:295] Iteration 3521 (no loss supplied for SingleUpdateStep)
I1111 00:33:47.929561  2593 solver.cpp:310]     Train net output #0: loss = 0.386812 (* 1 = 0.386812 loss)
I1111 00:33:47.929584  2593 sgd_solver.cpp:106] Iteration 3521, lr = 0.00025
I1111 00:33:50.286237  2593 solver.cpp:295] Iteration 3522 (no loss supplied for SingleUpdateStep)
I1111 00:33:50.286372  2593 solver.cpp:310]     Train net output #0: loss = 0.384126 (* 1 = 0.384126 loss)
I1111 00:33:50.286393  2593 sgd_solver.cpp:106] Iteration 3522, lr = 0.00025
I1111 00:33:52.836861  2593 solver.cpp:295] Iteration 3523 (no loss supplied for SingleUpdateStep)
I1111 00:33:52.836997  2593 solver.cpp:310]     Train net output #0: loss = 0.399667 (* 1 = 0.399667 loss)
I1111 00:33:52.837023  2593 sgd_solver.cpp:106] Iteration 3523, lr = 0.00025
I1111 00:33:55.153048  2593 solver.cpp:295] Iteration 3524 (no loss supplied for SingleUpdateStep)
I1111 00:33:55.153167  2593 solver.cpp:310]     Train net output #0: loss = 0.36582 (* 1 = 0.36582 loss)
I1111 00:33:55.153190  2593 sgd_solver.cpp:106] Iteration 3524, lr = 0.00025
I1111 00:33:57.598804  2593 solver.cpp:295] Iteration 3525 (no loss supplied for SingleUpdateStep)
I1111 00:33:57.598886  2593 solver.cpp:310]     Train net output #0: loss = 0.393257 (* 1 = 0.393257 loss)
I1111 00:33:57.598906  2593 sgd_solver.cpp:106] Iteration 3525, lr = 0.00025
I1111 00:33:59.910581  2593 solver.cpp:295] Iteration 3526 (no loss supplied for SingleUpdateStep)
I1111 00:33:59.910693  2593 solver.cpp:310]     Train net output #0: loss = 0.391179 (* 1 = 0.391179 loss)
I1111 00:33:59.910718  2593 sgd_solver.cpp:106] Iteration 3526, lr = 0.00025
I1111 00:34:02.257326  2593 solver.cpp:295] Iteration 3527 (no loss supplied for SingleUpdateStep)
I1111 00:34:02.257407  2593 solver.cpp:310]     Train net output #0: loss = 0.362671 (* 1 = 0.362671 loss)
I1111 00:34:02.257426  2593 sgd_solver.cpp:106] Iteration 3527, lr = 0.00025
I1111 00:34:04.966092  2593 solver.cpp:295] Iteration 3528 (no loss supplied for SingleUpdateStep)
I1111 00:34:04.966187  2593 solver.cpp:310]     Train net output #0: loss = 0.376071 (* 1 = 0.376071 loss)
I1111 00:34:04.966210  2593 sgd_solver.cpp:106] Iteration 3528, lr = 0.00025
I1111 00:34:07.539861  2593 solver.cpp:295] Iteration 3529 (no loss supplied for SingleUpdateStep)
I1111 00:34:07.539968  2593 solver.cpp:310]     Train net output #0: loss = 0.399702 (* 1 = 0.399702 loss)
I1111 00:34:07.539989  2593 sgd_solver.cpp:106] Iteration 3529, lr = 0.00025
I1111 00:34:09.815567  2593 solver.cpp:295] Iteration 3530 (no loss supplied for SingleUpdateStep)
I1111 00:34:09.815690  2593 solver.cpp:310]     Train net output #0: loss = 0.369194 (* 1 = 0.369194 loss)
I1111 00:34:09.815714  2593 sgd_solver.cpp:106] Iteration 3530, lr = 0.00025
I1111 00:34:12.080790  2593 solver.cpp:295] Iteration 3531 (no loss supplied for SingleUpdateStep)
I1111 00:34:12.080848  2593 solver.cpp:310]     Train net output #0: loss = 0.396192 (* 1 = 0.396192 loss)
I1111 00:34:12.080867  2593 sgd_solver.cpp:106] Iteration 3531, lr = 0.00025
I1111 00:34:14.350164  2593 solver.cpp:295] Iteration 3532 (no loss supplied for SingleUpdateStep)
I1111 00:34:14.350265  2593 solver.cpp:310]     Train net output #0: loss = 0.381437 (* 1 = 0.381437 loss)
I1111 00:34:14.350294  2593 sgd_solver.cpp:106] Iteration 3532, lr = 0.00025
I1111 00:34:16.846871  2593 solver.cpp:295] Iteration 3533 (no loss supplied for SingleUpdateStep)
I1111 00:34:16.846987  2593 solver.cpp:310]     Train net output #0: loss = 0.394052 (* 1 = 0.394052 loss)
I1111 00:34:16.847012  2593 sgd_solver.cpp:106] Iteration 3533, lr = 0.00025
I1111 00:34:19.176148  2593 solver.cpp:295] Iteration 3534 (no loss supplied for SingleUpdateStep)
I1111 00:34:19.176290  2593 solver.cpp:310]     Train net output #0: loss = 0.401026 (* 1 = 0.401026 loss)
I1111 00:34:19.176319  2593 sgd_solver.cpp:106] Iteration 3534, lr = 0.00025
I1111 00:34:21.596763  2593 solver.cpp:295] Iteration 3535 (no loss supplied for SingleUpdateStep)
I1111 00:34:21.596922  2593 solver.cpp:310]     Train net output #0: loss = 0.386714 (* 1 = 0.386714 loss)
I1111 00:34:21.596947  2593 sgd_solver.cpp:106] Iteration 3535, lr = 0.00025
I1111 00:34:24.436153  2593 solver.cpp:295] Iteration 3536 (no loss supplied for SingleUpdateStep)
I1111 00:34:24.436292  2593 solver.cpp:310]     Train net output #0: loss = 0.420394 (* 1 = 0.420394 loss)
I1111 00:34:24.436321  2593 sgd_solver.cpp:106] Iteration 3536, lr = 0.00025
I1111 00:34:27.213840  2593 solver.cpp:295] Iteration 3537 (no loss supplied for SingleUpdateStep)
I1111 00:34:27.213958  2593 solver.cpp:310]     Train net output #0: loss = 0.379625 (* 1 = 0.379625 loss)
I1111 00:34:27.213981  2593 sgd_solver.cpp:106] Iteration 3537, lr = 0.00025
I1111 00:34:30.100810  2593 solver.cpp:295] Iteration 3538 (no loss supplied for SingleUpdateStep)
I1111 00:34:30.100908  2593 solver.cpp:310]     Train net output #0: loss = 0.405474 (* 1 = 0.405474 loss)
I1111 00:34:30.100929  2593 sgd_solver.cpp:106] Iteration 3538, lr = 0.00025
I1111 00:34:32.427098  2593 solver.cpp:295] Iteration 3539 (no loss supplied for SingleUpdateStep)
I1111 00:34:32.427238  2593 solver.cpp:310]     Train net output #0: loss = 0.407608 (* 1 = 0.407608 loss)
I1111 00:34:32.427265  2593 sgd_solver.cpp:106] Iteration 3539, lr = 0.00025
I1111 00:34:34.674878  2593 solver.cpp:295] Iteration 3540 (no loss supplied for SingleUpdateStep)
I1111 00:34:34.674957  2593 solver.cpp:310]     Train net output #0: loss = 0.38234 (* 1 = 0.38234 loss)
I1111 00:34:34.674976  2593 sgd_solver.cpp:106] Iteration 3540, lr = 0.00025
I1111 00:34:36.936951  2593 solver.cpp:295] Iteration 3541 (no loss supplied for SingleUpdateStep)
I1111 00:34:36.937082  2593 solver.cpp:310]     Train net output #0: loss = 0.3989 (* 1 = 0.3989 loss)
I1111 00:34:36.937105  2593 sgd_solver.cpp:106] Iteration 3541, lr = 0.00025
I1111 00:34:39.243223  2593 solver.cpp:295] Iteration 3542 (no loss supplied for SingleUpdateStep)
I1111 00:34:39.243324  2593 solver.cpp:310]     Train net output #0: loss = 0.412369 (* 1 = 0.412369 loss)
I1111 00:34:39.243345  2593 sgd_solver.cpp:106] Iteration 3542, lr = 0.00025
I1111 00:34:41.548887  2593 solver.cpp:295] Iteration 3543 (no loss supplied for SingleUpdateStep)
I1111 00:34:41.548981  2593 solver.cpp:310]     Train net output #0: loss = 0.373056 (* 1 = 0.373056 loss)
I1111 00:34:41.549002  2593 sgd_solver.cpp:106] Iteration 3543, lr = 0.00025
I1111 00:34:43.789180  2593 solver.cpp:295] Iteration 3544 (no loss supplied for SingleUpdateStep)
I1111 00:34:43.789238  2593 solver.cpp:310]     Train net output #0: loss = 0.368763 (* 1 = 0.368763 loss)
I1111 00:34:43.789258  2593 sgd_solver.cpp:106] Iteration 3544, lr = 0.00025
I1111 00:34:46.050264  2593 solver.cpp:295] Iteration 3545 (no loss supplied for SingleUpdateStep)
I1111 00:34:46.050328  2593 solver.cpp:310]     Train net output #0: loss = 0.38029 (* 1 = 0.38029 loss)
I1111 00:34:46.050346  2593 sgd_solver.cpp:106] Iteration 3545, lr = 0.00025
I1111 00:34:48.364805  2593 solver.cpp:295] Iteration 3546 (no loss supplied for SingleUpdateStep)
I1111 00:34:48.364867  2593 solver.cpp:310]     Train net output #0: loss = 0.408952 (* 1 = 0.408952 loss)
I1111 00:34:48.364887  2593 sgd_solver.cpp:106] Iteration 3546, lr = 0.00025
I1111 00:34:50.621255  2593 solver.cpp:295] Iteration 3547 (no loss supplied for SingleUpdateStep)
I1111 00:34:50.621371  2593 solver.cpp:310]     Train net output #0: loss = 0.357316 (* 1 = 0.357316 loss)
I1111 00:34:50.621393  2593 sgd_solver.cpp:106] Iteration 3547, lr = 0.00025
I1111 00:34:52.869179  2593 solver.cpp:295] Iteration 3548 (no loss supplied for SingleUpdateStep)
I1111 00:34:52.869292  2593 solver.cpp:310]     Train net output #0: loss = 0.404619 (* 1 = 0.404619 loss)
I1111 00:34:52.869315  2593 sgd_solver.cpp:106] Iteration 3548, lr = 0.00025
I1111 00:34:55.242686  2593 solver.cpp:295] Iteration 3549 (no loss supplied for SingleUpdateStep)
I1111 00:34:55.242835  2593 solver.cpp:310]     Train net output #0: loss = 0.400496 (* 1 = 0.400496 loss)
I1111 00:34:55.242859  2593 sgd_solver.cpp:106] Iteration 3549, lr = 0.00025
I1111 00:34:57.530755  2593 solver.cpp:295] Iteration 3550 (no loss supplied for SingleUpdateStep)
I1111 00:34:57.530874  2593 solver.cpp:310]     Train net output #0: loss = 0.388792 (* 1 = 0.388792 loss)
I1111 00:34:57.530894  2593 sgd_solver.cpp:106] Iteration 3550, lr = 0.00025
I1111 00:34:59.918504  2593 solver.cpp:295] Iteration 3551 (no loss supplied for SingleUpdateStep)
I1111 00:34:59.918594  2593 solver.cpp:310]     Train net output #0: loss = 0.413319 (* 1 = 0.413319 loss)
I1111 00:34:59.918615  2593 sgd_solver.cpp:106] Iteration 3551, lr = 0.00025
I1111 00:35:02.460213  2593 solver.cpp:295] Iteration 3552 (no loss supplied for SingleUpdateStep)
I1111 00:35:02.460351  2593 solver.cpp:310]     Train net output #0: loss = 0.39386 (* 1 = 0.39386 loss)
I1111 00:35:02.460378  2593 sgd_solver.cpp:106] Iteration 3552, lr = 0.00025
I1111 00:35:04.848845  2593 solver.cpp:295] Iteration 3553 (no loss supplied for SingleUpdateStep)
I1111 00:35:04.848964  2593 solver.cpp:310]     Train net output #0: loss = 0.391565 (* 1 = 0.391565 loss)
I1111 00:35:04.848991  2593 sgd_solver.cpp:106] Iteration 3553, lr = 0.00025
I1111 00:35:07.089711  2593 solver.cpp:295] Iteration 3554 (no loss supplied for SingleUpdateStep)
I1111 00:35:07.089769  2593 solver.cpp:310]     Train net output #0: loss = 0.406031 (* 1 = 0.406031 loss)
I1111 00:35:07.089788  2593 sgd_solver.cpp:106] Iteration 3554, lr = 0.00025
I1111 00:35:09.357064  2593 solver.cpp:295] Iteration 3555 (no loss supplied for SingleUpdateStep)
I1111 00:35:09.357208  2593 solver.cpp:310]     Train net output #0: loss = 0.392752 (* 1 = 0.392752 loss)
I1111 00:35:09.357231  2593 sgd_solver.cpp:106] Iteration 3555, lr = 0.00025
I1111 00:35:11.659313  2593 solver.cpp:295] Iteration 3556 (no loss supplied for SingleUpdateStep)
I1111 00:35:11.659411  2593 solver.cpp:310]     Train net output #0: loss = 0.364307 (* 1 = 0.364307 loss)
I1111 00:35:11.659430  2593 sgd_solver.cpp:106] Iteration 3556, lr = 0.00025
I1111 00:35:13.968618  2593 solver.cpp:295] Iteration 3557 (no loss supplied for SingleUpdateStep)
I1111 00:35:13.968719  2593 solver.cpp:310]     Train net output #0: loss = 0.36925 (* 1 = 0.36925 loss)
I1111 00:35:13.968741  2593 sgd_solver.cpp:106] Iteration 3557, lr = 0.00025
I1111 00:35:16.290655  2593 solver.cpp:295] Iteration 3558 (no loss supplied for SingleUpdateStep)
I1111 00:35:16.290714  2593 solver.cpp:310]     Train net output #0: loss = 0.402054 (* 1 = 0.402054 loss)
I1111 00:35:16.290736  2593 sgd_solver.cpp:106] Iteration 3558, lr = 0.00025
I1111 00:35:18.441618  2593 solver.cpp:295] Iteration 3559 (no loss supplied for SingleUpdateStep)
I1111 00:35:18.441711  2593 solver.cpp:310]     Train net output #0: loss = 0.379199 (* 1 = 0.379199 loss)
I1111 00:35:18.441732  2593 sgd_solver.cpp:106] Iteration 3559, lr = 0.00025
I1111 00:35:20.695093  2593 solver.cpp:295] Iteration 3560 (no loss supplied for SingleUpdateStep)
I1111 00:35:20.695211  2593 solver.cpp:310]     Train net output #0: loss = 0.391018 (* 1 = 0.391018 loss)
I1111 00:35:20.695235  2593 sgd_solver.cpp:106] Iteration 3560, lr = 0.00025
I1111 00:35:22.971458  2593 solver.cpp:295] Iteration 3561 (no loss supplied for SingleUpdateStep)
I1111 00:35:22.971632  2593 solver.cpp:310]     Train net output #0: loss = 0.402784 (* 1 = 0.402784 loss)
I1111 00:35:22.971660  2593 sgd_solver.cpp:106] Iteration 3561, lr = 0.00025
I1111 00:35:25.368506  2593 solver.cpp:295] Iteration 3562 (no loss supplied for SingleUpdateStep)
I1111 00:35:25.368610  2593 solver.cpp:310]     Train net output #0: loss = 0.401093 (* 1 = 0.401093 loss)
I1111 00:35:25.368633  2593 sgd_solver.cpp:106] Iteration 3562, lr = 0.00025
I1111 00:35:27.615561  2593 solver.cpp:295] Iteration 3563 (no loss supplied for SingleUpdateStep)
I1111 00:35:27.615689  2593 solver.cpp:310]     Train net output #0: loss = 0.389319 (* 1 = 0.389319 loss)
I1111 00:35:27.615727  2593 sgd_solver.cpp:106] Iteration 3563, lr = 0.00025
I1111 00:35:29.916124  2593 solver.cpp:295] Iteration 3564 (no loss supplied for SingleUpdateStep)
I1111 00:35:29.916314  2593 solver.cpp:310]     Train net output #0: loss = 0.384901 (* 1 = 0.384901 loss)
I1111 00:35:29.916337  2593 sgd_solver.cpp:106] Iteration 3564, lr = 0.00025
I1111 00:35:32.191242  2593 solver.cpp:295] Iteration 3565 (no loss supplied for SingleUpdateStep)
I1111 00:35:32.191421  2593 solver.cpp:310]     Train net output #0: loss = 0.392136 (* 1 = 0.392136 loss)
I1111 00:35:32.191449  2593 sgd_solver.cpp:106] Iteration 3565, lr = 0.00025
I1111 00:35:34.506873  2593 solver.cpp:295] Iteration 3566 (no loss supplied for SingleUpdateStep)
I1111 00:35:34.506952  2593 solver.cpp:310]     Train net output #0: loss = 0.400166 (* 1 = 0.400166 loss)
I1111 00:35:34.506973  2593 sgd_solver.cpp:106] Iteration 3566, lr = 0.00025
I1111 00:35:37.192519  2593 solver.cpp:295] Iteration 3567 (no loss supplied for SingleUpdateStep)
I1111 00:35:37.192718  2593 solver.cpp:310]     Train net output #0: loss = 0.401387 (* 1 = 0.401387 loss)
I1111 00:35:37.192744  2593 sgd_solver.cpp:106] Iteration 3567, lr = 0.00025
I1111 00:35:39.862882  2593 solver.cpp:295] Iteration 3568 (no loss supplied for SingleUpdateStep)
I1111 00:35:39.862972  2593 solver.cpp:310]     Train net output #0: loss = 0.368598 (* 1 = 0.368598 loss)
I1111 00:35:39.862993  2593 sgd_solver.cpp:106] Iteration 3568, lr = 0.00025
I1111 00:35:42.213179  2593 solver.cpp:295] Iteration 3569 (no loss supplied for SingleUpdateStep)
I1111 00:35:42.213261  2593 solver.cpp:310]     Train net output #0: loss = 0.409189 (* 1 = 0.409189 loss)
I1111 00:35:42.213284  2593 sgd_solver.cpp:106] Iteration 3569, lr = 0.00025
I1111 00:35:44.571809  2593 solver.cpp:295] Iteration 3570 (no loss supplied for SingleUpdateStep)
I1111 00:35:44.571938  2593 solver.cpp:310]     Train net output #0: loss = 0.402229 (* 1 = 0.402229 loss)
I1111 00:35:44.571960  2593 sgd_solver.cpp:106] Iteration 3570, lr = 0.00025
I1111 00:35:47.187535  2593 solver.cpp:295] Iteration 3571 (no loss supplied for SingleUpdateStep)
I1111 00:35:47.187614  2593 solver.cpp:310]     Train net output #0: loss = 0.411086 (* 1 = 0.411086 loss)
I1111 00:35:47.187634  2593 sgd_solver.cpp:106] Iteration 3571, lr = 0.00025
I1111 00:35:49.467453  2593 solver.cpp:295] Iteration 3572 (no loss supplied for SingleUpdateStep)
I1111 00:35:49.467555  2593 solver.cpp:310]     Train net output #0: loss = 0.402844 (* 1 = 0.402844 loss)
I1111 00:35:49.467576  2593 sgd_solver.cpp:106] Iteration 3572, lr = 0.00025
I1111 00:35:51.792103  2593 solver.cpp:295] Iteration 3573 (no loss supplied for SingleUpdateStep)
I1111 00:35:51.792191  2593 solver.cpp:310]     Train net output #0: loss = 0.415228 (* 1 = 0.415228 loss)
I1111 00:35:51.792215  2593 sgd_solver.cpp:106] Iteration 3573, lr = 0.00025
I1111 00:35:53.905251  2593 solver.cpp:295] Iteration 3574 (no loss supplied for SingleUpdateStep)
I1111 00:35:53.905309  2593 solver.cpp:310]     Train net output #0: loss = 0.363633 (* 1 = 0.363633 loss)
I1111 00:35:53.905330  2593 sgd_solver.cpp:106] Iteration 3574, lr = 0.00025
I1111 00:35:56.222836  2593 solver.cpp:295] Iteration 3575 (no loss supplied for SingleUpdateStep)
I1111 00:35:56.222924  2593 solver.cpp:310]     Train net output #0: loss = 0.385912 (* 1 = 0.385912 loss)
I1111 00:35:56.222949  2593 sgd_solver.cpp:106] Iteration 3575, lr = 0.00025
I1111 00:35:58.444073  2593 solver.cpp:295] Iteration 3576 (no loss supplied for SingleUpdateStep)
I1111 00:35:58.444151  2593 solver.cpp:310]     Train net output #0: loss = 0.393957 (* 1 = 0.393957 loss)
I1111 00:35:58.444172  2593 sgd_solver.cpp:106] Iteration 3576, lr = 0.00025
I1111 00:36:00.731462  2593 solver.cpp:295] Iteration 3577 (no loss supplied for SingleUpdateStep)
I1111 00:36:00.731590  2593 solver.cpp:310]     Train net output #0: loss = 0.401903 (* 1 = 0.401903 loss)
I1111 00:36:00.731613  2593 sgd_solver.cpp:106] Iteration 3577, lr = 0.00025
I1111 00:36:03.068994  2593 solver.cpp:295] Iteration 3578 (no loss supplied for SingleUpdateStep)
I1111 00:36:03.069103  2593 solver.cpp:310]     Train net output #0: loss = 0.37504 (* 1 = 0.37504 loss)
I1111 00:36:03.069130  2593 sgd_solver.cpp:106] Iteration 3578, lr = 0.00025
I1111 00:36:05.247431  2593 solver.cpp:295] Iteration 3579 (no loss supplied for SingleUpdateStep)
I1111 00:36:05.247539  2593 solver.cpp:310]     Train net output #0: loss = 0.42411 (* 1 = 0.42411 loss)
I1111 00:36:05.247560  2593 sgd_solver.cpp:106] Iteration 3579, lr = 0.00025
I1111 00:36:07.646659  2593 solver.cpp:295] Iteration 3580 (no loss supplied for SingleUpdateStep)
I1111 00:36:07.646852  2593 solver.cpp:310]     Train net output #0: loss = 0.377636 (* 1 = 0.377636 loss)
I1111 00:36:07.646881  2593 sgd_solver.cpp:106] Iteration 3580, lr = 0.00025
I1111 00:36:10.117869  2593 solver.cpp:295] Iteration 3581 (no loss supplied for SingleUpdateStep)
I1111 00:36:10.117969  2593 solver.cpp:310]     Train net output #0: loss = 0.385338 (* 1 = 0.385338 loss)
I1111 00:36:10.117990  2593 sgd_solver.cpp:106] Iteration 3581, lr = 0.00025
I1111 00:36:12.509176  2593 solver.cpp:295] Iteration 3582 (no loss supplied for SingleUpdateStep)
I1111 00:36:12.509326  2593 solver.cpp:310]     Train net output #0: loss = 0.376743 (* 1 = 0.376743 loss)
I1111 00:36:12.509352  2593 sgd_solver.cpp:106] Iteration 3582, lr = 0.00025
I1111 00:36:14.627102  2593 solver.cpp:295] Iteration 3583 (no loss supplied for SingleUpdateStep)
I1111 00:36:14.627207  2593 solver.cpp:310]     Train net output #0: loss = 0.398861 (* 1 = 0.398861 loss)
I1111 00:36:14.627230  2593 sgd_solver.cpp:106] Iteration 3583, lr = 0.00025
I1111 00:36:17.094697  2593 solver.cpp:295] Iteration 3584 (no loss supplied for SingleUpdateStep)
I1111 00:36:17.094816  2593 solver.cpp:310]     Train net output #0: loss = 0.393057 (* 1 = 0.393057 loss)
I1111 00:36:17.094838  2593 sgd_solver.cpp:106] Iteration 3584, lr = 0.00025
I1111 00:36:19.649443  2593 solver.cpp:295] Iteration 3585 (no loss supplied for SingleUpdateStep)
I1111 00:36:19.649555  2593 solver.cpp:310]     Train net output #0: loss = 0.407546 (* 1 = 0.407546 loss)
I1111 00:36:19.649579  2593 sgd_solver.cpp:106] Iteration 3585, lr = 0.00025
I1111 00:36:22.157012  2593 solver.cpp:295] Iteration 3586 (no loss supplied for SingleUpdateStep)
I1111 00:36:22.157163  2593 solver.cpp:310]     Train net output #0: loss = 0.401384 (* 1 = 0.401384 loss)
I1111 00:36:22.157191  2593 sgd_solver.cpp:106] Iteration 3586, lr = 0.00025
I1111 00:36:24.504256  2593 solver.cpp:295] Iteration 3587 (no loss supplied for SingleUpdateStep)
I1111 00:36:24.504361  2593 solver.cpp:310]     Train net output #0: loss = 0.388803 (* 1 = 0.388803 loss)
I1111 00:36:24.504384  2593 sgd_solver.cpp:106] Iteration 3587, lr = 0.00025
I1111 00:36:27.060813  2593 solver.cpp:295] Iteration 3588 (no loss supplied for SingleUpdateStep)
I1111 00:36:27.060930  2593 solver.cpp:310]     Train net output #0: loss = 0.379958 (* 1 = 0.379958 loss)
I1111 00:36:27.060957  2593 sgd_solver.cpp:106] Iteration 3588, lr = 0.00025
I1111 00:36:29.926558  2593 solver.cpp:295] Iteration 3589 (no loss supplied for SingleUpdateStep)
I1111 00:36:29.926659  2593 solver.cpp:310]     Train net output #0: loss = 0.387764 (* 1 = 0.387764 loss)
I1111 00:36:29.926682  2593 sgd_solver.cpp:106] Iteration 3589, lr = 0.00025
I1111 00:36:33.465034  2593 solver.cpp:295] Iteration 3590 (no loss supplied for SingleUpdateStep)
I1111 00:36:33.465175  2593 solver.cpp:310]     Train net output #0: loss = 0.352481 (* 1 = 0.352481 loss)
I1111 00:36:33.465198  2593 sgd_solver.cpp:106] Iteration 3590, lr = 0.00025
I1111 00:36:37.385234  2593 solver.cpp:295] Iteration 3591 (no loss supplied for SingleUpdateStep)
I1111 00:36:37.385350  2593 solver.cpp:310]     Train net output #0: loss = 0.403078 (* 1 = 0.403078 loss)
I1111 00:36:37.385371  2593 sgd_solver.cpp:106] Iteration 3591, lr = 0.00025
I1111 00:36:40.529649  2593 solver.cpp:295] Iteration 3592 (no loss supplied for SingleUpdateStep)
I1111 00:36:40.529795  2593 solver.cpp:310]     Train net output #0: loss = 0.425185 (* 1 = 0.425185 loss)
I1111 00:36:40.529821  2593 sgd_solver.cpp:106] Iteration 3592, lr = 0.00025
I1111 00:36:42.816042  2593 solver.cpp:295] Iteration 3593 (no loss supplied for SingleUpdateStep)
I1111 00:36:42.816239  2593 solver.cpp:310]     Train net output #0: loss = 0.393977 (* 1 = 0.393977 loss)
I1111 00:36:42.816263  2593 sgd_solver.cpp:106] Iteration 3593, lr = 0.00025
I1111 00:36:45.251242  2593 solver.cpp:295] Iteration 3594 (no loss supplied for SingleUpdateStep)
I1111 00:36:45.251299  2593 solver.cpp:310]     Train net output #0: loss = 0.419388 (* 1 = 0.419388 loss)
I1111 00:36:45.251317  2593 sgd_solver.cpp:106] Iteration 3594, lr = 0.00025
I1111 00:36:47.605630  2593 solver.cpp:295] Iteration 3595 (no loss supplied for SingleUpdateStep)
I1111 00:36:47.605697  2593 solver.cpp:310]     Train net output #0: loss = 0.388851 (* 1 = 0.388851 loss)
I1111 00:36:47.605717  2593 sgd_solver.cpp:106] Iteration 3595, lr = 0.00025
I1111 00:36:50.083048  2593 solver.cpp:295] Iteration 3596 (no loss supplied for SingleUpdateStep)
I1111 00:36:50.083139  2593 solver.cpp:310]     Train net output #0: loss = 0.375647 (* 1 = 0.375647 loss)
I1111 00:36:50.083160  2593 sgd_solver.cpp:106] Iteration 3596, lr = 0.00025
I1111 00:36:52.565711  2593 solver.cpp:295] Iteration 3597 (no loss supplied for SingleUpdateStep)
I1111 00:36:52.565786  2593 solver.cpp:310]     Train net output #0: loss = 0.371473 (* 1 = 0.371473 loss)
I1111 00:36:52.565807  2593 sgd_solver.cpp:106] Iteration 3597, lr = 0.00025
I1111 00:36:55.163897  2593 solver.cpp:295] Iteration 3598 (no loss supplied for SingleUpdateStep)
I1111 00:36:55.164003  2593 solver.cpp:310]     Train net output #0: loss = 0.407743 (* 1 = 0.407743 loss)
I1111 00:36:55.164026  2593 sgd_solver.cpp:106] Iteration 3598, lr = 0.00025
I1111 00:36:57.582131  2593 solver.cpp:295] Iteration 3599 (no loss supplied for SingleUpdateStep)
I1111 00:36:57.582198  2593 solver.cpp:310]     Train net output #0: loss = 0.390316 (* 1 = 0.390316 loss)
I1111 00:36:57.582218  2593 sgd_solver.cpp:106] Iteration 3599, lr = 0.00025
I1111 00:36:59.849656  2593 solver.cpp:295] Iteration 3600 (no loss supplied for SingleUpdateStep)
I1111 00:36:59.849752  2593 solver.cpp:310]     Train net output #0: loss = 0.373005 (* 1 = 0.373005 loss)
I1111 00:36:59.849774  2593 sgd_solver.cpp:106] Iteration 3600, lr = 0.00025
I1111 00:37:02.160468  2593 solver.cpp:295] Iteration 3601 (no loss supplied for SingleUpdateStep)
I1111 00:37:02.160604  2593 solver.cpp:310]     Train net output #0: loss = 0.368785 (* 1 = 0.368785 loss)
I1111 00:37:02.160627  2593 sgd_solver.cpp:106] Iteration 3601, lr = 0.00025
I1111 00:37:04.910354  2593 solver.cpp:295] Iteration 3602 (no loss supplied for SingleUpdateStep)
I1111 00:37:04.910413  2593 solver.cpp:310]     Train net output #0: loss = 0.362915 (* 1 = 0.362915 loss)
I1111 00:37:04.910431  2593 sgd_solver.cpp:106] Iteration 3602, lr = 0.00025
I1111 00:37:07.420866  2593 solver.cpp:295] Iteration 3603 (no loss supplied for SingleUpdateStep)
I1111 00:37:07.420994  2593 solver.cpp:310]     Train net output #0: loss = 0.376948 (* 1 = 0.376948 loss)
I1111 00:37:07.421017  2593 sgd_solver.cpp:106] Iteration 3603, lr = 0.00025
I1111 00:37:09.994073  2593 solver.cpp:295] Iteration 3604 (no loss supplied for SingleUpdateStep)
I1111 00:37:09.994151  2593 solver.cpp:310]     Train net output #0: loss = 0.401569 (* 1 = 0.401569 loss)
I1111 00:37:09.994173  2593 sgd_solver.cpp:106] Iteration 3604, lr = 0.00025
I1111 00:37:12.367743  2593 solver.cpp:295] Iteration 3605 (no loss supplied for SingleUpdateStep)
I1111 00:37:12.367887  2593 solver.cpp:310]     Train net output #0: loss = 0.378064 (* 1 = 0.378064 loss)
I1111 00:37:12.367913  2593 sgd_solver.cpp:106] Iteration 3605, lr = 0.00025
I1111 00:37:14.686359  2593 solver.cpp:295] Iteration 3606 (no loss supplied for SingleUpdateStep)
I1111 00:37:14.686508  2593 solver.cpp:310]     Train net output #0: loss = 0.399277 (* 1 = 0.399277 loss)
I1111 00:37:14.686532  2593 sgd_solver.cpp:106] Iteration 3606, lr = 0.00025
I1111 00:37:17.160006  2593 solver.cpp:295] Iteration 3607 (no loss supplied for SingleUpdateStep)
I1111 00:37:17.160074  2593 solver.cpp:310]     Train net output #0: loss = 0.393831 (* 1 = 0.393831 loss)
I1111 00:37:17.160094  2593 sgd_solver.cpp:106] Iteration 3607, lr = 0.00025
I1111 00:37:19.653597  2593 solver.cpp:295] Iteration 3608 (no loss supplied for SingleUpdateStep)
I1111 00:37:19.653733  2593 solver.cpp:310]     Train net output #0: loss = 0.390131 (* 1 = 0.390131 loss)
I1111 00:37:19.653758  2593 sgd_solver.cpp:106] Iteration 3608, lr = 0.00025
I1111 00:37:21.940956  2593 solver.cpp:295] Iteration 3609 (no loss supplied for SingleUpdateStep)
I1111 00:37:21.941085  2593 solver.cpp:310]     Train net output #0: loss = 0.39974 (* 1 = 0.39974 loss)
I1111 00:37:21.941110  2593 sgd_solver.cpp:106] Iteration 3609, lr = 0.00025
I1111 00:37:24.381681  2593 solver.cpp:295] Iteration 3610 (no loss supplied for SingleUpdateStep)
I1111 00:37:24.381785  2593 solver.cpp:310]     Train net output #0: loss = 0.356045 (* 1 = 0.356045 loss)
I1111 00:37:24.381809  2593 sgd_solver.cpp:106] Iteration 3610, lr = 0.00025
I1111 00:37:26.859959  2593 solver.cpp:295] Iteration 3611 (no loss supplied for SingleUpdateStep)
I1111 00:37:26.860100  2593 solver.cpp:310]     Train net output #0: loss = 0.388426 (* 1 = 0.388426 loss)
I1111 00:37:26.860123  2593 sgd_solver.cpp:106] Iteration 3611, lr = 0.00025
I1111 00:37:29.794044  2593 solver.cpp:295] Iteration 3612 (no loss supplied for SingleUpdateStep)
I1111 00:37:29.794234  2593 solver.cpp:310]     Train net output #0: loss = 0.393104 (* 1 = 0.393104 loss)
I1111 00:37:29.794267  2593 sgd_solver.cpp:106] Iteration 3612, lr = 0.00025
I1111 00:37:33.307693  2593 solver.cpp:295] Iteration 3613 (no loss supplied for SingleUpdateStep)
I1111 00:37:33.307756  2593 solver.cpp:310]     Train net output #0: loss = 0.371438 (* 1 = 0.371438 loss)
I1111 00:37:33.307776  2593 sgd_solver.cpp:106] Iteration 3613, lr = 0.00025
I1111 00:37:36.108265  2593 solver.cpp:295] Iteration 3614 (no loss supplied for SingleUpdateStep)
I1111 00:37:36.108350  2593 solver.cpp:310]     Train net output #0: loss = 0.396749 (* 1 = 0.396749 loss)
I1111 00:37:36.108369  2593 sgd_solver.cpp:106] Iteration 3614, lr = 0.00025
I1111 00:37:38.445222  2593 solver.cpp:295] Iteration 3615 (no loss supplied for SingleUpdateStep)
I1111 00:37:38.445375  2593 solver.cpp:310]     Train net output #0: loss = 0.417818 (* 1 = 0.417818 loss)
I1111 00:37:38.445399  2593 sgd_solver.cpp:106] Iteration 3615, lr = 0.00025
I1111 00:37:40.804306  2593 solver.cpp:295] Iteration 3616 (no loss supplied for SingleUpdateStep)
I1111 00:37:40.804472  2593 solver.cpp:310]     Train net output #0: loss = 0.370376 (* 1 = 0.370376 loss)
I1111 00:37:40.804496  2593 sgd_solver.cpp:106] Iteration 3616, lr = 0.00025
I1111 00:37:43.190510  2593 solver.cpp:295] Iteration 3617 (no loss supplied for SingleUpdateStep)
I1111 00:37:43.190605  2593 solver.cpp:310]     Train net output #0: loss = 0.380601 (* 1 = 0.380601 loss)
I1111 00:37:43.190626  2593 sgd_solver.cpp:106] Iteration 3617, lr = 0.00025
I1111 00:37:45.692630  2593 solver.cpp:295] Iteration 3618 (no loss supplied for SingleUpdateStep)
I1111 00:37:45.692780  2593 solver.cpp:310]     Train net output #0: loss = 0.387653 (* 1 = 0.387653 loss)
I1111 00:37:45.692808  2593 sgd_solver.cpp:106] Iteration 3618, lr = 0.00025
I1111 00:37:48.113250  2593 solver.cpp:295] Iteration 3619 (no loss supplied for SingleUpdateStep)
I1111 00:37:48.113428  2593 solver.cpp:310]     Train net output #0: loss = 0.384836 (* 1 = 0.384836 loss)
I1111 00:37:48.113452  2593 sgd_solver.cpp:106] Iteration 3619, lr = 0.00025
I1111 00:37:50.491647  2593 solver.cpp:295] Iteration 3620 (no loss supplied for SingleUpdateStep)
I1111 00:37:50.491804  2593 solver.cpp:310]     Train net output #0: loss = 0.3865 (* 1 = 0.3865 loss)
I1111 00:37:50.491837  2593 sgd_solver.cpp:106] Iteration 3620, lr = 0.00025
I1111 00:37:52.912034  2593 solver.cpp:295] Iteration 3621 (no loss supplied for SingleUpdateStep)
I1111 00:37:52.912130  2593 solver.cpp:310]     Train net output #0: loss = 0.380119 (* 1 = 0.380119 loss)
I1111 00:37:52.912152  2593 sgd_solver.cpp:106] Iteration 3621, lr = 0.00025
I1111 00:37:55.300884  2593 solver.cpp:295] Iteration 3622 (no loss supplied for SingleUpdateStep)
I1111 00:37:55.300987  2593 solver.cpp:310]     Train net output #0: loss = 0.405642 (* 1 = 0.405642 loss)
I1111 00:37:55.301012  2593 sgd_solver.cpp:106] Iteration 3622, lr = 0.00025
I1111 00:37:57.706382  2593 solver.cpp:295] Iteration 3623 (no loss supplied for SingleUpdateStep)
I1111 00:37:57.706488  2593 solver.cpp:310]     Train net output #0: loss = 0.406357 (* 1 = 0.406357 loss)
I1111 00:37:57.706511  2593 sgd_solver.cpp:106] Iteration 3623, lr = 0.00025
I1111 00:38:00.223073  2593 solver.cpp:295] Iteration 3624 (no loss supplied for SingleUpdateStep)
I1111 00:38:00.223206  2593 solver.cpp:310]     Train net output #0: loss = 0.377935 (* 1 = 0.377935 loss)
I1111 00:38:00.223229  2593 sgd_solver.cpp:106] Iteration 3624, lr = 0.00025
I1111 00:38:02.586056  2593 solver.cpp:295] Iteration 3625 (no loss supplied for SingleUpdateStep)
I1111 00:38:02.586180  2593 solver.cpp:310]     Train net output #0: loss = 0.388041 (* 1 = 0.388041 loss)
I1111 00:38:02.586205  2593 sgd_solver.cpp:106] Iteration 3625, lr = 0.00025
I1111 00:38:04.993963  2593 solver.cpp:295] Iteration 3626 (no loss supplied for SingleUpdateStep)
I1111 00:38:04.994056  2593 solver.cpp:310]     Train net output #0: loss = 0.359196 (* 1 = 0.359196 loss)
I1111 00:38:04.994077  2593 sgd_solver.cpp:106] Iteration 3626, lr = 0.00025
I1111 00:38:07.247077  2593 solver.cpp:295] Iteration 3627 (no loss supplied for SingleUpdateStep)
I1111 00:38:07.247191  2593 solver.cpp:310]     Train net output #0: loss = 0.38391 (* 1 = 0.38391 loss)
I1111 00:38:07.247216  2593 sgd_solver.cpp:106] Iteration 3627, lr = 0.00025
I1111 00:38:09.651571  2593 solver.cpp:295] Iteration 3628 (no loss supplied for SingleUpdateStep)
I1111 00:38:09.651670  2593 solver.cpp:310]     Train net output #0: loss = 0.420407 (* 1 = 0.420407 loss)
I1111 00:38:09.651692  2593 sgd_solver.cpp:106] Iteration 3628, lr = 0.00025
I1111 00:38:12.296716  2593 solver.cpp:295] Iteration 3629 (no loss supplied for SingleUpdateStep)
I1111 00:38:12.296838  2593 solver.cpp:310]     Train net output #0: loss = 0.385283 (* 1 = 0.385283 loss)
I1111 00:38:12.296864  2593 sgd_solver.cpp:106] Iteration 3629, lr = 0.00025
I1111 00:38:15.004937  2593 solver.cpp:295] Iteration 3630 (no loss supplied for SingleUpdateStep)
I1111 00:38:15.004998  2593 solver.cpp:310]     Train net output #0: loss = 0.379539 (* 1 = 0.379539 loss)
I1111 00:38:15.005017  2593 sgd_solver.cpp:106] Iteration 3630, lr = 0.00025
I1111 00:38:17.337301  2593 solver.cpp:295] Iteration 3631 (no loss supplied for SingleUpdateStep)
I1111 00:38:17.337442  2593 solver.cpp:310]     Train net output #0: loss = 0.395376 (* 1 = 0.395376 loss)
I1111 00:38:17.337466  2593 sgd_solver.cpp:106] Iteration 3631, lr = 0.00025
I1111 00:38:19.724493  2593 solver.cpp:295] Iteration 3632 (no loss supplied for SingleUpdateStep)
I1111 00:38:19.724669  2593 solver.cpp:310]     Train net output #0: loss = 0.370118 (* 1 = 0.370118 loss)
I1111 00:38:19.724695  2593 sgd_solver.cpp:106] Iteration 3632, lr = 0.00025
I1111 00:38:21.962157  2593 solver.cpp:295] Iteration 3633 (no loss supplied for SingleUpdateStep)
I1111 00:38:21.962255  2593 solver.cpp:310]     Train net output #0: loss = 0.400151 (* 1 = 0.400151 loss)
I1111 00:38:21.962275  2593 sgd_solver.cpp:106] Iteration 3633, lr = 0.00025
I1111 00:38:24.256165  2593 solver.cpp:295] Iteration 3634 (no loss supplied for SingleUpdateStep)
I1111 00:38:24.256263  2593 solver.cpp:310]     Train net output #0: loss = 0.398284 (* 1 = 0.398284 loss)
I1111 00:38:24.256285  2593 sgd_solver.cpp:106] Iteration 3634, lr = 0.00025
I1111 00:38:26.553128  2593 solver.cpp:295] Iteration 3635 (no loss supplied for SingleUpdateStep)
I1111 00:38:26.553194  2593 solver.cpp:310]     Train net output #0: loss = 0.402982 (* 1 = 0.402982 loss)
I1111 00:38:26.553213  2593 sgd_solver.cpp:106] Iteration 3635, lr = 0.00025
I1111 00:38:29.067494  2593 solver.cpp:295] Iteration 3636 (no loss supplied for SingleUpdateStep)
I1111 00:38:29.067587  2593 solver.cpp:310]     Train net output #0: loss = 0.387045 (* 1 = 0.387045 loss)
I1111 00:38:29.067607  2593 sgd_solver.cpp:106] Iteration 3636, lr = 0.00025
I1111 00:38:32.053580  2593 solver.cpp:295] Iteration 3637 (no loss supplied for SingleUpdateStep)
I1111 00:38:32.053639  2593 solver.cpp:310]     Train net output #0: loss = 0.40018 (* 1 = 0.40018 loss)
I1111 00:38:32.053659  2593 sgd_solver.cpp:106] Iteration 3637, lr = 0.00025
I1111 00:38:34.523926  2593 solver.cpp:295] Iteration 3638 (no loss supplied for SingleUpdateStep)
I1111 00:38:34.524019  2593 solver.cpp:310]     Train net output #0: loss = 0.392048 (* 1 = 0.392048 loss)
I1111 00:38:34.524041  2593 sgd_solver.cpp:106] Iteration 3638, lr = 0.00025
I1111 00:38:36.827591  2593 solver.cpp:295] Iteration 3639 (no loss supplied for SingleUpdateStep)
I1111 00:38:36.827695  2593 solver.cpp:310]     Train net output #0: loss = 0.378313 (* 1 = 0.378313 loss)
I1111 00:38:36.827718  2593 sgd_solver.cpp:106] Iteration 3639, lr = 0.00025
I1111 00:38:39.180830  2593 solver.cpp:295] Iteration 3640 (no loss supplied for SingleUpdateStep)
I1111 00:38:39.180922  2593 solver.cpp:310]     Train net output #0: loss = 0.372927 (* 1 = 0.372927 loss)
I1111 00:38:39.180944  2593 sgd_solver.cpp:106] Iteration 3640, lr = 0.00025
I1111 00:38:41.601476  2593 solver.cpp:295] Iteration 3641 (no loss supplied for SingleUpdateStep)
I1111 00:38:41.601552  2593 solver.cpp:310]     Train net output #0: loss = 0.417748 (* 1 = 0.417748 loss)
I1111 00:38:41.601573  2593 sgd_solver.cpp:106] Iteration 3641, lr = 0.00025
I1111 00:38:44.042687  2593 solver.cpp:295] Iteration 3642 (no loss supplied for SingleUpdateStep)
I1111 00:38:44.042758  2593 solver.cpp:310]     Train net output #0: loss = 0.401748 (* 1 = 0.401748 loss)
I1111 00:38:44.042778  2593 sgd_solver.cpp:106] Iteration 3642, lr = 0.00025
I1111 00:38:46.343019  2593 solver.cpp:295] Iteration 3643 (no loss supplied for SingleUpdateStep)
I1111 00:38:46.343137  2593 solver.cpp:310]     Train net output #0: loss = 0.392814 (* 1 = 0.392814 loss)
I1111 00:38:46.343157  2593 sgd_solver.cpp:106] Iteration 3643, lr = 0.00025
I1111 00:38:48.766659  2593 solver.cpp:295] Iteration 3644 (no loss supplied for SingleUpdateStep)
I1111 00:38:48.766801  2593 solver.cpp:310]     Train net output #0: loss = 0.385915 (* 1 = 0.385915 loss)
I1111 00:38:48.766824  2593 sgd_solver.cpp:106] Iteration 3644, lr = 0.00025
I1111 00:38:51.458149  2593 solver.cpp:295] Iteration 3645 (no loss supplied for SingleUpdateStep)
I1111 00:38:51.458273  2593 solver.cpp:310]     Train net output #0: loss = 0.392216 (* 1 = 0.392216 loss)
I1111 00:38:51.458294  2593 sgd_solver.cpp:106] Iteration 3645, lr = 0.00025
I1111 00:38:54.243551  2593 solver.cpp:295] Iteration 3646 (no loss supplied for SingleUpdateStep)
I1111 00:38:54.243654  2593 solver.cpp:310]     Train net output #0: loss = 0.400948 (* 1 = 0.400948 loss)
I1111 00:38:54.243677  2593 sgd_solver.cpp:106] Iteration 3646, lr = 0.00025
I1111 00:38:56.589311  2593 solver.cpp:295] Iteration 3647 (no loss supplied for SingleUpdateStep)
I1111 00:38:56.589385  2593 solver.cpp:310]     Train net output #0: loss = 0.421015 (* 1 = 0.421015 loss)
I1111 00:38:56.589406  2593 sgd_solver.cpp:106] Iteration 3647, lr = 0.00025
I1111 00:38:58.933454  2593 solver.cpp:295] Iteration 3648 (no loss supplied for SingleUpdateStep)
I1111 00:38:58.933528  2593 solver.cpp:310]     Train net output #0: loss = 0.408647 (* 1 = 0.408647 loss)
I1111 00:38:58.933548  2593 sgd_solver.cpp:106] Iteration 3648, lr = 0.00025
I1111 00:39:01.685017  2593 solver.cpp:295] Iteration 3649 (no loss supplied for SingleUpdateStep)
I1111 00:39:01.685140  2593 solver.cpp:310]     Train net output #0: loss = 0.384439 (* 1 = 0.384439 loss)
I1111 00:39:01.685163  2593 sgd_solver.cpp:106] Iteration 3649, lr = 0.00025
I1111 00:39:04.396937  2593 solver.cpp:295] Iteration 3650 (no loss supplied for SingleUpdateStep)
I1111 00:39:04.397006  2593 solver.cpp:310]     Train net output #0: loss = 0.366004 (* 1 = 0.366004 loss)
I1111 00:39:04.397025  2593 sgd_solver.cpp:106] Iteration 3650, lr = 0.00025
I1111 00:39:06.790609  2593 solver.cpp:295] Iteration 3651 (no loss supplied for SingleUpdateStep)
I1111 00:39:06.790670  2593 solver.cpp:310]     Train net output #0: loss = 0.396505 (* 1 = 0.396505 loss)
I1111 00:39:06.790689  2593 sgd_solver.cpp:106] Iteration 3651, lr = 0.00025
I1111 00:39:09.370152  2593 solver.cpp:295] Iteration 3652 (no loss supplied for SingleUpdateStep)
I1111 00:39:09.370271  2593 solver.cpp:310]     Train net output #0: loss = 0.38428 (* 1 = 0.38428 loss)
I1111 00:39:09.370293  2593 sgd_solver.cpp:106] Iteration 3652, lr = 0.00025
I1111 00:39:11.725344  2593 solver.cpp:295] Iteration 3653 (no loss supplied for SingleUpdateStep)
I1111 00:39:11.725507  2593 solver.cpp:310]     Train net output #0: loss = 0.416336 (* 1 = 0.416336 loss)
I1111 00:39:11.725531  2593 sgd_solver.cpp:106] Iteration 3653, lr = 0.00025
I1111 00:39:14.111675  2593 solver.cpp:295] Iteration 3654 (no loss supplied for SingleUpdateStep)
I1111 00:39:14.111758  2593 solver.cpp:310]     Train net output #0: loss = 0.418186 (* 1 = 0.418186 loss)
I1111 00:39:14.111779  2593 sgd_solver.cpp:106] Iteration 3654, lr = 0.00025
I1111 00:39:16.595118  2593 solver.cpp:295] Iteration 3655 (no loss supplied for SingleUpdateStep)
I1111 00:39:16.595216  2593 solver.cpp:310]     Train net output #0: loss = 0.407078 (* 1 = 0.407078 loss)
I1111 00:39:16.595240  2593 sgd_solver.cpp:106] Iteration 3655, lr = 0.00025
I1111 00:39:18.768405  2593 solver.cpp:295] Iteration 3656 (no loss supplied for SingleUpdateStep)
I1111 00:39:18.768537  2593 solver.cpp:310]     Train net output #0: loss = 0.405716 (* 1 = 0.405716 loss)
I1111 00:39:18.768564  2593 sgd_solver.cpp:106] Iteration 3656, lr = 0.00025
I1111 00:39:21.065917  2593 solver.cpp:295] Iteration 3657 (no loss supplied for SingleUpdateStep)
I1111 00:39:21.066068  2593 solver.cpp:310]     Train net output #0: loss = 0.402483 (* 1 = 0.402483 loss)
I1111 00:39:21.066098  2593 sgd_solver.cpp:106] Iteration 3657, lr = 0.00025
I1111 00:39:23.328436  2593 solver.cpp:295] Iteration 3658 (no loss supplied for SingleUpdateStep)
I1111 00:39:23.328608  2593 solver.cpp:310]     Train net output #0: loss = 0.345075 (* 1 = 0.345075 loss)
I1111 00:39:23.328639  2593 sgd_solver.cpp:106] Iteration 3658, lr = 0.00025
I1111 00:39:25.637883  2593 solver.cpp:295] Iteration 3659 (no loss supplied for SingleUpdateStep)
I1111 00:39:25.637934  2593 solver.cpp:310]     Train net output #0: loss = 0.373154 (* 1 = 0.373154 loss)
I1111 00:39:25.637953  2593 sgd_solver.cpp:106] Iteration 3659, lr = 0.00025
I1111 00:39:27.850077  2593 solver.cpp:295] Iteration 3660 (no loss supplied for SingleUpdateStep)
I1111 00:39:27.850178  2593 solver.cpp:310]     Train net output #0: loss = 0.379029 (* 1 = 0.379029 loss)
I1111 00:39:27.850199  2593 sgd_solver.cpp:106] Iteration 3660, lr = 0.00025
I1111 00:39:30.113315  2593 solver.cpp:295] Iteration 3661 (no loss supplied for SingleUpdateStep)
I1111 00:39:30.113384  2593 solver.cpp:310]     Train net output #0: loss = 0.391869 (* 1 = 0.391869 loss)
I1111 00:39:30.113404  2593 sgd_solver.cpp:106] Iteration 3661, lr = 0.00025
I1111 00:39:32.306176  2593 solver.cpp:295] Iteration 3662 (no loss supplied for SingleUpdateStep)
I1111 00:39:32.306258  2593 solver.cpp:310]     Train net output #0: loss = 0.401211 (* 1 = 0.401211 loss)
I1111 00:39:32.306278  2593 sgd_solver.cpp:106] Iteration 3662, lr = 0.00025
I1111 00:39:34.597620  2593 solver.cpp:295] Iteration 3663 (no loss supplied for SingleUpdateStep)
I1111 00:39:34.597730  2593 solver.cpp:310]     Train net output #0: loss = 0.384602 (* 1 = 0.384602 loss)
I1111 00:39:34.597751  2593 sgd_solver.cpp:106] Iteration 3663, lr = 0.00025
I1111 00:39:36.972910  2593 solver.cpp:295] Iteration 3664 (no loss supplied for SingleUpdateStep)
I1111 00:39:36.973036  2593 solver.cpp:310]     Train net output #0: loss = 0.387132 (* 1 = 0.387132 loss)
I1111 00:39:36.973062  2593 sgd_solver.cpp:106] Iteration 3664, lr = 0.00025
I1111 00:39:39.499233  2593 solver.cpp:295] Iteration 3665 (no loss supplied for SingleUpdateStep)
I1111 00:39:39.499349  2593 solver.cpp:310]     Train net output #0: loss = 0.3824 (* 1 = 0.3824 loss)
I1111 00:39:39.499373  2593 sgd_solver.cpp:106] Iteration 3665, lr = 0.00025
I1111 00:39:41.885094  2593 solver.cpp:295] Iteration 3666 (no loss supplied for SingleUpdateStep)
I1111 00:39:41.885208  2593 solver.cpp:310]     Train net output #0: loss = 0.41245 (* 1 = 0.41245 loss)
I1111 00:39:41.885228  2593 sgd_solver.cpp:106] Iteration 3666, lr = 0.00025
I1111 00:39:44.395942  2593 solver.cpp:295] Iteration 3667 (no loss supplied for SingleUpdateStep)
I1111 00:39:44.396003  2593 solver.cpp:310]     Train net output #0: loss = 0.400203 (* 1 = 0.400203 loss)
I1111 00:39:44.396023  2593 sgd_solver.cpp:106] Iteration 3667, lr = 0.00025
I1111 00:39:46.771320  2593 solver.cpp:295] Iteration 3668 (no loss supplied for SingleUpdateStep)
I1111 00:39:46.771425  2593 solver.cpp:310]     Train net output #0: loss = 0.344812 (* 1 = 0.344812 loss)
I1111 00:39:46.771452  2593 sgd_solver.cpp:106] Iteration 3668, lr = 0.00025
I1111 00:39:49.153975  2593 solver.cpp:295] Iteration 3669 (no loss supplied for SingleUpdateStep)
I1111 00:39:49.154072  2593 solver.cpp:310]     Train net output #0: loss = 0.407564 (* 1 = 0.407564 loss)
I1111 00:39:49.154091  2593 sgd_solver.cpp:106] Iteration 3669, lr = 0.00025
I1111 00:39:51.409802  2593 solver.cpp:295] Iteration 3670 (no loss supplied for SingleUpdateStep)
I1111 00:39:51.409860  2593 solver.cpp:310]     Train net output #0: loss = 0.41276 (* 1 = 0.41276 loss)
I1111 00:39:51.409879  2593 sgd_solver.cpp:106] Iteration 3670, lr = 0.00025
I1111 00:39:53.893997  2593 solver.cpp:295] Iteration 3671 (no loss supplied for SingleUpdateStep)
I1111 00:39:53.894136  2593 solver.cpp:310]     Train net output #0: loss = 0.382127 (* 1 = 0.382127 loss)
I1111 00:39:53.894167  2593 sgd_solver.cpp:106] Iteration 3671, lr = 0.00025
I1111 00:39:56.157107  2593 solver.cpp:295] Iteration 3672 (no loss supplied for SingleUpdateStep)
I1111 00:39:56.157223  2593 solver.cpp:310]     Train net output #0: loss = 0.404675 (* 1 = 0.404675 loss)
I1111 00:39:56.157245  2593 sgd_solver.cpp:106] Iteration 3672, lr = 0.00025
I1111 00:39:58.435845  2593 solver.cpp:295] Iteration 3673 (no loss supplied for SingleUpdateStep)
I1111 00:39:58.435962  2593 solver.cpp:310]     Train net output #0: loss = 0.402548 (* 1 = 0.402548 loss)
I1111 00:39:58.435986  2593 sgd_solver.cpp:106] Iteration 3673, lr = 0.00025
I1111 00:40:00.875785  2593 solver.cpp:295] Iteration 3674 (no loss supplied for SingleUpdateStep)
I1111 00:40:00.875917  2593 solver.cpp:310]     Train net output #0: loss = 0.386454 (* 1 = 0.386454 loss)
I1111 00:40:00.875941  2593 sgd_solver.cpp:106] Iteration 3674, lr = 0.00025
I1111 00:40:03.317571  2593 solver.cpp:295] Iteration 3675 (no loss supplied for SingleUpdateStep)
I1111 00:40:03.317679  2593 solver.cpp:310]     Train net output #0: loss = 0.350752 (* 1 = 0.350752 loss)
I1111 00:40:03.317703  2593 sgd_solver.cpp:106] Iteration 3675, lr = 0.00025
I1111 00:40:05.776015  2593 solver.cpp:295] Iteration 3676 (no loss supplied for SingleUpdateStep)
I1111 00:40:05.776110  2593 solver.cpp:310]     Train net output #0: loss = 0.379796 (* 1 = 0.379796 loss)
I1111 00:40:05.776132  2593 sgd_solver.cpp:106] Iteration 3676, lr = 0.00025
I1111 00:40:08.434629  2593 solver.cpp:295] Iteration 3677 (no loss supplied for SingleUpdateStep)
I1111 00:40:08.434751  2593 solver.cpp:310]     Train net output #0: loss = 0.379847 (* 1 = 0.379847 loss)
I1111 00:40:08.434775  2593 sgd_solver.cpp:106] Iteration 3677, lr = 0.00025
I1111 00:40:11.098886  2593 solver.cpp:295] Iteration 3678 (no loss supplied for SingleUpdateStep)
I1111 00:40:11.099002  2593 solver.cpp:310]     Train net output #0: loss = 0.384604 (* 1 = 0.384604 loss)
I1111 00:40:11.099023  2593 sgd_solver.cpp:106] Iteration 3678, lr = 0.00025
I1111 00:40:13.504464  2593 solver.cpp:295] Iteration 3679 (no loss supplied for SingleUpdateStep)
I1111 00:40:13.504542  2593 solver.cpp:310]     Train net output #0: loss = 0.417248 (* 1 = 0.417248 loss)
I1111 00:40:13.504562  2593 sgd_solver.cpp:106] Iteration 3679, lr = 0.00025
I1111 00:40:15.955617  2593 solver.cpp:295] Iteration 3680 (no loss supplied for SingleUpdateStep)
I1111 00:40:15.955677  2593 solver.cpp:310]     Train net output #0: loss = 0.434637 (* 1 = 0.434637 loss)
I1111 00:40:15.955698  2593 sgd_solver.cpp:106] Iteration 3680, lr = 0.00025
I1111 00:40:18.533737  2593 solver.cpp:295] Iteration 3681 (no loss supplied for SingleUpdateStep)
I1111 00:40:18.533911  2593 solver.cpp:310]     Train net output #0: loss = 0.383047 (* 1 = 0.383047 loss)
I1111 00:40:18.533944  2593 sgd_solver.cpp:106] Iteration 3681, lr = 0.00025
I1111 00:40:21.582293  2593 solver.cpp:295] Iteration 3682 (no loss supplied for SingleUpdateStep)
I1111 00:40:21.582351  2593 solver.cpp:310]     Train net output #0: loss = 0.392749 (* 1 = 0.392749 loss)
I1111 00:40:21.582370  2593 sgd_solver.cpp:106] Iteration 3682, lr = 0.00025
I1111 00:40:24.055857  2593 solver.cpp:295] Iteration 3683 (no loss supplied for SingleUpdateStep)
I1111 00:40:24.055974  2593 solver.cpp:310]     Train net output #0: loss = 0.373248 (* 1 = 0.373248 loss)
I1111 00:40:24.055997  2593 sgd_solver.cpp:106] Iteration 3683, lr = 0.00025
I1111 00:40:26.421411  2593 solver.cpp:295] Iteration 3684 (no loss supplied for SingleUpdateStep)
I1111 00:40:26.467398  2593 solver.cpp:310]     Train net output #0: loss = 0.410136 (* 1 = 0.410136 loss)
I1111 00:40:26.467470  2593 sgd_solver.cpp:106] Iteration 3684, lr = 0.00025
I1111 00:40:29.429920  2593 solver.cpp:295] Iteration 3685 (no loss supplied for SingleUpdateStep)
I1111 00:40:29.430029  2593 solver.cpp:310]     Train net output #0: loss = 0.396318 (* 1 = 0.396318 loss)
I1111 00:40:29.430052  2593 sgd_solver.cpp:106] Iteration 3685, lr = 0.00025
I1111 00:40:31.993975  2593 solver.cpp:295] Iteration 3686 (no loss supplied for SingleUpdateStep)
I1111 00:40:31.994091  2593 solver.cpp:310]     Train net output #0: loss = 0.392371 (* 1 = 0.392371 loss)
I1111 00:40:31.994112  2593 sgd_solver.cpp:106] Iteration 3686, lr = 0.00025
I1111 00:40:34.486752  2593 solver.cpp:295] Iteration 3687 (no loss supplied for SingleUpdateStep)
I1111 00:40:34.486901  2593 solver.cpp:310]     Train net output #0: loss = 0.41084 (* 1 = 0.41084 loss)
I1111 00:40:34.486925  2593 sgd_solver.cpp:106] Iteration 3687, lr = 0.00025
I1111 00:40:37.045935  2593 solver.cpp:295] Iteration 3688 (no loss supplied for SingleUpdateStep)
I1111 00:40:37.046041  2593 solver.cpp:310]     Train net output #0: loss = 0.420934 (* 1 = 0.420934 loss)
I1111 00:40:37.046064  2593 sgd_solver.cpp:106] Iteration 3688, lr = 0.00025
I1111 00:40:39.555094  2593 solver.cpp:295] Iteration 3689 (no loss supplied for SingleUpdateStep)
I1111 00:40:39.555201  2593 solver.cpp:310]     Train net output #0: loss = 0.403021 (* 1 = 0.403021 loss)
I1111 00:40:39.555222  2593 sgd_solver.cpp:106] Iteration 3689, lr = 0.00025
I1111 00:40:42.047062  2593 solver.cpp:295] Iteration 3690 (no loss supplied for SingleUpdateStep)
I1111 00:40:42.047144  2593 solver.cpp:310]     Train net output #0: loss = 0.381931 (* 1 = 0.381931 loss)
I1111 00:40:42.047164  2593 sgd_solver.cpp:106] Iteration 3690, lr = 0.00025
I1111 00:40:44.279903  2593 solver.cpp:295] Iteration 3691 (no loss supplied for SingleUpdateStep)
I1111 00:40:44.280001  2593 solver.cpp:310]     Train net output #0: loss = 0.402784 (* 1 = 0.402784 loss)
I1111 00:40:44.280024  2593 sgd_solver.cpp:106] Iteration 3691, lr = 0.00025
I1111 00:40:47.036989  2593 solver.cpp:295] Iteration 3692 (no loss supplied for SingleUpdateStep)
I1111 00:40:47.037142  2593 solver.cpp:310]     Train net output #0: loss = 0.389554 (* 1 = 0.389554 loss)
I1111 00:40:47.037165  2593 sgd_solver.cpp:106] Iteration 3692, lr = 0.00025
I1111 00:40:50.166653  2593 solver.cpp:295] Iteration 3693 (no loss supplied for SingleUpdateStep)
I1111 00:40:50.166769  2593 solver.cpp:310]     Train net output #0: loss = 0.422206 (* 1 = 0.422206 loss)
I1111 00:40:50.166791  2593 sgd_solver.cpp:106] Iteration 3693, lr = 0.00025
I1111 00:40:53.084941  2593 solver.cpp:295] Iteration 3694 (no loss supplied for SingleUpdateStep)
I1111 00:40:53.085019  2593 solver.cpp:310]     Train net output #0: loss = 0.365315 (* 1 = 0.365315 loss)
I1111 00:40:53.085041  2593 sgd_solver.cpp:106] Iteration 3694, lr = 0.00025
I1111 00:40:56.272552  2593 solver.cpp:295] Iteration 3695 (no loss supplied for SingleUpdateStep)
I1111 00:40:56.272703  2593 solver.cpp:310]     Train net output #0: loss = 0.394227 (* 1 = 0.394227 loss)
I1111 00:40:56.272727  2593 sgd_solver.cpp:106] Iteration 3695, lr = 0.00025
I1111 00:40:59.384232  2593 solver.cpp:295] Iteration 3696 (no loss supplied for SingleUpdateStep)
I1111 00:40:59.384326  2593 solver.cpp:310]     Train net output #0: loss = 0.395861 (* 1 = 0.395861 loss)
I1111 00:40:59.384347  2593 sgd_solver.cpp:106] Iteration 3696, lr = 0.00025
I1111 00:41:02.906357  2593 solver.cpp:295] Iteration 3697 (no loss supplied for SingleUpdateStep)
I1111 00:41:02.906462  2593 solver.cpp:310]     Train net output #0: loss = 0.413797 (* 1 = 0.413797 loss)
I1111 00:41:02.906484  2593 sgd_solver.cpp:106] Iteration 3697, lr = 0.00025
I1111 00:41:06.420840  2593 solver.cpp:295] Iteration 3698 (no loss supplied for SingleUpdateStep)
I1111 00:41:06.420905  2593 solver.cpp:310]     Train net output #0: loss = 0.37178 (* 1 = 0.37178 loss)
I1111 00:41:06.420925  2593 sgd_solver.cpp:106] Iteration 3698, lr = 0.00025
I1111 00:41:10.143803  2593 solver.cpp:295] Iteration 3699 (no loss supplied for SingleUpdateStep)
I1111 00:41:10.143880  2593 solver.cpp:310]     Train net output #0: loss = 0.398412 (* 1 = 0.398412 loss)
I1111 00:41:10.143900  2593 sgd_solver.cpp:106] Iteration 3699, lr = 0.00025
I1111 00:41:13.675465  2593 solver.cpp:295] Iteration 3700 (no loss supplied for SingleUpdateStep)
I1111 00:41:13.675578  2593 solver.cpp:310]     Train net output #0: loss = 0.389939 (* 1 = 0.389939 loss)
I1111 00:41:13.675600  2593 sgd_solver.cpp:106] Iteration 3700, lr = 0.00025
I1111 00:41:17.136023  2593 solver.cpp:295] Iteration 3701 (no loss supplied for SingleUpdateStep)
I1111 00:41:17.136134  2593 solver.cpp:310]     Train net output #0: loss = 0.378518 (* 1 = 0.378518 loss)
I1111 00:41:17.136155  2593 sgd_solver.cpp:106] Iteration 3701, lr = 0.00025
I1111 00:41:19.565506  2593 solver.cpp:295] Iteration 3702 (no loss supplied for SingleUpdateStep)
I1111 00:41:19.565620  2593 solver.cpp:310]     Train net output #0: loss = 0.38136 (* 1 = 0.38136 loss)
I1111 00:41:19.565640  2593 sgd_solver.cpp:106] Iteration 3702, lr = 0.00025
I1111 00:41:22.027626  2593 solver.cpp:295] Iteration 3703 (no loss supplied for SingleUpdateStep)
I1111 00:41:22.027731  2593 solver.cpp:310]     Train net output #0: loss = 0.367796 (* 1 = 0.367796 loss)
I1111 00:41:22.027752  2593 sgd_solver.cpp:106] Iteration 3703, lr = 0.00025
I1111 00:41:24.383496  2593 solver.cpp:295] Iteration 3704 (no loss supplied for SingleUpdateStep)
I1111 00:41:24.383620  2593 solver.cpp:310]     Train net output #0: loss = 0.420714 (* 1 = 0.420714 loss)
I1111 00:41:24.383641  2593 sgd_solver.cpp:106] Iteration 3704, lr = 0.00025
I1111 00:41:26.598011  2593 solver.cpp:295] Iteration 3705 (no loss supplied for SingleUpdateStep)
I1111 00:41:26.598096  2593 solver.cpp:310]     Train net output #0: loss = 0.376421 (* 1 = 0.376421 loss)
I1111 00:41:26.598119  2593 sgd_solver.cpp:106] Iteration 3705, lr = 0.00025
I1111 00:41:28.983419  2593 solver.cpp:295] Iteration 3706 (no loss supplied for SingleUpdateStep)
I1111 00:41:28.983525  2593 solver.cpp:310]     Train net output #0: loss = 0.381495 (* 1 = 0.381495 loss)
I1111 00:41:28.983547  2593 sgd_solver.cpp:106] Iteration 3706, lr = 0.00025
I1111 00:41:31.491377  2593 solver.cpp:295] Iteration 3707 (no loss supplied for SingleUpdateStep)
I1111 00:41:31.491478  2593 solver.cpp:310]     Train net output #0: loss = 0.383629 (* 1 = 0.383629 loss)
I1111 00:41:31.491503  2593 sgd_solver.cpp:106] Iteration 3707, lr = 0.00025
I1111 00:41:33.733034  2593 solver.cpp:295] Iteration 3708 (no loss supplied for SingleUpdateStep)
I1111 00:41:33.733146  2593 solver.cpp:310]     Train net output #0: loss = 0.390978 (* 1 = 0.390978 loss)
I1111 00:41:33.733166  2593 sgd_solver.cpp:106] Iteration 3708, lr = 0.00025
I1111 00:41:36.078457  2593 solver.cpp:295] Iteration 3709 (no loss supplied for SingleUpdateStep)
I1111 00:41:36.078526  2593 solver.cpp:310]     Train net output #0: loss = 0.376373 (* 1 = 0.376373 loss)
I1111 00:41:36.078546  2593 sgd_solver.cpp:106] Iteration 3709, lr = 0.00025
I1111 00:41:38.387821  2593 solver.cpp:295] Iteration 3710 (no loss supplied for SingleUpdateStep)
I1111 00:41:38.387917  2593 solver.cpp:310]     Train net output #0: loss = 0.376126 (* 1 = 0.376126 loss)
I1111 00:41:38.387939  2593 sgd_solver.cpp:106] Iteration 3710, lr = 0.00025
I1111 00:41:40.647052  2593 solver.cpp:295] Iteration 3711 (no loss supplied for SingleUpdateStep)
I1111 00:41:40.647197  2593 solver.cpp:310]     Train net output #0: loss = 0.407115 (* 1 = 0.407115 loss)
I1111 00:41:40.647219  2593 sgd_solver.cpp:106] Iteration 3711, lr = 0.00025
I1111 00:41:43.549466  2593 solver.cpp:295] Iteration 3712 (no loss supplied for SingleUpdateStep)
I1111 00:41:43.549573  2593 solver.cpp:310]     Train net output #0: loss = 0.382636 (* 1 = 0.382636 loss)
I1111 00:41:43.549594  2593 sgd_solver.cpp:106] Iteration 3712, lr = 0.00025
I1111 00:41:45.923235  2593 solver.cpp:295] Iteration 3713 (no loss supplied for SingleUpdateStep)
I1111 00:41:45.923288  2593 solver.cpp:310]     Train net output #0: loss = 0.375534 (* 1 = 0.375534 loss)
I1111 00:41:45.923307  2593 sgd_solver.cpp:106] Iteration 3713, lr = 0.00025
I1111 00:41:48.257115  2593 solver.cpp:295] Iteration 3714 (no loss supplied for SingleUpdateStep)
I1111 00:41:48.257256  2593 solver.cpp:310]     Train net output #0: loss = 0.392273 (* 1 = 0.392273 loss)
I1111 00:41:48.257282  2593 sgd_solver.cpp:106] Iteration 3714, lr = 0.00025
I1111 00:41:50.467789  2593 solver.cpp:295] Iteration 3715 (no loss supplied for SingleUpdateStep)
I1111 00:41:50.467924  2593 solver.cpp:310]     Train net output #0: loss = 0.378029 (* 1 = 0.378029 loss)
I1111 00:41:50.467957  2593 sgd_solver.cpp:106] Iteration 3715, lr = 0.00025
I1111 00:41:53.030287  2593 solver.cpp:295] Iteration 3716 (no loss supplied for SingleUpdateStep)
I1111 00:41:53.030396  2593 solver.cpp:310]     Train net output #0: loss = 0.351834 (* 1 = 0.351834 loss)
I1111 00:41:53.030421  2593 sgd_solver.cpp:106] Iteration 3716, lr = 0.00025
I1111 00:41:55.487081  2593 solver.cpp:295] Iteration 3717 (no loss supplied for SingleUpdateStep)
I1111 00:41:55.487153  2593 solver.cpp:310]     Train net output #0: loss = 0.378158 (* 1 = 0.378158 loss)
I1111 00:41:55.487172  2593 sgd_solver.cpp:106] Iteration 3717, lr = 0.00025
I1111 00:41:57.850574  2593 solver.cpp:295] Iteration 3718 (no loss supplied for SingleUpdateStep)
I1111 00:41:57.850689  2593 solver.cpp:310]     Train net output #0: loss = 0.413585 (* 1 = 0.413585 loss)
I1111 00:41:57.850715  2593 sgd_solver.cpp:106] Iteration 3718, lr = 0.00025
I1111 00:42:00.362753  2593 solver.cpp:295] Iteration 3719 (no loss supplied for SingleUpdateStep)
I1111 00:42:00.362864  2593 solver.cpp:310]     Train net output #0: loss = 0.379594 (* 1 = 0.379594 loss)
I1111 00:42:00.362886  2593 sgd_solver.cpp:106] Iteration 3719, lr = 0.00025
I1111 00:42:02.684927  2593 solver.cpp:295] Iteration 3720 (no loss supplied for SingleUpdateStep)
I1111 00:42:02.685048  2593 solver.cpp:310]     Train net output #0: loss = 0.430661 (* 1 = 0.430661 loss)
I1111 00:42:02.685070  2593 sgd_solver.cpp:106] Iteration 3720, lr = 0.00025
I1111 00:42:04.862483  2593 solver.cpp:295] Iteration 3721 (no loss supplied for SingleUpdateStep)
I1111 00:42:04.862586  2593 solver.cpp:310]     Train net output #0: loss = 0.40284 (* 1 = 0.40284 loss)
I1111 00:42:04.862609  2593 sgd_solver.cpp:106] Iteration 3721, lr = 0.00025
I1111 00:42:07.203333  2593 solver.cpp:295] Iteration 3722 (no loss supplied for SingleUpdateStep)
I1111 00:42:07.203521  2593 solver.cpp:310]     Train net output #0: loss = 0.425204 (* 1 = 0.425204 loss)
I1111 00:42:07.203548  2593 sgd_solver.cpp:106] Iteration 3722, lr = 0.00025
I1111 00:42:09.735959  2593 solver.cpp:295] Iteration 3723 (no loss supplied for SingleUpdateStep)
I1111 00:42:09.736129  2593 solver.cpp:310]     Train net output #0: loss = 0.408839 (* 1 = 0.408839 loss)
I1111 00:42:09.736155  2593 sgd_solver.cpp:106] Iteration 3723, lr = 0.00025
I1111 00:42:12.334684  2593 solver.cpp:295] Iteration 3724 (no loss supplied for SingleUpdateStep)
I1111 00:42:12.334818  2593 solver.cpp:310]     Train net output #0: loss = 0.401296 (* 1 = 0.401296 loss)
I1111 00:42:12.334842  2593 sgd_solver.cpp:106] Iteration 3724, lr = 0.00025
I1111 00:42:14.875808  2593 solver.cpp:295] Iteration 3725 (no loss supplied for SingleUpdateStep)
I1111 00:42:14.876008  2593 solver.cpp:310]     Train net output #0: loss = 0.391363 (* 1 = 0.391363 loss)
I1111 00:42:14.876032  2593 sgd_solver.cpp:106] Iteration 3725, lr = 0.00025
I1111 00:42:17.291918  2593 solver.cpp:295] Iteration 3726 (no loss supplied for SingleUpdateStep)
I1111 00:42:17.291976  2593 solver.cpp:310]     Train net output #0: loss = 0.376252 (* 1 = 0.376252 loss)
I1111 00:42:17.291995  2593 sgd_solver.cpp:106] Iteration 3726, lr = 0.00025
I1111 00:42:19.646356  2593 solver.cpp:295] Iteration 3727 (no loss supplied for SingleUpdateStep)
I1111 00:42:19.646471  2593 solver.cpp:310]     Train net output #0: loss = 0.355744 (* 1 = 0.355744 loss)
I1111 00:42:19.646495  2593 sgd_solver.cpp:106] Iteration 3727, lr = 0.00025
I1111 00:42:22.048754  2593 solver.cpp:295] Iteration 3728 (no loss supplied for SingleUpdateStep)
I1111 00:42:22.048869  2593 solver.cpp:310]     Train net output #0: loss = 0.380309 (* 1 = 0.380309 loss)
I1111 00:42:22.048890  2593 sgd_solver.cpp:106] Iteration 3728, lr = 0.00025
I1111 00:42:24.366937  2593 solver.cpp:295] Iteration 3729 (no loss supplied for SingleUpdateStep)
I1111 00:42:24.367159  2593 solver.cpp:310]     Train net output #0: loss = 0.39268 (* 1 = 0.39268 loss)
I1111 00:42:24.367190  2593 sgd_solver.cpp:106] Iteration 3729, lr = 0.00025
I1111 00:42:26.603072  2593 solver.cpp:295] Iteration 3730 (no loss supplied for SingleUpdateStep)
I1111 00:42:26.603170  2593 solver.cpp:310]     Train net output #0: loss = 0.381435 (* 1 = 0.381435 loss)
I1111 00:42:26.603193  2593 sgd_solver.cpp:106] Iteration 3730, lr = 0.00025
I1111 00:42:28.796290  2593 solver.cpp:295] Iteration 3731 (no loss supplied for SingleUpdateStep)
I1111 00:42:28.796345  2593 solver.cpp:310]     Train net output #0: loss = 0.38672 (* 1 = 0.38672 loss)
I1111 00:42:28.796365  2593 sgd_solver.cpp:106] Iteration 3731, lr = 0.00025
I1111 00:42:31.117388  2593 solver.cpp:295] Iteration 3732 (no loss supplied for SingleUpdateStep)
I1111 00:42:31.117466  2593 solver.cpp:310]     Train net output #0: loss = 0.398735 (* 1 = 0.398735 loss)
I1111 00:42:31.117487  2593 sgd_solver.cpp:106] Iteration 3732, lr = 0.00025
I1111 00:42:33.566845  2593 solver.cpp:295] Iteration 3733 (no loss supplied for SingleUpdateStep)
I1111 00:42:33.566975  2593 solver.cpp:310]     Train net output #0: loss = 0.374012 (* 1 = 0.374012 loss)
I1111 00:42:33.566999  2593 sgd_solver.cpp:106] Iteration 3733, lr = 0.00025
I1111 00:42:35.821311  2593 solver.cpp:295] Iteration 3734 (no loss supplied for SingleUpdateStep)
I1111 00:42:35.821422  2593 solver.cpp:310]     Train net output #0: loss = 0.396834 (* 1 = 0.396834 loss)
I1111 00:42:35.821445  2593 sgd_solver.cpp:106] Iteration 3734, lr = 0.00025
I1111 00:42:38.097748  2593 solver.cpp:295] Iteration 3735 (no loss supplied for SingleUpdateStep)
I1111 00:42:38.097851  2593 solver.cpp:310]     Train net output #0: loss = 0.371015 (* 1 = 0.371015 loss)
I1111 00:42:38.097874  2593 sgd_solver.cpp:106] Iteration 3735, lr = 0.00025
I1111 00:42:40.477114  2593 solver.cpp:295] Iteration 3736 (no loss supplied for SingleUpdateStep)
I1111 00:42:40.477236  2593 solver.cpp:310]     Train net output #0: loss = 0.394549 (* 1 = 0.394549 loss)
I1111 00:42:40.477258  2593 sgd_solver.cpp:106] Iteration 3736, lr = 0.00025
I1111 00:42:42.888660  2593 solver.cpp:295] Iteration 3737 (no loss supplied for SingleUpdateStep)
I1111 00:42:42.888712  2593 solver.cpp:310]     Train net output #0: loss = 0.384073 (* 1 = 0.384073 loss)
I1111 00:42:42.888731  2593 sgd_solver.cpp:106] Iteration 3737, lr = 0.00025
I1111 00:42:45.363457  2593 solver.cpp:295] Iteration 3738 (no loss supplied for SingleUpdateStep)
I1111 00:42:45.363582  2593 solver.cpp:310]     Train net output #0: loss = 0.388741 (* 1 = 0.388741 loss)
I1111 00:42:45.363610  2593 sgd_solver.cpp:106] Iteration 3738, lr = 0.00025
I1111 00:42:47.771813  2593 solver.cpp:295] Iteration 3739 (no loss supplied for SingleUpdateStep)
I1111 00:42:47.771967  2593 solver.cpp:310]     Train net output #0: loss = 0.382926 (* 1 = 0.382926 loss)
I1111 00:42:47.771991  2593 sgd_solver.cpp:106] Iteration 3739, lr = 0.00025
I1111 00:42:50.160223  2593 solver.cpp:295] Iteration 3740 (no loss supplied for SingleUpdateStep)
I1111 00:42:50.160305  2593 solver.cpp:310]     Train net output #0: loss = 0.387207 (* 1 = 0.387207 loss)
I1111 00:42:50.160326  2593 sgd_solver.cpp:106] Iteration 3740, lr = 0.00025
I1111 00:42:52.491441  2593 solver.cpp:295] Iteration 3741 (no loss supplied for SingleUpdateStep)
I1111 00:42:52.491559  2593 solver.cpp:310]     Train net output #0: loss = 0.357604 (* 1 = 0.357604 loss)
I1111 00:42:52.491582  2593 sgd_solver.cpp:106] Iteration 3741, lr = 0.00025
I1111 00:42:54.679872  2593 solver.cpp:295] Iteration 3742 (no loss supplied for SingleUpdateStep)
I1111 00:42:54.679945  2593 solver.cpp:310]     Train net output #0: loss = 0.398524 (* 1 = 0.398524 loss)
I1111 00:42:54.679965  2593 sgd_solver.cpp:106] Iteration 3742, lr = 0.00025
I1111 00:42:56.927666  2593 solver.cpp:295] Iteration 3743 (no loss supplied for SingleUpdateStep)
I1111 00:42:56.927750  2593 solver.cpp:310]     Train net output #0: loss = 0.390759 (* 1 = 0.390759 loss)
I1111 00:42:56.927772  2593 sgd_solver.cpp:106] Iteration 3743, lr = 0.00025
I1111 00:42:59.326674  2593 solver.cpp:295] Iteration 3744 (no loss supplied for SingleUpdateStep)
I1111 00:42:59.326810  2593 solver.cpp:310]     Train net output #0: loss = 0.363059 (* 1 = 0.363059 loss)
I1111 00:42:59.326838  2593 sgd_solver.cpp:106] Iteration 3744, lr = 0.00025
I1111 00:43:01.736265  2593 solver.cpp:295] Iteration 3745 (no loss supplied for SingleUpdateStep)
I1111 00:43:01.736342  2593 solver.cpp:310]     Train net output #0: loss = 0.377868 (* 1 = 0.377868 loss)
I1111 00:43:01.736368  2593 sgd_solver.cpp:106] Iteration 3745, lr = 0.00025
I1111 00:43:04.107166  2593 solver.cpp:295] Iteration 3746 (no loss supplied for SingleUpdateStep)
I1111 00:43:04.107234  2593 solver.cpp:310]     Train net output #0: loss = 0.398132 (* 1 = 0.398132 loss)
I1111 00:43:04.107255  2593 sgd_solver.cpp:106] Iteration 3746, lr = 0.00025
I1111 00:43:06.320705  2593 solver.cpp:295] Iteration 3747 (no loss supplied for SingleUpdateStep)
I1111 00:43:06.320785  2593 solver.cpp:310]     Train net output #0: loss = 0.375687 (* 1 = 0.375687 loss)
I1111 00:43:06.320806  2593 sgd_solver.cpp:106] Iteration 3747, lr = 0.00025
I1111 00:43:09.001214  2593 solver.cpp:295] Iteration 3748 (no loss supplied for SingleUpdateStep)
I1111 00:43:09.001325  2593 solver.cpp:310]     Train net output #0: loss = 0.388708 (* 1 = 0.388708 loss)
I1111 00:43:09.001345  2593 sgd_solver.cpp:106] Iteration 3748, lr = 0.00025
I1111 00:43:11.291658  2593 solver.cpp:295] Iteration 3749 (no loss supplied for SingleUpdateStep)
I1111 00:43:11.291745  2593 solver.cpp:310]     Train net output #0: loss = 0.377054 (* 1 = 0.377054 loss)
I1111 00:43:11.291765  2593 sgd_solver.cpp:106] Iteration 3749, lr = 0.00025
I1111 00:43:13.555145  2593 solver.cpp:295] Iteration 3750 (no loss supplied for SingleUpdateStep)
I1111 00:43:13.555255  2593 solver.cpp:310]     Train net output #0: loss = 0.399463 (* 1 = 0.399463 loss)
I1111 00:43:13.555279  2593 sgd_solver.cpp:106] Iteration 3750, lr = 0.00025
I1111 00:43:15.845815  2593 solver.cpp:295] Iteration 3751 (no loss supplied for SingleUpdateStep)
I1111 00:43:15.845881  2593 solver.cpp:310]     Train net output #0: loss = 0.392463 (* 1 = 0.392463 loss)
I1111 00:43:15.845901  2593 sgd_solver.cpp:106] Iteration 3751, lr = 0.00025
I1111 00:43:18.709630  2593 solver.cpp:295] Iteration 3752 (no loss supplied for SingleUpdateStep)
I1111 00:43:18.709708  2593 solver.cpp:310]     Train net output #0: loss = 0.37338 (* 1 = 0.37338 loss)
I1111 00:43:18.709730  2593 sgd_solver.cpp:106] Iteration 3752, lr = 0.00025
I1111 00:43:21.279000  2593 solver.cpp:295] Iteration 3753 (no loss supplied for SingleUpdateStep)
I1111 00:43:21.279057  2593 solver.cpp:310]     Train net output #0: loss = 0.404485 (* 1 = 0.404485 loss)
I1111 00:43:21.279074  2593 sgd_solver.cpp:106] Iteration 3753, lr = 0.00025
I1111 00:43:23.753901  2593 solver.cpp:295] Iteration 3754 (no loss supplied for SingleUpdateStep)
I1111 00:43:23.754003  2593 solver.cpp:310]     Train net output #0: loss = 0.429918 (* 1 = 0.429918 loss)
I1111 00:43:23.754024  2593 sgd_solver.cpp:106] Iteration 3754, lr = 0.00025
I1111 00:43:26.262320  2593 solver.cpp:295] Iteration 3755 (no loss supplied for SingleUpdateStep)
I1111 00:43:26.262465  2593 solver.cpp:310]     Train net output #0: loss = 0.388331 (* 1 = 0.388331 loss)
I1111 00:43:26.262495  2593 sgd_solver.cpp:106] Iteration 3755, lr = 0.00025
I1111 00:43:28.421356  2593 solver.cpp:295] Iteration 3756 (no loss supplied for SingleUpdateStep)
I1111 00:43:28.421434  2593 solver.cpp:310]     Train net output #0: loss = 0.381401 (* 1 = 0.381401 loss)
I1111 00:43:28.421454  2593 sgd_solver.cpp:106] Iteration 3756, lr = 0.00025
I1111 00:43:30.958783  2593 solver.cpp:295] Iteration 3757 (no loss supplied for SingleUpdateStep)
I1111 00:43:30.958843  2593 solver.cpp:310]     Train net output #0: loss = 0.386089 (* 1 = 0.386089 loss)
I1111 00:43:30.958864  2593 sgd_solver.cpp:106] Iteration 3757, lr = 0.00025
I1111 00:43:33.490447  2593 solver.cpp:295] Iteration 3758 (no loss supplied for SingleUpdateStep)
I1111 00:43:33.490567  2593 solver.cpp:310]     Train net output #0: loss = 0.373527 (* 1 = 0.373527 loss)
I1111 00:43:33.490592  2593 sgd_solver.cpp:106] Iteration 3758, lr = 0.00025
I1111 00:43:35.739039  2593 solver.cpp:295] Iteration 3759 (no loss supplied for SingleUpdateStep)
I1111 00:43:35.739135  2593 solver.cpp:310]     Train net output #0: loss = 0.382898 (* 1 = 0.382898 loss)
I1111 00:43:35.739158  2593 sgd_solver.cpp:106] Iteration 3759, lr = 0.00025
I1111 00:43:38.204840  2593 solver.cpp:295] Iteration 3760 (no loss supplied for SingleUpdateStep)
I1111 00:43:38.204926  2593 solver.cpp:310]     Train net output #0: loss = 0.397851 (* 1 = 0.397851 loss)
I1111 00:43:38.204949  2593 sgd_solver.cpp:106] Iteration 3760, lr = 0.00025
I1111 00:43:40.671412  2593 solver.cpp:295] Iteration 3761 (no loss supplied for SingleUpdateStep)
I1111 00:43:40.671555  2593 solver.cpp:310]     Train net output #0: loss = 0.388905 (* 1 = 0.388905 loss)
I1111 00:43:40.671578  2593 sgd_solver.cpp:106] Iteration 3761, lr = 0.00025
I1111 00:43:43.075305  2593 solver.cpp:295] Iteration 3762 (no loss supplied for SingleUpdateStep)
I1111 00:43:43.075387  2593 solver.cpp:310]     Train net output #0: loss = 0.37465 (* 1 = 0.37465 loss)
I1111 00:43:43.075408  2593 sgd_solver.cpp:106] Iteration 3762, lr = 0.00025
I1111 00:43:45.554563  2593 solver.cpp:295] Iteration 3763 (no loss supplied for SingleUpdateStep)
I1111 00:43:45.554726  2593 solver.cpp:310]     Train net output #0: loss = 0.355747 (* 1 = 0.355747 loss)
I1111 00:43:45.554751  2593 sgd_solver.cpp:106] Iteration 3763, lr = 0.00025
I1111 00:43:47.968384  2593 solver.cpp:295] Iteration 3764 (no loss supplied for SingleUpdateStep)
I1111 00:43:47.968487  2593 solver.cpp:310]     Train net output #0: loss = 0.403533 (* 1 = 0.403533 loss)
I1111 00:43:47.968508  2593 sgd_solver.cpp:106] Iteration 3764, lr = 0.00025
I1111 00:43:50.371345  2593 solver.cpp:295] Iteration 3765 (no loss supplied for SingleUpdateStep)
I1111 00:43:50.371455  2593 solver.cpp:310]     Train net output #0: loss = 0.404021 (* 1 = 0.404021 loss)
I1111 00:43:50.371476  2593 sgd_solver.cpp:106] Iteration 3765, lr = 0.00025
I1111 00:43:52.964759  2593 solver.cpp:295] Iteration 3766 (no loss supplied for SingleUpdateStep)
I1111 00:43:52.964844  2593 solver.cpp:310]     Train net output #0: loss = 0.394682 (* 1 = 0.394682 loss)
I1111 00:43:52.964865  2593 sgd_solver.cpp:106] Iteration 3766, lr = 0.00025
I1111 00:43:55.423461  2593 solver.cpp:295] Iteration 3767 (no loss supplied for SingleUpdateStep)
I1111 00:43:55.423527  2593 solver.cpp:310]     Train net output #0: loss = 0.386309 (* 1 = 0.386309 loss)
I1111 00:43:55.423547  2593 sgd_solver.cpp:106] Iteration 3767, lr = 0.00025
I1111 00:43:57.805946  2593 solver.cpp:295] Iteration 3768 (no loss supplied for SingleUpdateStep)
I1111 00:43:57.806056  2593 solver.cpp:310]     Train net output #0: loss = 0.396919 (* 1 = 0.396919 loss)
I1111 00:43:57.806078  2593 sgd_solver.cpp:106] Iteration 3768, lr = 0.00025
I1111 00:44:00.306985  2593 solver.cpp:295] Iteration 3769 (no loss supplied for SingleUpdateStep)
I1111 00:44:00.307045  2593 solver.cpp:310]     Train net output #0: loss = 0.40104 (* 1 = 0.40104 loss)
I1111 00:44:00.307063  2593 sgd_solver.cpp:106] Iteration 3769, lr = 0.00025
I1111 00:44:02.587504  2593 solver.cpp:295] Iteration 3770 (no loss supplied for SingleUpdateStep)
I1111 00:44:02.596791  2593 solver.cpp:310]     Train net output #0: loss = 0.395973 (* 1 = 0.395973 loss)
I1111 00:44:02.596864  2593 sgd_solver.cpp:106] Iteration 3770, lr = 0.00025
I1111 00:44:04.932129  2593 solver.cpp:295] Iteration 3771 (no loss supplied for SingleUpdateStep)
I1111 00:44:04.932265  2593 solver.cpp:310]     Train net output #0: loss = 0.368205 (* 1 = 0.368205 loss)
I1111 00:44:04.932291  2593 sgd_solver.cpp:106] Iteration 3771, lr = 0.00025
I1111 00:44:07.646235  2593 solver.cpp:295] Iteration 3772 (no loss supplied for SingleUpdateStep)
I1111 00:44:07.646330  2593 solver.cpp:310]     Train net output #0: loss = 0.351025 (* 1 = 0.351025 loss)
I1111 00:44:07.646352  2593 sgd_solver.cpp:106] Iteration 3772, lr = 0.00025
I1111 00:44:10.077836  2593 solver.cpp:295] Iteration 3773 (no loss supplied for SingleUpdateStep)
I1111 00:44:10.077934  2593 solver.cpp:310]     Train net output #0: loss = 0.378556 (* 1 = 0.378556 loss)
I1111 00:44:10.077956  2593 sgd_solver.cpp:106] Iteration 3773, lr = 0.00025
I1111 00:44:12.346444  2593 solver.cpp:295] Iteration 3774 (no loss supplied for SingleUpdateStep)
I1111 00:44:12.346554  2593 solver.cpp:310]     Train net output #0: loss = 0.389979 (* 1 = 0.389979 loss)
I1111 00:44:12.346576  2593 sgd_solver.cpp:106] Iteration 3774, lr = 0.00025
I1111 00:44:14.588331  2593 solver.cpp:295] Iteration 3775 (no loss supplied for SingleUpdateStep)
I1111 00:44:14.588465  2593 solver.cpp:310]     Train net output #0: loss = 0.423171 (* 1 = 0.423171 loss)
I1111 00:44:14.588495  2593 sgd_solver.cpp:106] Iteration 3775, lr = 0.00025
I1111 00:44:16.931818  2593 solver.cpp:295] Iteration 3776 (no loss supplied for SingleUpdateStep)
I1111 00:44:16.931905  2593 solver.cpp:310]     Train net output #0: loss = 0.382232 (* 1 = 0.382232 loss)
I1111 00:44:16.931927  2593 sgd_solver.cpp:106] Iteration 3776, lr = 0.00025
I1111 00:44:19.226938  2593 solver.cpp:295] Iteration 3777 (no loss supplied for SingleUpdateStep)
I1111 00:44:19.227108  2593 solver.cpp:310]     Train net output #0: loss = 0.406548 (* 1 = 0.406548 loss)
I1111 00:44:19.227138  2593 sgd_solver.cpp:106] Iteration 3777, lr = 0.00025
I1111 00:44:21.607278  2593 solver.cpp:295] Iteration 3778 (no loss supplied for SingleUpdateStep)
I1111 00:44:21.607396  2593 solver.cpp:310]     Train net output #0: loss = 0.399647 (* 1 = 0.399647 loss)
I1111 00:44:21.607419  2593 sgd_solver.cpp:106] Iteration 3778, lr = 0.00025
I1111 00:44:24.957052  2593 solver.cpp:295] Iteration 3779 (no loss supplied for SingleUpdateStep)
I1111 00:44:24.957126  2593 solver.cpp:310]     Train net output #0: loss = 0.415724 (* 1 = 0.415724 loss)
I1111 00:44:24.957146  2593 sgd_solver.cpp:106] Iteration 3779, lr = 0.00025
I1111 00:44:27.387321  2593 solver.cpp:295] Iteration 3780 (no loss supplied for SingleUpdateStep)
I1111 00:44:27.387403  2593 solver.cpp:310]     Train net output #0: loss = 0.385426 (* 1 = 0.385426 loss)
I1111 00:44:27.387425  2593 sgd_solver.cpp:106] Iteration 3780, lr = 0.00025
I1111 00:44:29.657325  2593 solver.cpp:295] Iteration 3781 (no loss supplied for SingleUpdateStep)
I1111 00:44:29.657433  2593 solver.cpp:310]     Train net output #0: loss = 0.39625 (* 1 = 0.39625 loss)
I1111 00:44:29.657456  2593 sgd_solver.cpp:106] Iteration 3781, lr = 0.00025
I1111 00:44:32.036377  2593 solver.cpp:295] Iteration 3782 (no loss supplied for SingleUpdateStep)
I1111 00:44:32.036475  2593 solver.cpp:310]     Train net output #0: loss = 0.420114 (* 1 = 0.420114 loss)
I1111 00:44:32.036497  2593 sgd_solver.cpp:106] Iteration 3782, lr = 0.00025
I1111 00:44:34.388686  2593 solver.cpp:295] Iteration 3783 (no loss supplied for SingleUpdateStep)
I1111 00:44:34.388805  2593 solver.cpp:310]     Train net output #0: loss = 0.393689 (* 1 = 0.393689 loss)
I1111 00:44:34.388826  2593 sgd_solver.cpp:106] Iteration 3783, lr = 0.00025
I1111 00:44:36.709899  2593 solver.cpp:295] Iteration 3784 (no loss supplied for SingleUpdateStep)
I1111 00:44:36.709996  2593 solver.cpp:310]     Train net output #0: loss = 0.364311 (* 1 = 0.364311 loss)
I1111 00:44:36.710017  2593 sgd_solver.cpp:106] Iteration 3784, lr = 0.00025
I1111 00:44:39.121018  2593 solver.cpp:295] Iteration 3785 (no loss supplied for SingleUpdateStep)
I1111 00:44:39.121137  2593 solver.cpp:310]     Train net output #0: loss = 0.407273 (* 1 = 0.407273 loss)
I1111 00:44:39.121161  2593 sgd_solver.cpp:106] Iteration 3785, lr = 0.00025
I1111 00:44:41.492068  2593 solver.cpp:295] Iteration 3786 (no loss supplied for SingleUpdateStep)
I1111 00:44:41.492197  2593 solver.cpp:310]     Train net output #0: loss = 0.379051 (* 1 = 0.379051 loss)
I1111 00:44:41.492220  2593 sgd_solver.cpp:106] Iteration 3786, lr = 0.00025
I1111 00:44:44.012181  2593 solver.cpp:295] Iteration 3787 (no loss supplied for SingleUpdateStep)
I1111 00:44:44.012336  2593 solver.cpp:310]     Train net output #0: loss = 0.389027 (* 1 = 0.389027 loss)
I1111 00:44:44.012359  2593 sgd_solver.cpp:106] Iteration 3787, lr = 0.00025
I1111 00:44:46.517817  2593 solver.cpp:295] Iteration 3788 (no loss supplied for SingleUpdateStep)
I1111 00:44:46.517886  2593 solver.cpp:310]     Train net output #0: loss = 0.400838 (* 1 = 0.400838 loss)
I1111 00:44:46.517904  2593 sgd_solver.cpp:106] Iteration 3788, lr = 0.00025
I1111 00:44:48.890208  2593 solver.cpp:295] Iteration 3789 (no loss supplied for SingleUpdateStep)
I1111 00:44:48.890318  2593 solver.cpp:310]     Train net output #0: loss = 0.408551 (* 1 = 0.408551 loss)
I1111 00:44:48.890339  2593 sgd_solver.cpp:106] Iteration 3789, lr = 0.00025
I1111 00:44:51.246525  2593 solver.cpp:295] Iteration 3790 (no loss supplied for SingleUpdateStep)
I1111 00:44:51.246633  2593 solver.cpp:310]     Train net output #0: loss = 0.398558 (* 1 = 0.398558 loss)
I1111 00:44:51.246655  2593 sgd_solver.cpp:106] Iteration 3790, lr = 0.00025
I1111 00:44:53.543350  2593 solver.cpp:295] Iteration 3791 (no loss supplied for SingleUpdateStep)
I1111 00:44:53.543450  2593 solver.cpp:310]     Train net output #0: loss = 0.365868 (* 1 = 0.365868 loss)
I1111 00:44:53.543473  2593 sgd_solver.cpp:106] Iteration 3791, lr = 0.00025
I1111 00:44:55.797574  2593 solver.cpp:295] Iteration 3792 (no loss supplied for SingleUpdateStep)
I1111 00:44:55.797683  2593 solver.cpp:310]     Train net output #0: loss = 0.395292 (* 1 = 0.395292 loss)
I1111 00:44:55.797705  2593 sgd_solver.cpp:106] Iteration 3792, lr = 0.00025
I1111 00:44:58.225054  2593 solver.cpp:295] Iteration 3793 (no loss supplied for SingleUpdateStep)
I1111 00:44:58.225239  2593 solver.cpp:310]     Train net output #0: loss = 0.373197 (* 1 = 0.373197 loss)
I1111 00:44:58.225281  2593 sgd_solver.cpp:106] Iteration 3793, lr = 0.00025
I1111 00:45:00.573837  2593 solver.cpp:295] Iteration 3794 (no loss supplied for SingleUpdateStep)
I1111 00:45:00.573962  2593 solver.cpp:310]     Train net output #0: loss = 0.417259 (* 1 = 0.417259 loss)
I1111 00:45:00.573989  2593 sgd_solver.cpp:106] Iteration 3794, lr = 0.00025
I1111 00:45:03.135970  2593 solver.cpp:295] Iteration 3795 (no loss supplied for SingleUpdateStep)
I1111 00:45:03.136145  2593 solver.cpp:310]     Train net output #0: loss = 0.37193 (* 1 = 0.37193 loss)
I1111 00:45:03.136173  2593 sgd_solver.cpp:106] Iteration 3795, lr = 0.00025
I1111 00:45:06.206863  2593 solver.cpp:295] Iteration 3796 (no loss supplied for SingleUpdateStep)
I1111 00:45:06.206959  2593 solver.cpp:310]     Train net output #0: loss = 0.384677 (* 1 = 0.384677 loss)
I1111 00:45:06.206979  2593 sgd_solver.cpp:106] Iteration 3796, lr = 0.00025
I1111 00:45:09.686795  2593 solver.cpp:295] Iteration 3797 (no loss supplied for SingleUpdateStep)
I1111 00:45:09.686866  2593 solver.cpp:310]     Train net output #0: loss = 0.381226 (* 1 = 0.381226 loss)
I1111 00:45:09.686887  2593 sgd_solver.cpp:106] Iteration 3797, lr = 0.00025
I1111 00:45:13.641095  2593 solver.cpp:295] Iteration 3798 (no loss supplied for SingleUpdateStep)
I1111 00:45:13.641206  2593 solver.cpp:310]     Train net output #0: loss = 0.417104 (* 1 = 0.417104 loss)
I1111 00:45:13.641228  2593 sgd_solver.cpp:106] Iteration 3798, lr = 0.00025
I1111 00:45:17.156307  2593 solver.cpp:295] Iteration 3799 (no loss supplied for SingleUpdateStep)
I1111 00:45:17.156467  2593 solver.cpp:310]     Train net output #0: loss = 0.370581 (* 1 = 0.370581 loss)
I1111 00:45:17.156493  2593 sgd_solver.cpp:106] Iteration 3799, lr = 0.00025
I1111 00:45:19.972573  2593 solver.cpp:295] Iteration 3800 (no loss supplied for SingleUpdateStep)
I1111 00:45:19.972774  2593 solver.cpp:310]     Train net output #0: loss = 0.382146 (* 1 = 0.382146 loss)
I1111 00:45:19.972805  2593 sgd_solver.cpp:106] Iteration 3800, lr = 0.00025
I1111 00:45:22.850314  2593 solver.cpp:295] Iteration 3801 (no loss supplied for SingleUpdateStep)
I1111 00:45:22.850478  2593 solver.cpp:310]     Train net output #0: loss = 0.386169 (* 1 = 0.386169 loss)
I1111 00:45:22.850507  2593 sgd_solver.cpp:106] Iteration 3801, lr = 0.00025
I1111 00:45:25.269210  2593 solver.cpp:295] Iteration 3802 (no loss supplied for SingleUpdateStep)
I1111 00:45:25.269322  2593 solver.cpp:310]     Train net output #0: loss = 0.399712 (* 1 = 0.399712 loss)
I1111 00:45:25.269347  2593 sgd_solver.cpp:106] Iteration 3802, lr = 0.00025
I1111 00:45:27.900938  2593 solver.cpp:295] Iteration 3803 (no loss supplied for SingleUpdateStep)
I1111 00:45:27.901057  2593 solver.cpp:310]     Train net output #0: loss = 0.382355 (* 1 = 0.382355 loss)
I1111 00:45:27.901079  2593 sgd_solver.cpp:106] Iteration 3803, lr = 0.00025
I1111 00:45:30.404335  2593 solver.cpp:295] Iteration 3804 (no loss supplied for SingleUpdateStep)
I1111 00:45:30.404500  2593 solver.cpp:310]     Train net output #0: loss = 0.361988 (* 1 = 0.361988 loss)
I1111 00:45:30.404526  2593 sgd_solver.cpp:106] Iteration 3804, lr = 0.00025
I1111 00:45:33.062428  2593 solver.cpp:295] Iteration 3805 (no loss supplied for SingleUpdateStep)
I1111 00:45:33.062582  2593 solver.cpp:310]     Train net output #0: loss = 0.414926 (* 1 = 0.414926 loss)
I1111 00:45:33.062613  2593 sgd_solver.cpp:106] Iteration 3805, lr = 0.00025
I1111 00:45:35.639581  2593 solver.cpp:295] Iteration 3806 (no loss supplied for SingleUpdateStep)
I1111 00:45:35.639745  2593 solver.cpp:310]     Train net output #0: loss = 0.377725 (* 1 = 0.377725 loss)
I1111 00:45:35.639771  2593 sgd_solver.cpp:106] Iteration 3806, lr = 0.00025
I1111 00:45:38.103235  2593 solver.cpp:295] Iteration 3807 (no loss supplied for SingleUpdateStep)
I1111 00:45:38.103363  2593 solver.cpp:310]     Train net output #0: loss = 0.395851 (* 1 = 0.395851 loss)
I1111 00:45:38.103384  2593 sgd_solver.cpp:106] Iteration 3807, lr = 0.00025
I1111 00:45:40.445384  2593 solver.cpp:295] Iteration 3808 (no loss supplied for SingleUpdateStep)
I1111 00:45:40.445456  2593 solver.cpp:310]     Train net output #0: loss = 0.383074 (* 1 = 0.383074 loss)
I1111 00:45:40.445484  2593 sgd_solver.cpp:106] Iteration 3808, lr = 0.00025
I1111 00:45:42.874320  2593 solver.cpp:295] Iteration 3809 (no loss supplied for SingleUpdateStep)
I1111 00:45:42.874420  2593 solver.cpp:310]     Train net output #0: loss = 0.370206 (* 1 = 0.370206 loss)
I1111 00:45:42.874444  2593 sgd_solver.cpp:106] Iteration 3809, lr = 0.00025
I1111 00:45:45.126467  2593 solver.cpp:295] Iteration 3810 (no loss supplied for SingleUpdateStep)
I1111 00:45:45.126600  2593 solver.cpp:310]     Train net output #0: loss = 0.411258 (* 1 = 0.411258 loss)
I1111 00:45:45.126623  2593 sgd_solver.cpp:106] Iteration 3810, lr = 0.00025
I1111 00:45:47.484258  2593 solver.cpp:295] Iteration 3811 (no loss supplied for SingleUpdateStep)
I1111 00:45:47.484379  2593 solver.cpp:310]     Train net output #0: loss = 0.381719 (* 1 = 0.381719 loss)
I1111 00:45:47.484402  2593 sgd_solver.cpp:106] Iteration 3811, lr = 0.00025
I1111 00:45:49.752552  2593 solver.cpp:295] Iteration 3812 (no loss supplied for SingleUpdateStep)
I1111 00:45:49.752750  2593 solver.cpp:310]     Train net output #0: loss = 0.348842 (* 1 = 0.348842 loss)
I1111 00:45:49.752791  2593 sgd_solver.cpp:106] Iteration 3812, lr = 0.00025
I1111 00:45:51.960847  2593 solver.cpp:295] Iteration 3813 (no loss supplied for SingleUpdateStep)
I1111 00:45:51.960918  2593 solver.cpp:310]     Train net output #0: loss = 0.414045 (* 1 = 0.414045 loss)
I1111 00:45:51.960938  2593 sgd_solver.cpp:106] Iteration 3813, lr = 0.00025
I1111 00:45:54.248728  2593 solver.cpp:295] Iteration 3814 (no loss supplied for SingleUpdateStep)
I1111 00:45:54.248805  2593 solver.cpp:310]     Train net output #0: loss = 0.395584 (* 1 = 0.395584 loss)
I1111 00:45:54.248826  2593 sgd_solver.cpp:106] Iteration 3814, lr = 0.00025
I1111 00:45:56.474200  2593 solver.cpp:295] Iteration 3815 (no loss supplied for SingleUpdateStep)
I1111 00:45:56.474336  2593 solver.cpp:310]     Train net output #0: loss = 0.386893 (* 1 = 0.386893 loss)
I1111 00:45:56.474364  2593 sgd_solver.cpp:106] Iteration 3815, lr = 0.00025
I1111 00:45:58.977869  2593 solver.cpp:295] Iteration 3816 (no loss supplied for SingleUpdateStep)
I1111 00:45:58.977984  2593 solver.cpp:310]     Train net output #0: loss = 0.388985 (* 1 = 0.388985 loss)
I1111 00:45:58.978008  2593 sgd_solver.cpp:106] Iteration 3816, lr = 0.00025
I1111 00:46:01.233024  2593 solver.cpp:295] Iteration 3817 (no loss supplied for SingleUpdateStep)
I1111 00:46:01.233129  2593 solver.cpp:310]     Train net output #0: loss = 0.389647 (* 1 = 0.389647 loss)
I1111 00:46:01.233150  2593 sgd_solver.cpp:106] Iteration 3817, lr = 0.00025
I1111 00:46:03.647758  2593 solver.cpp:295] Iteration 3818 (no loss supplied for SingleUpdateStep)
I1111 00:46:03.647881  2593 solver.cpp:310]     Train net output #0: loss = 0.399182 (* 1 = 0.399182 loss)
I1111 00:46:03.647904  2593 sgd_solver.cpp:106] Iteration 3818, lr = 0.00025
I1111 00:46:06.098814  2593 solver.cpp:295] Iteration 3819 (no loss supplied for SingleUpdateStep)
I1111 00:46:06.098945  2593 solver.cpp:310]     Train net output #0: loss = 0.396024 (* 1 = 0.396024 loss)
I1111 00:46:06.098968  2593 sgd_solver.cpp:106] Iteration 3819, lr = 0.00025
I1111 00:46:08.678966  2593 solver.cpp:295] Iteration 3820 (no loss supplied for SingleUpdateStep)
I1111 00:46:08.679030  2593 solver.cpp:310]     Train net output #0: loss = 0.353688 (* 1 = 0.353688 loss)
I1111 00:46:08.679050  2593 sgd_solver.cpp:106] Iteration 3820, lr = 0.00025
I1111 00:46:11.109292  2593 solver.cpp:295] Iteration 3821 (no loss supplied for SingleUpdateStep)
I1111 00:46:11.109417  2593 solver.cpp:310]     Train net output #0: loss = 0.371143 (* 1 = 0.371143 loss)
I1111 00:46:11.109447  2593 sgd_solver.cpp:106] Iteration 3821, lr = 0.00025
I1111 00:46:14.034370  2593 solver.cpp:295] Iteration 3822 (no loss supplied for SingleUpdateStep)
I1111 00:46:14.034476  2593 solver.cpp:310]     Train net output #0: loss = 0.395084 (* 1 = 0.395084 loss)
I1111 00:46:14.034497  2593 sgd_solver.cpp:106] Iteration 3822, lr = 0.00025
I1111 00:46:17.299912  2593 solver.cpp:295] Iteration 3823 (no loss supplied for SingleUpdateStep)
I1111 00:46:17.300017  2593 solver.cpp:310]     Train net output #0: loss = 0.363553 (* 1 = 0.363553 loss)
I1111 00:46:17.300037  2593 sgd_solver.cpp:106] Iteration 3823, lr = 0.00025
I1111 00:46:20.626219  2593 solver.cpp:295] Iteration 3824 (no loss supplied for SingleUpdateStep)
I1111 00:46:20.626343  2593 solver.cpp:310]     Train net output #0: loss = 0.382999 (* 1 = 0.382999 loss)
I1111 00:46:20.626376  2593 sgd_solver.cpp:106] Iteration 3824, lr = 0.00025
I1111 00:46:24.457283  2593 solver.cpp:295] Iteration 3825 (no loss supplied for SingleUpdateStep)
I1111 00:46:24.457393  2593 solver.cpp:310]     Train net output #0: loss = 0.384414 (* 1 = 0.384414 loss)
I1111 00:46:24.457417  2593 sgd_solver.cpp:106] Iteration 3825, lr = 0.00025
I1111 00:46:27.479331  2593 solver.cpp:295] Iteration 3826 (no loss supplied for SingleUpdateStep)
I1111 00:46:27.479428  2593 solver.cpp:310]     Train net output #0: loss = 0.38163 (* 1 = 0.38163 loss)
I1111 00:46:27.479450  2593 sgd_solver.cpp:106] Iteration 3826, lr = 0.00025
I1111 00:46:30.316349  2593 solver.cpp:295] Iteration 3827 (no loss supplied for SingleUpdateStep)
I1111 00:46:30.316444  2593 solver.cpp:310]     Train net output #0: loss = 0.412702 (* 1 = 0.412702 loss)
I1111 00:46:30.316467  2593 sgd_solver.cpp:106] Iteration 3827, lr = 0.00025
I1111 00:46:32.608080  2593 solver.cpp:295] Iteration 3828 (no loss supplied for SingleUpdateStep)
I1111 00:46:32.608203  2593 solver.cpp:310]     Train net output #0: loss = 0.377578 (* 1 = 0.377578 loss)
I1111 00:46:32.608225  2593 sgd_solver.cpp:106] Iteration 3828, lr = 0.00025
I1111 00:46:34.976088  2593 solver.cpp:295] Iteration 3829 (no loss supplied for SingleUpdateStep)
I1111 00:46:34.976166  2593 solver.cpp:310]     Train net output #0: loss = 0.380448 (* 1 = 0.380448 loss)
I1111 00:46:34.976186  2593 sgd_solver.cpp:106] Iteration 3829, lr = 0.00025
I1111 00:46:37.534713  2593 solver.cpp:295] Iteration 3830 (no loss supplied for SingleUpdateStep)
I1111 00:46:37.534824  2593 solver.cpp:310]     Train net output #0: loss = 0.361502 (* 1 = 0.361502 loss)
I1111 00:46:37.534848  2593 sgd_solver.cpp:106] Iteration 3830, lr = 0.00025
I1111 00:46:39.933634  2593 solver.cpp:295] Iteration 3831 (no loss supplied for SingleUpdateStep)
I1111 00:46:39.933763  2593 solver.cpp:310]     Train net output #0: loss = 0.404611 (* 1 = 0.404611 loss)
I1111 00:46:39.933789  2593 sgd_solver.cpp:106] Iteration 3831, lr = 0.00025
I1111 00:46:42.781211  2593 solver.cpp:295] Iteration 3832 (no loss supplied for SingleUpdateStep)
I1111 00:46:42.781386  2593 solver.cpp:310]     Train net output #0: loss = 0.403819 (* 1 = 0.403819 loss)
I1111 00:46:42.781422  2593 sgd_solver.cpp:106] Iteration 3832, lr = 0.00025
I1111 00:46:45.148854  2593 solver.cpp:295] Iteration 3833 (no loss supplied for SingleUpdateStep)
I1111 00:46:45.148917  2593 solver.cpp:310]     Train net output #0: loss = 0.406638 (* 1 = 0.406638 loss)
I1111 00:46:45.148936  2593 sgd_solver.cpp:106] Iteration 3833, lr = 0.00025
I1111 00:46:48.092417  2593 solver.cpp:295] Iteration 3834 (no loss supplied for SingleUpdateStep)
I1111 00:46:48.092473  2593 solver.cpp:310]     Train net output #0: loss = 0.418061 (* 1 = 0.418061 loss)
I1111 00:46:48.092496  2593 sgd_solver.cpp:106] Iteration 3834, lr = 0.00025
I1111 00:46:50.791951  2593 solver.cpp:295] Iteration 3835 (no loss supplied for SingleUpdateStep)
I1111 00:46:50.792034  2593 solver.cpp:310]     Train net output #0: loss = 0.395223 (* 1 = 0.395223 loss)
I1111 00:46:50.792057  2593 sgd_solver.cpp:106] Iteration 3835, lr = 0.00025
I1111 00:46:53.464949  2593 solver.cpp:295] Iteration 3836 (no loss supplied for SingleUpdateStep)
I1111 00:46:53.465013  2593 solver.cpp:310]     Train net output #0: loss = 0.394976 (* 1 = 0.394976 loss)
I1111 00:46:53.465031  2593 sgd_solver.cpp:106] Iteration 3836, lr = 0.00025
I1111 00:46:56.583086  2593 solver.cpp:295] Iteration 3837 (no loss supplied for SingleUpdateStep)
I1111 00:46:56.583201  2593 solver.cpp:310]     Train net output #0: loss = 0.384588 (* 1 = 0.384588 loss)
I1111 00:46:56.583226  2593 sgd_solver.cpp:106] Iteration 3837, lr = 0.00025
I1111 00:46:59.630667  2593 solver.cpp:295] Iteration 3838 (no loss supplied for SingleUpdateStep)
I1111 00:46:59.630805  2593 solver.cpp:310]     Train net output #0: loss = 0.403282 (* 1 = 0.403282 loss)
I1111 00:46:59.630827  2593 sgd_solver.cpp:106] Iteration 3838, lr = 0.00025
I1111 00:47:02.166013  2593 solver.cpp:295] Iteration 3839 (no loss supplied for SingleUpdateStep)
I1111 00:47:02.166177  2593 solver.cpp:310]     Train net output #0: loss = 0.400847 (* 1 = 0.400847 loss)
I1111 00:47:02.166200  2593 sgd_solver.cpp:106] Iteration 3839, lr = 0.00025
I1111 00:47:04.897522  2593 solver.cpp:295] Iteration 3840 (no loss supplied for SingleUpdateStep)
I1111 00:47:04.897658  2593 solver.cpp:310]     Train net output #0: loss = 0.392563 (* 1 = 0.392563 loss)
I1111 00:47:04.897680  2593 sgd_solver.cpp:106] Iteration 3840, lr = 0.00025
I1111 00:47:07.716716  2593 solver.cpp:295] Iteration 3841 (no loss supplied for SingleUpdateStep)
I1111 00:47:07.716797  2593 solver.cpp:310]     Train net output #0: loss = 0.395238 (* 1 = 0.395238 loss)
I1111 00:47:07.716819  2593 sgd_solver.cpp:106] Iteration 3841, lr = 0.00025
I1111 00:47:10.069135  2593 solver.cpp:295] Iteration 3842 (no loss supplied for SingleUpdateStep)
I1111 00:47:10.069198  2593 solver.cpp:310]     Train net output #0: loss = 0.380956 (* 1 = 0.380956 loss)
I1111 00:47:10.069217  2593 sgd_solver.cpp:106] Iteration 3842, lr = 0.00025
I1111 00:47:12.297387  2593 solver.cpp:295] Iteration 3843 (no loss supplied for SingleUpdateStep)
I1111 00:47:12.297546  2593 solver.cpp:310]     Train net output #0: loss = 0.378694 (* 1 = 0.378694 loss)
I1111 00:47:12.297572  2593 sgd_solver.cpp:106] Iteration 3843, lr = 0.00025
I1111 00:47:14.723824  2593 solver.cpp:295] Iteration 3844 (no loss supplied for SingleUpdateStep)
I1111 00:47:14.723922  2593 solver.cpp:310]     Train net output #0: loss = 0.405788 (* 1 = 0.405788 loss)
I1111 00:47:14.723945  2593 sgd_solver.cpp:106] Iteration 3844, lr = 0.00025
I1111 00:47:17.028738  2593 solver.cpp:295] Iteration 3845 (no loss supplied for SingleUpdateStep)
I1111 00:47:17.028800  2593 solver.cpp:310]     Train net output #0: loss = 0.371306 (* 1 = 0.371306 loss)
I1111 00:47:17.028821  2593 sgd_solver.cpp:106] Iteration 3845, lr = 0.00025
I1111 00:47:19.553400  2593 solver.cpp:295] Iteration 3846 (no loss supplied for SingleUpdateStep)
I1111 00:47:19.553504  2593 solver.cpp:310]     Train net output #0: loss = 0.393907 (* 1 = 0.393907 loss)
I1111 00:47:19.553525  2593 sgd_solver.cpp:106] Iteration 3846, lr = 0.00025
I1111 00:47:21.857950  2593 solver.cpp:295] Iteration 3847 (no loss supplied for SingleUpdateStep)
I1111 00:47:21.858010  2593 solver.cpp:310]     Train net output #0: loss = 0.37062 (* 1 = 0.37062 loss)
I1111 00:47:21.858028  2593 sgd_solver.cpp:106] Iteration 3847, lr = 0.00025
I1111 00:47:24.153406  2593 solver.cpp:295] Iteration 3848 (no loss supplied for SingleUpdateStep)
I1111 00:47:24.153519  2593 solver.cpp:310]     Train net output #0: loss = 0.395404 (* 1 = 0.395404 loss)
I1111 00:47:24.153542  2593 sgd_solver.cpp:106] Iteration 3848, lr = 0.00025
I1111 00:47:26.369197  2593 solver.cpp:295] Iteration 3849 (no loss supplied for SingleUpdateStep)
I1111 00:47:26.369312  2593 solver.cpp:310]     Train net output #0: loss = 0.364736 (* 1 = 0.364736 loss)
I1111 00:47:26.369333  2593 sgd_solver.cpp:106] Iteration 3849, lr = 0.00025
I1111 00:47:28.664100  2593 solver.cpp:295] Iteration 3850 (no loss supplied for SingleUpdateStep)
I1111 00:47:28.664189  2593 solver.cpp:310]     Train net output #0: loss = 0.402317 (* 1 = 0.402317 loss)
I1111 00:47:28.664209  2593 sgd_solver.cpp:106] Iteration 3850, lr = 0.00025
I1111 00:47:31.264478  2593 solver.cpp:295] Iteration 3851 (no loss supplied for SingleUpdateStep)
I1111 00:47:31.264551  2593 solver.cpp:310]     Train net output #0: loss = 0.356159 (* 1 = 0.356159 loss)
I1111 00:47:31.264570  2593 sgd_solver.cpp:106] Iteration 3851, lr = 0.00025
I1111 00:47:33.574609  2593 solver.cpp:295] Iteration 3852 (no loss supplied for SingleUpdateStep)
I1111 00:47:33.574764  2593 solver.cpp:310]     Train net output #0: loss = 0.365819 (* 1 = 0.365819 loss)
I1111 00:47:33.574789  2593 sgd_solver.cpp:106] Iteration 3852, lr = 0.00025
I1111 00:47:35.929080  2593 solver.cpp:295] Iteration 3853 (no loss supplied for SingleUpdateStep)
I1111 00:47:35.929162  2593 solver.cpp:310]     Train net output #0: loss = 0.379355 (* 1 = 0.379355 loss)
I1111 00:47:35.929183  2593 sgd_solver.cpp:106] Iteration 3853, lr = 0.00025
I1111 00:47:38.532007  2593 solver.cpp:295] Iteration 3854 (no loss supplied for SingleUpdateStep)
I1111 00:47:38.532069  2593 solver.cpp:310]     Train net output #0: loss = 0.390784 (* 1 = 0.390784 loss)
I1111 00:47:38.532088  2593 sgd_solver.cpp:106] Iteration 3854, lr = 0.00025
I1111 00:47:41.049787  2593 solver.cpp:295] Iteration 3855 (no loss supplied for SingleUpdateStep)
I1111 00:47:41.049917  2593 solver.cpp:310]     Train net output #0: loss = 0.377233 (* 1 = 0.377233 loss)
I1111 00:47:41.049939  2593 sgd_solver.cpp:106] Iteration 3855, lr = 0.00025
I1111 00:47:43.423959  2593 solver.cpp:295] Iteration 3856 (no loss supplied for SingleUpdateStep)
I1111 00:47:43.424116  2593 solver.cpp:310]     Train net output #0: loss = 0.394941 (* 1 = 0.394941 loss)
I1111 00:47:43.424140  2593 sgd_solver.cpp:106] Iteration 3856, lr = 0.00025
I1111 00:47:45.828001  2593 solver.cpp:295] Iteration 3857 (no loss supplied for SingleUpdateStep)
I1111 00:47:45.828054  2593 solver.cpp:310]     Train net output #0: loss = 0.406607 (* 1 = 0.406607 loss)
I1111 00:47:45.828073  2593 sgd_solver.cpp:106] Iteration 3857, lr = 0.00025
I1111 00:47:48.539113  2593 solver.cpp:295] Iteration 3858 (no loss supplied for SingleUpdateStep)
I1111 00:47:48.539219  2593 solver.cpp:310]     Train net output #0: loss = 0.382765 (* 1 = 0.382765 loss)
I1111 00:47:48.539242  2593 sgd_solver.cpp:106] Iteration 3858, lr = 0.00025
I1111 00:47:50.675763  2593 solver.cpp:295] Iteration 3859 (no loss supplied for SingleUpdateStep)
I1111 00:47:50.675882  2593 solver.cpp:310]     Train net output #0: loss = 0.402868 (* 1 = 0.402868 loss)
I1111 00:47:50.675904  2593 sgd_solver.cpp:106] Iteration 3859, lr = 0.00025
I1111 00:47:52.872314  2593 solver.cpp:295] Iteration 3860 (no loss supplied for SingleUpdateStep)
I1111 00:47:52.872437  2593 solver.cpp:310]     Train net output #0: loss = 0.406764 (* 1 = 0.406764 loss)
I1111 00:47:52.872462  2593 sgd_solver.cpp:106] Iteration 3860, lr = 0.00025
I1111 00:47:55.178822  2593 solver.cpp:295] Iteration 3861 (no loss supplied for SingleUpdateStep)
I1111 00:47:55.178977  2593 solver.cpp:310]     Train net output #0: loss = 0.383116 (* 1 = 0.383116 loss)
I1111 00:47:55.179005  2593 sgd_solver.cpp:106] Iteration 3861, lr = 0.00025
I1111 00:47:57.598068  2593 solver.cpp:295] Iteration 3862 (no loss supplied for SingleUpdateStep)
I1111 00:47:57.598188  2593 solver.cpp:310]     Train net output #0: loss = 0.406808 (* 1 = 0.406808 loss)
I1111 00:47:57.598217  2593 sgd_solver.cpp:106] Iteration 3862, lr = 0.00025
I1111 00:47:59.909068  2593 solver.cpp:295] Iteration 3863 (no loss supplied for SingleUpdateStep)
I1111 00:47:59.909188  2593 solver.cpp:310]     Train net output #0: loss = 0.400458 (* 1 = 0.400458 loss)
I1111 00:47:59.909211  2593 sgd_solver.cpp:106] Iteration 3863, lr = 0.00025
I1111 00:48:02.209611  2593 solver.cpp:295] Iteration 3864 (no loss supplied for SingleUpdateStep)
I1111 00:48:02.209703  2593 solver.cpp:310]     Train net output #0: loss = 0.374892 (* 1 = 0.374892 loss)
I1111 00:48:02.209724  2593 sgd_solver.cpp:106] Iteration 3864, lr = 0.00025
I1111 00:48:04.500650  2593 solver.cpp:295] Iteration 3865 (no loss supplied for SingleUpdateStep)
I1111 00:48:04.500828  2593 solver.cpp:310]     Train net output #0: loss = 0.410869 (* 1 = 0.410869 loss)
I1111 00:48:04.500859  2593 sgd_solver.cpp:106] Iteration 3865, lr = 0.00025
I1111 00:48:06.761718  2593 solver.cpp:295] Iteration 3866 (no loss supplied for SingleUpdateStep)
I1111 00:48:06.761836  2593 solver.cpp:310]     Train net output #0: loss = 0.396046 (* 1 = 0.396046 loss)
I1111 00:48:06.761857  2593 sgd_solver.cpp:106] Iteration 3866, lr = 0.00025
I1111 00:48:09.339200  2593 solver.cpp:295] Iteration 3867 (no loss supplied for SingleUpdateStep)
I1111 00:48:09.339323  2593 solver.cpp:310]     Train net output #0: loss = 0.385699 (* 1 = 0.385699 loss)
I1111 00:48:09.339349  2593 sgd_solver.cpp:106] Iteration 3867, lr = 0.00025
I1111 00:48:11.612210  2593 solver.cpp:295] Iteration 3868 (no loss supplied for SingleUpdateStep)
I1111 00:48:11.612265  2593 solver.cpp:310]     Train net output #0: loss = 0.394156 (* 1 = 0.394156 loss)
I1111 00:48:11.612283  2593 sgd_solver.cpp:106] Iteration 3868, lr = 0.00025
I1111 00:48:13.920038  2593 solver.cpp:295] Iteration 3869 (no loss supplied for SingleUpdateStep)
I1111 00:48:13.920193  2593 solver.cpp:310]     Train net output #0: loss = 0.404551 (* 1 = 0.404551 loss)
I1111 00:48:13.920218  2593 sgd_solver.cpp:106] Iteration 3869, lr = 0.00025
I1111 00:48:16.261858  2593 solver.cpp:295] Iteration 3870 (no loss supplied for SingleUpdateStep)
I1111 00:48:16.262009  2593 solver.cpp:310]     Train net output #0: loss = 0.383003 (* 1 = 0.383003 loss)
I1111 00:48:16.262037  2593 sgd_solver.cpp:106] Iteration 3870, lr = 0.00025
I1111 00:48:18.589179  2593 solver.cpp:295] Iteration 3871 (no loss supplied for SingleUpdateStep)
I1111 00:48:18.589339  2593 solver.cpp:310]     Train net output #0: loss = 0.396551 (* 1 = 0.396551 loss)
I1111 00:48:18.589373  2593 sgd_solver.cpp:106] Iteration 3871, lr = 0.00025
I1111 00:48:20.788070  2593 solver.cpp:295] Iteration 3872 (no loss supplied for SingleUpdateStep)
I1111 00:48:20.788251  2593 solver.cpp:310]     Train net output #0: loss = 0.382674 (* 1 = 0.382674 loss)
I1111 00:48:20.788280  2593 sgd_solver.cpp:106] Iteration 3872, lr = 0.00025
I1111 00:48:23.116699  2593 solver.cpp:295] Iteration 3873 (no loss supplied for SingleUpdateStep)
I1111 00:48:23.116868  2593 solver.cpp:310]     Train net output #0: loss = 0.383524 (* 1 = 0.383524 loss)
I1111 00:48:23.116893  2593 sgd_solver.cpp:106] Iteration 3873, lr = 0.00025
I1111 00:48:25.371037  2593 solver.cpp:295] Iteration 3874 (no loss supplied for SingleUpdateStep)
I1111 00:48:25.371230  2593 solver.cpp:310]     Train net output #0: loss = 0.359491 (* 1 = 0.359491 loss)
I1111 00:48:25.371259  2593 sgd_solver.cpp:106] Iteration 3874, lr = 0.00025
I1111 00:48:27.868510  2593 solver.cpp:295] Iteration 3875 (no loss supplied for SingleUpdateStep)
I1111 00:48:27.868593  2593 solver.cpp:310]     Train net output #0: loss = 0.396495 (* 1 = 0.396495 loss)
I1111 00:48:27.868613  2593 sgd_solver.cpp:106] Iteration 3875, lr = 0.00025
I1111 00:48:30.343513  2593 solver.cpp:295] Iteration 3876 (no loss supplied for SingleUpdateStep)
I1111 00:48:30.343688  2593 solver.cpp:310]     Train net output #0: loss = 0.363788 (* 1 = 0.363788 loss)
I1111 00:48:30.343729  2593 sgd_solver.cpp:106] Iteration 3876, lr = 0.00025
I1111 00:48:32.765285  2593 solver.cpp:295] Iteration 3877 (no loss supplied for SingleUpdateStep)
I1111 00:48:32.765400  2593 solver.cpp:310]     Train net output #0: loss = 0.413633 (* 1 = 0.413633 loss)
I1111 00:48:32.765426  2593 sgd_solver.cpp:106] Iteration 3877, lr = 0.00025
I1111 00:48:35.159497  2593 solver.cpp:295] Iteration 3878 (no loss supplied for SingleUpdateStep)
I1111 00:48:35.159587  2593 solver.cpp:310]     Train net output #0: loss = 0.394333 (* 1 = 0.394333 loss)
I1111 00:48:35.159611  2593 sgd_solver.cpp:106] Iteration 3878, lr = 0.00025
I1111 00:48:37.645148  2593 solver.cpp:295] Iteration 3879 (no loss supplied for SingleUpdateStep)
I1111 00:48:37.645264  2593 solver.cpp:310]     Train net output #0: loss = 0.378985 (* 1 = 0.378985 loss)
I1111 00:48:37.645285  2593 sgd_solver.cpp:106] Iteration 3879, lr = 0.00025
I1111 00:48:39.900866  2593 solver.cpp:295] Iteration 3880 (no loss supplied for SingleUpdateStep)
I1111 00:48:39.900971  2593 solver.cpp:310]     Train net output #0: loss = 0.400013 (* 1 = 0.400013 loss)
I1111 00:48:39.900991  2593 sgd_solver.cpp:106] Iteration 3880, lr = 0.00025
I1111 00:48:42.194844  2593 solver.cpp:295] Iteration 3881 (no loss supplied for SingleUpdateStep)
I1111 00:48:42.194933  2593 solver.cpp:310]     Train net output #0: loss = 0.40793 (* 1 = 0.40793 loss)
I1111 00:48:42.194955  2593 sgd_solver.cpp:106] Iteration 3881, lr = 0.00025
I1111 00:48:44.480207  2593 solver.cpp:295] Iteration 3882 (no loss supplied for SingleUpdateStep)
I1111 00:48:44.480355  2593 solver.cpp:310]     Train net output #0: loss = 0.399366 (* 1 = 0.399366 loss)
I1111 00:48:44.480379  2593 sgd_solver.cpp:106] Iteration 3882, lr = 0.00025
I1111 00:48:46.854054  2593 solver.cpp:295] Iteration 3883 (no loss supplied for SingleUpdateStep)
I1111 00:48:46.854152  2593 solver.cpp:310]     Train net output #0: loss = 0.388054 (* 1 = 0.388054 loss)
I1111 00:48:46.854173  2593 sgd_solver.cpp:106] Iteration 3883, lr = 0.00025
I1111 00:48:49.567800  2593 solver.cpp:295] Iteration 3884 (no loss supplied for SingleUpdateStep)
I1111 00:48:49.567860  2593 solver.cpp:310]     Train net output #0: loss = 0.398658 (* 1 = 0.398658 loss)
I1111 00:48:49.567879  2593 sgd_solver.cpp:106] Iteration 3884, lr = 0.00025
I1111 00:48:52.069275  2593 solver.cpp:295] Iteration 3885 (no loss supplied for SingleUpdateStep)
I1111 00:48:52.069352  2593 solver.cpp:310]     Train net output #0: loss = 0.399395 (* 1 = 0.399395 loss)
I1111 00:48:52.069371  2593 sgd_solver.cpp:106] Iteration 3885, lr = 0.00025
I1111 00:48:54.351682  2593 solver.cpp:295] Iteration 3886 (no loss supplied for SingleUpdateStep)
I1111 00:48:54.351847  2593 solver.cpp:310]     Train net output #0: loss = 0.407139 (* 1 = 0.407139 loss)
I1111 00:48:54.351884  2593 sgd_solver.cpp:106] Iteration 3886, lr = 0.00025
I1111 00:48:57.015041  2593 solver.cpp:295] Iteration 3887 (no loss supplied for SingleUpdateStep)
I1111 00:48:57.015383  2593 solver.cpp:310]     Train net output #0: loss = 0.381397 (* 1 = 0.381397 loss)
I1111 00:48:57.015440  2593 sgd_solver.cpp:106] Iteration 3887, lr = 0.00025
I1111 00:48:59.565497  2593 solver.cpp:295] Iteration 3888 (no loss supplied for SingleUpdateStep)
I1111 00:48:59.565618  2593 solver.cpp:310]     Train net output #0: loss = 0.408537 (* 1 = 0.408537 loss)
I1111 00:48:59.565647  2593 sgd_solver.cpp:106] Iteration 3888, lr = 0.00025
I1111 00:49:02.001677  2593 solver.cpp:295] Iteration 3889 (no loss supplied for SingleUpdateStep)
I1111 00:49:02.001797  2593 solver.cpp:310]     Train net output #0: loss = 0.38724 (* 1 = 0.38724 loss)
I1111 00:49:02.001818  2593 sgd_solver.cpp:106] Iteration 3889, lr = 0.00025
I1111 00:49:04.330726  2593 solver.cpp:295] Iteration 3890 (no loss supplied for SingleUpdateStep)
I1111 00:49:04.330821  2593 solver.cpp:310]     Train net output #0: loss = 0.413922 (* 1 = 0.413922 loss)
I1111 00:49:04.330844  2593 sgd_solver.cpp:106] Iteration 3890, lr = 0.00025
I1111 00:49:06.853474  2593 solver.cpp:295] Iteration 3891 (no loss supplied for SingleUpdateStep)
I1111 00:49:06.853615  2593 solver.cpp:310]     Train net output #0: loss = 0.380968 (* 1 = 0.380968 loss)
I1111 00:49:06.853639  2593 sgd_solver.cpp:106] Iteration 3891, lr = 0.00025
I1111 00:49:09.246445  2593 solver.cpp:295] Iteration 3892 (no loss supplied for SingleUpdateStep)
I1111 00:49:09.246649  2593 solver.cpp:310]     Train net output #0: loss = 0.378952 (* 1 = 0.378952 loss)
I1111 00:49:09.246680  2593 sgd_solver.cpp:106] Iteration 3892, lr = 0.00025
I1111 00:49:11.590291  2593 solver.cpp:295] Iteration 3893 (no loss supplied for SingleUpdateStep)
I1111 00:49:11.590374  2593 solver.cpp:310]     Train net output #0: loss = 0.388386 (* 1 = 0.388386 loss)
I1111 00:49:11.590395  2593 sgd_solver.cpp:106] Iteration 3893, lr = 0.00025
I1111 00:49:14.186398  2593 solver.cpp:295] Iteration 3894 (no loss supplied for SingleUpdateStep)
I1111 00:49:14.186509  2593 solver.cpp:310]     Train net output #0: loss = 0.366125 (* 1 = 0.366125 loss)
I1111 00:49:14.186532  2593 sgd_solver.cpp:106] Iteration 3894, lr = 0.00025
I1111 00:49:16.575153  2593 solver.cpp:295] Iteration 3895 (no loss supplied for SingleUpdateStep)
I1111 00:49:16.575286  2593 solver.cpp:310]     Train net output #0: loss = 0.373396 (* 1 = 0.373396 loss)
I1111 00:49:16.575312  2593 sgd_solver.cpp:106] Iteration 3895, lr = 0.00025
I1111 00:49:19.000560  2593 solver.cpp:295] Iteration 3896 (no loss supplied for SingleUpdateStep)
I1111 00:49:19.000767  2593 solver.cpp:310]     Train net output #0: loss = 0.366426 (* 1 = 0.366426 loss)
I1111 00:49:19.000793  2593 sgd_solver.cpp:106] Iteration 3896, lr = 0.00025
I1111 00:49:21.276504  2593 solver.cpp:295] Iteration 3897 (no loss supplied for SingleUpdateStep)
I1111 00:49:21.276636  2593 solver.cpp:310]     Train net output #0: loss = 0.406096 (* 1 = 0.406096 loss)
I1111 00:49:21.276662  2593 sgd_solver.cpp:106] Iteration 3897, lr = 0.00025
I1111 00:49:23.601047  2593 solver.cpp:295] Iteration 3898 (no loss supplied for SingleUpdateStep)
I1111 00:49:23.601223  2593 solver.cpp:310]     Train net output #0: loss = 0.361794 (* 1 = 0.361794 loss)
I1111 00:49:23.601250  2593 sgd_solver.cpp:106] Iteration 3898, lr = 0.00025
I1111 00:49:26.245972  2593 solver.cpp:295] Iteration 3899 (no loss supplied for SingleUpdateStep)
I1111 00:49:26.246081  2593 solver.cpp:310]     Train net output #0: loss = 0.395586 (* 1 = 0.395586 loss)
I1111 00:49:26.246105  2593 sgd_solver.cpp:106] Iteration 3899, lr = 0.00025
I1111 00:49:28.719730  2593 solver.cpp:295] Iteration 3900 (no loss supplied for SingleUpdateStep)
I1111 00:49:28.719909  2593 solver.cpp:310]     Train net output #0: loss = 0.396497 (* 1 = 0.396497 loss)
I1111 00:49:28.719941  2593 sgd_solver.cpp:106] Iteration 3900, lr = 0.00025
I1111 00:49:31.543303  2593 solver.cpp:295] Iteration 3901 (no loss supplied for SingleUpdateStep)
I1111 00:49:31.543421  2593 solver.cpp:310]     Train net output #0: loss = 0.426978 (* 1 = 0.426978 loss)
I1111 00:49:31.543444  2593 sgd_solver.cpp:106] Iteration 3901, lr = 0.00025
I1111 00:49:34.799046  2593 solver.cpp:295] Iteration 3902 (no loss supplied for SingleUpdateStep)
I1111 00:49:34.799144  2593 solver.cpp:310]     Train net output #0: loss = 0.37813 (* 1 = 0.37813 loss)
I1111 00:49:34.799165  2593 sgd_solver.cpp:106] Iteration 3902, lr = 0.00025
I1111 00:49:37.716106  2593 solver.cpp:295] Iteration 3903 (no loss supplied for SingleUpdateStep)
I1111 00:49:37.716250  2593 solver.cpp:310]     Train net output #0: loss = 0.389106 (* 1 = 0.389106 loss)
I1111 00:49:37.716275  2593 sgd_solver.cpp:106] Iteration 3903, lr = 0.00025
I1111 00:49:41.204840  2593 solver.cpp:295] Iteration 3904 (no loss supplied for SingleUpdateStep)
I1111 00:49:41.204943  2593 solver.cpp:310]     Train net output #0: loss = 0.381982 (* 1 = 0.381982 loss)
I1111 00:49:41.204963  2593 sgd_solver.cpp:106] Iteration 3904, lr = 0.00025
I1111 00:49:45.102280  2593 solver.cpp:295] Iteration 3905 (no loss supplied for SingleUpdateStep)
I1111 00:49:45.102396  2593 solver.cpp:310]     Train net output #0: loss = 0.399412 (* 1 = 0.399412 loss)
I1111 00:49:45.102421  2593 sgd_solver.cpp:106] Iteration 3905, lr = 0.00025
I1111 00:49:48.312245  2593 solver.cpp:295] Iteration 3906 (no loss supplied for SingleUpdateStep)
I1111 00:49:48.312304  2593 solver.cpp:310]     Train net output #0: loss = 0.387169 (* 1 = 0.387169 loss)
I1111 00:49:48.312322  2593 sgd_solver.cpp:106] Iteration 3906, lr = 0.00025
I1111 00:49:51.568438  2593 solver.cpp:295] Iteration 3907 (no loss supplied for SingleUpdateStep)
I1111 00:49:51.568524  2593 solver.cpp:310]     Train net output #0: loss = 0.355166 (* 1 = 0.355166 loss)
I1111 00:49:51.568547  2593 sgd_solver.cpp:106] Iteration 3907, lr = 0.00025
I1111 00:49:54.586762  2593 solver.cpp:295] Iteration 3908 (no loss supplied for SingleUpdateStep)
I1111 00:49:54.586844  2593 solver.cpp:310]     Train net output #0: loss = 0.37454 (* 1 = 0.37454 loss)
I1111 00:49:54.586866  2593 sgd_solver.cpp:106] Iteration 3908, lr = 0.00025
I1111 00:49:56.960865  2593 solver.cpp:295] Iteration 3909 (no loss supplied for SingleUpdateStep)
I1111 00:49:56.961037  2593 solver.cpp:310]     Train net output #0: loss = 0.409614 (* 1 = 0.409614 loss)
I1111 00:49:56.961062  2593 sgd_solver.cpp:106] Iteration 3909, lr = 0.00025
I1111 00:49:59.701998  2593 solver.cpp:295] Iteration 3910 (no loss supplied for SingleUpdateStep)
I1111 00:49:59.702092  2593 solver.cpp:310]     Train net output #0: loss = 0.375492 (* 1 = 0.375492 loss)
I1111 00:49:59.702112  2593 sgd_solver.cpp:106] Iteration 3910, lr = 0.00025
I1111 00:50:02.274732  2593 solver.cpp:295] Iteration 3911 (no loss supplied for SingleUpdateStep)
I1111 00:50:02.274837  2593 solver.cpp:310]     Train net output #0: loss = 0.400542 (* 1 = 0.400542 loss)
I1111 00:50:02.274859  2593 sgd_solver.cpp:106] Iteration 3911, lr = 0.00025
I1111 00:50:04.737130  2593 solver.cpp:295] Iteration 3912 (no loss supplied for SingleUpdateStep)
I1111 00:50:04.737258  2593 solver.cpp:310]     Train net output #0: loss = 0.378907 (* 1 = 0.378907 loss)
I1111 00:50:04.737285  2593 sgd_solver.cpp:106] Iteration 3912, lr = 0.00025
I1111 00:50:07.059048  2593 solver.cpp:295] Iteration 3913 (no loss supplied for SingleUpdateStep)
I1111 00:50:07.059146  2593 solver.cpp:310]     Train net output #0: loss = 0.395073 (* 1 = 0.395073 loss)
I1111 00:50:07.059168  2593 sgd_solver.cpp:106] Iteration 3913, lr = 0.00025
I1111 00:50:09.196012  2593 solver.cpp:295] Iteration 3914 (no loss supplied for SingleUpdateStep)
I1111 00:50:09.196105  2593 solver.cpp:310]     Train net output #0: loss = 0.374144 (* 1 = 0.374144 loss)
I1111 00:50:09.196130  2593 sgd_solver.cpp:106] Iteration 3914, lr = 0.00025
I1111 00:50:11.324383  2593 solver.cpp:295] Iteration 3915 (no loss supplied for SingleUpdateStep)
I1111 00:50:11.324590  2593 solver.cpp:310]     Train net output #0: loss = 0.413589 (* 1 = 0.413589 loss)
I1111 00:50:11.324643  2593 sgd_solver.cpp:106] Iteration 3915, lr = 0.00025
I1111 00:50:13.611829  2593 solver.cpp:295] Iteration 3916 (no loss supplied for SingleUpdateStep)
I1111 00:50:13.611896  2593 solver.cpp:310]     Train net output #0: loss = 0.367217 (* 1 = 0.367217 loss)
I1111 00:50:13.611917  2593 sgd_solver.cpp:106] Iteration 3916, lr = 0.00025
I1111 00:50:16.072875  2593 solver.cpp:295] Iteration 3917 (no loss supplied for SingleUpdateStep)
I1111 00:50:16.072993  2593 solver.cpp:310]     Train net output #0: loss = 0.367356 (* 1 = 0.367356 loss)
I1111 00:50:16.073014  2593 sgd_solver.cpp:106] Iteration 3917, lr = 0.00025
I1111 00:50:18.709738  2593 solver.cpp:295] Iteration 3918 (no loss supplied for SingleUpdateStep)
I1111 00:50:18.709856  2593 solver.cpp:310]     Train net output #0: loss = 0.394251 (* 1 = 0.394251 loss)
I1111 00:50:18.709880  2593 sgd_solver.cpp:106] Iteration 3918, lr = 0.00025
I1111 00:50:21.909404  2593 solver.cpp:295] Iteration 3919 (no loss supplied for SingleUpdateStep)
I1111 00:50:21.909499  2593 solver.cpp:310]     Train net output #0: loss = 0.397469 (* 1 = 0.397469 loss)
I1111 00:50:21.909520  2593 sgd_solver.cpp:106] Iteration 3919, lr = 0.00025
I1111 00:50:25.200001  2593 solver.cpp:295] Iteration 3920 (no loss supplied for SingleUpdateStep)
I1111 00:50:25.200090  2593 solver.cpp:310]     Train net output #0: loss = 0.384119 (* 1 = 0.384119 loss)
I1111 00:50:25.200111  2593 sgd_solver.cpp:106] Iteration 3920, lr = 0.00025
I1111 00:50:27.993688  2593 solver.cpp:295] Iteration 3921 (no loss supplied for SingleUpdateStep)
I1111 00:50:27.993806  2593 solver.cpp:310]     Train net output #0: loss = 0.402264 (* 1 = 0.402264 loss)
I1111 00:50:27.993830  2593 sgd_solver.cpp:106] Iteration 3921, lr = 0.00025
I1111 00:50:30.552786  2593 solver.cpp:295] Iteration 3922 (no loss supplied for SingleUpdateStep)
I1111 00:50:30.552899  2593 solver.cpp:310]     Train net output #0: loss = 0.385369 (* 1 = 0.385369 loss)
I1111 00:50:30.552922  2593 sgd_solver.cpp:106] Iteration 3922, lr = 0.00025
I1111 00:50:32.827994  2593 solver.cpp:295] Iteration 3923 (no loss supplied for SingleUpdateStep)
I1111 00:50:32.828142  2593 solver.cpp:310]     Train net output #0: loss = 0.391604 (* 1 = 0.391604 loss)
I1111 00:50:32.828171  2593 sgd_solver.cpp:106] Iteration 3923, lr = 0.00025
I1111 00:50:35.248528  2593 solver.cpp:295] Iteration 3924 (no loss supplied for SingleUpdateStep)
I1111 00:50:35.248648  2593 solver.cpp:310]     Train net output #0: loss = 0.403712 (* 1 = 0.403712 loss)
I1111 00:50:35.248672  2593 sgd_solver.cpp:106] Iteration 3924, lr = 0.00025
I1111 00:50:37.565500  2593 solver.cpp:295] Iteration 3925 (no loss supplied for SingleUpdateStep)
I1111 00:50:37.565598  2593 solver.cpp:310]     Train net output #0: loss = 0.388895 (* 1 = 0.388895 loss)
I1111 00:50:37.565621  2593 sgd_solver.cpp:106] Iteration 3925, lr = 0.00025
I1111 00:50:39.888205  2593 solver.cpp:295] Iteration 3926 (no loss supplied for SingleUpdateStep)
I1111 00:50:39.888288  2593 solver.cpp:310]     Train net output #0: loss = 0.395717 (* 1 = 0.395717 loss)
I1111 00:50:39.888309  2593 sgd_solver.cpp:106] Iteration 3926, lr = 0.00025
I1111 00:50:42.394284  2593 solver.cpp:295] Iteration 3927 (no loss supplied for SingleUpdateStep)
I1111 00:50:42.394413  2593 solver.cpp:310]     Train net output #0: loss = 0.392102 (* 1 = 0.392102 loss)
I1111 00:50:42.394435  2593 sgd_solver.cpp:106] Iteration 3927, lr = 0.00025
I1111 00:50:44.852411  2593 solver.cpp:295] Iteration 3928 (no loss supplied for SingleUpdateStep)
I1111 00:50:44.852556  2593 solver.cpp:310]     Train net output #0: loss = 0.377649 (* 1 = 0.377649 loss)
I1111 00:50:44.852602  2593 sgd_solver.cpp:106] Iteration 3928, lr = 0.00025
I1111 00:50:47.165252  2593 solver.cpp:295] Iteration 3929 (no loss supplied for SingleUpdateStep)
I1111 00:50:47.165391  2593 solver.cpp:310]     Train net output #0: loss = 0.379878 (* 1 = 0.379878 loss)
I1111 00:50:47.165415  2593 sgd_solver.cpp:106] Iteration 3929, lr = 0.00025
I1111 00:50:49.630954  2593 solver.cpp:295] Iteration 3930 (no loss supplied for SingleUpdateStep)
I1111 00:50:49.631024  2593 solver.cpp:310]     Train net output #0: loss = 0.404454 (* 1 = 0.404454 loss)
I1111 00:50:49.631044  2593 sgd_solver.cpp:106] Iteration 3930, lr = 0.00025
I1111 00:50:51.916806  2593 solver.cpp:295] Iteration 3931 (no loss supplied for SingleUpdateStep)
I1111 00:50:51.916963  2593 solver.cpp:310]     Train net output #0: loss = 0.37057 (* 1 = 0.37057 loss)
I1111 00:50:51.916991  2593 sgd_solver.cpp:106] Iteration 3931, lr = 0.00025
I1111 00:50:54.157066  2593 solver.cpp:295] Iteration 3932 (no loss supplied for SingleUpdateStep)
I1111 00:50:54.157207  2593 solver.cpp:310]     Train net output #0: loss = 0.37571 (* 1 = 0.37571 loss)
I1111 00:50:54.157232  2593 sgd_solver.cpp:106] Iteration 3932, lr = 0.00025
I1111 00:50:56.552610  2593 solver.cpp:295] Iteration 3933 (no loss supplied for SingleUpdateStep)
I1111 00:50:56.552666  2593 solver.cpp:310]     Train net output #0: loss = 0.397634 (* 1 = 0.397634 loss)
I1111 00:50:56.552685  2593 sgd_solver.cpp:106] Iteration 3933, lr = 0.00025
I1111 00:50:58.780761  2593 solver.cpp:295] Iteration 3934 (no loss supplied for SingleUpdateStep)
I1111 00:50:58.780875  2593 solver.cpp:310]     Train net output #0: loss = 0.367354 (* 1 = 0.367354 loss)
I1111 00:50:58.780899  2593 sgd_solver.cpp:106] Iteration 3934, lr = 0.00025
I1111 00:51:01.055276  2593 solver.cpp:295] Iteration 3935 (no loss supplied for SingleUpdateStep)
I1111 00:51:01.055407  2593 solver.cpp:310]     Train net output #0: loss = 0.360681 (* 1 = 0.360681 loss)
I1111 00:51:01.055434  2593 sgd_solver.cpp:106] Iteration 3935, lr = 0.00025
I1111 00:51:03.307390  2593 solver.cpp:295] Iteration 3936 (no loss supplied for SingleUpdateStep)
I1111 00:51:03.307452  2593 solver.cpp:310]     Train net output #0: loss = 0.41488 (* 1 = 0.41488 loss)
I1111 00:51:03.307471  2593 sgd_solver.cpp:106] Iteration 3936, lr = 0.00025
I1111 00:51:06.083911  2593 solver.cpp:295] Iteration 3937 (no loss supplied for SingleUpdateStep)
I1111 00:51:06.083983  2593 solver.cpp:310]     Train net output #0: loss = 0.361918 (* 1 = 0.361918 loss)
I1111 00:51:06.084004  2593 sgd_solver.cpp:106] Iteration 3937, lr = 0.00025
I1111 00:51:09.188884  2593 solver.cpp:295] Iteration 3938 (no loss supplied for SingleUpdateStep)
I1111 00:51:09.189116  2593 solver.cpp:310]     Train net output #0: loss = 0.38596 (* 1 = 0.38596 loss)
I1111 00:51:09.189160  2593 sgd_solver.cpp:106] Iteration 3938, lr = 0.00025
I1111 00:51:12.224180  2593 solver.cpp:295] Iteration 3939 (no loss supplied for SingleUpdateStep)
I1111 00:51:12.224290  2593 solver.cpp:310]     Train net output #0: loss = 0.398664 (* 1 = 0.398664 loss)
I1111 00:51:12.224313  2593 sgd_solver.cpp:106] Iteration 3939, lr = 0.00025
I1111 00:51:14.539257  2593 solver.cpp:295] Iteration 3940 (no loss supplied for SingleUpdateStep)
I1111 00:51:14.539340  2593 solver.cpp:310]     Train net output #0: loss = 0.390917 (* 1 = 0.390917 loss)
I1111 00:51:14.539361  2593 sgd_solver.cpp:106] Iteration 3940, lr = 0.00025
I1111 00:51:16.940251  2593 solver.cpp:295] Iteration 3941 (no loss supplied for SingleUpdateStep)
I1111 00:51:16.940379  2593 solver.cpp:310]     Train net output #0: loss = 0.387288 (* 1 = 0.387288 loss)
I1111 00:51:16.940417  2593 sgd_solver.cpp:106] Iteration 3941, lr = 0.00025
I1111 00:51:19.229089  2593 solver.cpp:295] Iteration 3942 (no loss supplied for SingleUpdateStep)
I1111 00:51:19.229228  2593 solver.cpp:310]     Train net output #0: loss = 0.398013 (* 1 = 0.398013 loss)
I1111 00:51:19.229255  2593 sgd_solver.cpp:106] Iteration 3942, lr = 0.00025
I1111 00:51:21.525786  2593 solver.cpp:295] Iteration 3943 (no loss supplied for SingleUpdateStep)
I1111 00:51:21.525928  2593 solver.cpp:310]     Train net output #0: loss = 0.360385 (* 1 = 0.360385 loss)
I1111 00:51:21.525964  2593 sgd_solver.cpp:106] Iteration 3943, lr = 0.00025
I1111 00:51:23.821691  2593 solver.cpp:295] Iteration 3944 (no loss supplied for SingleUpdateStep)
I1111 00:51:23.821764  2593 solver.cpp:310]     Train net output #0: loss = 0.386147 (* 1 = 0.386147 loss)
I1111 00:51:23.821784  2593 sgd_solver.cpp:106] Iteration 3944, lr = 0.00025
I1111 00:51:26.409096  2593 solver.cpp:295] Iteration 3945 (no loss supplied for SingleUpdateStep)
I1111 00:51:26.409232  2593 solver.cpp:310]     Train net output #0: loss = 0.382186 (* 1 = 0.382186 loss)
I1111 00:51:26.409256  2593 sgd_solver.cpp:106] Iteration 3945, lr = 0.00025
I1111 00:51:28.844564  2593 solver.cpp:295] Iteration 3946 (no loss supplied for SingleUpdateStep)
I1111 00:51:28.844650  2593 solver.cpp:310]     Train net output #0: loss = 0.41497 (* 1 = 0.41497 loss)
I1111 00:51:28.844671  2593 sgd_solver.cpp:106] Iteration 3946, lr = 0.00025
I1111 00:51:31.340629  2593 solver.cpp:295] Iteration 3947 (no loss supplied for SingleUpdateStep)
I1111 00:51:31.340816  2593 solver.cpp:310]     Train net output #0: loss = 0.375545 (* 1 = 0.375545 loss)
I1111 00:51:31.340844  2593 sgd_solver.cpp:106] Iteration 3947, lr = 0.00025
I1111 00:51:33.541478  2593 solver.cpp:295] Iteration 3948 (no loss supplied for SingleUpdateStep)
I1111 00:51:33.541729  2593 solver.cpp:310]     Train net output #0: loss = 0.382163 (* 1 = 0.382163 loss)
I1111 00:51:33.541759  2593 sgd_solver.cpp:106] Iteration 3948, lr = 0.00025
I1111 00:51:35.879869  2593 solver.cpp:295] Iteration 3949 (no loss supplied for SingleUpdateStep)
I1111 00:51:35.879978  2593 solver.cpp:310]     Train net output #0: loss = 0.376115 (* 1 = 0.376115 loss)
I1111 00:51:35.880002  2593 sgd_solver.cpp:106] Iteration 3949, lr = 0.00025
I1111 00:51:38.075572  2593 solver.cpp:295] Iteration 3950 (no loss supplied for SingleUpdateStep)
I1111 00:51:38.075733  2593 solver.cpp:310]     Train net output #0: loss = 0.393017 (* 1 = 0.393017 loss)
I1111 00:51:38.075758  2593 sgd_solver.cpp:106] Iteration 3950, lr = 0.00025
I1111 00:51:40.456755  2593 solver.cpp:295] Iteration 3951 (no loss supplied for SingleUpdateStep)
I1111 00:51:40.456853  2593 solver.cpp:310]     Train net output #0: loss = 0.375727 (* 1 = 0.375727 loss)
I1111 00:51:40.456873  2593 sgd_solver.cpp:106] Iteration 3951, lr = 0.00025
I1111 00:51:42.571280  2593 solver.cpp:295] Iteration 3952 (no loss supplied for SingleUpdateStep)
I1111 00:51:42.571416  2593 solver.cpp:310]     Train net output #0: loss = 0.414803 (* 1 = 0.414803 loss)
I1111 00:51:42.571449  2593 sgd_solver.cpp:106] Iteration 3952, lr = 0.00025
I1111 00:51:44.973233  2593 solver.cpp:295] Iteration 3953 (no loss supplied for SingleUpdateStep)
I1111 00:51:44.973399  2593 solver.cpp:310]     Train net output #0: loss = 0.39367 (* 1 = 0.39367 loss)
I1111 00:51:44.973425  2593 sgd_solver.cpp:106] Iteration 3953, lr = 0.00025
I1111 00:51:47.310109  2593 solver.cpp:295] Iteration 3954 (no loss supplied for SingleUpdateStep)
I1111 00:51:47.310262  2593 solver.cpp:310]     Train net output #0: loss = 0.350781 (* 1 = 0.350781 loss)
I1111 00:51:47.310288  2593 sgd_solver.cpp:106] Iteration 3954, lr = 0.00025
I1111 00:51:49.531378  2593 solver.cpp:295] Iteration 3955 (no loss supplied for SingleUpdateStep)
I1111 00:51:49.531498  2593 solver.cpp:310]     Train net output #0: loss = 0.382094 (* 1 = 0.382094 loss)
I1111 00:51:49.531520  2593 sgd_solver.cpp:106] Iteration 3955, lr = 0.00025
I1111 00:51:51.817831  2593 solver.cpp:295] Iteration 3956 (no loss supplied for SingleUpdateStep)
I1111 00:51:51.817929  2593 solver.cpp:310]     Train net output #0: loss = 0.373396 (* 1 = 0.373396 loss)
I1111 00:51:51.817951  2593 sgd_solver.cpp:106] Iteration 3956, lr = 0.00025
I1111 00:51:54.273332  2593 solver.cpp:295] Iteration 3957 (no loss supplied for SingleUpdateStep)
I1111 00:51:54.273427  2593 solver.cpp:310]     Train net output #0: loss = 0.405923 (* 1 = 0.405923 loss)
I1111 00:51:54.273448  2593 sgd_solver.cpp:106] Iteration 3957, lr = 0.00025
I1111 00:51:56.580348  2593 solver.cpp:295] Iteration 3958 (no loss supplied for SingleUpdateStep)
I1111 00:51:56.580500  2593 solver.cpp:310]     Train net output #0: loss = 0.38288 (* 1 = 0.38288 loss)
I1111 00:51:56.580525  2593 sgd_solver.cpp:106] Iteration 3958, lr = 0.00025
I1111 00:51:59.009567  2593 solver.cpp:295] Iteration 3959 (no loss supplied for SingleUpdateStep)
I1111 00:51:59.009649  2593 solver.cpp:310]     Train net output #0: loss = 0.382852 (* 1 = 0.382852 loss)
I1111 00:51:59.009668  2593 sgd_solver.cpp:106] Iteration 3959, lr = 0.00025
I1111 00:52:01.438338  2593 solver.cpp:295] Iteration 3960 (no loss supplied for SingleUpdateStep)
I1111 00:52:01.438410  2593 solver.cpp:310]     Train net output #0: loss = 0.409697 (* 1 = 0.409697 loss)
I1111 00:52:01.438429  2593 sgd_solver.cpp:106] Iteration 3960, lr = 0.00025
I1111 00:52:04.120389  2593 solver.cpp:295] Iteration 3961 (no loss supplied for SingleUpdateStep)
I1111 00:52:04.120460  2593 solver.cpp:310]     Train net output #0: loss = 0.384393 (* 1 = 0.384393 loss)
I1111 00:52:04.120478  2593 sgd_solver.cpp:106] Iteration 3961, lr = 0.00025
I1111 00:52:06.704715  2593 solver.cpp:295] Iteration 3962 (no loss supplied for SingleUpdateStep)
I1111 00:52:06.704891  2593 solver.cpp:310]     Train net output #0: loss = 0.377381 (* 1 = 0.377381 loss)
I1111 00:52:06.704921  2593 sgd_solver.cpp:106] Iteration 3962, lr = 0.00025
I1111 00:52:09.158220  2593 solver.cpp:295] Iteration 3963 (no loss supplied for SingleUpdateStep)
I1111 00:52:09.158323  2593 solver.cpp:310]     Train net output #0: loss = 0.389552 (* 1 = 0.389552 loss)
I1111 00:52:09.158344  2593 sgd_solver.cpp:106] Iteration 3963, lr = 0.00025
I1111 00:52:11.550503  2593 solver.cpp:295] Iteration 3964 (no loss supplied for SingleUpdateStep)
I1111 00:52:11.550585  2593 solver.cpp:310]     Train net output #0: loss = 0.385025 (* 1 = 0.385025 loss)
I1111 00:52:11.550606  2593 sgd_solver.cpp:106] Iteration 3964, lr = 0.00025
I1111 00:52:13.657660  2593 solver.cpp:295] Iteration 3965 (no loss supplied for SingleUpdateStep)
I1111 00:52:13.657781  2593 solver.cpp:310]     Train net output #0: loss = 0.384421 (* 1 = 0.384421 loss)
I1111 00:52:13.657809  2593 sgd_solver.cpp:106] Iteration 3965, lr = 0.00025
I1111 00:52:15.930207  2593 solver.cpp:295] Iteration 3966 (no loss supplied for SingleUpdateStep)
I1111 00:52:15.930357  2593 solver.cpp:310]     Train net output #0: loss = 0.393695 (* 1 = 0.393695 loss)
I1111 00:52:15.930382  2593 sgd_solver.cpp:106] Iteration 3966, lr = 0.00025
I1111 00:52:18.153306  2593 solver.cpp:295] Iteration 3967 (no loss supplied for SingleUpdateStep)
I1111 00:52:18.153455  2593 solver.cpp:310]     Train net output #0: loss = 0.357323 (* 1 = 0.357323 loss)
I1111 00:52:18.153482  2593 sgd_solver.cpp:106] Iteration 3967, lr = 0.00025
I1111 00:52:20.578255  2593 solver.cpp:295] Iteration 3968 (no loss supplied for SingleUpdateStep)
I1111 00:52:20.578392  2593 solver.cpp:310]     Train net output #0: loss = 0.422151 (* 1 = 0.422151 loss)
I1111 00:52:20.578419  2593 sgd_solver.cpp:106] Iteration 3968, lr = 0.00025
I1111 00:52:22.911223  2593 solver.cpp:295] Iteration 3969 (no loss supplied for SingleUpdateStep)
I1111 00:52:22.911361  2593 solver.cpp:310]     Train net output #0: loss = 0.363421 (* 1 = 0.363421 loss)
I1111 00:52:22.911389  2593 sgd_solver.cpp:106] Iteration 3969, lr = 0.00025
I1111 00:52:25.220803  2593 solver.cpp:295] Iteration 3970 (no loss supplied for SingleUpdateStep)
I1111 00:52:25.220983  2593 solver.cpp:310]     Train net output #0: loss = 0.357721 (* 1 = 0.357721 loss)
I1111 00:52:25.221014  2593 sgd_solver.cpp:106] Iteration 3970, lr = 0.00025
I1111 00:52:27.515856  2593 solver.cpp:295] Iteration 3971 (no loss supplied for SingleUpdateStep)
I1111 00:52:27.516021  2593 solver.cpp:310]     Train net output #0: loss = 0.368419 (* 1 = 0.368419 loss)
I1111 00:52:27.516049  2593 sgd_solver.cpp:106] Iteration 3971, lr = 0.00025
I1111 00:52:29.791893  2593 solver.cpp:295] Iteration 3972 (no loss supplied for SingleUpdateStep)
I1111 00:52:29.792088  2593 solver.cpp:310]     Train net output #0: loss = 0.392084 (* 1 = 0.392084 loss)
I1111 00:52:29.792114  2593 sgd_solver.cpp:106] Iteration 3972, lr = 0.00025
I1111 00:52:32.144765  2593 solver.cpp:295] Iteration 3973 (no loss supplied for SingleUpdateStep)
I1111 00:52:32.145020  2593 solver.cpp:310]     Train net output #0: loss = 0.421086 (* 1 = 0.421086 loss)
I1111 00:52:32.145058  2593 sgd_solver.cpp:106] Iteration 3973, lr = 0.00025
I1111 00:52:34.468407  2593 solver.cpp:295] Iteration 3974 (no loss supplied for SingleUpdateStep)
I1111 00:52:34.468533  2593 solver.cpp:310]     Train net output #0: loss = 0.405052 (* 1 = 0.405052 loss)
I1111 00:52:34.468554  2593 sgd_solver.cpp:106] Iteration 3974, lr = 0.00025
I1111 00:52:36.653771  2593 solver.cpp:295] Iteration 3975 (no loss supplied for SingleUpdateStep)
I1111 00:52:36.653959  2593 solver.cpp:310]     Train net output #0: loss = 0.41816 (* 1 = 0.41816 loss)
I1111 00:52:36.653988  2593 sgd_solver.cpp:106] Iteration 3975, lr = 0.00025
I1111 00:52:39.037930  2593 solver.cpp:295] Iteration 3976 (no loss supplied for SingleUpdateStep)
I1111 00:52:39.038086  2593 solver.cpp:310]     Train net output #0: loss = 0.382172 (* 1 = 0.382172 loss)
I1111 00:52:39.038110  2593 sgd_solver.cpp:106] Iteration 3976, lr = 0.00025
I1111 00:52:41.565980  2593 solver.cpp:295] Iteration 3977 (no loss supplied for SingleUpdateStep)
I1111 00:52:41.566092  2593 solver.cpp:310]     Train net output #0: loss = 0.406137 (* 1 = 0.406137 loss)
I1111 00:52:41.566114  2593 sgd_solver.cpp:106] Iteration 3977, lr = 0.00025
I1111 00:52:44.200649  2593 solver.cpp:295] Iteration 3978 (no loss supplied for SingleUpdateStep)
I1111 00:52:44.200799  2593 solver.cpp:310]     Train net output #0: loss = 0.389945 (* 1 = 0.389945 loss)
I1111 00:52:44.200824  2593 sgd_solver.cpp:106] Iteration 3978, lr = 0.00025
I1111 00:52:47.620544  2593 solver.cpp:295] Iteration 3979 (no loss supplied for SingleUpdateStep)
I1111 00:52:47.620790  2593 solver.cpp:310]     Train net output #0: loss = 0.372441 (* 1 = 0.372441 loss)
I1111 00:52:47.620822  2593 sgd_solver.cpp:106] Iteration 3979, lr = 0.00025
I1111 00:52:50.624387  2593 solver.cpp:295] Iteration 3980 (no loss supplied for SingleUpdateStep)
I1111 00:52:50.624495  2593 solver.cpp:310]     Train net output #0: loss = 0.358075 (* 1 = 0.358075 loss)
I1111 00:52:50.624517  2593 sgd_solver.cpp:106] Iteration 3980, lr = 0.00025
I1111 00:52:52.988445  2593 solver.cpp:295] Iteration 3981 (no loss supplied for SingleUpdateStep)
I1111 00:52:52.988522  2593 solver.cpp:310]     Train net output #0: loss = 0.390063 (* 1 = 0.390063 loss)
I1111 00:52:52.988544  2593 sgd_solver.cpp:106] Iteration 3981, lr = 0.00025
I1111 00:52:55.377565  2593 solver.cpp:295] Iteration 3982 (no loss supplied for SingleUpdateStep)
I1111 00:52:55.377629  2593 solver.cpp:310]     Train net output #0: loss = 0.375839 (* 1 = 0.375839 loss)
I1111 00:52:55.377647  2593 sgd_solver.cpp:106] Iteration 3982, lr = 0.00025
I1111 00:52:57.719084  2593 solver.cpp:295] Iteration 3983 (no loss supplied for SingleUpdateStep)
I1111 00:52:57.719158  2593 solver.cpp:310]     Train net output #0: loss = 0.352814 (* 1 = 0.352814 loss)
I1111 00:52:57.719177  2593 sgd_solver.cpp:106] Iteration 3983, lr = 0.00025
I1111 00:53:00.081290  2593 solver.cpp:295] Iteration 3984 (no loss supplied for SingleUpdateStep)
I1111 00:53:00.081404  2593 solver.cpp:310]     Train net output #0: loss = 0.380571 (* 1 = 0.380571 loss)
I1111 00:53:00.081428  2593 sgd_solver.cpp:106] Iteration 3984, lr = 0.00025
I1111 00:53:02.458475  2593 solver.cpp:295] Iteration 3985 (no loss supplied for SingleUpdateStep)
I1111 00:53:02.458647  2593 solver.cpp:310]     Train net output #0: loss = 0.379784 (* 1 = 0.379784 loss)
I1111 00:53:02.458684  2593 sgd_solver.cpp:106] Iteration 3985, lr = 0.00025
I1111 00:53:05.074419  2593 solver.cpp:295] Iteration 3986 (no loss supplied for SingleUpdateStep)
I1111 00:53:05.074548  2593 solver.cpp:310]     Train net output #0: loss = 0.360119 (* 1 = 0.360119 loss)
I1111 00:53:05.074576  2593 sgd_solver.cpp:106] Iteration 3986, lr = 0.00025
I1111 00:53:07.794183  2593 solver.cpp:295] Iteration 3987 (no loss supplied for SingleUpdateStep)
I1111 00:53:07.794311  2593 solver.cpp:310]     Train net output #0: loss = 0.405038 (* 1 = 0.405038 loss)
I1111 00:53:07.794335  2593 sgd_solver.cpp:106] Iteration 3987, lr = 0.00025
I1111 00:53:10.245347  2593 solver.cpp:295] Iteration 3988 (no loss supplied for SingleUpdateStep)
I1111 00:53:10.245471  2593 solver.cpp:310]     Train net output #0: loss = 0.380794 (* 1 = 0.380794 loss)
I1111 00:53:10.245494  2593 sgd_solver.cpp:106] Iteration 3988, lr = 0.00025
I1111 00:53:12.448801  2593 solver.cpp:295] Iteration 3989 (no loss supplied for SingleUpdateStep)
I1111 00:53:12.448918  2593 solver.cpp:310]     Train net output #0: loss = 0.384118 (* 1 = 0.384118 loss)
I1111 00:53:12.448943  2593 sgd_solver.cpp:106] Iteration 3989, lr = 0.00025
I1111 00:53:14.911916  2593 solver.cpp:295] Iteration 3990 (no loss supplied for SingleUpdateStep)
I1111 00:53:14.912024  2593 solver.cpp:310]     Train net output #0: loss = 0.381131 (* 1 = 0.381131 loss)
I1111 00:53:14.912046  2593 sgd_solver.cpp:106] Iteration 3990, lr = 0.00025
I1111 00:53:17.572373  2593 solver.cpp:295] Iteration 3991 (no loss supplied for SingleUpdateStep)
I1111 00:53:17.572438  2593 solver.cpp:310]     Train net output #0: loss = 0.3898 (* 1 = 0.3898 loss)
I1111 00:53:17.572463  2593 sgd_solver.cpp:106] Iteration 3991, lr = 0.00025
I1111 00:53:20.121551  2593 solver.cpp:295] Iteration 3992 (no loss supplied for SingleUpdateStep)
I1111 00:53:20.121673  2593 solver.cpp:310]     Train net output #0: loss = 0.390169 (* 1 = 0.390169 loss)
I1111 00:53:20.121693  2593 sgd_solver.cpp:106] Iteration 3992, lr = 0.00025
I1111 00:53:22.770282  2593 solver.cpp:295] Iteration 3993 (no loss supplied for SingleUpdateStep)
I1111 00:53:22.770396  2593 solver.cpp:310]     Train net output #0: loss = 0.377813 (* 1 = 0.377813 loss)
I1111 00:53:22.770421  2593 sgd_solver.cpp:106] Iteration 3993, lr = 0.00025
I1111 00:53:25.323125  2593 solver.cpp:295] Iteration 3994 (no loss supplied for SingleUpdateStep)
I1111 00:53:25.323232  2593 solver.cpp:310]     Train net output #0: loss = 0.404552 (* 1 = 0.404552 loss)
I1111 00:53:25.323254  2593 sgd_solver.cpp:106] Iteration 3994, lr = 0.00025
I1111 00:53:27.768735  2593 solver.cpp:295] Iteration 3995 (no loss supplied for SingleUpdateStep)
I1111 00:53:27.768824  2593 solver.cpp:310]     Train net output #0: loss = 0.408891 (* 1 = 0.408891 loss)
I1111 00:53:27.768846  2593 sgd_solver.cpp:106] Iteration 3995, lr = 0.00025
I1111 00:53:30.476596  2593 solver.cpp:295] Iteration 3996 (no loss supplied for SingleUpdateStep)
I1111 00:53:30.476683  2593 solver.cpp:310]     Train net output #0: loss = 0.374337 (* 1 = 0.374337 loss)
I1111 00:53:30.476706  2593 sgd_solver.cpp:106] Iteration 3996, lr = 0.00025
I1111 00:53:33.019472  2593 solver.cpp:295] Iteration 3997 (no loss supplied for SingleUpdateStep)
I1111 00:53:33.019554  2593 solver.cpp:310]     Train net output #0: loss = 0.373633 (* 1 = 0.373633 loss)
I1111 00:53:33.019588  2593 sgd_solver.cpp:106] Iteration 3997, lr = 0.00025
I1111 00:53:35.798431  2593 solver.cpp:295] Iteration 3998 (no loss supplied for SingleUpdateStep)
I1111 00:53:35.798532  2593 solver.cpp:310]     Train net output #0: loss = 0.392431 (* 1 = 0.392431 loss)
I1111 00:53:35.798557  2593 sgd_solver.cpp:106] Iteration 3998, lr = 0.00025
I1111 00:53:39.259631  2593 solver.cpp:295] Iteration 3999 (no loss supplied for SingleUpdateStep)
I1111 00:53:39.259706  2593 solver.cpp:310]     Train net output #0: loss = 0.382735 (* 1 = 0.382735 loss)
I1111 00:53:39.259723  2593 sgd_solver.cpp:106] Iteration 3999, lr = 0.00025
I1111 00:53:39.259835  2593 solver.cpp:534] Snapshotting to binary proto file stitch_iter_4000.caffemodel
I1111 00:53:39.259860  2593 net.cpp:1022] Serializing 2 layers
I1111 00:53:39.267410  2593 sgd_solver.cpp:269] Snapshotting solver state to binary proto file stitch_iter_4000.solverstate
I1111 00:53:42.846585  2593 solver.cpp:295] Iteration 4000 (no loss supplied for SingleUpdateStep)
I1111 00:53:42.846699  2593 solver.cpp:310]     Train net output #0: loss = 0.41048 (* 1 = 0.41048 loss)
I1111 00:53:42.846726  2593 sgd_solver.cpp:106] Iteration 4000, lr = 0.00025
I1111 00:53:46.367877  2593 solver.cpp:295] Iteration 4001 (no loss supplied for SingleUpdateStep)
I1111 00:53:46.367941  2593 solver.cpp:310]     Train net output #0: loss = 0.381514 (* 1 = 0.381514 loss)
I1111 00:53:46.367960  2593 sgd_solver.cpp:106] Iteration 4001, lr = 0.00025
I1111 00:53:49.730041  2593 solver.cpp:295] Iteration 4002 (no loss supplied for SingleUpdateStep)
I1111 00:53:49.730126  2593 solver.cpp:310]     Train net output #0: loss = 0.401113 (* 1 = 0.401113 loss)
I1111 00:53:49.730146  2593 sgd_solver.cpp:106] Iteration 4002, lr = 0.00025
I1111 00:53:52.404480  2593 solver.cpp:295] Iteration 4003 (no loss supplied for SingleUpdateStep)
I1111 00:53:52.404614  2593 solver.cpp:310]     Train net output #0: loss = 0.349879 (* 1 = 0.349879 loss)
I1111 00:53:52.404639  2593 sgd_solver.cpp:106] Iteration 4003, lr = 0.00025
I1111 00:53:54.851402  2593 solver.cpp:295] Iteration 4004 (no loss supplied for SingleUpdateStep)
I1111 00:53:54.851482  2593 solver.cpp:310]     Train net output #0: loss = 0.416945 (* 1 = 0.416945 loss)
I1111 00:53:54.851505  2593 sgd_solver.cpp:106] Iteration 4004, lr = 0.00025
I1111 00:53:57.148171  2593 solver.cpp:295] Iteration 4005 (no loss supplied for SingleUpdateStep)
I1111 00:53:57.148303  2593 solver.cpp:310]     Train net output #0: loss = 0.393504 (* 1 = 0.393504 loss)
I1111 00:53:57.148325  2593 sgd_solver.cpp:106] Iteration 4005, lr = 0.00025
I1111 00:53:59.606752  2593 solver.cpp:295] Iteration 4006 (no loss supplied for SingleUpdateStep)
I1111 00:53:59.606880  2593 solver.cpp:310]     Train net output #0: loss = 0.409162 (* 1 = 0.409162 loss)
I1111 00:53:59.606904  2593 sgd_solver.cpp:106] Iteration 4006, lr = 0.00025
I1111 00:54:01.697587  2593 solver.cpp:295] Iteration 4007 (no loss supplied for SingleUpdateStep)
I1111 00:54:01.697726  2593 solver.cpp:310]     Train net output #0: loss = 0.396868 (* 1 = 0.396868 loss)
I1111 00:54:01.697748  2593 sgd_solver.cpp:106] Iteration 4007, lr = 0.00025
I1111 00:54:04.026574  2593 solver.cpp:295] Iteration 4008 (no loss supplied for SingleUpdateStep)
I1111 00:54:04.026689  2593 solver.cpp:310]     Train net output #0: loss = 0.400648 (* 1 = 0.400648 loss)
I1111 00:54:04.026712  2593 sgd_solver.cpp:106] Iteration 4008, lr = 0.00025
I1111 00:54:06.579610  2593 solver.cpp:295] Iteration 4009 (no loss supplied for SingleUpdateStep)
I1111 00:54:06.579730  2593 solver.cpp:310]     Train net output #0: loss = 0.366617 (* 1 = 0.366617 loss)
I1111 00:54:06.579753  2593 sgd_solver.cpp:106] Iteration 4009, lr = 0.00025
I1111 00:54:08.781129  2593 solver.cpp:295] Iteration 4010 (no loss supplied for SingleUpdateStep)
I1111 00:54:08.781195  2593 solver.cpp:310]     Train net output #0: loss = 0.4324 (* 1 = 0.4324 loss)
I1111 00:54:08.781214  2593 sgd_solver.cpp:106] Iteration 4010, lr = 0.00025
I1111 00:54:11.154440  2593 solver.cpp:295] Iteration 4011 (no loss supplied for SingleUpdateStep)
I1111 00:54:11.154500  2593 solver.cpp:310]     Train net output #0: loss = 0.368515 (* 1 = 0.368515 loss)
I1111 00:54:11.154520  2593 sgd_solver.cpp:106] Iteration 4011, lr = 0.00025
I1111 00:54:13.549422  2593 solver.cpp:295] Iteration 4012 (no loss supplied for SingleUpdateStep)
I1111 00:54:13.549496  2593 solver.cpp:310]     Train net output #0: loss = 0.397178 (* 1 = 0.397178 loss)
I1111 00:54:13.549517  2593 sgd_solver.cpp:106] Iteration 4012, lr = 0.00025
I1111 00:54:15.898895  2593 solver.cpp:295] Iteration 4013 (no loss supplied for SingleUpdateStep)
I1111 00:54:15.898990  2593 solver.cpp:310]     Train net output #0: loss = 0.408436 (* 1 = 0.408436 loss)
I1111 00:54:15.899015  2593 sgd_solver.cpp:106] Iteration 4013, lr = 0.00025
I1111 00:54:18.234339  2593 solver.cpp:295] Iteration 4014 (no loss supplied for SingleUpdateStep)
I1111 00:54:18.234458  2593 solver.cpp:310]     Train net output #0: loss = 0.372563 (* 1 = 0.372563 loss)
I1111 00:54:18.234480  2593 sgd_solver.cpp:106] Iteration 4014, lr = 0.00025
I1111 00:54:20.485869  2593 solver.cpp:295] Iteration 4015 (no loss supplied for SingleUpdateStep)
I1111 00:54:20.485923  2593 solver.cpp:310]     Train net output #0: loss = 0.356974 (* 1 = 0.356974 loss)
I1111 00:54:20.485940  2593 sgd_solver.cpp:106] Iteration 4015, lr = 0.00025
I1111 00:54:22.896972  2593 solver.cpp:295] Iteration 4016 (no loss supplied for SingleUpdateStep)
I1111 00:54:22.897095  2593 solver.cpp:310]     Train net output #0: loss = 0.424256 (* 1 = 0.424256 loss)
I1111 00:54:22.897124  2593 sgd_solver.cpp:106] Iteration 4016, lr = 0.00025
I1111 00:54:25.393846  2593 solver.cpp:295] Iteration 4017 (no loss supplied for SingleUpdateStep)
I1111 00:54:25.393972  2593 solver.cpp:310]     Train net output #0: loss = 0.350268 (* 1 = 0.350268 loss)
I1111 00:54:25.394001  2593 sgd_solver.cpp:106] Iteration 4017, lr = 0.00025
I1111 00:54:28.042055  2593 solver.cpp:295] Iteration 4018 (no loss supplied for SingleUpdateStep)
I1111 00:54:28.042186  2593 solver.cpp:310]     Train net output #0: loss = 0.384184 (* 1 = 0.384184 loss)
I1111 00:54:28.042212  2593 sgd_solver.cpp:106] Iteration 4018, lr = 0.00025
I1111 00:54:30.288569  2593 solver.cpp:295] Iteration 4019 (no loss supplied for SingleUpdateStep)
I1111 00:54:30.288674  2593 solver.cpp:310]     Train net output #0: loss = 0.373573 (* 1 = 0.373573 loss)
I1111 00:54:30.288697  2593 sgd_solver.cpp:106] Iteration 4019, lr = 0.00025
I1111 00:54:32.457267  2593 solver.cpp:295] Iteration 4020 (no loss supplied for SingleUpdateStep)
I1111 00:54:32.457383  2593 solver.cpp:310]     Train net output #0: loss = 0.416389 (* 1 = 0.416389 loss)
I1111 00:54:32.457407  2593 sgd_solver.cpp:106] Iteration 4020, lr = 0.00025
I1111 00:54:34.748713  2593 solver.cpp:295] Iteration 4021 (no loss supplied for SingleUpdateStep)
I1111 00:54:34.748833  2593 solver.cpp:310]     Train net output #0: loss = 0.388087 (* 1 = 0.388087 loss)
I1111 00:54:34.748854  2593 sgd_solver.cpp:106] Iteration 4021, lr = 0.00025
I1111 00:54:37.166501  2593 solver.cpp:295] Iteration 4022 (no loss supplied for SingleUpdateStep)
I1111 00:54:37.166618  2593 solver.cpp:310]     Train net output #0: loss = 0.403377 (* 1 = 0.403377 loss)
I1111 00:54:37.166642  2593 sgd_solver.cpp:106] Iteration 4022, lr = 0.00025
I1111 00:54:40.224998  2593 solver.cpp:295] Iteration 4023 (no loss supplied for SingleUpdateStep)
I1111 00:54:40.225105  2593 solver.cpp:310]     Train net output #0: loss = 0.368743 (* 1 = 0.368743 loss)
I1111 00:54:40.225124  2593 sgd_solver.cpp:106] Iteration 4023, lr = 0.00025
I1111 00:54:43.344545  2593 solver.cpp:295] Iteration 4024 (no loss supplied for SingleUpdateStep)
I1111 00:54:43.344640  2593 solver.cpp:310]     Train net output #0: loss = 0.395406 (* 1 = 0.395406 loss)
I1111 00:54:43.344661  2593 sgd_solver.cpp:106] Iteration 4024, lr = 0.00025
I1111 00:54:46.431722  2593 solver.cpp:295] Iteration 4025 (no loss supplied for SingleUpdateStep)
I1111 00:54:46.431826  2593 solver.cpp:310]     Train net output #0: loss = 0.380095 (* 1 = 0.380095 loss)
I1111 00:54:46.431848  2593 sgd_solver.cpp:106] Iteration 4025, lr = 0.00025
I1111 00:54:49.290284  2593 solver.cpp:295] Iteration 4026 (no loss supplied for SingleUpdateStep)
I1111 00:54:49.290472  2593 solver.cpp:310]     Train net output #0: loss = 0.376194 (* 1 = 0.376194 loss)
I1111 00:54:49.290509  2593 sgd_solver.cpp:106] Iteration 4026, lr = 0.00025
I1111 00:54:51.722592  2593 solver.cpp:295] Iteration 4027 (no loss supplied for SingleUpdateStep)
I1111 00:54:51.722728  2593 solver.cpp:310]     Train net output #0: loss = 0.383785 (* 1 = 0.383785 loss)
I1111 00:54:51.722751  2593 sgd_solver.cpp:106] Iteration 4027, lr = 0.00025
I1111 00:54:54.118161  2593 solver.cpp:295] Iteration 4028 (no loss supplied for SingleUpdateStep)
I1111 00:54:54.118229  2593 solver.cpp:310]     Train net output #0: loss = 0.39416 (* 1 = 0.39416 loss)
I1111 00:54:54.118248  2593 sgd_solver.cpp:106] Iteration 4028, lr = 0.00025
I1111 00:54:56.421231  2593 solver.cpp:295] Iteration 4029 (no loss supplied for SingleUpdateStep)
I1111 00:54:56.421303  2593 solver.cpp:310]     Train net output #0: loss = 0.364147 (* 1 = 0.364147 loss)
I1111 00:54:56.421324  2593 sgd_solver.cpp:106] Iteration 4029, lr = 0.00025
I1111 00:54:58.829973  2593 solver.cpp:295] Iteration 4030 (no loss supplied for SingleUpdateStep)
I1111 00:54:58.830096  2593 solver.cpp:310]     Train net output #0: loss = 0.400422 (* 1 = 0.400422 loss)
I1111 00:54:58.830119  2593 sgd_solver.cpp:106] Iteration 4030, lr = 0.00025
I1111 00:55:01.638794  2593 solver.cpp:295] Iteration 4031 (no loss supplied for SingleUpdateStep)
I1111 00:55:01.638931  2593 solver.cpp:310]     Train net output #0: loss = 0.378902 (* 1 = 0.378902 loss)
I1111 00:55:01.638957  2593 sgd_solver.cpp:106] Iteration 4031, lr = 0.00025
I1111 00:55:04.986270  2593 solver.cpp:295] Iteration 4032 (no loss supplied for SingleUpdateStep)
I1111 00:55:04.986395  2593 solver.cpp:310]     Train net output #0: loss = 0.392871 (* 1 = 0.392871 loss)
I1111 00:55:04.986423  2593 sgd_solver.cpp:106] Iteration 4032, lr = 0.00025
I1111 00:55:07.686609  2593 solver.cpp:295] Iteration 4033 (no loss supplied for SingleUpdateStep)
I1111 00:55:07.686686  2593 solver.cpp:310]     Train net output #0: loss = 0.374719 (* 1 = 0.374719 loss)
I1111 00:55:07.686707  2593 sgd_solver.cpp:106] Iteration 4033, lr = 0.00025
I1111 00:55:10.132350  2593 solver.cpp:295] Iteration 4034 (no loss supplied for SingleUpdateStep)
I1111 00:55:10.132478  2593 solver.cpp:310]     Train net output #0: loss = 0.377506 (* 1 = 0.377506 loss)
I1111 00:55:10.132505  2593 sgd_solver.cpp:106] Iteration 4034, lr = 0.00025
I1111 00:55:12.450171  2593 solver.cpp:295] Iteration 4035 (no loss supplied for SingleUpdateStep)
I1111 00:55:12.450316  2593 solver.cpp:310]     Train net output #0: loss = 0.377298 (* 1 = 0.377298 loss)
I1111 00:55:12.450343  2593 sgd_solver.cpp:106] Iteration 4035, lr = 0.00025
I1111 00:55:14.834656  2593 solver.cpp:295] Iteration 4036 (no loss supplied for SingleUpdateStep)
I1111 00:55:14.834789  2593 solver.cpp:310]     Train net output #0: loss = 0.406155 (* 1 = 0.406155 loss)
I1111 00:55:14.834812  2593 sgd_solver.cpp:106] Iteration 4036, lr = 0.00025
I1111 00:55:17.058490  2593 solver.cpp:295] Iteration 4037 (no loss supplied for SingleUpdateStep)
I1111 00:55:17.058590  2593 solver.cpp:310]     Train net output #0: loss = 0.363918 (* 1 = 0.363918 loss)
I1111 00:55:17.058612  2593 sgd_solver.cpp:106] Iteration 4037, lr = 0.00025
I1111 00:55:19.357091  2593 solver.cpp:295] Iteration 4038 (no loss supplied for SingleUpdateStep)
I1111 00:55:19.357153  2593 solver.cpp:310]     Train net output #0: loss = 0.380909 (* 1 = 0.380909 loss)
I1111 00:55:19.357173  2593 sgd_solver.cpp:106] Iteration 4038, lr = 0.00025
I1111 00:55:21.761204  2593 solver.cpp:295] Iteration 4039 (no loss supplied for SingleUpdateStep)
I1111 00:55:21.761374  2593 solver.cpp:310]     Train net output #0: loss = 0.37226 (* 1 = 0.37226 loss)
I1111 00:55:21.761421  2593 sgd_solver.cpp:106] Iteration 4039, lr = 0.00025
I1111 00:55:24.001399  2593 solver.cpp:295] Iteration 4040 (no loss supplied for SingleUpdateStep)
I1111 00:55:24.001556  2593 solver.cpp:310]     Train net output #0: loss = 0.394998 (* 1 = 0.394998 loss)
I1111 00:55:24.001582  2593 sgd_solver.cpp:106] Iteration 4040, lr = 0.00025
I1111 00:55:26.160091  2593 solver.cpp:295] Iteration 4041 (no loss supplied for SingleUpdateStep)
I1111 00:55:26.160210  2593 solver.cpp:310]     Train net output #0: loss = 0.371698 (* 1 = 0.371698 loss)
I1111 00:55:26.160233  2593 sgd_solver.cpp:106] Iteration 4041, lr = 0.00025
I1111 00:55:28.668396  2593 solver.cpp:295] Iteration 4042 (no loss supplied for SingleUpdateStep)
I1111 00:55:28.668514  2593 solver.cpp:310]     Train net output #0: loss = 0.392716 (* 1 = 0.392716 loss)
I1111 00:55:28.668534  2593 sgd_solver.cpp:106] Iteration 4042, lr = 0.00025
I1111 00:55:31.037135  2593 solver.cpp:295] Iteration 4043 (no loss supplied for SingleUpdateStep)
I1111 00:55:31.037210  2593 solver.cpp:310]     Train net output #0: loss = 0.354058 (* 1 = 0.354058 loss)
I1111 00:55:31.037230  2593 sgd_solver.cpp:106] Iteration 4043, lr = 0.00025
I1111 00:55:33.445448  2593 solver.cpp:295] Iteration 4044 (no loss supplied for SingleUpdateStep)
I1111 00:55:33.445574  2593 solver.cpp:310]     Train net output #0: loss = 0.391194 (* 1 = 0.391194 loss)
I1111 00:55:33.445595  2593 sgd_solver.cpp:106] Iteration 4044, lr = 0.00025
I1111 00:55:35.881664  2593 solver.cpp:295] Iteration 4045 (no loss supplied for SingleUpdateStep)
I1111 00:55:35.881757  2593 solver.cpp:310]     Train net output #0: loss = 0.387166 (* 1 = 0.387166 loss)
I1111 00:55:35.881780  2593 sgd_solver.cpp:106] Iteration 4045, lr = 0.00025
I1111 00:55:38.293084  2593 solver.cpp:295] Iteration 4046 (no loss supplied for SingleUpdateStep)
I1111 00:55:38.293150  2593 solver.cpp:310]     Train net output #0: loss = 0.39279 (* 1 = 0.39279 loss)
I1111 00:55:38.293170  2593 sgd_solver.cpp:106] Iteration 4046, lr = 0.00025
I1111 00:55:40.625807  2593 solver.cpp:295] Iteration 4047 (no loss supplied for SingleUpdateStep)
I1111 00:55:40.625912  2593 solver.cpp:310]     Train net output #0: loss = 0.394833 (* 1 = 0.394833 loss)
I1111 00:55:40.625934  2593 sgd_solver.cpp:106] Iteration 4047, lr = 0.00025
I1111 00:55:42.935072  2593 solver.cpp:295] Iteration 4048 (no loss supplied for SingleUpdateStep)
I1111 00:55:42.935225  2593 solver.cpp:310]     Train net output #0: loss = 0.370401 (* 1 = 0.370401 loss)
I1111 00:55:42.935246  2593 sgd_solver.cpp:106] Iteration 4048, lr = 0.00025
I1111 00:55:45.322013  2593 solver.cpp:295] Iteration 4049 (no loss supplied for SingleUpdateStep)
I1111 00:55:45.322084  2593 solver.cpp:310]     Train net output #0: loss = 0.381761 (* 1 = 0.381761 loss)
I1111 00:55:45.322105  2593 sgd_solver.cpp:106] Iteration 4049, lr = 0.00025
I1111 00:55:47.756758  2593 solver.cpp:295] Iteration 4050 (no loss supplied for SingleUpdateStep)
I1111 00:55:47.756819  2593 solver.cpp:310]     Train net output #0: loss = 0.387993 (* 1 = 0.387993 loss)
I1111 00:55:47.756839  2593 sgd_solver.cpp:106] Iteration 4050, lr = 0.00025
I1111 00:55:50.081615  2593 solver.cpp:295] Iteration 4051 (no loss supplied for SingleUpdateStep)
I1111 00:55:50.081722  2593 solver.cpp:310]     Train net output #0: loss = 0.378437 (* 1 = 0.378437 loss)
I1111 00:55:50.081743  2593 sgd_solver.cpp:106] Iteration 4051, lr = 0.00025
I1111 00:55:52.325515  2593 solver.cpp:295] Iteration 4052 (no loss supplied for SingleUpdateStep)
I1111 00:55:52.325662  2593 solver.cpp:310]     Train net output #0: loss = 0.379069 (* 1 = 0.379069 loss)
I1111 00:55:52.325685  2593 sgd_solver.cpp:106] Iteration 4052, lr = 0.00025
I1111 00:55:54.704104  2593 solver.cpp:295] Iteration 4053 (no loss supplied for SingleUpdateStep)
I1111 00:55:54.704207  2593 solver.cpp:310]     Train net output #0: loss = 0.360447 (* 1 = 0.360447 loss)
I1111 00:55:54.704229  2593 sgd_solver.cpp:106] Iteration 4053, lr = 0.00025
I1111 00:55:57.250113  2593 solver.cpp:295] Iteration 4054 (no loss supplied for SingleUpdateStep)
I1111 00:55:57.250188  2593 solver.cpp:310]     Train net output #0: loss = 0.394477 (* 1 = 0.394477 loss)
I1111 00:55:57.250208  2593 sgd_solver.cpp:106] Iteration 4054, lr = 0.00025
I1111 00:55:59.569465  2593 solver.cpp:295] Iteration 4055 (no loss supplied for SingleUpdateStep)
I1111 00:55:59.569591  2593 solver.cpp:310]     Train net output #0: loss = 0.355903 (* 1 = 0.355903 loss)
I1111 00:55:59.569614  2593 sgd_solver.cpp:106] Iteration 4055, lr = 0.00025
I1111 00:56:01.977535  2593 solver.cpp:295] Iteration 4056 (no loss supplied for SingleUpdateStep)
I1111 00:56:01.977674  2593 solver.cpp:310]     Train net output #0: loss = 0.359387 (* 1 = 0.359387 loss)
I1111 00:56:01.977697  2593 sgd_solver.cpp:106] Iteration 4056, lr = 0.00025
I1111 00:56:04.611879  2593 solver.cpp:295] Iteration 4057 (no loss supplied for SingleUpdateStep)
I1111 00:56:04.611970  2593 solver.cpp:310]     Train net output #0: loss = 0.401074 (* 1 = 0.401074 loss)
I1111 00:56:04.611992  2593 sgd_solver.cpp:106] Iteration 4057, lr = 0.00025
I1111 00:56:08.526720  2593 solver.cpp:295] Iteration 4058 (no loss supplied for SingleUpdateStep)
I1111 00:56:08.526803  2593 solver.cpp:310]     Train net output #0: loss = 0.396917 (* 1 = 0.396917 loss)
I1111 00:56:08.526824  2593 sgd_solver.cpp:106] Iteration 4058, lr = 0.00025
I1111 00:56:11.441360  2593 solver.cpp:295] Iteration 4059 (no loss supplied for SingleUpdateStep)
I1111 00:56:11.441467  2593 solver.cpp:310]     Train net output #0: loss = 0.382719 (* 1 = 0.382719 loss)
I1111 00:56:11.441489  2593 sgd_solver.cpp:106] Iteration 4059, lr = 0.00025
I1111 00:56:13.820354  2593 solver.cpp:295] Iteration 4060 (no loss supplied for SingleUpdateStep)
I1111 00:56:13.820502  2593 solver.cpp:310]     Train net output #0: loss = 0.407132 (* 1 = 0.407132 loss)
I1111 00:56:13.820525  2593 sgd_solver.cpp:106] Iteration 4060, lr = 0.00025
I1111 00:56:16.188078  2593 solver.cpp:295] Iteration 4061 (no loss supplied for SingleUpdateStep)
I1111 00:56:16.188206  2593 solver.cpp:310]     Train net output #0: loss = 0.390504 (* 1 = 0.390504 loss)
I1111 00:56:16.188231  2593 sgd_solver.cpp:106] Iteration 4061, lr = 0.00025
I1111 00:56:18.964963  2593 solver.cpp:295] Iteration 4062 (no loss supplied for SingleUpdateStep)
I1111 00:56:18.965101  2593 solver.cpp:310]     Train net output #0: loss = 0.388205 (* 1 = 0.388205 loss)
I1111 00:56:18.965134  2593 sgd_solver.cpp:106] Iteration 4062, lr = 0.00025
I1111 00:56:21.688413  2593 solver.cpp:295] Iteration 4063 (no loss supplied for SingleUpdateStep)
I1111 00:56:21.688561  2593 solver.cpp:310]     Train net output #0: loss = 0.365432 (* 1 = 0.365432 loss)
I1111 00:56:21.688587  2593 sgd_solver.cpp:106] Iteration 4063, lr = 0.00025
I1111 00:56:24.711204  2593 solver.cpp:295] Iteration 4064 (no loss supplied for SingleUpdateStep)
I1111 00:56:24.711313  2593 solver.cpp:310]     Train net output #0: loss = 0.413794 (* 1 = 0.413794 loss)
I1111 00:56:24.711336  2593 sgd_solver.cpp:106] Iteration 4064, lr = 0.00025
I1111 00:56:27.055600  2593 solver.cpp:295] Iteration 4065 (no loss supplied for SingleUpdateStep)
I1111 00:56:27.055683  2593 solver.cpp:310]     Train net output #0: loss = 0.365703 (* 1 = 0.365703 loss)
I1111 00:56:27.055703  2593 sgd_solver.cpp:106] Iteration 4065, lr = 0.00025
I1111 00:56:29.524922  2593 solver.cpp:295] Iteration 4066 (no loss supplied for SingleUpdateStep)
I1111 00:56:29.525022  2593 solver.cpp:310]     Train net output #0: loss = 0.420127 (* 1 = 0.420127 loss)
I1111 00:56:29.525048  2593 sgd_solver.cpp:106] Iteration 4066, lr = 0.00025
I1111 00:56:32.196893  2593 solver.cpp:295] Iteration 4067 (no loss supplied for SingleUpdateStep)
I1111 00:56:32.196975  2593 solver.cpp:310]     Train net output #0: loss = 0.386231 (* 1 = 0.386231 loss)
I1111 00:56:32.196996  2593 sgd_solver.cpp:106] Iteration 4067, lr = 0.00025
I1111 00:56:34.799502  2593 solver.cpp:295] Iteration 4068 (no loss supplied for SingleUpdateStep)
I1111 00:56:34.799566  2593 solver.cpp:310]     Train net output #0: loss = 0.394306 (* 1 = 0.394306 loss)
I1111 00:56:34.799599  2593 sgd_solver.cpp:106] Iteration 4068, lr = 0.00025
I1111 00:56:37.466660  2593 solver.cpp:295] Iteration 4069 (no loss supplied for SingleUpdateStep)
I1111 00:56:37.466797  2593 solver.cpp:310]     Train net output #0: loss = 0.412032 (* 1 = 0.412032 loss)
I1111 00:56:37.466820  2593 sgd_solver.cpp:106] Iteration 4069, lr = 0.00025
I1111 00:56:40.205973  2593 solver.cpp:295] Iteration 4070 (no loss supplied for SingleUpdateStep)
I1111 00:56:40.206095  2593 solver.cpp:310]     Train net output #0: loss = 0.397919 (* 1 = 0.397919 loss)
I1111 00:56:40.206118  2593 sgd_solver.cpp:106] Iteration 4070, lr = 0.00025
I1111 00:56:42.558604  2593 solver.cpp:295] Iteration 4071 (no loss supplied for SingleUpdateStep)
I1111 00:56:42.558728  2593 solver.cpp:310]     Train net output #0: loss = 0.380822 (* 1 = 0.380822 loss)
I1111 00:56:42.558750  2593 sgd_solver.cpp:106] Iteration 4071, lr = 0.00025
I1111 00:56:44.887699  2593 solver.cpp:295] Iteration 4072 (no loss supplied for SingleUpdateStep)
I1111 00:56:44.887806  2593 solver.cpp:310]     Train net output #0: loss = 0.400229 (* 1 = 0.400229 loss)
I1111 00:56:44.887830  2593 sgd_solver.cpp:106] Iteration 4072, lr = 0.00025
I1111 00:56:47.171229  2593 solver.cpp:295] Iteration 4073 (no loss supplied for SingleUpdateStep)
I1111 00:56:47.171363  2593 solver.cpp:310]     Train net output #0: loss = 0.372149 (* 1 = 0.372149 loss)
I1111 00:56:47.171391  2593 sgd_solver.cpp:106] Iteration 4073, lr = 0.00025
I1111 00:56:49.428800  2593 solver.cpp:295] Iteration 4074 (no loss supplied for SingleUpdateStep)
I1111 00:56:49.428899  2593 solver.cpp:310]     Train net output #0: loss = 0.378452 (* 1 = 0.378452 loss)
I1111 00:56:49.428920  2593 sgd_solver.cpp:106] Iteration 4074, lr = 0.00025
I1111 00:56:51.711982  2593 solver.cpp:295] Iteration 4075 (no loss supplied for SingleUpdateStep)
I1111 00:56:51.712100  2593 solver.cpp:310]     Train net output #0: loss = 0.386892 (* 1 = 0.386892 loss)
I1111 00:56:51.712124  2593 sgd_solver.cpp:106] Iteration 4075, lr = 0.00025
I1111 00:56:54.153569  2593 solver.cpp:295] Iteration 4076 (no loss supplied for SingleUpdateStep)
I1111 00:56:54.153638  2593 solver.cpp:310]     Train net output #0: loss = 0.398411 (* 1 = 0.398411 loss)
I1111 00:56:54.153658  2593 sgd_solver.cpp:106] Iteration 4076, lr = 0.00025
I1111 00:56:56.691812  2593 solver.cpp:295] Iteration 4077 (no loss supplied for SingleUpdateStep)
I1111 00:56:56.691948  2593 solver.cpp:310]     Train net output #0: loss = 0.391953 (* 1 = 0.391953 loss)
I1111 00:56:56.691970  2593 sgd_solver.cpp:106] Iteration 4077, lr = 0.00025
I1111 00:56:59.879297  2593 solver.cpp:295] Iteration 4078 (no loss supplied for SingleUpdateStep)
I1111 00:56:59.879405  2593 solver.cpp:310]     Train net output #0: loss = 0.403846 (* 1 = 0.403846 loss)
I1111 00:56:59.879427  2593 sgd_solver.cpp:106] Iteration 4078, lr = 0.00025
I1111 00:57:02.731374  2593 solver.cpp:295] Iteration 4079 (no loss supplied for SingleUpdateStep)
I1111 00:57:02.731498  2593 solver.cpp:310]     Train net output #0: loss = 0.401851 (* 1 = 0.401851 loss)
I1111 00:57:02.731526  2593 sgd_solver.cpp:106] Iteration 4079, lr = 0.00025
I1111 00:57:05.423498  2593 solver.cpp:295] Iteration 4080 (no loss supplied for SingleUpdateStep)
I1111 00:57:05.423560  2593 solver.cpp:310]     Train net output #0: loss = 0.365484 (* 1 = 0.365484 loss)
I1111 00:57:05.423579  2593 sgd_solver.cpp:106] Iteration 4080, lr = 0.00025
I1111 00:57:08.187294  2593 solver.cpp:295] Iteration 4081 (no loss supplied for SingleUpdateStep)
I1111 00:57:08.187443  2593 solver.cpp:310]     Train net output #0: loss = 0.373972 (* 1 = 0.373972 loss)
I1111 00:57:08.187466  2593 sgd_solver.cpp:106] Iteration 4081, lr = 0.00025
I1111 00:57:10.480852  2593 solver.cpp:295] Iteration 4082 (no loss supplied for SingleUpdateStep)
I1111 00:57:10.480986  2593 solver.cpp:310]     Train net output #0: loss = 0.408021 (* 1 = 0.408021 loss)
I1111 00:57:10.481009  2593 sgd_solver.cpp:106] Iteration 4082, lr = 0.00025
I1111 00:57:12.663168  2593 solver.cpp:295] Iteration 4083 (no loss supplied for SingleUpdateStep)
I1111 00:57:12.663305  2593 solver.cpp:310]     Train net output #0: loss = 0.366865 (* 1 = 0.366865 loss)
I1111 00:57:12.663327  2593 sgd_solver.cpp:106] Iteration 4083, lr = 0.00025
I1111 00:57:15.051741  2593 solver.cpp:295] Iteration 4084 (no loss supplied for SingleUpdateStep)
I1111 00:57:15.051841  2593 solver.cpp:310]     Train net output #0: loss = 0.374671 (* 1 = 0.374671 loss)
I1111 00:57:15.051862  2593 sgd_solver.cpp:106] Iteration 4084, lr = 0.00025
I1111 00:57:17.350657  2593 solver.cpp:295] Iteration 4085 (no loss supplied for SingleUpdateStep)
I1111 00:57:17.350769  2593 solver.cpp:310]     Train net output #0: loss = 0.393202 (* 1 = 0.393202 loss)
I1111 00:57:17.350790  2593 sgd_solver.cpp:106] Iteration 4085, lr = 0.00025
I1111 00:57:19.697105  2593 solver.cpp:295] Iteration 4086 (no loss supplied for SingleUpdateStep)
I1111 00:57:19.697222  2593 solver.cpp:310]     Train net output #0: loss = 0.368086 (* 1 = 0.368086 loss)
I1111 00:57:19.697245  2593 sgd_solver.cpp:106] Iteration 4086, lr = 0.00025
I1111 00:57:22.074178  2593 solver.cpp:295] Iteration 4087 (no loss supplied for SingleUpdateStep)
I1111 00:57:22.074290  2593 solver.cpp:310]     Train net output #0: loss = 0.400902 (* 1 = 0.400902 loss)
I1111 00:57:22.074312  2593 sgd_solver.cpp:106] Iteration 4087, lr = 0.00025
I1111 00:57:24.886670  2593 solver.cpp:295] Iteration 4088 (no loss supplied for SingleUpdateStep)
I1111 00:57:24.886759  2593 solver.cpp:310]     Train net output #0: loss = 0.371803 (* 1 = 0.371803 loss)
I1111 00:57:24.886780  2593 sgd_solver.cpp:106] Iteration 4088, lr = 0.00025
I1111 00:57:28.411830  2593 solver.cpp:295] Iteration 4089 (no loss supplied for SingleUpdateStep)
I1111 00:57:28.411963  2593 solver.cpp:310]     Train net output #0: loss = 0.359412 (* 1 = 0.359412 loss)
I1111 00:57:28.411988  2593 sgd_solver.cpp:106] Iteration 4089, lr = 0.00025
I1111 00:57:31.917834  2593 solver.cpp:295] Iteration 4090 (no loss supplied for SingleUpdateStep)
I1111 00:57:31.917915  2593 solver.cpp:310]     Train net output #0: loss = 0.388487 (* 1 = 0.388487 loss)
I1111 00:57:31.917937  2593 sgd_solver.cpp:106] Iteration 4090, lr = 0.00025
I1111 00:57:34.915523  2593 solver.cpp:295] Iteration 4091 (no loss supplied for SingleUpdateStep)
I1111 00:57:34.915650  2593 solver.cpp:310]     Train net output #0: loss = 0.362047 (* 1 = 0.362047 loss)
I1111 00:57:34.915678  2593 sgd_solver.cpp:106] Iteration 4091, lr = 0.00025
I1111 00:57:37.168308  2593 solver.cpp:295] Iteration 4092 (no loss supplied for SingleUpdateStep)
I1111 00:57:37.168387  2593 solver.cpp:310]     Train net output #0: loss = 0.389325 (* 1 = 0.389325 loss)
I1111 00:57:37.168408  2593 sgd_solver.cpp:106] Iteration 4092, lr = 0.00025
I1111 00:57:39.400357  2593 solver.cpp:295] Iteration 4093 (no loss supplied for SingleUpdateStep)
I1111 00:57:39.400490  2593 solver.cpp:310]     Train net output #0: loss = 0.358272 (* 1 = 0.358272 loss)
I1111 00:57:39.400519  2593 sgd_solver.cpp:106] Iteration 4093, lr = 0.00025
I1111 00:57:41.755230  2593 solver.cpp:295] Iteration 4094 (no loss supplied for SingleUpdateStep)
I1111 00:57:41.755349  2593 solver.cpp:310]     Train net output #0: loss = 0.388862 (* 1 = 0.388862 loss)
I1111 00:57:41.755373  2593 sgd_solver.cpp:106] Iteration 4094, lr = 0.00025
I1111 00:57:44.033735  2593 solver.cpp:295] Iteration 4095 (no loss supplied for SingleUpdateStep)
I1111 00:57:44.033823  2593 solver.cpp:310]     Train net output #0: loss = 0.369406 (* 1 = 0.369406 loss)
I1111 00:57:44.033845  2593 sgd_solver.cpp:106] Iteration 4095, lr = 0.00025
I1111 00:57:46.547463  2593 solver.cpp:295] Iteration 4096 (no loss supplied for SingleUpdateStep)
I1111 00:57:46.547667  2593 solver.cpp:310]     Train net output #0: loss = 0.37239 (* 1 = 0.37239 loss)
I1111 00:57:46.547703  2593 sgd_solver.cpp:106] Iteration 4096, lr = 0.00025
I1111 00:57:48.891432  2593 solver.cpp:295] Iteration 4097 (no loss supplied for SingleUpdateStep)
I1111 00:57:48.891516  2593 solver.cpp:310]     Train net output #0: loss = 0.396656 (* 1 = 0.396656 loss)
I1111 00:57:48.891536  2593 sgd_solver.cpp:106] Iteration 4097, lr = 0.00025
I1111 00:57:51.461113  2593 solver.cpp:295] Iteration 4098 (no loss supplied for SingleUpdateStep)
I1111 00:57:51.461206  2593 solver.cpp:310]     Train net output #0: loss = 0.395268 (* 1 = 0.395268 loss)
I1111 00:57:51.461227  2593 sgd_solver.cpp:106] Iteration 4098, lr = 0.00025
I1111 00:57:53.698956  2593 solver.cpp:295] Iteration 4099 (no loss supplied for SingleUpdateStep)
I1111 00:57:53.699015  2593 solver.cpp:310]     Train net output #0: loss = 0.386147 (* 1 = 0.386147 loss)
I1111 00:57:53.699035  2593 sgd_solver.cpp:106] Iteration 4099, lr = 0.00025
I1111 00:57:55.981248  2593 solver.cpp:295] Iteration 4100 (no loss supplied for SingleUpdateStep)
I1111 00:57:55.981307  2593 solver.cpp:310]     Train net output #0: loss = 0.358665 (* 1 = 0.358665 loss)
I1111 00:57:55.981325  2593 sgd_solver.cpp:106] Iteration 4100, lr = 0.00025
I1111 00:57:59.002012  2593 solver.cpp:295] Iteration 4101 (no loss supplied for SingleUpdateStep)
I1111 00:57:59.002158  2593 solver.cpp:310]     Train net output #0: loss = 0.357732 (* 1 = 0.357732 loss)
I1111 00:57:59.002182  2593 sgd_solver.cpp:106] Iteration 4101, lr = 0.00025
I1111 00:58:01.560570  2593 solver.cpp:295] Iteration 4102 (no loss supplied for SingleUpdateStep)
I1111 00:58:01.560643  2593 solver.cpp:310]     Train net output #0: loss = 0.372546 (* 1 = 0.372546 loss)
I1111 00:58:01.560662  2593 sgd_solver.cpp:106] Iteration 4102, lr = 0.00025
I1111 00:58:04.168265  2593 solver.cpp:295] Iteration 4103 (no loss supplied for SingleUpdateStep)
I1111 00:58:04.168401  2593 solver.cpp:310]     Train net output #0: loss = 0.369546 (* 1 = 0.369546 loss)
I1111 00:58:04.168428  2593 sgd_solver.cpp:106] Iteration 4103, lr = 0.00025
I1111 00:58:08.566273  2593 solver.cpp:295] Iteration 4104 (no loss supplied for SingleUpdateStep)
I1111 00:58:08.566390  2593 solver.cpp:310]     Train net output #0: loss = 0.39078 (* 1 = 0.39078 loss)
I1111 00:58:08.566411  2593 sgd_solver.cpp:106] Iteration 4104, lr = 0.00025
I1111 00:58:11.781311  2593 solver.cpp:295] Iteration 4105 (no loss supplied for SingleUpdateStep)
I1111 00:58:11.781429  2593 solver.cpp:310]     Train net output #0: loss = 0.36535 (* 1 = 0.36535 loss)
I1111 00:58:11.781450  2593 sgd_solver.cpp:106] Iteration 4105, lr = 0.00025
I1111 00:58:15.009853  2593 solver.cpp:295] Iteration 4106 (no loss supplied for SingleUpdateStep)
I1111 00:58:15.009968  2593 solver.cpp:310]     Train net output #0: loss = 0.403791 (* 1 = 0.403791 loss)
I1111 00:58:15.009987  2593 sgd_solver.cpp:106] Iteration 4106, lr = 0.00025
I1111 00:58:18.636049  2593 solver.cpp:295] Iteration 4107 (no loss supplied for SingleUpdateStep)
I1111 00:58:18.636173  2593 solver.cpp:310]     Train net output #0: loss = 0.386101 (* 1 = 0.386101 loss)
I1111 00:58:18.636194  2593 sgd_solver.cpp:106] Iteration 4107, lr = 0.00025
I1111 00:58:21.716627  2593 solver.cpp:295] Iteration 4108 (no loss supplied for SingleUpdateStep)
I1111 00:58:21.716738  2593 solver.cpp:310]     Train net output #0: loss = 0.376806 (* 1 = 0.376806 loss)
I1111 00:58:21.716759  2593 sgd_solver.cpp:106] Iteration 4108, lr = 0.00025
I1111 00:58:24.715787  2593 solver.cpp:295] Iteration 4109 (no loss supplied for SingleUpdateStep)
I1111 00:58:24.715909  2593 solver.cpp:310]     Train net output #0: loss = 0.382591 (* 1 = 0.382591 loss)
I1111 00:58:24.715934  2593 sgd_solver.cpp:106] Iteration 4109, lr = 0.00025
I1111 00:58:27.739986  2593 solver.cpp:295] Iteration 4110 (no loss supplied for SingleUpdateStep)
I1111 00:58:27.740062  2593 solver.cpp:310]     Train net output #0: loss = 0.383489 (* 1 = 0.383489 loss)
I1111 00:58:27.740083  2593 sgd_solver.cpp:106] Iteration 4110, lr = 0.00025
I1111 00:58:30.482556  2593 solver.cpp:295] Iteration 4111 (no loss supplied for SingleUpdateStep)
I1111 00:58:30.482664  2593 solver.cpp:310]     Train net output #0: loss = 0.390852 (* 1 = 0.390852 loss)
I1111 00:58:30.482692  2593 sgd_solver.cpp:106] Iteration 4111, lr = 0.00025
I1111 00:58:33.341714  2593 solver.cpp:295] Iteration 4112 (no loss supplied for SingleUpdateStep)
I1111 00:58:33.341799  2593 solver.cpp:310]     Train net output #0: loss = 0.370635 (* 1 = 0.370635 loss)
I1111 00:58:33.341821  2593 sgd_solver.cpp:106] Iteration 4112, lr = 0.00025
I1111 00:58:35.712160  2593 solver.cpp:295] Iteration 4113 (no loss supplied for SingleUpdateStep)
I1111 00:58:35.712229  2593 solver.cpp:310]     Train net output #0: loss = 0.40238 (* 1 = 0.40238 loss)
I1111 00:58:35.712249  2593 sgd_solver.cpp:106] Iteration 4113, lr = 0.00025
I1111 00:58:38.271260  2593 solver.cpp:295] Iteration 4114 (no loss supplied for SingleUpdateStep)
I1111 00:58:38.271373  2593 solver.cpp:310]     Train net output #0: loss = 0.36366 (* 1 = 0.36366 loss)
I1111 00:58:38.271397  2593 sgd_solver.cpp:106] Iteration 4114, lr = 0.00025
I1111 00:58:40.877254  2593 solver.cpp:295] Iteration 4115 (no loss supplied for SingleUpdateStep)
I1111 00:58:40.877363  2593 solver.cpp:310]     Train net output #0: loss = 0.40105 (* 1 = 0.40105 loss)
I1111 00:58:40.877382  2593 sgd_solver.cpp:106] Iteration 4115, lr = 0.00025
I1111 00:58:43.444293  2593 solver.cpp:295] Iteration 4116 (no loss supplied for SingleUpdateStep)
I1111 00:58:43.444427  2593 solver.cpp:310]     Train net output #0: loss = 0.378182 (* 1 = 0.378182 loss)
I1111 00:58:43.444449  2593 sgd_solver.cpp:106] Iteration 4116, lr = 0.00025
I1111 00:58:45.995950  2593 solver.cpp:295] Iteration 4117 (no loss supplied for SingleUpdateStep)
I1111 00:58:45.996009  2593 solver.cpp:310]     Train net output #0: loss = 0.396084 (* 1 = 0.396084 loss)
I1111 00:58:45.996028  2593 sgd_solver.cpp:106] Iteration 4117, lr = 0.00025
I1111 00:58:48.411298  2593 solver.cpp:295] Iteration 4118 (no loss supplied for SingleUpdateStep)
I1111 00:58:48.411397  2593 solver.cpp:310]     Train net output #0: loss = 0.378532 (* 1 = 0.378532 loss)
I1111 00:58:48.411417  2593 sgd_solver.cpp:106] Iteration 4118, lr = 0.00025
I1111 00:58:50.858229  2593 solver.cpp:295] Iteration 4119 (no loss supplied for SingleUpdateStep)
I1111 00:58:50.858333  2593 solver.cpp:310]     Train net output #0: loss = 0.381361 (* 1 = 0.381361 loss)
I1111 00:58:50.858355  2593 sgd_solver.cpp:106] Iteration 4119, lr = 0.00025
I1111 00:58:53.716809  2593 solver.cpp:295] Iteration 4120 (no loss supplied for SingleUpdateStep)
I1111 00:58:53.716987  2593 solver.cpp:310]     Train net output #0: loss = 0.35793 (* 1 = 0.35793 loss)
I1111 00:58:53.717020  2593 sgd_solver.cpp:106] Iteration 4120, lr = 0.00025
I1111 00:58:55.913828  2593 solver.cpp:295] Iteration 4121 (no loss supplied for SingleUpdateStep)
I1111 00:58:55.913938  2593 solver.cpp:310]     Train net output #0: loss = 0.398787 (* 1 = 0.398787 loss)
I1111 00:58:55.913960  2593 sgd_solver.cpp:106] Iteration 4121, lr = 0.00025
I1111 00:58:58.272534  2593 solver.cpp:295] Iteration 4122 (no loss supplied for SingleUpdateStep)
I1111 00:58:58.272650  2593 solver.cpp:310]     Train net output #0: loss = 0.37143 (* 1 = 0.37143 loss)
I1111 00:58:58.272672  2593 sgd_solver.cpp:106] Iteration 4122, lr = 0.00025
I1111 00:59:00.670801  2593 solver.cpp:295] Iteration 4123 (no loss supplied for SingleUpdateStep)
I1111 00:59:00.670923  2593 solver.cpp:310]     Train net output #0: loss = 0.367901 (* 1 = 0.367901 loss)
I1111 00:59:00.670948  2593 sgd_solver.cpp:106] Iteration 4123, lr = 0.00025
I1111 00:59:03.048048  2593 solver.cpp:295] Iteration 4124 (no loss supplied for SingleUpdateStep)
I1111 00:59:03.048131  2593 solver.cpp:310]     Train net output #0: loss = 0.385508 (* 1 = 0.385508 loss)
I1111 00:59:03.048153  2593 sgd_solver.cpp:106] Iteration 4124, lr = 0.00025
I1111 00:59:05.601331  2593 solver.cpp:295] Iteration 4125 (no loss supplied for SingleUpdateStep)
I1111 00:59:05.601501  2593 solver.cpp:310]     Train net output #0: loss = 0.393431 (* 1 = 0.393431 loss)
I1111 00:59:05.601528  2593 sgd_solver.cpp:106] Iteration 4125, lr = 0.00025
I1111 00:59:07.711815  2593 solver.cpp:295] Iteration 4126 (no loss supplied for SingleUpdateStep)
I1111 00:59:07.711904  2593 solver.cpp:310]     Train net output #0: loss = 0.391686 (* 1 = 0.391686 loss)
I1111 00:59:07.711923  2593 sgd_solver.cpp:106] Iteration 4126, lr = 0.00025
I1111 00:59:10.279830  2593 solver.cpp:295] Iteration 4127 (no loss supplied for SingleUpdateStep)
I1111 00:59:10.279999  2593 solver.cpp:310]     Train net output #0: loss = 0.419946 (* 1 = 0.419946 loss)
I1111 00:59:10.280021  2593 sgd_solver.cpp:106] Iteration 4127, lr = 0.00025
I1111 00:59:12.753376  2593 solver.cpp:295] Iteration 4128 (no loss supplied for SingleUpdateStep)
I1111 00:59:12.753468  2593 solver.cpp:310]     Train net output #0: loss = 0.398967 (* 1 = 0.398967 loss)
I1111 00:59:12.753501  2593 sgd_solver.cpp:106] Iteration 4128, lr = 0.00025
I1111 00:59:15.094665  2593 solver.cpp:295] Iteration 4129 (no loss supplied for SingleUpdateStep)
I1111 00:59:15.094781  2593 solver.cpp:310]     Train net output #0: loss = 0.370235 (* 1 = 0.370235 loss)
I1111 00:59:15.094805  2593 sgd_solver.cpp:106] Iteration 4129, lr = 0.00025
I1111 00:59:17.588120  2593 solver.cpp:295] Iteration 4130 (no loss supplied for SingleUpdateStep)
I1111 00:59:17.588290  2593 solver.cpp:310]     Train net output #0: loss = 0.374443 (* 1 = 0.374443 loss)
I1111 00:59:17.588327  2593 sgd_solver.cpp:106] Iteration 4130, lr = 0.00025
I1111 00:59:19.993016  2593 solver.cpp:295] Iteration 4131 (no loss supplied for SingleUpdateStep)
I1111 00:59:19.993160  2593 solver.cpp:310]     Train net output #0: loss = 0.390125 (* 1 = 0.390125 loss)
I1111 00:59:19.993194  2593 sgd_solver.cpp:106] Iteration 4131, lr = 0.00025
I1111 00:59:22.359179  2593 solver.cpp:295] Iteration 4132 (no loss supplied for SingleUpdateStep)
I1111 00:59:22.359308  2593 solver.cpp:310]     Train net output #0: loss = 0.373452 (* 1 = 0.373452 loss)
I1111 00:59:22.359329  2593 sgd_solver.cpp:106] Iteration 4132, lr = 0.00025
I1111 00:59:25.085796  2593 solver.cpp:295] Iteration 4133 (no loss supplied for SingleUpdateStep)
I1111 00:59:25.085997  2593 solver.cpp:310]     Train net output #0: loss = 0.370267 (* 1 = 0.370267 loss)
I1111 00:59:25.086037  2593 sgd_solver.cpp:106] Iteration 4133, lr = 0.00025
I1111 00:59:27.665472  2593 solver.cpp:295] Iteration 4134 (no loss supplied for SingleUpdateStep)
I1111 00:59:27.665601  2593 solver.cpp:310]     Train net output #0: loss = 0.375442 (* 1 = 0.375442 loss)
I1111 00:59:27.665627  2593 sgd_solver.cpp:106] Iteration 4134, lr = 0.00025
I1111 00:59:30.062959  2593 solver.cpp:295] Iteration 4135 (no loss supplied for SingleUpdateStep)
I1111 00:59:30.063026  2593 solver.cpp:310]     Train net output #0: loss = 0.359815 (* 1 = 0.359815 loss)
I1111 00:59:30.063046  2593 sgd_solver.cpp:106] Iteration 4135, lr = 0.00025
I1111 00:59:32.230036  2593 solver.cpp:295] Iteration 4136 (no loss supplied for SingleUpdateStep)
I1111 00:59:32.230150  2593 solver.cpp:310]     Train net output #0: loss = 0.385176 (* 1 = 0.385176 loss)
I1111 00:59:32.230176  2593 sgd_solver.cpp:106] Iteration 4136, lr = 0.00025
I1111 00:59:34.690044  2593 solver.cpp:295] Iteration 4137 (no loss supplied for SingleUpdateStep)
I1111 00:59:34.690196  2593 solver.cpp:310]     Train net output #0: loss = 0.369164 (* 1 = 0.369164 loss)
I1111 00:59:34.690218  2593 sgd_solver.cpp:106] Iteration 4137, lr = 0.00025
I1111 00:59:37.386941  2593 solver.cpp:295] Iteration 4138 (no loss supplied for SingleUpdateStep)
I1111 00:59:37.387028  2593 solver.cpp:310]     Train net output #0: loss = 0.387811 (* 1 = 0.387811 loss)
I1111 00:59:37.387050  2593 sgd_solver.cpp:106] Iteration 4138, lr = 0.00025
I1111 00:59:40.110827  2593 solver.cpp:295] Iteration 4139 (no loss supplied for SingleUpdateStep)
I1111 00:59:40.110926  2593 solver.cpp:310]     Train net output #0: loss = 0.387317 (* 1 = 0.387317 loss)
I1111 00:59:40.110947  2593 sgd_solver.cpp:106] Iteration 4139, lr = 0.00025
I1111 00:59:42.736477  2593 solver.cpp:295] Iteration 4140 (no loss supplied for SingleUpdateStep)
I1111 00:59:42.736620  2593 solver.cpp:310]     Train net output #0: loss = 0.380558 (* 1 = 0.380558 loss)
I1111 00:59:42.736644  2593 sgd_solver.cpp:106] Iteration 4140, lr = 0.00025
I1111 00:59:44.916321  2593 solver.cpp:295] Iteration 4141 (no loss supplied for SingleUpdateStep)
I1111 00:59:44.916438  2593 solver.cpp:310]     Train net output #0: loss = 0.416384 (* 1 = 0.416384 loss)
I1111 00:59:44.916460  2593 sgd_solver.cpp:106] Iteration 4141, lr = 0.00025
I1111 00:59:47.270407  2593 solver.cpp:295] Iteration 4142 (no loss supplied for SingleUpdateStep)
I1111 00:59:47.270580  2593 solver.cpp:310]     Train net output #0: loss = 0.363956 (* 1 = 0.363956 loss)
I1111 00:59:47.270608  2593 sgd_solver.cpp:106] Iteration 4142, lr = 0.00025
I1111 00:59:49.601928  2593 solver.cpp:295] Iteration 4143 (no loss supplied for SingleUpdateStep)
I1111 00:59:49.601989  2593 solver.cpp:310]     Train net output #0: loss = 0.393704 (* 1 = 0.393704 loss)
I1111 00:59:49.602010  2593 sgd_solver.cpp:106] Iteration 4143, lr = 0.00025
I1111 00:59:51.896567  2593 solver.cpp:295] Iteration 4144 (no loss supplied for SingleUpdateStep)
I1111 00:59:51.896620  2593 solver.cpp:310]     Train net output #0: loss = 0.370981 (* 1 = 0.370981 loss)
I1111 00:59:51.896638  2593 sgd_solver.cpp:106] Iteration 4144, lr = 0.00025
I1111 00:59:54.377897  2593 solver.cpp:295] Iteration 4145 (no loss supplied for SingleUpdateStep)
I1111 00:59:54.378010  2593 solver.cpp:310]     Train net output #0: loss = 0.396032 (* 1 = 0.396032 loss)
I1111 00:59:54.378033  2593 sgd_solver.cpp:106] Iteration 4145, lr = 0.00025
I1111 00:59:56.695021  2593 solver.cpp:295] Iteration 4146 (no loss supplied for SingleUpdateStep)
I1111 00:59:56.695139  2593 solver.cpp:310]     Train net output #0: loss = 0.38798 (* 1 = 0.38798 loss)
I1111 00:59:56.695163  2593 sgd_solver.cpp:106] Iteration 4146, lr = 0.00025
I1111 00:59:59.078320  2593 solver.cpp:295] Iteration 4147 (no loss supplied for SingleUpdateStep)
I1111 00:59:59.078426  2593 solver.cpp:310]     Train net output #0: loss = 0.370874 (* 1 = 0.370874 loss)
I1111 00:59:59.078447  2593 sgd_solver.cpp:106] Iteration 4147, lr = 0.00025
I1111 01:00:01.484820  2593 solver.cpp:295] Iteration 4148 (no loss supplied for SingleUpdateStep)
I1111 01:00:01.484927  2593 solver.cpp:310]     Train net output #0: loss = 0.396854 (* 1 = 0.396854 loss)
I1111 01:00:01.484949  2593 sgd_solver.cpp:106] Iteration 4148, lr = 0.00025
I1111 01:00:03.876785  2593 solver.cpp:295] Iteration 4149 (no loss supplied for SingleUpdateStep)
I1111 01:00:03.876895  2593 solver.cpp:310]     Train net output #0: loss = 0.374166 (* 1 = 0.374166 loss)
I1111 01:00:03.876919  2593 sgd_solver.cpp:106] Iteration 4149, lr = 0.00025
I1111 01:00:06.374661  2593 solver.cpp:295] Iteration 4150 (no loss supplied for SingleUpdateStep)
I1111 01:00:06.374769  2593 solver.cpp:310]     Train net output #0: loss = 0.40248 (* 1 = 0.40248 loss)
I1111 01:00:06.374793  2593 sgd_solver.cpp:106] Iteration 4150, lr = 0.00025
I1111 01:00:08.847250  2593 solver.cpp:295] Iteration 4151 (no loss supplied for SingleUpdateStep)
I1111 01:00:08.847384  2593 solver.cpp:310]     Train net output #0: loss = 0.373587 (* 1 = 0.373587 loss)
I1111 01:00:08.847411  2593 sgd_solver.cpp:106] Iteration 4151, lr = 0.00025
I1111 01:00:11.090998  2593 solver.cpp:295] Iteration 4152 (no loss supplied for SingleUpdateStep)
I1111 01:00:11.091135  2593 solver.cpp:310]     Train net output #0: loss = 0.375759 (* 1 = 0.375759 loss)
I1111 01:00:11.091159  2593 sgd_solver.cpp:106] Iteration 4152, lr = 0.00025
I1111 01:00:13.459812  2593 solver.cpp:295] Iteration 4153 (no loss supplied for SingleUpdateStep)
I1111 01:00:13.459866  2593 solver.cpp:310]     Train net output #0: loss = 0.375315 (* 1 = 0.375315 loss)
I1111 01:00:13.459883  2593 sgd_solver.cpp:106] Iteration 4153, lr = 0.00025
I1111 01:00:15.782646  2593 solver.cpp:295] Iteration 4154 (no loss supplied for SingleUpdateStep)
I1111 01:00:15.782744  2593 solver.cpp:310]     Train net output #0: loss = 0.402728 (* 1 = 0.402728 loss)
I1111 01:00:15.782765  2593 sgd_solver.cpp:106] Iteration 4154, lr = 0.00025
I1111 01:00:18.021667  2593 solver.cpp:295] Iteration 4155 (no loss supplied for SingleUpdateStep)
I1111 01:00:18.021790  2593 solver.cpp:310]     Train net output #0: loss = 0.410541 (* 1 = 0.410541 loss)
I1111 01:00:18.021811  2593 sgd_solver.cpp:106] Iteration 4155, lr = 0.00025
I1111 01:00:20.290479  2593 solver.cpp:295] Iteration 4156 (no loss supplied for SingleUpdateStep)
I1111 01:00:20.290563  2593 solver.cpp:310]     Train net output #0: loss = 0.358013 (* 1 = 0.358013 loss)
I1111 01:00:20.290596  2593 sgd_solver.cpp:106] Iteration 4156, lr = 0.00025
I1111 01:00:22.542927  2593 solver.cpp:295] Iteration 4157 (no loss supplied for SingleUpdateStep)
I1111 01:00:22.543020  2593 solver.cpp:310]     Train net output #0: loss = 0.383037 (* 1 = 0.383037 loss)
I1111 01:00:22.543042  2593 sgd_solver.cpp:106] Iteration 4157, lr = 0.00025
I1111 01:00:24.796958  2593 solver.cpp:295] Iteration 4158 (no loss supplied for SingleUpdateStep)
I1111 01:00:24.797045  2593 solver.cpp:310]     Train net output #0: loss = 0.381876 (* 1 = 0.381876 loss)
I1111 01:00:24.797070  2593 sgd_solver.cpp:106] Iteration 4158, lr = 0.00025
I1111 01:00:27.526384  2593 solver.cpp:295] Iteration 4159 (no loss supplied for SingleUpdateStep)
I1111 01:00:27.526540  2593 solver.cpp:310]     Train net output #0: loss = 0.354239 (* 1 = 0.354239 loss)
I1111 01:00:27.526571  2593 sgd_solver.cpp:106] Iteration 4159, lr = 0.00025
I1111 01:00:29.846325  2593 solver.cpp:295] Iteration 4160 (no loss supplied for SingleUpdateStep)
I1111 01:00:29.846436  2593 solver.cpp:310]     Train net output #0: loss = 0.379514 (* 1 = 0.379514 loss)
I1111 01:00:29.846460  2593 sgd_solver.cpp:106] Iteration 4160, lr = 0.00025
I1111 01:00:32.181921  2593 solver.cpp:295] Iteration 4161 (no loss supplied for SingleUpdateStep)
I1111 01:00:32.181978  2593 solver.cpp:310]     Train net output #0: loss = 0.398232 (* 1 = 0.398232 loss)
I1111 01:00:32.181996  2593 sgd_solver.cpp:106] Iteration 4161, lr = 0.00025
I1111 01:00:34.532553  2593 solver.cpp:295] Iteration 4162 (no loss supplied for SingleUpdateStep)
I1111 01:00:34.532651  2593 solver.cpp:310]     Train net output #0: loss = 0.391297 (* 1 = 0.391297 loss)
I1111 01:00:34.532675  2593 sgd_solver.cpp:106] Iteration 4162, lr = 0.00025
I1111 01:00:36.852712  2593 solver.cpp:295] Iteration 4163 (no loss supplied for SingleUpdateStep)
I1111 01:00:36.852820  2593 solver.cpp:310]     Train net output #0: loss = 0.398447 (* 1 = 0.398447 loss)
I1111 01:00:36.852844  2593 sgd_solver.cpp:106] Iteration 4163, lr = 0.00025
I1111 01:00:39.228438  2593 solver.cpp:295] Iteration 4164 (no loss supplied for SingleUpdateStep)
I1111 01:00:39.228552  2593 solver.cpp:310]     Train net output #0: loss = 0.382073 (* 1 = 0.382073 loss)
I1111 01:00:39.228579  2593 sgd_solver.cpp:106] Iteration 4164, lr = 0.00025
I1111 01:00:41.673686  2593 solver.cpp:295] Iteration 4165 (no loss supplied for SingleUpdateStep)
I1111 01:00:41.673760  2593 solver.cpp:310]     Train net output #0: loss = 0.390449 (* 1 = 0.390449 loss)
I1111 01:00:41.673782  2593 sgd_solver.cpp:106] Iteration 4165, lr = 0.00025
I1111 01:00:44.013412  2593 solver.cpp:295] Iteration 4166 (no loss supplied for SingleUpdateStep)
I1111 01:00:44.013541  2593 solver.cpp:310]     Train net output #0: loss = 0.378343 (* 1 = 0.378343 loss)
I1111 01:00:44.013566  2593 sgd_solver.cpp:106] Iteration 4166, lr = 0.00025
I1111 01:00:46.241750  2593 solver.cpp:295] Iteration 4167 (no loss supplied for SingleUpdateStep)
I1111 01:00:46.241858  2593 solver.cpp:310]     Train net output #0: loss = 0.365083 (* 1 = 0.365083 loss)
I1111 01:00:46.241883  2593 sgd_solver.cpp:106] Iteration 4167, lr = 0.00025
I1111 01:00:48.489287  2593 solver.cpp:295] Iteration 4168 (no loss supplied for SingleUpdateStep)
I1111 01:00:48.489398  2593 solver.cpp:310]     Train net output #0: loss = 0.372329 (* 1 = 0.372329 loss)
I1111 01:00:48.489439  2593 sgd_solver.cpp:106] Iteration 4168, lr = 0.00025
I1111 01:00:50.887446  2593 solver.cpp:295] Iteration 4169 (no loss supplied for SingleUpdateStep)
I1111 01:00:50.887543  2593 solver.cpp:310]     Train net output #0: loss = 0.382487 (* 1 = 0.382487 loss)
I1111 01:00:50.887568  2593 sgd_solver.cpp:106] Iteration 4169, lr = 0.00025
I1111 01:00:53.363777  2593 solver.cpp:295] Iteration 4170 (no loss supplied for SingleUpdateStep)
I1111 01:00:53.363888  2593 solver.cpp:310]     Train net output #0: loss = 0.356358 (* 1 = 0.356358 loss)
I1111 01:00:53.363909  2593 sgd_solver.cpp:106] Iteration 4170, lr = 0.00025
I1111 01:00:55.645895  2593 solver.cpp:295] Iteration 4171 (no loss supplied for SingleUpdateStep)
I1111 01:00:55.646013  2593 solver.cpp:310]     Train net output #0: loss = 0.392731 (* 1 = 0.392731 loss)
I1111 01:00:55.646037  2593 sgd_solver.cpp:106] Iteration 4171, lr = 0.00025
I1111 01:00:57.849545  2593 solver.cpp:295] Iteration 4172 (no loss supplied for SingleUpdateStep)
I1111 01:00:57.849635  2593 solver.cpp:310]     Train net output #0: loss = 0.37623 (* 1 = 0.37623 loss)
I1111 01:00:57.849656  2593 sgd_solver.cpp:106] Iteration 4172, lr = 0.00025
I1111 01:01:00.366585  2593 solver.cpp:295] Iteration 4173 (no loss supplied for SingleUpdateStep)
I1111 01:01:00.366646  2593 solver.cpp:310]     Train net output #0: loss = 0.381534 (* 1 = 0.381534 loss)
I1111 01:01:00.366664  2593 sgd_solver.cpp:106] Iteration 4173, lr = 0.00025
I1111 01:01:02.641618  2593 solver.cpp:295] Iteration 4174 (no loss supplied for SingleUpdateStep)
I1111 01:01:02.641683  2593 solver.cpp:310]     Train net output #0: loss = 0.373924 (* 1 = 0.373924 loss)
I1111 01:01:02.641703  2593 sgd_solver.cpp:106] Iteration 4174, lr = 0.00025
I1111 01:01:05.015138  2593 solver.cpp:295] Iteration 4175 (no loss supplied for SingleUpdateStep)
I1111 01:01:05.015270  2593 solver.cpp:310]     Train net output #0: loss = 0.378424 (* 1 = 0.378424 loss)
I1111 01:01:05.015293  2593 sgd_solver.cpp:106] Iteration 4175, lr = 0.00025
I1111 01:01:07.345262  2593 solver.cpp:295] Iteration 4176 (no loss supplied for SingleUpdateStep)
I1111 01:01:07.345388  2593 solver.cpp:310]     Train net output #0: loss = 0.380613 (* 1 = 0.380613 loss)
I1111 01:01:07.345414  2593 sgd_solver.cpp:106] Iteration 4176, lr = 0.00025
I1111 01:01:09.970093  2593 solver.cpp:295] Iteration 4177 (no loss supplied for SingleUpdateStep)
I1111 01:01:09.970247  2593 solver.cpp:310]     Train net output #0: loss = 0.385491 (* 1 = 0.385491 loss)
I1111 01:01:09.970270  2593 sgd_solver.cpp:106] Iteration 4177, lr = 0.00025
I1111 01:01:12.307842  2593 solver.cpp:295] Iteration 4178 (no loss supplied for SingleUpdateStep)
I1111 01:01:12.307936  2593 solver.cpp:310]     Train net output #0: loss = 0.395474 (* 1 = 0.395474 loss)
I1111 01:01:12.307961  2593 sgd_solver.cpp:106] Iteration 4178, lr = 0.00025
I1111 01:01:14.591656  2593 solver.cpp:295] Iteration 4179 (no loss supplied for SingleUpdateStep)
I1111 01:01:14.591765  2593 solver.cpp:310]     Train net output #0: loss = 0.365116 (* 1 = 0.365116 loss)
I1111 01:01:14.591789  2593 sgd_solver.cpp:106] Iteration 4179, lr = 0.00025
I1111 01:01:16.933977  2593 solver.cpp:295] Iteration 4180 (no loss supplied for SingleUpdateStep)
I1111 01:01:16.934062  2593 solver.cpp:310]     Train net output #0: loss = 0.358365 (* 1 = 0.358365 loss)
I1111 01:01:16.934085  2593 sgd_solver.cpp:106] Iteration 4180, lr = 0.00025
I1111 01:01:19.486331  2593 solver.cpp:295] Iteration 4181 (no loss supplied for SingleUpdateStep)
I1111 01:01:19.486451  2593 solver.cpp:310]     Train net output #0: loss = 0.392191 (* 1 = 0.392191 loss)
I1111 01:01:19.486474  2593 sgd_solver.cpp:106] Iteration 4181, lr = 0.00025
I1111 01:01:22.006724  2593 solver.cpp:295] Iteration 4182 (no loss supplied for SingleUpdateStep)
I1111 01:01:22.006840  2593 solver.cpp:310]     Train net output #0: loss = 0.378692 (* 1 = 0.378692 loss)
I1111 01:01:22.006862  2593 sgd_solver.cpp:106] Iteration 4182, lr = 0.00025
I1111 01:01:24.447504  2593 solver.cpp:295] Iteration 4183 (no loss supplied for SingleUpdateStep)
I1111 01:01:24.447561  2593 solver.cpp:310]     Train net output #0: loss = 0.379456 (* 1 = 0.379456 loss)
I1111 01:01:24.447578  2593 sgd_solver.cpp:106] Iteration 4183, lr = 0.00025
I1111 01:01:27.042129  2593 solver.cpp:295] Iteration 4184 (no loss supplied for SingleUpdateStep)
I1111 01:01:27.042273  2593 solver.cpp:310]     Train net output #0: loss = 0.375989 (* 1 = 0.375989 loss)
I1111 01:01:27.042297  2593 sgd_solver.cpp:106] Iteration 4184, lr = 0.00025
I1111 01:01:29.435449  2593 solver.cpp:295] Iteration 4185 (no loss supplied for SingleUpdateStep)
I1111 01:01:29.435544  2593 solver.cpp:310]     Train net output #0: loss = 0.379205 (* 1 = 0.379205 loss)
I1111 01:01:29.435566  2593 sgd_solver.cpp:106] Iteration 4185, lr = 0.00025
I1111 01:01:31.977690  2593 solver.cpp:295] Iteration 4186 (no loss supplied for SingleUpdateStep)
I1111 01:01:31.977803  2593 solver.cpp:310]     Train net output #0: loss = 0.389775 (* 1 = 0.389775 loss)
I1111 01:01:31.977828  2593 sgd_solver.cpp:106] Iteration 4186, lr = 0.00025
I1111 01:01:34.229823  2593 solver.cpp:295] Iteration 4187 (no loss supplied for SingleUpdateStep)
I1111 01:01:34.229905  2593 solver.cpp:310]     Train net output #0: loss = 0.366223 (* 1 = 0.366223 loss)
I1111 01:01:34.229926  2593 sgd_solver.cpp:106] Iteration 4187, lr = 0.00025
I1111 01:01:36.649083  2593 solver.cpp:295] Iteration 4188 (no loss supplied for SingleUpdateStep)
I1111 01:01:36.649201  2593 solver.cpp:310]     Train net output #0: loss = 0.374133 (* 1 = 0.374133 loss)
I1111 01:01:36.649224  2593 sgd_solver.cpp:106] Iteration 4188, lr = 0.00025
I1111 01:01:38.874284  2593 solver.cpp:295] Iteration 4189 (no loss supplied for SingleUpdateStep)
I1111 01:01:38.874416  2593 solver.cpp:310]     Train net output #0: loss = 0.384996 (* 1 = 0.384996 loss)
I1111 01:01:38.874444  2593 sgd_solver.cpp:106] Iteration 4189, lr = 0.00025
I1111 01:01:41.224038  2593 solver.cpp:295] Iteration 4190 (no loss supplied for SingleUpdateStep)
I1111 01:01:41.224100  2593 solver.cpp:310]     Train net output #0: loss = 0.370321 (* 1 = 0.370321 loss)
I1111 01:01:41.224119  2593 sgd_solver.cpp:106] Iteration 4190, lr = 0.00025
I1111 01:01:43.362512  2593 solver.cpp:295] Iteration 4191 (no loss supplied for SingleUpdateStep)
I1111 01:01:43.362572  2593 solver.cpp:310]     Train net output #0: loss = 0.364942 (* 1 = 0.364942 loss)
I1111 01:01:43.362591  2593 sgd_solver.cpp:106] Iteration 4191, lr = 0.00025
I1111 01:01:46.004276  2593 solver.cpp:295] Iteration 4192 (no loss supplied for SingleUpdateStep)
I1111 01:01:46.004379  2593 solver.cpp:310]     Train net output #0: loss = 0.358535 (* 1 = 0.358535 loss)
I1111 01:01:46.004401  2593 sgd_solver.cpp:106] Iteration 4192, lr = 0.00025
I1111 01:01:49.360357  2593 solver.cpp:295] Iteration 4193 (no loss supplied for SingleUpdateStep)
I1111 01:01:49.360450  2593 solver.cpp:310]     Train net output #0: loss = 0.413215 (* 1 = 0.413215 loss)
I1111 01:01:49.360471  2593 sgd_solver.cpp:106] Iteration 4193, lr = 0.00025
I1111 01:01:52.518594  2593 solver.cpp:295] Iteration 4194 (no loss supplied for SingleUpdateStep)
I1111 01:01:52.518704  2593 solver.cpp:310]     Train net output #0: loss = 0.385193 (* 1 = 0.385193 loss)
I1111 01:01:52.518728  2593 sgd_solver.cpp:106] Iteration 4194, lr = 0.00025
I1111 01:01:55.518805  2593 solver.cpp:295] Iteration 4195 (no loss supplied for SingleUpdateStep)
I1111 01:01:55.518975  2593 solver.cpp:310]     Train net output #0: loss = 0.391679 (* 1 = 0.391679 loss)
I1111 01:01:55.519000  2593 sgd_solver.cpp:106] Iteration 4195, lr = 0.00025
I1111 01:01:58.075126  2593 solver.cpp:295] Iteration 4196 (no loss supplied for SingleUpdateStep)
I1111 01:01:58.075294  2593 solver.cpp:310]     Train net output #0: loss = 0.3789 (* 1 = 0.3789 loss)
I1111 01:01:58.075317  2593 sgd_solver.cpp:106] Iteration 4196, lr = 0.00025
I1111 01:02:00.573632  2593 solver.cpp:295] Iteration 4197 (no loss supplied for SingleUpdateStep)
I1111 01:02:00.573794  2593 solver.cpp:310]     Train net output #0: loss = 0.402356 (* 1 = 0.402356 loss)
I1111 01:02:00.573823  2593 sgd_solver.cpp:106] Iteration 4197, lr = 0.00025
I1111 01:02:02.831516  2593 solver.cpp:295] Iteration 4198 (no loss supplied for SingleUpdateStep)
I1111 01:02:02.831578  2593 solver.cpp:310]     Train net output #0: loss = 0.37084 (* 1 = 0.37084 loss)
I1111 01:02:02.831598  2593 sgd_solver.cpp:106] Iteration 4198, lr = 0.00025
I1111 01:02:05.343264  2593 solver.cpp:295] Iteration 4199 (no loss supplied for SingleUpdateStep)
I1111 01:02:05.343376  2593 solver.cpp:310]     Train net output #0: loss = 0.386138 (* 1 = 0.386138 loss)
I1111 01:02:05.343399  2593 sgd_solver.cpp:106] Iteration 4199, lr = 0.00025
I1111 01:02:08.009650  2593 solver.cpp:295] Iteration 4200 (no loss supplied for SingleUpdateStep)
I1111 01:02:08.009763  2593 solver.cpp:310]     Train net output #0: loss = 0.38131 (* 1 = 0.38131 loss)
I1111 01:02:08.009786  2593 sgd_solver.cpp:106] Iteration 4200, lr = 0.00025
I1111 01:02:10.237427  2593 solver.cpp:295] Iteration 4201 (no loss supplied for SingleUpdateStep)
I1111 01:02:10.237515  2593 solver.cpp:310]     Train net output #0: loss = 0.398601 (* 1 = 0.398601 loss)
I1111 01:02:10.237539  2593 sgd_solver.cpp:106] Iteration 4201, lr = 0.00025
I1111 01:02:12.813391  2593 solver.cpp:295] Iteration 4202 (no loss supplied for SingleUpdateStep)
I1111 01:02:12.813467  2593 solver.cpp:310]     Train net output #0: loss = 0.379437 (* 1 = 0.379437 loss)
I1111 01:02:12.813491  2593 sgd_solver.cpp:106] Iteration 4202, lr = 0.00025
I1111 01:02:15.493193  2593 solver.cpp:295] Iteration 4203 (no loss supplied for SingleUpdateStep)
I1111 01:02:15.493273  2593 solver.cpp:310]     Train net output #0: loss = 0.359654 (* 1 = 0.359654 loss)
I1111 01:02:15.493294  2593 sgd_solver.cpp:106] Iteration 4203, lr = 0.00025
I1111 01:02:19.592684  2593 solver.cpp:295] Iteration 4204 (no loss supplied for SingleUpdateStep)
I1111 01:02:19.592752  2593 solver.cpp:310]     Train net output #0: loss = 0.386901 (* 1 = 0.386901 loss)
I1111 01:02:19.592771  2593 sgd_solver.cpp:106] Iteration 4204, lr = 0.00025
I1111 01:02:22.884866  2593 solver.cpp:295] Iteration 4205 (no loss supplied for SingleUpdateStep)
I1111 01:02:22.885013  2593 solver.cpp:310]     Train net output #0: loss = 0.366571 (* 1 = 0.366571 loss)
I1111 01:02:22.885036  2593 sgd_solver.cpp:106] Iteration 4205, lr = 0.00025
I1111 01:02:26.917951  2593 solver.cpp:295] Iteration 4206 (no loss supplied for SingleUpdateStep)
I1111 01:02:26.918081  2593 solver.cpp:310]     Train net output #0: loss = 0.398993 (* 1 = 0.398993 loss)
I1111 01:02:26.918110  2593 sgd_solver.cpp:106] Iteration 4206, lr = 0.00025
I1111 01:02:30.087980  2593 solver.cpp:295] Iteration 4207 (no loss supplied for SingleUpdateStep)
I1111 01:02:30.088136  2593 solver.cpp:310]     Train net output #0: loss = 0.362195 (* 1 = 0.362195 loss)
I1111 01:02:30.088161  2593 sgd_solver.cpp:106] Iteration 4207, lr = 0.00025
I1111 01:02:32.822317  2593 solver.cpp:295] Iteration 4208 (no loss supplied for SingleUpdateStep)
I1111 01:02:32.822432  2593 solver.cpp:310]     Train net output #0: loss = 0.389052 (* 1 = 0.389052 loss)
I1111 01:02:32.822453  2593 sgd_solver.cpp:106] Iteration 4208, lr = 0.00025
I1111 01:02:35.497601  2593 solver.cpp:295] Iteration 4209 (no loss supplied for SingleUpdateStep)
I1111 01:02:35.497696  2593 solver.cpp:310]     Train net output #0: loss = 0.349399 (* 1 = 0.349399 loss)
I1111 01:02:35.497716  2593 sgd_solver.cpp:106] Iteration 4209, lr = 0.00025
I1111 01:02:38.056946  2593 solver.cpp:295] Iteration 4210 (no loss supplied for SingleUpdateStep)
I1111 01:02:38.057015  2593 solver.cpp:310]     Train net output #0: loss = 0.390804 (* 1 = 0.390804 loss)
I1111 01:02:38.057036  2593 sgd_solver.cpp:106] Iteration 4210, lr = 0.00025
I1111 01:02:40.969434  2593 solver.cpp:295] Iteration 4211 (no loss supplied for SingleUpdateStep)
I1111 01:02:40.969545  2593 solver.cpp:310]     Train net output #0: loss = 0.380745 (* 1 = 0.380745 loss)
I1111 01:02:40.969566  2593 sgd_solver.cpp:106] Iteration 4211, lr = 0.00025
I1111 01:02:43.868855  2593 solver.cpp:295] Iteration 4212 (no loss supplied for SingleUpdateStep)
I1111 01:02:43.869061  2593 solver.cpp:310]     Train net output #0: loss = 0.36693 (* 1 = 0.36693 loss)
I1111 01:02:43.869091  2593 sgd_solver.cpp:106] Iteration 4212, lr = 0.00025
I1111 01:02:47.114202  2593 solver.cpp:295] Iteration 4213 (no loss supplied for SingleUpdateStep)
I1111 01:02:47.114421  2593 solver.cpp:310]     Train net output #0: loss = 0.377676 (* 1 = 0.377676 loss)
I1111 01:02:47.114454  2593 sgd_solver.cpp:106] Iteration 4213, lr = 0.00025
I1111 01:02:49.871773  2593 solver.cpp:295] Iteration 4214 (no loss supplied for SingleUpdateStep)
I1111 01:02:49.871850  2593 solver.cpp:310]     Train net output #0: loss = 0.386456 (* 1 = 0.386456 loss)
I1111 01:02:49.871870  2593 sgd_solver.cpp:106] Iteration 4214, lr = 0.00025
I1111 01:02:52.491722  2593 solver.cpp:295] Iteration 4215 (no loss supplied for SingleUpdateStep)
I1111 01:02:52.491871  2593 solver.cpp:310]     Train net output #0: loss = 0.371482 (* 1 = 0.371482 loss)
I1111 01:02:52.491896  2593 sgd_solver.cpp:106] Iteration 4215, lr = 0.00025
I1111 01:02:55.174753  2593 solver.cpp:295] Iteration 4216 (no loss supplied for SingleUpdateStep)
I1111 01:02:55.174814  2593 solver.cpp:310]     Train net output #0: loss = 0.374941 (* 1 = 0.374941 loss)
I1111 01:02:55.174834  2593 sgd_solver.cpp:106] Iteration 4216, lr = 0.00025
I1111 01:02:57.811568  2593 solver.cpp:295] Iteration 4217 (no loss supplied for SingleUpdateStep)
I1111 01:02:57.811691  2593 solver.cpp:310]     Train net output #0: loss = 0.356275 (* 1 = 0.356275 loss)
I1111 01:02:57.811712  2593 sgd_solver.cpp:106] Iteration 4217, lr = 0.00025
I1111 01:03:00.863587  2593 solver.cpp:295] Iteration 4218 (no loss supplied for SingleUpdateStep)
I1111 01:03:00.863725  2593 solver.cpp:310]     Train net output #0: loss = 0.396725 (* 1 = 0.396725 loss)
I1111 01:03:00.863747  2593 sgd_solver.cpp:106] Iteration 4218, lr = 0.00025
I1111 01:03:03.279310  2593 solver.cpp:295] Iteration 4219 (no loss supplied for SingleUpdateStep)
I1111 01:03:03.279414  2593 solver.cpp:310]     Train net output #0: loss = 0.382867 (* 1 = 0.382867 loss)
I1111 01:03:03.279438  2593 sgd_solver.cpp:106] Iteration 4219, lr = 0.00025
I1111 01:03:05.651984  2593 solver.cpp:295] Iteration 4220 (no loss supplied for SingleUpdateStep)
I1111 01:03:05.652078  2593 solver.cpp:310]     Train net output #0: loss = 0.354943 (* 1 = 0.354943 loss)
I1111 01:03:05.652102  2593 sgd_solver.cpp:106] Iteration 4220, lr = 0.00025
I1111 01:03:07.971581  2593 solver.cpp:295] Iteration 4221 (no loss supplied for SingleUpdateStep)
I1111 01:03:07.971748  2593 solver.cpp:310]     Train net output #0: loss = 0.397978 (* 1 = 0.397978 loss)
I1111 01:03:07.971777  2593 sgd_solver.cpp:106] Iteration 4221, lr = 0.00025
I1111 01:03:10.249436  2593 solver.cpp:295] Iteration 4222 (no loss supplied for SingleUpdateStep)
I1111 01:03:10.249577  2593 solver.cpp:310]     Train net output #0: loss = 0.389498 (* 1 = 0.389498 loss)
I1111 01:03:10.249604  2593 sgd_solver.cpp:106] Iteration 4222, lr = 0.00025
I1111 01:03:12.522315  2593 solver.cpp:295] Iteration 4223 (no loss supplied for SingleUpdateStep)
I1111 01:03:12.522480  2593 solver.cpp:310]     Train net output #0: loss = 0.383643 (* 1 = 0.383643 loss)
I1111 01:03:12.522507  2593 sgd_solver.cpp:106] Iteration 4223, lr = 0.00025
I1111 01:03:14.852905  2593 solver.cpp:295] Iteration 4224 (no loss supplied for SingleUpdateStep)
I1111 01:03:14.853008  2593 solver.cpp:310]     Train net output #0: loss = 0.379156 (* 1 = 0.379156 loss)
I1111 01:03:14.853029  2593 sgd_solver.cpp:106] Iteration 4224, lr = 0.00025
I1111 01:03:17.789610  2593 solver.cpp:295] Iteration 4225 (no loss supplied for SingleUpdateStep)
I1111 01:03:17.789680  2593 solver.cpp:310]     Train net output #0: loss = 0.411878 (* 1 = 0.411878 loss)
I1111 01:03:17.789700  2593 sgd_solver.cpp:106] Iteration 4225, lr = 0.00025
I1111 01:03:21.159402  2593 solver.cpp:295] Iteration 4226 (no loss supplied for SingleUpdateStep)
I1111 01:03:21.159529  2593 solver.cpp:310]     Train net output #0: loss = 0.369266 (* 1 = 0.369266 loss)
I1111 01:03:21.159554  2593 sgd_solver.cpp:106] Iteration 4226, lr = 0.00025
I1111 01:03:25.029549  2593 solver.cpp:295] Iteration 4227 (no loss supplied for SingleUpdateStep)
I1111 01:03:25.029656  2593 solver.cpp:310]     Train net output #0: loss = 0.39693 (* 1 = 0.39693 loss)
I1111 01:03:25.029681  2593 sgd_solver.cpp:106] Iteration 4227, lr = 0.00025
I1111 01:03:28.498661  2593 solver.cpp:295] Iteration 4228 (no loss supplied for SingleUpdateStep)
I1111 01:03:28.498718  2593 solver.cpp:310]     Train net output #0: loss = 0.376532 (* 1 = 0.376532 loss)
I1111 01:03:28.498735  2593 sgd_solver.cpp:106] Iteration 4228, lr = 0.00025
I1111 01:03:32.154363  2593 solver.cpp:295] Iteration 4229 (no loss supplied for SingleUpdateStep)
I1111 01:03:32.154433  2593 solver.cpp:310]     Train net output #0: loss = 0.374437 (* 1 = 0.374437 loss)
I1111 01:03:32.154451  2593 sgd_solver.cpp:106] Iteration 4229, lr = 0.00025
I1111 01:03:34.535704  2593 solver.cpp:295] Iteration 4230 (no loss supplied for SingleUpdateStep)
I1111 01:03:34.535770  2593 solver.cpp:310]     Train net output #0: loss = 0.378155 (* 1 = 0.378155 loss)
I1111 01:03:34.535789  2593 sgd_solver.cpp:106] Iteration 4230, lr = 0.00025
I1111 01:03:37.076856  2593 solver.cpp:295] Iteration 4231 (no loss supplied for SingleUpdateStep)
I1111 01:03:37.076930  2593 solver.cpp:310]     Train net output #0: loss = 0.387201 (* 1 = 0.387201 loss)
I1111 01:03:37.076949  2593 sgd_solver.cpp:106] Iteration 4231, lr = 0.00025
I1111 01:03:39.409365  2593 solver.cpp:295] Iteration 4232 (no loss supplied for SingleUpdateStep)
I1111 01:03:39.409440  2593 solver.cpp:310]     Train net output #0: loss = 0.372029 (* 1 = 0.372029 loss)
I1111 01:03:39.409459  2593 sgd_solver.cpp:106] Iteration 4232, lr = 0.00025
I1111 01:03:41.592921  2593 solver.cpp:295] Iteration 4233 (no loss supplied for SingleUpdateStep)
I1111 01:03:41.593039  2593 solver.cpp:310]     Train net output #0: loss = 0.401637 (* 1 = 0.401637 loss)
I1111 01:03:41.593065  2593 sgd_solver.cpp:106] Iteration 4233, lr = 0.00025
I1111 01:03:43.785043  2593 solver.cpp:295] Iteration 4234 (no loss supplied for SingleUpdateStep)
I1111 01:03:43.785151  2593 solver.cpp:310]     Train net output #0: loss = 0.390622 (* 1 = 0.390622 loss)
I1111 01:03:43.785172  2593 sgd_solver.cpp:106] Iteration 4234, lr = 0.00025
I1111 01:03:46.186697  2593 solver.cpp:295] Iteration 4235 (no loss supplied for SingleUpdateStep)
I1111 01:03:46.186799  2593 solver.cpp:310]     Train net output #0: loss = 0.378573 (* 1 = 0.378573 loss)
I1111 01:03:46.186818  2593 sgd_solver.cpp:106] Iteration 4235, lr = 0.00025
I1111 01:03:48.434689  2593 solver.cpp:295] Iteration 4236 (no loss supplied for SingleUpdateStep)
I1111 01:03:48.434792  2593 solver.cpp:310]     Train net output #0: loss = 0.377557 (* 1 = 0.377557 loss)
I1111 01:03:48.434813  2593 sgd_solver.cpp:106] Iteration 4236, lr = 0.00025
I1111 01:03:50.726842  2593 solver.cpp:295] Iteration 4237 (no loss supplied for SingleUpdateStep)
I1111 01:03:50.726904  2593 solver.cpp:310]     Train net output #0: loss = 0.364002 (* 1 = 0.364002 loss)
I1111 01:03:50.726923  2593 sgd_solver.cpp:106] Iteration 4237, lr = 0.00025
I1111 01:03:52.934499  2593 solver.cpp:295] Iteration 4238 (no loss supplied for SingleUpdateStep)
I1111 01:03:52.934563  2593 solver.cpp:310]     Train net output #0: loss = 0.376757 (* 1 = 0.376757 loss)
I1111 01:03:52.934582  2593 sgd_solver.cpp:106] Iteration 4238, lr = 0.00025
I1111 01:03:55.042600  2593 solver.cpp:295] Iteration 4239 (no loss supplied for SingleUpdateStep)
I1111 01:03:55.042709  2593 solver.cpp:310]     Train net output #0: loss = 0.36523 (* 1 = 0.36523 loss)
I1111 01:03:55.042732  2593 sgd_solver.cpp:106] Iteration 4239, lr = 0.00025
I1111 01:03:57.332231  2593 solver.cpp:295] Iteration 4240 (no loss supplied for SingleUpdateStep)
I1111 01:03:57.332363  2593 solver.cpp:310]     Train net output #0: loss = 0.37955 (* 1 = 0.37955 loss)
I1111 01:03:57.332386  2593 sgd_solver.cpp:106] Iteration 4240, lr = 0.00025
I1111 01:03:59.579180  2593 solver.cpp:295] Iteration 4241 (no loss supplied for SingleUpdateStep)
I1111 01:03:59.579282  2593 solver.cpp:310]     Train net output #0: loss = 0.380531 (* 1 = 0.380531 loss)
I1111 01:03:59.579301  2593 sgd_solver.cpp:106] Iteration 4241, lr = 0.00025
I1111 01:04:01.850816  2593 solver.cpp:295] Iteration 4242 (no loss supplied for SingleUpdateStep)
I1111 01:04:01.850873  2593 solver.cpp:310]     Train net output #0: loss = 0.390411 (* 1 = 0.390411 loss)
I1111 01:04:01.850893  2593 sgd_solver.cpp:106] Iteration 4242, lr = 0.00025
I1111 01:04:04.102696  2593 solver.cpp:295] Iteration 4243 (no loss supplied for SingleUpdateStep)
I1111 01:04:04.102769  2593 solver.cpp:310]     Train net output #0: loss = 0.386274 (* 1 = 0.386274 loss)
I1111 01:04:04.102789  2593 sgd_solver.cpp:106] Iteration 4243, lr = 0.00025
I1111 01:04:06.510941  2593 solver.cpp:295] Iteration 4244 (no loss supplied for SingleUpdateStep)
I1111 01:04:06.510996  2593 solver.cpp:310]     Train net output #0: loss = 0.375914 (* 1 = 0.375914 loss)
I1111 01:04:06.511014  2593 sgd_solver.cpp:106] Iteration 4244, lr = 0.00025
I1111 01:04:08.943229  2593 solver.cpp:295] Iteration 4245 (no loss supplied for SingleUpdateStep)
I1111 01:04:08.943321  2593 solver.cpp:310]     Train net output #0: loss = 0.379286 (* 1 = 0.379286 loss)
I1111 01:04:08.943342  2593 sgd_solver.cpp:106] Iteration 4245, lr = 0.00025
I1111 01:04:11.194144  2593 solver.cpp:295] Iteration 4246 (no loss supplied for SingleUpdateStep)
I1111 01:04:11.194257  2593 solver.cpp:310]     Train net output #0: loss = 0.401208 (* 1 = 0.401208 loss)
I1111 01:04:11.194280  2593 sgd_solver.cpp:106] Iteration 4246, lr = 0.00025
I1111 01:04:13.687896  2593 solver.cpp:295] Iteration 4247 (no loss supplied for SingleUpdateStep)
I1111 01:04:13.688038  2593 solver.cpp:310]     Train net output #0: loss = 0.373855 (* 1 = 0.373855 loss)
I1111 01:04:13.688061  2593 sgd_solver.cpp:106] Iteration 4247, lr = 0.00025
I1111 01:04:16.021792  2593 solver.cpp:295] Iteration 4248 (no loss supplied for SingleUpdateStep)
I1111 01:04:16.021934  2593 solver.cpp:310]     Train net output #0: loss = 0.380322 (* 1 = 0.380322 loss)
I1111 01:04:16.021958  2593 sgd_solver.cpp:106] Iteration 4248, lr = 0.00025
I1111 01:04:18.188884  2593 solver.cpp:295] Iteration 4249 (no loss supplied for SingleUpdateStep)
I1111 01:04:18.188951  2593 solver.cpp:310]     Train net output #0: loss = 0.36273 (* 1 = 0.36273 loss)
I1111 01:04:18.188971  2593 sgd_solver.cpp:106] Iteration 4249, lr = 0.00025
I1111 01:04:20.488903  2593 solver.cpp:295] Iteration 4250 (no loss supplied for SingleUpdateStep)
I1111 01:04:20.488968  2593 solver.cpp:310]     Train net output #0: loss = 0.385103 (* 1 = 0.385103 loss)
I1111 01:04:20.488987  2593 sgd_solver.cpp:106] Iteration 4250, lr = 0.00025
I1111 01:04:22.795800  2593 solver.cpp:295] Iteration 4251 (no loss supplied for SingleUpdateStep)
I1111 01:04:22.795864  2593 solver.cpp:310]     Train net output #0: loss = 0.374357 (* 1 = 0.374357 loss)
I1111 01:04:22.795884  2593 sgd_solver.cpp:106] Iteration 4251, lr = 0.00025
I1111 01:04:24.969851  2593 solver.cpp:295] Iteration 4252 (no loss supplied for SingleUpdateStep)
I1111 01:04:24.969948  2593 solver.cpp:310]     Train net output #0: loss = 0.35866 (* 1 = 0.35866 loss)
I1111 01:04:24.969969  2593 sgd_solver.cpp:106] Iteration 4252, lr = 0.00025
I1111 01:04:27.208094  2593 solver.cpp:295] Iteration 4253 (no loss supplied for SingleUpdateStep)
I1111 01:04:27.208220  2593 solver.cpp:310]     Train net output #0: loss = 0.383392 (* 1 = 0.383392 loss)
I1111 01:04:27.208247  2593 sgd_solver.cpp:106] Iteration 4253, lr = 0.00025
I1111 01:04:29.817329  2593 solver.cpp:295] Iteration 4254 (no loss supplied for SingleUpdateStep)
I1111 01:04:29.817435  2593 solver.cpp:310]     Train net output #0: loss = 0.389619 (* 1 = 0.389619 loss)
I1111 01:04:29.817456  2593 sgd_solver.cpp:106] Iteration 4254, lr = 0.00025
I1111 01:04:32.394773  2593 solver.cpp:295] Iteration 4255 (no loss supplied for SingleUpdateStep)
I1111 01:04:32.394904  2593 solver.cpp:310]     Train net output #0: loss = 0.374089 (* 1 = 0.374089 loss)
I1111 01:04:32.394930  2593 sgd_solver.cpp:106] Iteration 4255, lr = 0.00025
I1111 01:04:34.959071  2593 solver.cpp:295] Iteration 4256 (no loss supplied for SingleUpdateStep)
I1111 01:04:34.959136  2593 solver.cpp:310]     Train net output #0: loss = 0.384684 (* 1 = 0.384684 loss)
I1111 01:04:34.959156  2593 sgd_solver.cpp:106] Iteration 4256, lr = 0.00025
I1111 01:04:37.636402  2593 solver.cpp:295] Iteration 4257 (no loss supplied for SingleUpdateStep)
I1111 01:04:37.636467  2593 solver.cpp:310]     Train net output #0: loss = 0.377205 (* 1 = 0.377205 loss)
I1111 01:04:37.636488  2593 sgd_solver.cpp:106] Iteration 4257, lr = 0.00025
I1111 01:04:39.905704  2593 solver.cpp:295] Iteration 4258 (no loss supplied for SingleUpdateStep)
I1111 01:04:39.905763  2593 solver.cpp:310]     Train net output #0: loss = 0.361158 (* 1 = 0.361158 loss)
I1111 01:04:39.905783  2593 sgd_solver.cpp:106] Iteration 4258, lr = 0.00025
I1111 01:04:42.232733  2593 solver.cpp:295] Iteration 4259 (no loss supplied for SingleUpdateStep)
I1111 01:04:42.232882  2593 solver.cpp:310]     Train net output #0: loss = 0.391706 (* 1 = 0.391706 loss)
I1111 01:04:42.232906  2593 sgd_solver.cpp:106] Iteration 4259, lr = 0.00025
I1111 01:04:45.310400  2593 solver.cpp:295] Iteration 4260 (no loss supplied for SingleUpdateStep)
I1111 01:04:45.310600  2593 solver.cpp:310]     Train net output #0: loss = 0.367355 (* 1 = 0.367355 loss)
I1111 01:04:45.310642  2593 sgd_solver.cpp:106] Iteration 4260, lr = 0.00025
I1111 01:04:47.805670  2593 solver.cpp:295] Iteration 4261 (no loss supplied for SingleUpdateStep)
I1111 01:04:47.805801  2593 solver.cpp:310]     Train net output #0: loss = 0.362043 (* 1 = 0.362043 loss)
I1111 01:04:47.805824  2593 sgd_solver.cpp:106] Iteration 4261, lr = 0.00025
I1111 01:04:50.175961  2593 solver.cpp:295] Iteration 4262 (no loss supplied for SingleUpdateStep)
I1111 01:04:50.176019  2593 solver.cpp:310]     Train net output #0: loss = 0.37905 (* 1 = 0.37905 loss)
I1111 01:04:50.176039  2593 sgd_solver.cpp:106] Iteration 4262, lr = 0.00025
I1111 01:04:52.662241  2593 solver.cpp:295] Iteration 4263 (no loss supplied for SingleUpdateStep)
I1111 01:04:52.662356  2593 solver.cpp:310]     Train net output #0: loss = 0.384463 (* 1 = 0.384463 loss)
I1111 01:04:52.662392  2593 sgd_solver.cpp:106] Iteration 4263, lr = 0.00025
I1111 01:04:55.236285  2593 solver.cpp:295] Iteration 4264 (no loss supplied for SingleUpdateStep)
I1111 01:04:55.236399  2593 solver.cpp:310]     Train net output #0: loss = 0.387024 (* 1 = 0.387024 loss)
I1111 01:04:55.236421  2593 sgd_solver.cpp:106] Iteration 4264, lr = 0.00025
I1111 01:04:57.771445  2593 solver.cpp:295] Iteration 4265 (no loss supplied for SingleUpdateStep)
I1111 01:04:57.771505  2593 solver.cpp:310]     Train net output #0: loss = 0.374684 (* 1 = 0.374684 loss)
I1111 01:04:57.771525  2593 sgd_solver.cpp:106] Iteration 4265, lr = 0.00025
I1111 01:05:00.041649  2593 solver.cpp:295] Iteration 4266 (no loss supplied for SingleUpdateStep)
I1111 01:05:00.041761  2593 solver.cpp:310]     Train net output #0: loss = 0.35676 (* 1 = 0.35676 loss)
I1111 01:05:00.041785  2593 sgd_solver.cpp:106] Iteration 4266, lr = 0.00025
I1111 01:05:02.504489  2593 solver.cpp:295] Iteration 4267 (no loss supplied for SingleUpdateStep)
I1111 01:05:02.504611  2593 solver.cpp:310]     Train net output #0: loss = 0.382369 (* 1 = 0.382369 loss)
I1111 01:05:02.504634  2593 sgd_solver.cpp:106] Iteration 4267, lr = 0.00025
I1111 01:05:05.070911  2593 solver.cpp:295] Iteration 4268 (no loss supplied for SingleUpdateStep)
I1111 01:05:05.071014  2593 solver.cpp:310]     Train net output #0: loss = 0.366288 (* 1 = 0.366288 loss)
I1111 01:05:05.071038  2593 sgd_solver.cpp:106] Iteration 4268, lr = 0.00025
I1111 01:05:07.420694  2593 solver.cpp:295] Iteration 4269 (no loss supplied for SingleUpdateStep)
I1111 01:05:07.420802  2593 solver.cpp:310]     Train net output #0: loss = 0.410365 (* 1 = 0.410365 loss)
I1111 01:05:07.420825  2593 sgd_solver.cpp:106] Iteration 4269, lr = 0.00025
I1111 01:05:10.014395  2593 solver.cpp:295] Iteration 4270 (no loss supplied for SingleUpdateStep)
I1111 01:05:10.014487  2593 solver.cpp:310]     Train net output #0: loss = 0.381981 (* 1 = 0.381981 loss)
I1111 01:05:10.014509  2593 sgd_solver.cpp:106] Iteration 4270, lr = 0.00025
I1111 01:05:12.384965  2593 solver.cpp:295] Iteration 4271 (no loss supplied for SingleUpdateStep)
I1111 01:05:12.385072  2593 solver.cpp:310]     Train net output #0: loss = 0.370763 (* 1 = 0.370763 loss)
I1111 01:05:12.385095  2593 sgd_solver.cpp:106] Iteration 4271, lr = 0.00025
I1111 01:05:14.708609  2593 solver.cpp:295] Iteration 4272 (no loss supplied for SingleUpdateStep)
I1111 01:05:14.708724  2593 solver.cpp:310]     Train net output #0: loss = 0.380617 (* 1 = 0.380617 loss)
I1111 01:05:14.708746  2593 sgd_solver.cpp:106] Iteration 4272, lr = 0.00025
I1111 01:05:17.026010  2593 solver.cpp:295] Iteration 4273 (no loss supplied for SingleUpdateStep)
I1111 01:05:17.026113  2593 solver.cpp:310]     Train net output #0: loss = 0.372216 (* 1 = 0.372216 loss)
I1111 01:05:17.026134  2593 sgd_solver.cpp:106] Iteration 4273, lr = 0.00025
I1111 01:05:19.836552  2593 solver.cpp:295] Iteration 4274 (no loss supplied for SingleUpdateStep)
I1111 01:05:19.836655  2593 solver.cpp:310]     Train net output #0: loss = 0.394787 (* 1 = 0.394787 loss)
I1111 01:05:19.836678  2593 sgd_solver.cpp:106] Iteration 4274, lr = 0.00025
I1111 01:05:22.994179  2593 solver.cpp:295] Iteration 4275 (no loss supplied for SingleUpdateStep)
I1111 01:05:22.994246  2593 solver.cpp:310]     Train net output #0: loss = 0.402339 (* 1 = 0.402339 loss)
I1111 01:05:22.994266  2593 sgd_solver.cpp:106] Iteration 4275, lr = 0.00025
I1111 01:05:25.288961  2593 solver.cpp:295] Iteration 4276 (no loss supplied for SingleUpdateStep)
I1111 01:05:25.289090  2593 solver.cpp:310]     Train net output #0: loss = 0.387689 (* 1 = 0.387689 loss)
I1111 01:05:25.289113  2593 sgd_solver.cpp:106] Iteration 4276, lr = 0.00025
I1111 01:05:27.790575  2593 solver.cpp:295] Iteration 4277 (no loss supplied for SingleUpdateStep)
I1111 01:05:27.790630  2593 solver.cpp:310]     Train net output #0: loss = 0.393647 (* 1 = 0.393647 loss)
I1111 01:05:27.790650  2593 sgd_solver.cpp:106] Iteration 4277, lr = 0.00025
I1111 01:05:30.308439  2593 solver.cpp:295] Iteration 4278 (no loss supplied for SingleUpdateStep)
I1111 01:05:30.308550  2593 solver.cpp:310]     Train net output #0: loss = 0.378324 (* 1 = 0.378324 loss)
I1111 01:05:30.308573  2593 sgd_solver.cpp:106] Iteration 4278, lr = 0.00025
I1111 01:05:32.809362  2593 solver.cpp:295] Iteration 4279 (no loss supplied for SingleUpdateStep)
I1111 01:05:32.809495  2593 solver.cpp:310]     Train net output #0: loss = 0.377663 (* 1 = 0.377663 loss)
I1111 01:05:32.809519  2593 sgd_solver.cpp:106] Iteration 4279, lr = 0.00025
I1111 01:05:35.696490  2593 solver.cpp:295] Iteration 4280 (no loss supplied for SingleUpdateStep)
I1111 01:05:35.696589  2593 solver.cpp:310]     Train net output #0: loss = 0.383385 (* 1 = 0.383385 loss)
I1111 01:05:35.696614  2593 sgd_solver.cpp:106] Iteration 4280, lr = 0.00025
I1111 01:05:38.659235  2593 solver.cpp:295] Iteration 4281 (no loss supplied for SingleUpdateStep)
I1111 01:05:38.659297  2593 solver.cpp:310]     Train net output #0: loss = 0.392672 (* 1 = 0.392672 loss)
I1111 01:05:38.659317  2593 sgd_solver.cpp:106] Iteration 4281, lr = 0.00025
I1111 01:05:41.093768  2593 solver.cpp:295] Iteration 4282 (no loss supplied for SingleUpdateStep)
I1111 01:05:41.093884  2593 solver.cpp:310]     Train net output #0: loss = 0.364491 (* 1 = 0.364491 loss)
I1111 01:05:41.093909  2593 sgd_solver.cpp:106] Iteration 4282, lr = 0.00025
I1111 01:05:43.622422  2593 solver.cpp:295] Iteration 4283 (no loss supplied for SingleUpdateStep)
I1111 01:05:43.622581  2593 solver.cpp:310]     Train net output #0: loss = 0.368945 (* 1 = 0.368945 loss)
I1111 01:05:43.622604  2593 sgd_solver.cpp:106] Iteration 4283, lr = 0.00025
I1111 01:05:46.187958  2593 solver.cpp:295] Iteration 4284 (no loss supplied for SingleUpdateStep)
I1111 01:05:46.188029  2593 solver.cpp:310]     Train net output #0: loss = 0.385898 (* 1 = 0.385898 loss)
I1111 01:05:46.188048  2593 sgd_solver.cpp:106] Iteration 4284, lr = 0.00025
I1111 01:05:48.509793  2593 solver.cpp:295] Iteration 4285 (no loss supplied for SingleUpdateStep)
I1111 01:05:48.509925  2593 solver.cpp:310]     Train net output #0: loss = 0.385689 (* 1 = 0.385689 loss)
I1111 01:05:48.509948  2593 sgd_solver.cpp:106] Iteration 4285, lr = 0.00025
I1111 01:05:51.311664  2593 solver.cpp:295] Iteration 4286 (no loss supplied for SingleUpdateStep)
I1111 01:05:51.311746  2593 solver.cpp:310]     Train net output #0: loss = 0.387406 (* 1 = 0.387406 loss)
I1111 01:05:51.311765  2593 sgd_solver.cpp:106] Iteration 4286, lr = 0.00025
I1111 01:05:54.272367  2593 solver.cpp:295] Iteration 4287 (no loss supplied for SingleUpdateStep)
I1111 01:05:54.272476  2593 solver.cpp:310]     Train net output #0: loss = 0.385178 (* 1 = 0.385178 loss)
I1111 01:05:54.272498  2593 sgd_solver.cpp:106] Iteration 4287, lr = 0.00025
I1111 01:05:56.716913  2593 solver.cpp:295] Iteration 4288 (no loss supplied for SingleUpdateStep)
I1111 01:05:56.717012  2593 solver.cpp:310]     Train net output #0: loss = 0.399638 (* 1 = 0.399638 loss)
I1111 01:05:56.717034  2593 sgd_solver.cpp:106] Iteration 4288, lr = 0.00025
I1111 01:05:59.163723  2593 solver.cpp:295] Iteration 4289 (no loss supplied for SingleUpdateStep)
I1111 01:05:59.163852  2593 solver.cpp:310]     Train net output #0: loss = 0.370256 (* 1 = 0.370256 loss)
I1111 01:05:59.163874  2593 sgd_solver.cpp:106] Iteration 4289, lr = 0.00025
I1111 01:06:01.776707  2593 solver.cpp:295] Iteration 4290 (no loss supplied for SingleUpdateStep)
I1111 01:06:01.776818  2593 solver.cpp:310]     Train net output #0: loss = 0.345552 (* 1 = 0.345552 loss)
I1111 01:06:01.776840  2593 sgd_solver.cpp:106] Iteration 4290, lr = 0.00025
I1111 01:06:04.452308  2593 solver.cpp:295] Iteration 4291 (no loss supplied for SingleUpdateStep)
I1111 01:06:04.452392  2593 solver.cpp:310]     Train net output #0: loss = 0.385728 (* 1 = 0.385728 loss)
I1111 01:06:04.452414  2593 sgd_solver.cpp:106] Iteration 4291, lr = 0.00025
I1111 01:06:07.139387  2593 solver.cpp:295] Iteration 4292 (no loss supplied for SingleUpdateStep)
I1111 01:06:07.139520  2593 solver.cpp:310]     Train net output #0: loss = 0.369913 (* 1 = 0.369913 loss)
I1111 01:06:07.139549  2593 sgd_solver.cpp:106] Iteration 4292, lr = 0.00025
I1111 01:06:09.700615  2593 solver.cpp:295] Iteration 4293 (no loss supplied for SingleUpdateStep)
I1111 01:06:09.700680  2593 solver.cpp:310]     Train net output #0: loss = 0.356591 (* 1 = 0.356591 loss)
I1111 01:06:09.700700  2593 sgd_solver.cpp:106] Iteration 4293, lr = 0.00025
I1111 01:06:12.120710  2593 solver.cpp:295] Iteration 4294 (no loss supplied for SingleUpdateStep)
I1111 01:06:12.120802  2593 solver.cpp:310]     Train net output #0: loss = 0.406151 (* 1 = 0.406151 loss)
I1111 01:06:12.120825  2593 sgd_solver.cpp:106] Iteration 4294, lr = 0.00025
I1111 01:06:14.468855  2593 solver.cpp:295] Iteration 4295 (no loss supplied for SingleUpdateStep)
I1111 01:06:14.468921  2593 solver.cpp:310]     Train net output #0: loss = 0.383942 (* 1 = 0.383942 loss)
I1111 01:06:14.468941  2593 sgd_solver.cpp:106] Iteration 4295, lr = 0.00025
I1111 01:06:16.813396  2593 solver.cpp:295] Iteration 4296 (no loss supplied for SingleUpdateStep)
I1111 01:06:16.813499  2593 solver.cpp:310]     Train net output #0: loss = 0.396175 (* 1 = 0.396175 loss)
I1111 01:06:16.813524  2593 sgd_solver.cpp:106] Iteration 4296, lr = 0.00025
I1111 01:06:19.201843  2593 solver.cpp:295] Iteration 4297 (no loss supplied for SingleUpdateStep)
I1111 01:06:19.201956  2593 solver.cpp:310]     Train net output #0: loss = 0.389461 (* 1 = 0.389461 loss)
I1111 01:06:19.201978  2593 sgd_solver.cpp:106] Iteration 4297, lr = 0.00025
I1111 01:06:21.789713  2593 solver.cpp:295] Iteration 4298 (no loss supplied for SingleUpdateStep)
I1111 01:06:21.789764  2593 solver.cpp:310]     Train net output #0: loss = 0.395164 (* 1 = 0.395164 loss)
I1111 01:06:21.789783  2593 sgd_solver.cpp:106] Iteration 4298, lr = 0.00025
I1111 01:06:24.190044  2593 solver.cpp:295] Iteration 4299 (no loss supplied for SingleUpdateStep)
I1111 01:06:24.190107  2593 solver.cpp:310]     Train net output #0: loss = 0.357336 (* 1 = 0.357336 loss)
I1111 01:06:24.190126  2593 sgd_solver.cpp:106] Iteration 4299, lr = 0.00025
I1111 01:06:26.436748  2593 solver.cpp:295] Iteration 4300 (no loss supplied for SingleUpdateStep)
I1111 01:06:26.436857  2593 solver.cpp:310]     Train net output #0: loss = 0.386262 (* 1 = 0.386262 loss)
I1111 01:06:26.436883  2593 sgd_solver.cpp:106] Iteration 4300, lr = 0.00025
I1111 01:06:29.158321  2593 solver.cpp:295] Iteration 4301 (no loss supplied for SingleUpdateStep)
I1111 01:06:29.158435  2593 solver.cpp:310]     Train net output #0: loss = 0.390393 (* 1 = 0.390393 loss)
I1111 01:06:29.158457  2593 sgd_solver.cpp:106] Iteration 4301, lr = 0.00025
I1111 01:06:31.579741  2593 solver.cpp:295] Iteration 4302 (no loss supplied for SingleUpdateStep)
I1111 01:06:31.579844  2593 solver.cpp:310]     Train net output #0: loss = 0.37935 (* 1 = 0.37935 loss)
I1111 01:06:31.579866  2593 sgd_solver.cpp:106] Iteration 4302, lr = 0.00025
I1111 01:06:34.310906  2593 solver.cpp:295] Iteration 4303 (no loss supplied for SingleUpdateStep)
I1111 01:06:34.311030  2593 solver.cpp:310]     Train net output #0: loss = 0.382449 (* 1 = 0.382449 loss)
I1111 01:06:34.311055  2593 sgd_solver.cpp:106] Iteration 4303, lr = 0.00025
I1111 01:06:37.321058  2593 solver.cpp:295] Iteration 4304 (no loss supplied for SingleUpdateStep)
I1111 01:06:37.321179  2593 solver.cpp:310]     Train net output #0: loss = 0.385488 (* 1 = 0.385488 loss)
I1111 01:06:37.321205  2593 sgd_solver.cpp:106] Iteration 4304, lr = 0.00025
I1111 01:06:40.946344  2593 solver.cpp:295] Iteration 4305 (no loss supplied for SingleUpdateStep)
I1111 01:06:40.946432  2593 solver.cpp:310]     Train net output #0: loss = 0.389235 (* 1 = 0.389235 loss)
I1111 01:06:40.946455  2593 sgd_solver.cpp:106] Iteration 4305, lr = 0.00025
I1111 01:06:44.269696  2593 solver.cpp:295] Iteration 4306 (no loss supplied for SingleUpdateStep)
I1111 01:06:44.269806  2593 solver.cpp:310]     Train net output #0: loss = 0.384286 (* 1 = 0.384286 loss)
I1111 01:06:44.269829  2593 sgd_solver.cpp:106] Iteration 4306, lr = 0.00025
I1111 01:06:48.209643  2593 solver.cpp:295] Iteration 4307 (no loss supplied for SingleUpdateStep)
I1111 01:06:48.209749  2593 solver.cpp:310]     Train net output #0: loss = 0.378319 (* 1 = 0.378319 loss)
I1111 01:06:48.209772  2593 sgd_solver.cpp:106] Iteration 4307, lr = 0.00025
I1111 01:06:52.297791  2593 solver.cpp:295] Iteration 4308 (no loss supplied for SingleUpdateStep)
I1111 01:06:52.297847  2593 solver.cpp:310]     Train net output #0: loss = 0.344547 (* 1 = 0.344547 loss)
I1111 01:06:52.297865  2593 sgd_solver.cpp:106] Iteration 4308, lr = 0.00025
I1111 01:06:55.560978  2593 solver.cpp:295] Iteration 4309 (no loss supplied for SingleUpdateStep)
I1111 01:06:55.561081  2593 solver.cpp:310]     Train net output #0: loss = 0.378734 (* 1 = 0.378734 loss)
I1111 01:06:55.561101  2593 sgd_solver.cpp:106] Iteration 4309, lr = 0.00025
I1111 01:06:58.115372  2593 solver.cpp:295] Iteration 4310 (no loss supplied for SingleUpdateStep)
I1111 01:06:58.115509  2593 solver.cpp:310]     Train net output #0: loss = 0.363441 (* 1 = 0.363441 loss)
I1111 01:06:58.115531  2593 sgd_solver.cpp:106] Iteration 4310, lr = 0.00025
I1111 01:07:00.687564  2593 solver.cpp:295] Iteration 4311 (no loss supplied for SingleUpdateStep)
I1111 01:07:00.687690  2593 solver.cpp:310]     Train net output #0: loss = 0.369348 (* 1 = 0.369348 loss)
I1111 01:07:00.687718  2593 sgd_solver.cpp:106] Iteration 4311, lr = 0.00025
I1111 01:07:03.046314  2593 solver.cpp:295] Iteration 4312 (no loss supplied for SingleUpdateStep)
I1111 01:07:03.046452  2593 solver.cpp:310]     Train net output #0: loss = 0.361709 (* 1 = 0.361709 loss)
I1111 01:07:03.046475  2593 sgd_solver.cpp:106] Iteration 4312, lr = 0.00025
I1111 01:07:05.468861  2593 solver.cpp:295] Iteration 4313 (no loss supplied for SingleUpdateStep)
I1111 01:07:05.468998  2593 solver.cpp:310]     Train net output #0: loss = 0.372733 (* 1 = 0.372733 loss)
I1111 01:07:05.469022  2593 sgd_solver.cpp:106] Iteration 4313, lr = 0.00025
I1111 01:07:08.221474  2593 solver.cpp:295] Iteration 4314 (no loss supplied for SingleUpdateStep)
I1111 01:07:08.221617  2593 solver.cpp:310]     Train net output #0: loss = 0.409934 (* 1 = 0.409934 loss)
I1111 01:07:08.221640  2593 sgd_solver.cpp:106] Iteration 4314, lr = 0.00025
I1111 01:07:10.554100  2593 solver.cpp:295] Iteration 4315 (no loss supplied for SingleUpdateStep)
I1111 01:07:10.554205  2593 solver.cpp:310]     Train net output #0: loss = 0.378881 (* 1 = 0.378881 loss)
I1111 01:07:10.554226  2593 sgd_solver.cpp:106] Iteration 4315, lr = 0.00025
I1111 01:07:12.786350  2593 solver.cpp:295] Iteration 4316 (no loss supplied for SingleUpdateStep)
I1111 01:07:12.786470  2593 solver.cpp:310]     Train net output #0: loss = 0.366021 (* 1 = 0.366021 loss)
I1111 01:07:12.786491  2593 sgd_solver.cpp:106] Iteration 4316, lr = 0.00025
I1111 01:07:15.252933  2593 solver.cpp:295] Iteration 4317 (no loss supplied for SingleUpdateStep)
I1111 01:07:15.252993  2593 solver.cpp:310]     Train net output #0: loss = 0.367577 (* 1 = 0.367577 loss)
I1111 01:07:15.253012  2593 sgd_solver.cpp:106] Iteration 4317, lr = 0.00025
I1111 01:07:17.619483  2593 solver.cpp:295] Iteration 4318 (no loss supplied for SingleUpdateStep)
I1111 01:07:17.619544  2593 solver.cpp:310]     Train net output #0: loss = 0.347352 (* 1 = 0.347352 loss)
I1111 01:07:17.619563  2593 sgd_solver.cpp:106] Iteration 4318, lr = 0.00025
I1111 01:07:20.063000  2593 solver.cpp:295] Iteration 4319 (no loss supplied for SingleUpdateStep)
I1111 01:07:20.063102  2593 solver.cpp:310]     Train net output #0: loss = 0.370971 (* 1 = 0.370971 loss)
I1111 01:07:20.063122  2593 sgd_solver.cpp:106] Iteration 4319, lr = 0.00025
I1111 01:07:22.342424  2593 solver.cpp:295] Iteration 4320 (no loss supplied for SingleUpdateStep)
I1111 01:07:22.342519  2593 solver.cpp:310]     Train net output #0: loss = 0.377408 (* 1 = 0.377408 loss)
I1111 01:07:22.342541  2593 sgd_solver.cpp:106] Iteration 4320, lr = 0.00025
I1111 01:07:24.750203  2593 solver.cpp:295] Iteration 4321 (no loss supplied for SingleUpdateStep)
I1111 01:07:24.750303  2593 solver.cpp:310]     Train net output #0: loss = 0.377503 (* 1 = 0.377503 loss)
I1111 01:07:24.750324  2593 sgd_solver.cpp:106] Iteration 4321, lr = 0.00025
I1111 01:07:27.114022  2593 solver.cpp:295] Iteration 4322 (no loss supplied for SingleUpdateStep)
I1111 01:07:27.114121  2593 solver.cpp:310]     Train net output #0: loss = 0.404255 (* 1 = 0.404255 loss)
I1111 01:07:27.114145  2593 sgd_solver.cpp:106] Iteration 4322, lr = 0.00025
I1111 01:07:29.740360  2593 solver.cpp:295] Iteration 4323 (no loss supplied for SingleUpdateStep)
I1111 01:07:29.740447  2593 solver.cpp:310]     Train net output #0: loss = 0.345842 (* 1 = 0.345842 loss)
I1111 01:07:29.740469  2593 sgd_solver.cpp:106] Iteration 4323, lr = 0.00025
I1111 01:07:32.134418  2593 solver.cpp:295] Iteration 4324 (no loss supplied for SingleUpdateStep)
I1111 01:07:32.134555  2593 solver.cpp:310]     Train net output #0: loss = 0.372735 (* 1 = 0.372735 loss)
I1111 01:07:32.134587  2593 sgd_solver.cpp:106] Iteration 4324, lr = 0.00025
I1111 01:07:34.551128  2593 solver.cpp:295] Iteration 4325 (no loss supplied for SingleUpdateStep)
I1111 01:07:34.551228  2593 solver.cpp:310]     Train net output #0: loss = 0.407458 (* 1 = 0.407458 loss)
I1111 01:07:34.551249  2593 sgd_solver.cpp:106] Iteration 4325, lr = 0.00025
I1111 01:07:37.344167  2593 solver.cpp:295] Iteration 4326 (no loss supplied for SingleUpdateStep)
I1111 01:07:37.344225  2593 solver.cpp:310]     Train net output #0: loss = 0.395772 (* 1 = 0.395772 loss)
I1111 01:07:37.344244  2593 sgd_solver.cpp:106] Iteration 4326, lr = 0.00025
I1111 01:07:40.658399  2593 solver.cpp:295] Iteration 4327 (no loss supplied for SingleUpdateStep)
I1111 01:07:40.658488  2593 solver.cpp:310]     Train net output #0: loss = 0.370158 (* 1 = 0.370158 loss)
I1111 01:07:40.658507  2593 sgd_solver.cpp:106] Iteration 4327, lr = 0.00025
I1111 01:07:43.250350  2593 solver.cpp:295] Iteration 4328 (no loss supplied for SingleUpdateStep)
I1111 01:07:43.250424  2593 solver.cpp:310]     Train net output #0: loss = 0.400632 (* 1 = 0.400632 loss)
I1111 01:07:43.250447  2593 sgd_solver.cpp:106] Iteration 4328, lr = 0.00025
I1111 01:07:45.786167  2593 solver.cpp:295] Iteration 4329 (no loss supplied for SingleUpdateStep)
I1111 01:07:45.786293  2593 solver.cpp:310]     Train net output #0: loss = 0.370874 (* 1 = 0.370874 loss)
I1111 01:07:45.786319  2593 sgd_solver.cpp:106] Iteration 4329, lr = 0.00025
I1111 01:07:48.265707  2593 solver.cpp:295] Iteration 4330 (no loss supplied for SingleUpdateStep)
I1111 01:07:48.265769  2593 solver.cpp:310]     Train net output #0: loss = 0.366653 (* 1 = 0.366653 loss)
I1111 01:07:48.265789  2593 sgd_solver.cpp:106] Iteration 4330, lr = 0.00025
I1111 01:07:51.008669  2593 solver.cpp:295] Iteration 4331 (no loss supplied for SingleUpdateStep)
I1111 01:07:51.008783  2593 solver.cpp:310]     Train net output #0: loss = 0.353922 (* 1 = 0.353922 loss)
I1111 01:07:51.008805  2593 sgd_solver.cpp:106] Iteration 4331, lr = 0.00025
I1111 01:07:53.268816  2593 solver.cpp:295] Iteration 4332 (no loss supplied for SingleUpdateStep)
I1111 01:07:53.268936  2593 solver.cpp:310]     Train net output #0: loss = 0.375312 (* 1 = 0.375312 loss)
I1111 01:07:53.268964  2593 sgd_solver.cpp:106] Iteration 4332, lr = 0.00025
I1111 01:07:55.747572  2593 solver.cpp:295] Iteration 4333 (no loss supplied for SingleUpdateStep)
I1111 01:07:55.747675  2593 solver.cpp:310]     Train net output #0: loss = 0.378818 (* 1 = 0.378818 loss)
I1111 01:07:55.747697  2593 sgd_solver.cpp:106] Iteration 4333, lr = 0.00025
I1111 01:07:58.071962  2593 solver.cpp:295] Iteration 4334 (no loss supplied for SingleUpdateStep)
I1111 01:07:58.072059  2593 solver.cpp:310]     Train net output #0: loss = 0.387347 (* 1 = 0.387347 loss)
I1111 01:07:58.072083  2593 sgd_solver.cpp:106] Iteration 4334, lr = 0.00025
I1111 01:08:00.321095  2593 solver.cpp:295] Iteration 4335 (no loss supplied for SingleUpdateStep)
I1111 01:08:00.321228  2593 solver.cpp:310]     Train net output #0: loss = 0.378089 (* 1 = 0.378089 loss)
I1111 01:08:00.321254  2593 sgd_solver.cpp:106] Iteration 4335, lr = 0.00025
I1111 01:08:02.656116  2593 solver.cpp:295] Iteration 4336 (no loss supplied for SingleUpdateStep)
I1111 01:08:02.656244  2593 solver.cpp:310]     Train net output #0: loss = 0.37709 (* 1 = 0.37709 loss)
I1111 01:08:02.656271  2593 sgd_solver.cpp:106] Iteration 4336, lr = 0.00025
I1111 01:08:05.022646  2593 solver.cpp:295] Iteration 4337 (no loss supplied for SingleUpdateStep)
I1111 01:08:05.022728  2593 solver.cpp:310]     Train net output #0: loss = 0.375711 (* 1 = 0.375711 loss)
I1111 01:08:05.022749  2593 sgd_solver.cpp:106] Iteration 4337, lr = 0.00025
I1111 01:08:07.323997  2593 solver.cpp:295] Iteration 4338 (no loss supplied for SingleUpdateStep)
I1111 01:08:07.324139  2593 solver.cpp:310]     Train net output #0: loss = 0.386589 (* 1 = 0.386589 loss)
I1111 01:08:07.324162  2593 sgd_solver.cpp:106] Iteration 4338, lr = 0.00025
I1111 01:08:09.548388  2593 solver.cpp:295] Iteration 4339 (no loss supplied for SingleUpdateStep)
I1111 01:08:09.548460  2593 solver.cpp:310]     Train net output #0: loss = 0.369698 (* 1 = 0.369698 loss)
I1111 01:08:09.548483  2593 sgd_solver.cpp:106] Iteration 4339, lr = 0.00025
I1111 01:08:11.909044  2593 solver.cpp:295] Iteration 4340 (no loss supplied for SingleUpdateStep)
I1111 01:08:11.909158  2593 solver.cpp:310]     Train net output #0: loss = 0.377221 (* 1 = 0.377221 loss)
I1111 01:08:11.909184  2593 sgd_solver.cpp:106] Iteration 4340, lr = 0.00025
I1111 01:08:14.116017  2593 solver.cpp:295] Iteration 4341 (no loss supplied for SingleUpdateStep)
I1111 01:08:14.116147  2593 solver.cpp:310]     Train net output #0: loss = 0.374583 (* 1 = 0.374583 loss)
I1111 01:08:14.116173  2593 sgd_solver.cpp:106] Iteration 4341, lr = 0.00025
I1111 01:08:16.550721  2593 solver.cpp:295] Iteration 4342 (no loss supplied for SingleUpdateStep)
I1111 01:08:16.550835  2593 solver.cpp:310]     Train net output #0: loss = 0.390327 (* 1 = 0.390327 loss)
I1111 01:08:16.550856  2593 sgd_solver.cpp:106] Iteration 4342, lr = 0.00025
I1111 01:08:19.160914  2593 solver.cpp:295] Iteration 4343 (no loss supplied for SingleUpdateStep)
I1111 01:08:19.161006  2593 solver.cpp:310]     Train net output #0: loss = 0.386536 (* 1 = 0.386536 loss)
I1111 01:08:19.161026  2593 sgd_solver.cpp:106] Iteration 4343, lr = 0.00025
I1111 01:08:22.184876  2593 solver.cpp:295] Iteration 4344 (no loss supplied for SingleUpdateStep)
I1111 01:08:22.184981  2593 solver.cpp:310]     Train net output #0: loss = 0.385425 (* 1 = 0.385425 loss)
I1111 01:08:22.185004  2593 sgd_solver.cpp:106] Iteration 4344, lr = 0.00025
I1111 01:08:25.023522  2593 solver.cpp:295] Iteration 4345 (no loss supplied for SingleUpdateStep)
I1111 01:08:25.023666  2593 solver.cpp:310]     Train net output #0: loss = 0.3639 (* 1 = 0.3639 loss)
I1111 01:08:25.023690  2593 sgd_solver.cpp:106] Iteration 4345, lr = 0.00025
I1111 01:08:27.603824  2593 solver.cpp:295] Iteration 4346 (no loss supplied for SingleUpdateStep)
I1111 01:08:27.603906  2593 solver.cpp:310]     Train net output #0: loss = 0.382122 (* 1 = 0.382122 loss)
I1111 01:08:27.603927  2593 sgd_solver.cpp:106] Iteration 4346, lr = 0.00025
I1111 01:08:30.165107  2593 solver.cpp:295] Iteration 4347 (no loss supplied for SingleUpdateStep)
I1111 01:08:30.165169  2593 solver.cpp:310]     Train net output #0: loss = 0.38253 (* 1 = 0.38253 loss)
I1111 01:08:30.165189  2593 sgd_solver.cpp:106] Iteration 4347, lr = 0.00025
I1111 01:08:32.633328  2593 solver.cpp:295] Iteration 4348 (no loss supplied for SingleUpdateStep)
I1111 01:08:32.633414  2593 solver.cpp:310]     Train net output #0: loss = 0.395243 (* 1 = 0.395243 loss)
I1111 01:08:32.633432  2593 sgd_solver.cpp:106] Iteration 4348, lr = 0.00025
I1111 01:08:35.035116  2593 solver.cpp:295] Iteration 4349 (no loss supplied for SingleUpdateStep)
I1111 01:08:35.035207  2593 solver.cpp:310]     Train net output #0: loss = 0.381464 (* 1 = 0.381464 loss)
I1111 01:08:35.035226  2593 sgd_solver.cpp:106] Iteration 4349, lr = 0.00025
I1111 01:08:37.629016  2593 solver.cpp:295] Iteration 4350 (no loss supplied for SingleUpdateStep)
I1111 01:08:37.629127  2593 solver.cpp:310]     Train net output #0: loss = 0.370076 (* 1 = 0.370076 loss)
I1111 01:08:37.629148  2593 sgd_solver.cpp:106] Iteration 4350, lr = 0.00025
I1111 01:08:40.383141  2593 solver.cpp:295] Iteration 4351 (no loss supplied for SingleUpdateStep)
I1111 01:08:40.383254  2593 solver.cpp:310]     Train net output #0: loss = 0.396872 (* 1 = 0.396872 loss)
I1111 01:08:40.383277  2593 sgd_solver.cpp:106] Iteration 4351, lr = 0.00025
I1111 01:08:42.772727  2593 solver.cpp:295] Iteration 4352 (no loss supplied for SingleUpdateStep)
I1111 01:08:42.772804  2593 solver.cpp:310]     Train net output #0: loss = 0.395613 (* 1 = 0.395613 loss)
I1111 01:08:42.772825  2593 sgd_solver.cpp:106] Iteration 4352, lr = 0.00025
I1111 01:08:45.173097  2593 solver.cpp:295] Iteration 4353 (no loss supplied for SingleUpdateStep)
I1111 01:08:45.173207  2593 solver.cpp:310]     Train net output #0: loss = 0.389799 (* 1 = 0.389799 loss)
I1111 01:08:45.173230  2593 sgd_solver.cpp:106] Iteration 4353, lr = 0.00025
I1111 01:08:47.607913  2593 solver.cpp:295] Iteration 4354 (no loss supplied for SingleUpdateStep)
I1111 01:08:47.607970  2593 solver.cpp:310]     Train net output #0: loss = 0.36824 (* 1 = 0.36824 loss)
I1111 01:08:47.607990  2593 sgd_solver.cpp:106] Iteration 4354, lr = 0.00025
I1111 01:08:50.021065  2593 solver.cpp:295] Iteration 4355 (no loss supplied for SingleUpdateStep)
I1111 01:08:50.021162  2593 solver.cpp:310]     Train net output #0: loss = 0.370787 (* 1 = 0.370787 loss)
I1111 01:08:50.021184  2593 sgd_solver.cpp:106] Iteration 4355, lr = 0.00025
I1111 01:08:52.618682  2593 solver.cpp:295] Iteration 4356 (no loss supplied for SingleUpdateStep)
I1111 01:08:52.618813  2593 solver.cpp:310]     Train net output #0: loss = 0.369428 (* 1 = 0.369428 loss)
I1111 01:08:52.618836  2593 sgd_solver.cpp:106] Iteration 4356, lr = 0.00025
I1111 01:08:54.980142  2593 solver.cpp:295] Iteration 4357 (no loss supplied for SingleUpdateStep)
I1111 01:08:54.980202  2593 solver.cpp:310]     Train net output #0: loss = 0.370374 (* 1 = 0.370374 loss)
I1111 01:08:54.980222  2593 sgd_solver.cpp:106] Iteration 4357, lr = 0.00025
I1111 01:08:57.702684  2593 solver.cpp:295] Iteration 4358 (no loss supplied for SingleUpdateStep)
I1111 01:08:57.702778  2593 solver.cpp:310]     Train net output #0: loss = 0.420229 (* 1 = 0.420229 loss)
I1111 01:08:57.702800  2593 sgd_solver.cpp:106] Iteration 4358, lr = 0.00025
I1111 01:09:00.149415  2593 solver.cpp:295] Iteration 4359 (no loss supplied for SingleUpdateStep)
I1111 01:09:00.149515  2593 solver.cpp:310]     Train net output #0: loss = 0.380251 (* 1 = 0.380251 loss)
I1111 01:09:00.149538  2593 sgd_solver.cpp:106] Iteration 4359, lr = 0.00025
I1111 01:09:02.500536  2593 solver.cpp:295] Iteration 4360 (no loss supplied for SingleUpdateStep)
I1111 01:09:02.500597  2593 solver.cpp:310]     Train net output #0: loss = 0.384776 (* 1 = 0.384776 loss)
I1111 01:09:02.500615  2593 sgd_solver.cpp:106] Iteration 4360, lr = 0.00025
I1111 01:09:04.885527  2593 solver.cpp:295] Iteration 4361 (no loss supplied for SingleUpdateStep)
I1111 01:09:04.885587  2593 solver.cpp:310]     Train net output #0: loss = 0.401641 (* 1 = 0.401641 loss)
I1111 01:09:04.885607  2593 sgd_solver.cpp:106] Iteration 4361, lr = 0.00025
I1111 01:09:07.249433  2593 solver.cpp:295] Iteration 4362 (no loss supplied for SingleUpdateStep)
I1111 01:09:07.249541  2593 solver.cpp:310]     Train net output #0: loss = 0.37419 (* 1 = 0.37419 loss)
I1111 01:09:07.249564  2593 sgd_solver.cpp:106] Iteration 4362, lr = 0.00025
I1111 01:09:09.554005  2593 solver.cpp:295] Iteration 4363 (no loss supplied for SingleUpdateStep)
I1111 01:09:09.554143  2593 solver.cpp:310]     Train net output #0: loss = 0.365682 (* 1 = 0.365682 loss)
I1111 01:09:09.554174  2593 sgd_solver.cpp:106] Iteration 4363, lr = 0.00025
I1111 01:09:11.897126  2593 solver.cpp:295] Iteration 4364 (no loss supplied for SingleUpdateStep)
I1111 01:09:11.897188  2593 solver.cpp:310]     Train net output #0: loss = 0.359853 (* 1 = 0.359853 loss)
I1111 01:09:11.897207  2593 sgd_solver.cpp:106] Iteration 4364, lr = 0.00025
I1111 01:09:14.310900  2593 solver.cpp:295] Iteration 4365 (no loss supplied for SingleUpdateStep)
I1111 01:09:14.311034  2593 solver.cpp:310]     Train net output #0: loss = 0.380824 (* 1 = 0.380824 loss)
I1111 01:09:14.311056  2593 sgd_solver.cpp:106] Iteration 4365, lr = 0.00025
I1111 01:09:17.027015  2593 solver.cpp:295] Iteration 4366 (no loss supplied for SingleUpdateStep)
I1111 01:09:17.027158  2593 solver.cpp:310]     Train net output #0: loss = 0.391516 (* 1 = 0.391516 loss)
I1111 01:09:17.027180  2593 sgd_solver.cpp:106] Iteration 4366, lr = 0.00025
I1111 01:09:19.332365  2593 solver.cpp:295] Iteration 4367 (no loss supplied for SingleUpdateStep)
I1111 01:09:19.332418  2593 solver.cpp:310]     Train net output #0: loss = 0.387226 (* 1 = 0.387226 loss)
I1111 01:09:19.332437  2593 sgd_solver.cpp:106] Iteration 4367, lr = 0.00025
I1111 01:09:21.610497  2593 solver.cpp:295] Iteration 4368 (no loss supplied for SingleUpdateStep)
I1111 01:09:21.610553  2593 solver.cpp:310]     Train net output #0: loss = 0.364163 (* 1 = 0.364163 loss)
I1111 01:09:21.610573  2593 sgd_solver.cpp:106] Iteration 4368, lr = 0.00025
I1111 01:09:24.007591  2593 solver.cpp:295] Iteration 4369 (no loss supplied for SingleUpdateStep)
I1111 01:09:24.007652  2593 solver.cpp:310]     Train net output #0: loss = 0.385755 (* 1 = 0.385755 loss)
I1111 01:09:24.007671  2593 sgd_solver.cpp:106] Iteration 4369, lr = 0.00025
I1111 01:09:26.415937  2593 solver.cpp:295] Iteration 4370 (no loss supplied for SingleUpdateStep)
I1111 01:09:26.416025  2593 solver.cpp:310]     Train net output #0: loss = 0.386 (* 1 = 0.386 loss)
I1111 01:09:26.416048  2593 sgd_solver.cpp:106] Iteration 4370, lr = 0.00025
I1111 01:09:28.730258  2593 solver.cpp:295] Iteration 4371 (no loss supplied for SingleUpdateStep)
I1111 01:09:28.730316  2593 solver.cpp:310]     Train net output #0: loss = 0.404435 (* 1 = 0.404435 loss)
I1111 01:09:28.730336  2593 sgd_solver.cpp:106] Iteration 4371, lr = 0.00025
I1111 01:09:31.352680  2593 solver.cpp:295] Iteration 4372 (no loss supplied for SingleUpdateStep)
I1111 01:09:31.352744  2593 solver.cpp:310]     Train net output #0: loss = 0.407092 (* 1 = 0.407092 loss)
I1111 01:09:31.352764  2593 sgd_solver.cpp:106] Iteration 4372, lr = 0.00025
I1111 01:09:33.680404  2593 solver.cpp:295] Iteration 4373 (no loss supplied for SingleUpdateStep)
I1111 01:09:33.680464  2593 solver.cpp:310]     Train net output #0: loss = 0.392585 (* 1 = 0.392585 loss)
I1111 01:09:33.680483  2593 sgd_solver.cpp:106] Iteration 4373, lr = 0.00025
I1111 01:09:35.961016  2593 solver.cpp:295] Iteration 4374 (no loss supplied for SingleUpdateStep)
I1111 01:09:35.961082  2593 solver.cpp:310]     Train net output #0: loss = 0.359756 (* 1 = 0.359756 loss)
I1111 01:09:35.961103  2593 sgd_solver.cpp:106] Iteration 4374, lr = 0.00025
I1111 01:09:38.174203  2593 solver.cpp:295] Iteration 4375 (no loss supplied for SingleUpdateStep)
I1111 01:09:38.174324  2593 solver.cpp:310]     Train net output #0: loss = 0.385834 (* 1 = 0.385834 loss)
I1111 01:09:38.174348  2593 sgd_solver.cpp:106] Iteration 4375, lr = 0.00025
I1111 01:09:40.585322  2593 solver.cpp:295] Iteration 4376 (no loss supplied for SingleUpdateStep)
I1111 01:09:40.585435  2593 solver.cpp:310]     Train net output #0: loss = 0.370841 (* 1 = 0.370841 loss)
I1111 01:09:40.585456  2593 sgd_solver.cpp:106] Iteration 4376, lr = 0.00025
I1111 01:09:43.576015  2593 solver.cpp:295] Iteration 4377 (no loss supplied for SingleUpdateStep)
I1111 01:09:43.576122  2593 solver.cpp:310]     Train net output #0: loss = 0.425617 (* 1 = 0.425617 loss)
I1111 01:09:43.576143  2593 sgd_solver.cpp:106] Iteration 4377, lr = 0.00025
I1111 01:09:45.810130  2593 solver.cpp:295] Iteration 4378 (no loss supplied for SingleUpdateStep)
I1111 01:09:45.810201  2593 solver.cpp:310]     Train net output #0: loss = 0.347686 (* 1 = 0.347686 loss)
I1111 01:09:45.810221  2593 sgd_solver.cpp:106] Iteration 4378, lr = 0.00025
I1111 01:09:48.298488  2593 solver.cpp:295] Iteration 4379 (no loss supplied for SingleUpdateStep)
I1111 01:09:48.298553  2593 solver.cpp:310]     Train net output #0: loss = 0.410347 (* 1 = 0.410347 loss)
I1111 01:09:48.298573  2593 sgd_solver.cpp:106] Iteration 4379, lr = 0.00025
I1111 01:09:50.785171  2593 solver.cpp:295] Iteration 4380 (no loss supplied for SingleUpdateStep)
I1111 01:09:50.785285  2593 solver.cpp:310]     Train net output #0: loss = 0.394065 (* 1 = 0.394065 loss)
I1111 01:09:50.785305  2593 sgd_solver.cpp:106] Iteration 4380, lr = 0.00025
I1111 01:09:53.389794  2593 solver.cpp:295] Iteration 4381 (no loss supplied for SingleUpdateStep)
I1111 01:09:53.389930  2593 solver.cpp:310]     Train net output #0: loss = 0.361179 (* 1 = 0.361179 loss)
I1111 01:09:53.389950  2593 sgd_solver.cpp:106] Iteration 4381, lr = 0.00025
I1111 01:09:55.955585  2593 solver.cpp:295] Iteration 4382 (no loss supplied for SingleUpdateStep)
I1111 01:09:55.955646  2593 solver.cpp:310]     Train net output #0: loss = 0.359199 (* 1 = 0.359199 loss)
I1111 01:09:55.955665  2593 sgd_solver.cpp:106] Iteration 4382, lr = 0.00025
I1111 01:09:58.491827  2593 solver.cpp:295] Iteration 4383 (no loss supplied for SingleUpdateStep)
I1111 01:09:58.499018  2593 solver.cpp:310]     Train net output #0: loss = 0.406919 (* 1 = 0.406919 loss)
I1111 01:09:58.499078  2593 sgd_solver.cpp:106] Iteration 4383, lr = 0.00025
I1111 01:10:00.918860  2593 solver.cpp:295] Iteration 4384 (no loss supplied for SingleUpdateStep)
I1111 01:10:00.919003  2593 solver.cpp:310]     Train net output #0: loss = 0.35644 (* 1 = 0.35644 loss)
I1111 01:10:00.919025  2593 sgd_solver.cpp:106] Iteration 4384, lr = 0.00025
I1111 01:10:03.224998  2593 solver.cpp:295] Iteration 4385 (no loss supplied for SingleUpdateStep)
I1111 01:10:03.225142  2593 solver.cpp:310]     Train net output #0: loss = 0.384454 (* 1 = 0.384454 loss)
I1111 01:10:03.225172  2593 sgd_solver.cpp:106] Iteration 4385, lr = 0.00025
I1111 01:10:05.496036  2593 solver.cpp:295] Iteration 4386 (no loss supplied for SingleUpdateStep)
I1111 01:10:05.496150  2593 solver.cpp:310]     Train net output #0: loss = 0.380732 (* 1 = 0.380732 loss)
I1111 01:10:05.496171  2593 sgd_solver.cpp:106] Iteration 4386, lr = 0.00025
I1111 01:10:07.783617  2593 solver.cpp:295] Iteration 4387 (no loss supplied for SingleUpdateStep)
I1111 01:10:07.783733  2593 solver.cpp:310]     Train net output #0: loss = 0.356774 (* 1 = 0.356774 loss)
I1111 01:10:07.783753  2593 sgd_solver.cpp:106] Iteration 4387, lr = 0.00025
I1111 01:10:10.123584  2593 solver.cpp:295] Iteration 4388 (no loss supplied for SingleUpdateStep)
I1111 01:10:10.123678  2593 solver.cpp:310]     Train net output #0: loss = 0.377407 (* 1 = 0.377407 loss)
I1111 01:10:10.123700  2593 sgd_solver.cpp:106] Iteration 4388, lr = 0.00025
I1111 01:10:12.362180  2593 solver.cpp:295] Iteration 4389 (no loss supplied for SingleUpdateStep)
I1111 01:10:12.362260  2593 solver.cpp:310]     Train net output #0: loss = 0.393973 (* 1 = 0.393973 loss)
I1111 01:10:12.362282  2593 sgd_solver.cpp:106] Iteration 4389, lr = 0.00025
I1111 01:10:14.945822  2593 solver.cpp:295] Iteration 4390 (no loss supplied for SingleUpdateStep)
I1111 01:10:14.945967  2593 solver.cpp:310]     Train net output #0: loss = 0.388542 (* 1 = 0.388542 loss)
I1111 01:10:14.945991  2593 sgd_solver.cpp:106] Iteration 4390, lr = 0.00025
I1111 01:10:17.362704  2593 solver.cpp:295] Iteration 4391 (no loss supplied for SingleUpdateStep)
I1111 01:10:17.362799  2593 solver.cpp:310]     Train net output #0: loss = 0.362156 (* 1 = 0.362156 loss)
I1111 01:10:17.362821  2593 sgd_solver.cpp:106] Iteration 4391, lr = 0.00025
I1111 01:10:19.623240  2593 solver.cpp:295] Iteration 4392 (no loss supplied for SingleUpdateStep)
I1111 01:10:19.623373  2593 solver.cpp:310]     Train net output #0: loss = 0.37399 (* 1 = 0.37399 loss)
I1111 01:10:19.623406  2593 sgd_solver.cpp:106] Iteration 4392, lr = 0.00025
I1111 01:10:22.007237  2593 solver.cpp:295] Iteration 4393 (no loss supplied for SingleUpdateStep)
I1111 01:10:22.007314  2593 solver.cpp:310]     Train net output #0: loss = 0.395021 (* 1 = 0.395021 loss)
I1111 01:10:22.007335  2593 sgd_solver.cpp:106] Iteration 4393, lr = 0.00025
I1111 01:10:24.540511  2593 solver.cpp:295] Iteration 4394 (no loss supplied for SingleUpdateStep)
I1111 01:10:24.540647  2593 solver.cpp:310]     Train net output #0: loss = 0.378824 (* 1 = 0.378824 loss)
I1111 01:10:24.540675  2593 sgd_solver.cpp:106] Iteration 4394, lr = 0.00025
I1111 01:10:27.171996  2593 solver.cpp:295] Iteration 4395 (no loss supplied for SingleUpdateStep)
I1111 01:10:27.172075  2593 solver.cpp:310]     Train net output #0: loss = 0.374237 (* 1 = 0.374237 loss)
I1111 01:10:27.172096  2593 sgd_solver.cpp:106] Iteration 4395, lr = 0.00025
I1111 01:10:29.729681  2593 solver.cpp:295] Iteration 4396 (no loss supplied for SingleUpdateStep)
I1111 01:10:29.729801  2593 solver.cpp:310]     Train net output #0: loss = 0.378691 (* 1 = 0.378691 loss)
I1111 01:10:29.729828  2593 sgd_solver.cpp:106] Iteration 4396, lr = 0.00025
I1111 01:10:32.075938  2593 solver.cpp:295] Iteration 4397 (no loss supplied for SingleUpdateStep)
I1111 01:10:32.076001  2593 solver.cpp:310]     Train net output #0: loss = 0.3618 (* 1 = 0.3618 loss)
I1111 01:10:32.076020  2593 sgd_solver.cpp:106] Iteration 4397, lr = 0.00025
I1111 01:10:34.696797  2593 solver.cpp:295] Iteration 4398 (no loss supplied for SingleUpdateStep)
I1111 01:10:34.696907  2593 solver.cpp:310]     Train net output #0: loss = 0.377205 (* 1 = 0.377205 loss)
I1111 01:10:34.696929  2593 sgd_solver.cpp:106] Iteration 4398, lr = 0.00025
I1111 01:10:37.938916  2593 solver.cpp:295] Iteration 4399 (no loss supplied for SingleUpdateStep)
I1111 01:10:37.939033  2593 solver.cpp:310]     Train net output #0: loss = 0.350418 (* 1 = 0.350418 loss)
I1111 01:10:37.939059  2593 sgd_solver.cpp:106] Iteration 4399, lr = 0.00025
I1111 01:10:41.463644  2593 solver.cpp:295] Iteration 4400 (no loss supplied for SingleUpdateStep)
I1111 01:10:41.463724  2593 solver.cpp:310]     Train net output #0: loss = 0.362899 (* 1 = 0.362899 loss)
I1111 01:10:41.463744  2593 sgd_solver.cpp:106] Iteration 4400, lr = 0.00025
I1111 01:10:45.143643  2593 solver.cpp:295] Iteration 4401 (no loss supplied for SingleUpdateStep)
I1111 01:10:45.143697  2593 solver.cpp:310]     Train net output #0: loss = 0.363176 (* 1 = 0.363176 loss)
I1111 01:10:45.143717  2593 sgd_solver.cpp:106] Iteration 4401, lr = 0.00025
I1111 01:10:48.743088  2593 solver.cpp:295] Iteration 4402 (no loss supplied for SingleUpdateStep)
I1111 01:10:48.743191  2593 solver.cpp:310]     Train net output #0: loss = 0.415512 (* 1 = 0.415512 loss)
I1111 01:10:48.743212  2593 sgd_solver.cpp:106] Iteration 4402, lr = 0.00025
I1111 01:10:51.830157  2593 solver.cpp:295] Iteration 4403 (no loss supplied for SingleUpdateStep)
I1111 01:10:51.830287  2593 solver.cpp:310]     Train net output #0: loss = 0.381635 (* 1 = 0.381635 loss)
I1111 01:10:51.830309  2593 sgd_solver.cpp:106] Iteration 4403, lr = 0.00025
I1111 01:10:54.239920  2593 solver.cpp:295] Iteration 4404 (no loss supplied for SingleUpdateStep)
I1111 01:10:54.239984  2593 solver.cpp:310]     Train net output #0: loss = 0.387913 (* 1 = 0.387913 loss)
I1111 01:10:54.240003  2593 sgd_solver.cpp:106] Iteration 4404, lr = 0.00025
I1111 01:10:56.597929  2593 solver.cpp:295] Iteration 4405 (no loss supplied for SingleUpdateStep)
I1111 01:10:56.598011  2593 solver.cpp:310]     Train net output #0: loss = 0.393756 (* 1 = 0.393756 loss)
I1111 01:10:56.598031  2593 sgd_solver.cpp:106] Iteration 4405, lr = 0.00025
I1111 01:10:59.419961  2593 solver.cpp:295] Iteration 4406 (no loss supplied for SingleUpdateStep)
I1111 01:10:59.420037  2593 solver.cpp:310]     Train net output #0: loss = 0.380932 (* 1 = 0.380932 loss)
I1111 01:10:59.420059  2593 sgd_solver.cpp:106] Iteration 4406, lr = 0.00025
I1111 01:11:02.320586  2593 solver.cpp:295] Iteration 4407 (no loss supplied for SingleUpdateStep)
I1111 01:11:02.320740  2593 solver.cpp:310]     Train net output #0: loss = 0.376446 (* 1 = 0.376446 loss)
I1111 01:11:02.320765  2593 sgd_solver.cpp:106] Iteration 4407, lr = 0.00025
I1111 01:11:04.982060  2593 solver.cpp:295] Iteration 4408 (no loss supplied for SingleUpdateStep)
I1111 01:11:04.982116  2593 solver.cpp:310]     Train net output #0: loss = 0.370437 (* 1 = 0.370437 loss)
I1111 01:11:04.982136  2593 sgd_solver.cpp:106] Iteration 4408, lr = 0.00025
I1111 01:11:07.167197  2593 solver.cpp:295] Iteration 4409 (no loss supplied for SingleUpdateStep)
I1111 01:11:07.167289  2593 solver.cpp:310]     Train net output #0: loss = 0.368077 (* 1 = 0.368077 loss)
I1111 01:11:07.167309  2593 sgd_solver.cpp:106] Iteration 4409, lr = 0.00025
I1111 01:11:10.495926  2593 solver.cpp:295] Iteration 4410 (no loss supplied for SingleUpdateStep)
I1111 01:11:10.496006  2593 solver.cpp:310]     Train net output #0: loss = 0.377507 (* 1 = 0.377507 loss)
I1111 01:11:10.496027  2593 sgd_solver.cpp:106] Iteration 4410, lr = 0.00025
I1111 01:11:12.889593  2593 solver.cpp:295] Iteration 4411 (no loss supplied for SingleUpdateStep)
I1111 01:11:12.889699  2593 solver.cpp:310]     Train net output #0: loss = 0.396981 (* 1 = 0.396981 loss)
I1111 01:11:12.889720  2593 sgd_solver.cpp:106] Iteration 4411, lr = 0.00025
I1111 01:11:15.374094  2593 solver.cpp:295] Iteration 4412 (no loss supplied for SingleUpdateStep)
I1111 01:11:15.374207  2593 solver.cpp:310]     Train net output #0: loss = 0.379205 (* 1 = 0.379205 loss)
I1111 01:11:15.374228  2593 sgd_solver.cpp:106] Iteration 4412, lr = 0.00025
I1111 01:11:18.036507  2593 solver.cpp:295] Iteration 4413 (no loss supplied for SingleUpdateStep)
I1111 01:11:18.036624  2593 solver.cpp:310]     Train net output #0: loss = 0.396467 (* 1 = 0.396467 loss)
I1111 01:11:18.036651  2593 sgd_solver.cpp:106] Iteration 4413, lr = 0.00025
I1111 01:11:20.424860  2593 solver.cpp:295] Iteration 4414 (no loss supplied for SingleUpdateStep)
I1111 01:11:20.424988  2593 solver.cpp:310]     Train net output #0: loss = 0.334794 (* 1 = 0.334794 loss)
I1111 01:11:20.425016  2593 sgd_solver.cpp:106] Iteration 4414, lr = 0.00025
I1111 01:11:22.938896  2593 solver.cpp:295] Iteration 4415 (no loss supplied for SingleUpdateStep)
I1111 01:11:22.939030  2593 solver.cpp:310]     Train net output #0: loss = 0.368418 (* 1 = 0.368418 loss)
I1111 01:11:22.939056  2593 sgd_solver.cpp:106] Iteration 4415, lr = 0.00025
I1111 01:11:25.848551  2593 solver.cpp:295] Iteration 4416 (no loss supplied for SingleUpdateStep)
I1111 01:11:25.848676  2593 solver.cpp:310]     Train net output #0: loss = 0.392619 (* 1 = 0.392619 loss)
I1111 01:11:25.848700  2593 sgd_solver.cpp:106] Iteration 4416, lr = 0.00025
I1111 01:11:28.585129  2593 solver.cpp:295] Iteration 4417 (no loss supplied for SingleUpdateStep)
I1111 01:11:28.585194  2593 solver.cpp:310]     Train net output #0: loss = 0.339727 (* 1 = 0.339727 loss)
I1111 01:11:28.585214  2593 sgd_solver.cpp:106] Iteration 4417, lr = 0.00025
I1111 01:11:30.954951  2593 solver.cpp:295] Iteration 4418 (no loss supplied for SingleUpdateStep)
I1111 01:11:30.955054  2593 solver.cpp:310]     Train net output #0: loss = 0.387189 (* 1 = 0.387189 loss)
I1111 01:11:30.955076  2593 sgd_solver.cpp:106] Iteration 4418, lr = 0.00025
I1111 01:11:33.357522  2593 solver.cpp:295] Iteration 4419 (no loss supplied for SingleUpdateStep)
I1111 01:11:33.357611  2593 solver.cpp:310]     Train net output #0: loss = 0.363271 (* 1 = 0.363271 loss)
I1111 01:11:33.357631  2593 sgd_solver.cpp:106] Iteration 4419, lr = 0.00025
I1111 01:11:35.999158  2593 solver.cpp:295] Iteration 4420 (no loss supplied for SingleUpdateStep)
I1111 01:11:35.999260  2593 solver.cpp:310]     Train net output #0: loss = 0.383494 (* 1 = 0.383494 loss)
I1111 01:11:35.999284  2593 sgd_solver.cpp:106] Iteration 4420, lr = 0.00025
I1111 01:11:38.875700  2593 solver.cpp:295] Iteration 4421 (no loss supplied for SingleUpdateStep)
I1111 01:11:38.875805  2593 solver.cpp:310]     Train net output #0: loss = 0.385556 (* 1 = 0.385556 loss)
I1111 01:11:38.875828  2593 sgd_solver.cpp:106] Iteration 4421, lr = 0.00025
I1111 01:11:42.430686  2593 solver.cpp:295] Iteration 4422 (no loss supplied for SingleUpdateStep)
I1111 01:11:42.430806  2593 solver.cpp:310]     Train net output #0: loss = 0.417844 (* 1 = 0.417844 loss)
I1111 01:11:42.430829  2593 sgd_solver.cpp:106] Iteration 4422, lr = 0.00025
I1111 01:11:45.878996  2593 solver.cpp:295] Iteration 4423 (no loss supplied for SingleUpdateStep)
I1111 01:11:45.879195  2593 solver.cpp:310]     Train net output #0: loss = 0.353893 (* 1 = 0.353893 loss)
I1111 01:11:45.879236  2593 sgd_solver.cpp:106] Iteration 4423, lr = 0.00025
I1111 01:11:49.619132  2593 solver.cpp:295] Iteration 4424 (no loss supplied for SingleUpdateStep)
I1111 01:11:49.619192  2593 solver.cpp:310]     Train net output #0: loss = 0.386013 (* 1 = 0.386013 loss)
I1111 01:11:49.619212  2593 sgd_solver.cpp:106] Iteration 4424, lr = 0.00025
I1111 01:11:52.910157  2593 solver.cpp:295] Iteration 4425 (no loss supplied for SingleUpdateStep)
I1111 01:11:52.910255  2593 solver.cpp:310]     Train net output #0: loss = 0.369452 (* 1 = 0.369452 loss)
I1111 01:11:52.910277  2593 sgd_solver.cpp:106] Iteration 4425, lr = 0.00025
I1111 01:11:56.071159  2593 solver.cpp:295] Iteration 4426 (no loss supplied for SingleUpdateStep)
I1111 01:11:56.071254  2593 solver.cpp:310]     Train net output #0: loss = 0.344183 (* 1 = 0.344183 loss)
I1111 01:11:56.071275  2593 sgd_solver.cpp:106] Iteration 4426, lr = 0.00025
I1111 01:11:58.394881  2593 solver.cpp:295] Iteration 4427 (no loss supplied for SingleUpdateStep)
I1111 01:11:58.394987  2593 solver.cpp:310]     Train net output #0: loss = 0.391446 (* 1 = 0.391446 loss)
I1111 01:11:58.395009  2593 sgd_solver.cpp:106] Iteration 4427, lr = 0.00025
I1111 01:12:00.899796  2593 solver.cpp:295] Iteration 4428 (no loss supplied for SingleUpdateStep)
I1111 01:12:00.899931  2593 solver.cpp:310]     Train net output #0: loss = 0.37703 (* 1 = 0.37703 loss)
I1111 01:12:00.899953  2593 sgd_solver.cpp:106] Iteration 4428, lr = 0.00025
I1111 01:12:03.414440  2593 solver.cpp:295] Iteration 4429 (no loss supplied for SingleUpdateStep)
I1111 01:12:03.414579  2593 solver.cpp:310]     Train net output #0: loss = 0.374288 (* 1 = 0.374288 loss)
I1111 01:12:03.414602  2593 sgd_solver.cpp:106] Iteration 4429, lr = 0.00025
I1111 01:12:06.021528  2593 solver.cpp:295] Iteration 4430 (no loss supplied for SingleUpdateStep)
I1111 01:12:06.021631  2593 solver.cpp:310]     Train net output #0: loss = 0.350333 (* 1 = 0.350333 loss)
I1111 01:12:06.021652  2593 sgd_solver.cpp:106] Iteration 4430, lr = 0.00025
I1111 01:12:08.232832  2593 solver.cpp:295] Iteration 4431 (no loss supplied for SingleUpdateStep)
I1111 01:12:08.232939  2593 solver.cpp:310]     Train net output #0: loss = 0.37062 (* 1 = 0.37062 loss)
I1111 01:12:08.232961  2593 sgd_solver.cpp:106] Iteration 4431, lr = 0.00025
I1111 01:12:10.702368  2593 solver.cpp:295] Iteration 4432 (no loss supplied for SingleUpdateStep)
I1111 01:12:10.702443  2593 solver.cpp:310]     Train net output #0: loss = 0.376082 (* 1 = 0.376082 loss)
I1111 01:12:10.702463  2593 sgd_solver.cpp:106] Iteration 4432, lr = 0.00025
I1111 01:12:13.296133  2593 solver.cpp:295] Iteration 4433 (no loss supplied for SingleUpdateStep)
I1111 01:12:13.296197  2593 solver.cpp:310]     Train net output #0: loss = 0.374254 (* 1 = 0.374254 loss)
I1111 01:12:13.296216  2593 sgd_solver.cpp:106] Iteration 4433, lr = 0.00025
I1111 01:12:15.728536  2593 solver.cpp:295] Iteration 4434 (no loss supplied for SingleUpdateStep)
I1111 01:12:15.728590  2593 solver.cpp:310]     Train net output #0: loss = 0.368214 (* 1 = 0.368214 loss)
I1111 01:12:15.728610  2593 sgd_solver.cpp:106] Iteration 4434, lr = 0.00025
I1111 01:12:18.058670  2593 solver.cpp:295] Iteration 4435 (no loss supplied for SingleUpdateStep)
I1111 01:12:18.058792  2593 solver.cpp:310]     Train net output #0: loss = 0.381995 (* 1 = 0.381995 loss)
I1111 01:12:18.058817  2593 sgd_solver.cpp:106] Iteration 4435, lr = 0.00025
I1111 01:12:20.341502  2593 solver.cpp:295] Iteration 4436 (no loss supplied for SingleUpdateStep)
I1111 01:12:20.341620  2593 solver.cpp:310]     Train net output #0: loss = 0.397729 (* 1 = 0.397729 loss)
I1111 01:12:20.341647  2593 sgd_solver.cpp:106] Iteration 4436, lr = 0.00025
I1111 01:12:22.573240  2593 solver.cpp:295] Iteration 4437 (no loss supplied for SingleUpdateStep)
I1111 01:12:22.573310  2593 solver.cpp:310]     Train net output #0: loss = 0.364793 (* 1 = 0.364793 loss)
I1111 01:12:22.573330  2593 sgd_solver.cpp:106] Iteration 4437, lr = 0.00025
I1111 01:12:24.760232  2593 solver.cpp:295] Iteration 4438 (no loss supplied for SingleUpdateStep)
I1111 01:12:24.760332  2593 solver.cpp:310]     Train net output #0: loss = 0.349055 (* 1 = 0.349055 loss)
I1111 01:12:24.760354  2593 sgd_solver.cpp:106] Iteration 4438, lr = 0.00025
I1111 01:12:27.286689  2593 solver.cpp:295] Iteration 4439 (no loss supplied for SingleUpdateStep)
I1111 01:12:27.286754  2593 solver.cpp:310]     Train net output #0: loss = 0.381453 (* 1 = 0.381453 loss)
I1111 01:12:27.286778  2593 sgd_solver.cpp:106] Iteration 4439, lr = 0.00025
I1111 01:12:29.645540  2593 solver.cpp:295] Iteration 4440 (no loss supplied for SingleUpdateStep)
I1111 01:12:29.645619  2593 solver.cpp:310]     Train net output #0: loss = 0.363395 (* 1 = 0.363395 loss)
I1111 01:12:29.645642  2593 sgd_solver.cpp:106] Iteration 4440, lr = 0.00025
I1111 01:12:32.210261  2593 solver.cpp:295] Iteration 4441 (no loss supplied for SingleUpdateStep)
I1111 01:12:32.210397  2593 solver.cpp:310]     Train net output #0: loss = 0.405638 (* 1 = 0.405638 loss)
I1111 01:12:32.210419  2593 sgd_solver.cpp:106] Iteration 4441, lr = 0.00025
I1111 01:12:34.625388  2593 solver.cpp:295] Iteration 4442 (no loss supplied for SingleUpdateStep)
I1111 01:12:34.625442  2593 solver.cpp:310]     Train net output #0: loss = 0.358426 (* 1 = 0.358426 loss)
I1111 01:12:34.625461  2593 sgd_solver.cpp:106] Iteration 4442, lr = 0.00025
I1111 01:12:36.978411  2593 solver.cpp:295] Iteration 4443 (no loss supplied for SingleUpdateStep)
I1111 01:12:36.978554  2593 solver.cpp:310]     Train net output #0: loss = 0.366133 (* 1 = 0.366133 loss)
I1111 01:12:36.978576  2593 sgd_solver.cpp:106] Iteration 4443, lr = 0.00025
I1111 01:12:39.410420  2593 solver.cpp:295] Iteration 4444 (no loss supplied for SingleUpdateStep)
I1111 01:12:39.410480  2593 solver.cpp:310]     Train net output #0: loss = 0.381868 (* 1 = 0.381868 loss)
I1111 01:12:39.410501  2593 sgd_solver.cpp:106] Iteration 4444, lr = 0.00025
I1111 01:12:41.934504  2593 solver.cpp:295] Iteration 4445 (no loss supplied for SingleUpdateStep)
I1111 01:12:41.934626  2593 solver.cpp:310]     Train net output #0: loss = 0.40018 (* 1 = 0.40018 loss)
I1111 01:12:41.934648  2593 sgd_solver.cpp:106] Iteration 4445, lr = 0.00025
I1111 01:12:44.569542  2593 solver.cpp:295] Iteration 4446 (no loss supplied for SingleUpdateStep)
I1111 01:12:44.569612  2593 solver.cpp:310]     Train net output #0: loss = 0.354112 (* 1 = 0.354112 loss)
I1111 01:12:44.569633  2593 sgd_solver.cpp:106] Iteration 4446, lr = 0.00025
I1111 01:12:47.308756  2593 solver.cpp:295] Iteration 4447 (no loss supplied for SingleUpdateStep)
I1111 01:12:47.308854  2593 solver.cpp:310]     Train net output #0: loss = 0.40669 (* 1 = 0.40669 loss)
I1111 01:12:47.308874  2593 sgd_solver.cpp:106] Iteration 4447, lr = 0.00025
I1111 01:12:49.756927  2593 solver.cpp:295] Iteration 4448 (no loss supplied for SingleUpdateStep)
I1111 01:12:49.757040  2593 solver.cpp:310]     Train net output #0: loss = 0.366667 (* 1 = 0.366667 loss)
I1111 01:12:49.757061  2593 sgd_solver.cpp:106] Iteration 4448, lr = 0.00025
I1111 01:12:52.120103  2593 solver.cpp:295] Iteration 4449 (no loss supplied for SingleUpdateStep)
I1111 01:12:52.120343  2593 solver.cpp:310]     Train net output #0: loss = 0.385975 (* 1 = 0.385975 loss)
I1111 01:12:52.120378  2593 sgd_solver.cpp:106] Iteration 4449, lr = 0.00025
I1111 01:12:54.726744  2593 solver.cpp:295] Iteration 4450 (no loss supplied for SingleUpdateStep)
I1111 01:12:54.726841  2593 solver.cpp:310]     Train net output #0: loss = 0.377033 (* 1 = 0.377033 loss)
I1111 01:12:54.726862  2593 sgd_solver.cpp:106] Iteration 4450, lr = 0.00025
I1111 01:12:56.939744  2593 solver.cpp:295] Iteration 4451 (no loss supplied for SingleUpdateStep)
I1111 01:12:56.939833  2593 solver.cpp:310]     Train net output #0: loss = 0.361716 (* 1 = 0.361716 loss)
I1111 01:12:56.939852  2593 sgd_solver.cpp:106] Iteration 4451, lr = 0.00025
I1111 01:12:59.419526  2593 solver.cpp:295] Iteration 4452 (no loss supplied for SingleUpdateStep)
I1111 01:12:59.419620  2593 solver.cpp:310]     Train net output #0: loss = 0.355906 (* 1 = 0.355906 loss)
I1111 01:12:59.419641  2593 sgd_solver.cpp:106] Iteration 4452, lr = 0.00025
I1111 01:13:01.639678  2593 solver.cpp:295] Iteration 4453 (no loss supplied for SingleUpdateStep)
I1111 01:13:01.639780  2593 solver.cpp:310]     Train net output #0: loss = 0.354122 (* 1 = 0.354122 loss)
I1111 01:13:01.639802  2593 sgd_solver.cpp:106] Iteration 4453, lr = 0.00025
I1111 01:13:03.836267  2593 solver.cpp:295] Iteration 4454 (no loss supplied for SingleUpdateStep)
I1111 01:13:03.836343  2593 solver.cpp:310]     Train net output #0: loss = 0.386743 (* 1 = 0.386743 loss)
I1111 01:13:03.836361  2593 sgd_solver.cpp:106] Iteration 4454, lr = 0.00025
I1111 01:13:06.252915  2593 solver.cpp:295] Iteration 4455 (no loss supplied for SingleUpdateStep)
I1111 01:13:06.253015  2593 solver.cpp:310]     Train net output #0: loss = 0.386345 (* 1 = 0.386345 loss)
I1111 01:13:06.253036  2593 sgd_solver.cpp:106] Iteration 4455, lr = 0.00025
I1111 01:13:09.100184  2593 solver.cpp:295] Iteration 4456 (no loss supplied for SingleUpdateStep)
I1111 01:13:09.100244  2593 solver.cpp:310]     Train net output #0: loss = 0.400053 (* 1 = 0.400053 loss)
I1111 01:13:09.100263  2593 sgd_solver.cpp:106] Iteration 4456, lr = 0.00025
I1111 01:13:11.410079  2593 solver.cpp:295] Iteration 4457 (no loss supplied for SingleUpdateStep)
I1111 01:13:11.410166  2593 solver.cpp:310]     Train net output #0: loss = 0.35586 (* 1 = 0.35586 loss)
I1111 01:13:11.410186  2593 sgd_solver.cpp:106] Iteration 4457, lr = 0.00025
I1111 01:13:13.628196  2593 solver.cpp:295] Iteration 4458 (no loss supplied for SingleUpdateStep)
I1111 01:13:13.628299  2593 solver.cpp:310]     Train net output #0: loss = 0.366503 (* 1 = 0.366503 loss)
I1111 01:13:13.628322  2593 sgd_solver.cpp:106] Iteration 4458, lr = 0.00025
I1111 01:13:15.949615  2593 solver.cpp:295] Iteration 4459 (no loss supplied for SingleUpdateStep)
I1111 01:13:15.949726  2593 solver.cpp:310]     Train net output #0: loss = 0.350198 (* 1 = 0.350198 loss)
I1111 01:13:15.949751  2593 sgd_solver.cpp:106] Iteration 4459, lr = 0.00025
I1111 01:13:18.345335  2593 solver.cpp:295] Iteration 4460 (no loss supplied for SingleUpdateStep)
I1111 01:13:18.345456  2593 solver.cpp:310]     Train net output #0: loss = 0.386409 (* 1 = 0.386409 loss)
I1111 01:13:18.345477  2593 sgd_solver.cpp:106] Iteration 4460, lr = 0.00025
I1111 01:13:20.748488  2593 solver.cpp:295] Iteration 4461 (no loss supplied for SingleUpdateStep)
I1111 01:13:20.748544  2593 solver.cpp:310]     Train net output #0: loss = 0.415934 (* 1 = 0.415934 loss)
I1111 01:13:20.748565  2593 sgd_solver.cpp:106] Iteration 4461, lr = 0.00025
I1111 01:13:23.187432  2593 solver.cpp:295] Iteration 4462 (no loss supplied for SingleUpdateStep)
I1111 01:13:23.187492  2593 solver.cpp:310]     Train net output #0: loss = 0.390278 (* 1 = 0.390278 loss)
I1111 01:13:23.187512  2593 sgd_solver.cpp:106] Iteration 4462, lr = 0.00025
I1111 01:13:25.755348  2593 solver.cpp:295] Iteration 4463 (no loss supplied for SingleUpdateStep)
I1111 01:13:25.755452  2593 solver.cpp:310]     Train net output #0: loss = 0.404387 (* 1 = 0.404387 loss)
I1111 01:13:25.755475  2593 sgd_solver.cpp:106] Iteration 4463, lr = 0.00025
I1111 01:13:28.360141  2593 solver.cpp:295] Iteration 4464 (no loss supplied for SingleUpdateStep)
I1111 01:13:28.360218  2593 solver.cpp:310]     Train net output #0: loss = 0.363399 (* 1 = 0.363399 loss)
I1111 01:13:28.360237  2593 sgd_solver.cpp:106] Iteration 4464, lr = 0.00025
I1111 01:13:30.842274  2593 solver.cpp:295] Iteration 4465 (no loss supplied for SingleUpdateStep)
I1111 01:13:30.842385  2593 solver.cpp:310]     Train net output #0: loss = 0.382264 (* 1 = 0.382264 loss)
I1111 01:13:30.842406  2593 sgd_solver.cpp:106] Iteration 4465, lr = 0.00025
I1111 01:13:33.578727  2593 solver.cpp:295] Iteration 4466 (no loss supplied for SingleUpdateStep)
I1111 01:13:33.578826  2593 solver.cpp:310]     Train net output #0: loss = 0.383076 (* 1 = 0.383076 loss)
I1111 01:13:33.578848  2593 sgd_solver.cpp:106] Iteration 4466, lr = 0.00025
I1111 01:13:36.058740  2593 solver.cpp:295] Iteration 4467 (no loss supplied for SingleUpdateStep)
I1111 01:13:36.058887  2593 solver.cpp:310]     Train net output #0: loss = 0.369733 (* 1 = 0.369733 loss)
I1111 01:13:36.058910  2593 sgd_solver.cpp:106] Iteration 4467, lr = 0.00025
I1111 01:13:38.436069  2593 solver.cpp:295] Iteration 4468 (no loss supplied for SingleUpdateStep)
I1111 01:13:38.436127  2593 solver.cpp:310]     Train net output #0: loss = 0.361695 (* 1 = 0.361695 loss)
I1111 01:13:38.436146  2593 sgd_solver.cpp:106] Iteration 4468, lr = 0.00025
I1111 01:13:40.726738  2593 solver.cpp:295] Iteration 4469 (no loss supplied for SingleUpdateStep)
I1111 01:13:40.726850  2593 solver.cpp:310]     Train net output #0: loss = 0.412826 (* 1 = 0.412826 loss)
I1111 01:13:40.726877  2593 sgd_solver.cpp:106] Iteration 4469, lr = 0.00025
I1111 01:13:43.035245  2593 solver.cpp:295] Iteration 4470 (no loss supplied for SingleUpdateStep)
I1111 01:13:43.035300  2593 solver.cpp:310]     Train net output #0: loss = 0.382104 (* 1 = 0.382104 loss)
I1111 01:13:43.035320  2593 sgd_solver.cpp:106] Iteration 4470, lr = 0.00025
I1111 01:13:45.296126  2593 solver.cpp:295] Iteration 4471 (no loss supplied for SingleUpdateStep)
I1111 01:13:45.296226  2593 solver.cpp:310]     Train net output #0: loss = 0.391783 (* 1 = 0.391783 loss)
I1111 01:13:45.296249  2593 sgd_solver.cpp:106] Iteration 4471, lr = 0.00025
I1111 01:13:47.628918  2593 solver.cpp:295] Iteration 4472 (no loss supplied for SingleUpdateStep)
I1111 01:13:47.629011  2593 solver.cpp:310]     Train net output #0: loss = 0.389524 (* 1 = 0.389524 loss)
I1111 01:13:47.629034  2593 sgd_solver.cpp:106] Iteration 4472, lr = 0.00025
I1111 01:13:49.837469  2593 solver.cpp:295] Iteration 4473 (no loss supplied for SingleUpdateStep)
I1111 01:13:49.837587  2593 solver.cpp:310]     Train net output #0: loss = 0.37535 (* 1 = 0.37535 loss)
I1111 01:13:49.837609  2593 sgd_solver.cpp:106] Iteration 4473, lr = 0.00025
I1111 01:13:52.165654  2593 solver.cpp:295] Iteration 4474 (no loss supplied for SingleUpdateStep)
I1111 01:13:52.165765  2593 solver.cpp:310]     Train net output #0: loss = 0.349099 (* 1 = 0.349099 loss)
I1111 01:13:52.165786  2593 sgd_solver.cpp:106] Iteration 4474, lr = 0.00025
I1111 01:13:54.549214  2593 solver.cpp:295] Iteration 4475 (no loss supplied for SingleUpdateStep)
I1111 01:13:54.549327  2593 solver.cpp:310]     Train net output #0: loss = 0.360881 (* 1 = 0.360881 loss)
I1111 01:13:54.549350  2593 sgd_solver.cpp:106] Iteration 4475, lr = 0.00025
I1111 01:13:56.891765  2593 solver.cpp:295] Iteration 4476 (no loss supplied for SingleUpdateStep)
I1111 01:13:56.891891  2593 solver.cpp:310]     Train net output #0: loss = 0.381801 (* 1 = 0.381801 loss)
I1111 01:13:56.891918  2593 sgd_solver.cpp:106] Iteration 4476, lr = 0.00025
I1111 01:13:59.171879  2593 solver.cpp:295] Iteration 4477 (no loss supplied for SingleUpdateStep)
I1111 01:13:59.171989  2593 solver.cpp:310]     Train net output #0: loss = 0.409664 (* 1 = 0.409664 loss)
I1111 01:13:59.172011  2593 sgd_solver.cpp:106] Iteration 4477, lr = 0.00025
I1111 01:14:01.601016  2593 solver.cpp:295] Iteration 4478 (no loss supplied for SingleUpdateStep)
I1111 01:14:01.601099  2593 solver.cpp:310]     Train net output #0: loss = 0.385358 (* 1 = 0.385358 loss)
I1111 01:14:01.601117  2593 sgd_solver.cpp:106] Iteration 4478, lr = 0.00025
I1111 01:14:03.937850  2593 solver.cpp:295] Iteration 4479 (no loss supplied for SingleUpdateStep)
I1111 01:14:03.937912  2593 solver.cpp:310]     Train net output #0: loss = 0.366694 (* 1 = 0.366694 loss)
I1111 01:14:03.937932  2593 sgd_solver.cpp:106] Iteration 4479, lr = 0.00025
I1111 01:14:06.157511  2593 solver.cpp:295] Iteration 4480 (no loss supplied for SingleUpdateStep)
I1111 01:14:06.157567  2593 solver.cpp:310]     Train net output #0: loss = 0.394221 (* 1 = 0.394221 loss)
I1111 01:14:06.157587  2593 sgd_solver.cpp:106] Iteration 4480, lr = 0.00025
I1111 01:14:08.995321  2593 solver.cpp:295] Iteration 4481 (no loss supplied for SingleUpdateStep)
I1111 01:14:08.995381  2593 solver.cpp:310]     Train net output #0: loss = 0.347585 (* 1 = 0.347585 loss)
I1111 01:14:08.995400  2593 sgd_solver.cpp:106] Iteration 4481, lr = 0.00025
I1111 01:14:12.618108  2593 solver.cpp:295] Iteration 4482 (no loss supplied for SingleUpdateStep)
I1111 01:14:12.618170  2593 solver.cpp:310]     Train net output #0: loss = 0.366348 (* 1 = 0.366348 loss)
I1111 01:14:12.618190  2593 sgd_solver.cpp:106] Iteration 4482, lr = 0.00025
I1111 01:14:15.997704  2593 solver.cpp:295] Iteration 4483 (no loss supplied for SingleUpdateStep)
I1111 01:14:15.997802  2593 solver.cpp:310]     Train net output #0: loss = 0.384866 (* 1 = 0.384866 loss)
I1111 01:14:15.997822  2593 sgd_solver.cpp:106] Iteration 4483, lr = 0.00025
I1111 01:14:18.387720  2593 solver.cpp:295] Iteration 4484 (no loss supplied for SingleUpdateStep)
I1111 01:14:18.387835  2593 solver.cpp:310]     Train net output #0: loss = 0.386656 (* 1 = 0.386656 loss)
I1111 01:14:18.387861  2593 sgd_solver.cpp:106] Iteration 4484, lr = 0.00025
I1111 01:14:20.757681  2593 solver.cpp:295] Iteration 4485 (no loss supplied for SingleUpdateStep)
I1111 01:14:20.757787  2593 solver.cpp:310]     Train net output #0: loss = 0.36292 (* 1 = 0.36292 loss)
I1111 01:14:20.757810  2593 sgd_solver.cpp:106] Iteration 4485, lr = 0.00025
I1111 01:14:23.026908  2593 solver.cpp:295] Iteration 4486 (no loss supplied for SingleUpdateStep)
I1111 01:14:23.026978  2593 solver.cpp:310]     Train net output #0: loss = 0.380874 (* 1 = 0.380874 loss)
I1111 01:14:23.026998  2593 sgd_solver.cpp:106] Iteration 4486, lr = 0.00025
I1111 01:14:25.339597  2593 solver.cpp:295] Iteration 4487 (no loss supplied for SingleUpdateStep)
I1111 01:14:25.339705  2593 solver.cpp:310]     Train net output #0: loss = 0.371532 (* 1 = 0.371532 loss)
I1111 01:14:25.339727  2593 sgd_solver.cpp:106] Iteration 4487, lr = 0.00025
I1111 01:14:27.825114  2593 solver.cpp:295] Iteration 4488 (no loss supplied for SingleUpdateStep)
I1111 01:14:27.825209  2593 solver.cpp:310]     Train net output #0: loss = 0.384351 (* 1 = 0.384351 loss)
I1111 01:14:27.825232  2593 sgd_solver.cpp:106] Iteration 4488, lr = 0.00025
I1111 01:14:30.256115  2593 solver.cpp:295] Iteration 4489 (no loss supplied for SingleUpdateStep)
I1111 01:14:30.256219  2593 solver.cpp:310]     Train net output #0: loss = 0.400873 (* 1 = 0.400873 loss)
I1111 01:14:30.256239  2593 sgd_solver.cpp:106] Iteration 4489, lr = 0.00025
I1111 01:14:32.607076  2593 solver.cpp:295] Iteration 4490 (no loss supplied for SingleUpdateStep)
I1111 01:14:32.607205  2593 solver.cpp:310]     Train net output #0: loss = 0.385681 (* 1 = 0.385681 loss)
I1111 01:14:32.607230  2593 sgd_solver.cpp:106] Iteration 4490, lr = 0.00025
I1111 01:14:35.061542  2593 solver.cpp:295] Iteration 4491 (no loss supplied for SingleUpdateStep)
I1111 01:14:35.061689  2593 solver.cpp:310]     Train net output #0: loss = 0.368818 (* 1 = 0.368818 loss)
I1111 01:14:35.061713  2593 sgd_solver.cpp:106] Iteration 4491, lr = 0.00025
I1111 01:14:37.396759  2593 solver.cpp:295] Iteration 4492 (no loss supplied for SingleUpdateStep)
I1111 01:14:37.396904  2593 solver.cpp:310]     Train net output #0: loss = 0.362731 (* 1 = 0.362731 loss)
I1111 01:14:37.396927  2593 sgd_solver.cpp:106] Iteration 4492, lr = 0.00025
I1111 01:14:39.793395  2593 solver.cpp:295] Iteration 4493 (no loss supplied for SingleUpdateStep)
I1111 01:14:39.793505  2593 solver.cpp:310]     Train net output #0: loss = 0.337464 (* 1 = 0.337464 loss)
I1111 01:14:39.793526  2593 sgd_solver.cpp:106] Iteration 4493, lr = 0.00025
I1111 01:14:42.296871  2593 solver.cpp:295] Iteration 4494 (no loss supplied for SingleUpdateStep)
I1111 01:14:42.296995  2593 solver.cpp:310]     Train net output #0: loss = 0.386445 (* 1 = 0.386445 loss)
I1111 01:14:42.297024  2593 sgd_solver.cpp:106] Iteration 4494, lr = 0.00025
I1111 01:14:44.794348  2593 solver.cpp:295] Iteration 4495 (no loss supplied for SingleUpdateStep)
I1111 01:14:44.794410  2593 solver.cpp:310]     Train net output #0: loss = 0.393988 (* 1 = 0.393988 loss)
I1111 01:14:44.794430  2593 sgd_solver.cpp:106] Iteration 4495, lr = 0.00025
I1111 01:14:47.171175  2593 solver.cpp:295] Iteration 4496 (no loss supplied for SingleUpdateStep)
I1111 01:14:47.171280  2593 solver.cpp:310]     Train net output #0: loss = 0.356297 (* 1 = 0.356297 loss)
I1111 01:14:47.171303  2593 sgd_solver.cpp:106] Iteration 4496, lr = 0.00025
I1111 01:14:49.812252  2593 solver.cpp:295] Iteration 4497 (no loss supplied for SingleUpdateStep)
I1111 01:14:49.812381  2593 solver.cpp:310]     Train net output #0: loss = 0.360459 (* 1 = 0.360459 loss)
I1111 01:14:49.812420  2593 sgd_solver.cpp:106] Iteration 4497, lr = 0.00025
I1111 01:14:52.269104  2593 solver.cpp:295] Iteration 4498 (no loss supplied for SingleUpdateStep)
I1111 01:14:52.269193  2593 solver.cpp:310]     Train net output #0: loss = 0.343337 (* 1 = 0.343337 loss)
I1111 01:14:52.269214  2593 sgd_solver.cpp:106] Iteration 4498, lr = 0.00025
I1111 01:14:54.589572  2593 solver.cpp:295] Iteration 4499 (no loss supplied for SingleUpdateStep)
I1111 01:14:54.589629  2593 solver.cpp:310]     Train net output #0: loss = 0.356395 (* 1 = 0.356395 loss)
I1111 01:14:54.589648  2593 sgd_solver.cpp:106] Iteration 4499, lr = 0.00025
I1111 01:14:56.939844  2593 solver.cpp:295] Iteration 4500 (no loss supplied for SingleUpdateStep)
I1111 01:14:56.939908  2593 solver.cpp:310]     Train net output #0: loss = 0.385834 (* 1 = 0.385834 loss)
I1111 01:14:56.939929  2593 sgd_solver.cpp:106] Iteration 4500, lr = 0.000125
Setting caffe mode: GPU
Doing special batch 0 stuff!
multiplied parameters by 6.220843 (old param norm 2.554631, new param norm 15.891956)
0 train loss is 1.01958870888
0 val loss is 1.00860655308
1 train loss is 0.976724684238
1 val loss is 1.01131939888
2 train loss is 1.01556777954
2 val loss is 1.01108622551
3 train loss is 0.944301247597
3 val loss is 1.01229417324
4 train loss is 1.01643776894
4 val loss is 1.01521956921
5 train loss is 0.997278273106
5 val loss is 1.01187598705
6 train loss is 0.993324041367
6 val loss is 1.0138938427
7 train loss is 0.925577163696
7 val loss is 1.01444935799
8 train loss is 0.968648076057
8 val loss is 1.01836025715
9 train loss is 1.04947292805
9 val loss is 1.02089214325
10 train loss is 1.03384661674
10 val loss is 1.0172573328
11 train loss is 1.04829311371
11 val loss is 1.01426160336
12 train loss is 1.01745855808
12 val loss is 1.02011227608
13 train loss is 1.04585003853
13 val loss is 1.02255356312
14 train loss is 0.978581786156
14 val loss is 1.0204590559
15 train loss is 0.921099722385
15 val loss is 1.02339804173
16 train loss is 1.03671216965
16 val loss is 1.02844822407
17 train loss is 0.936196148396
17 val loss is 1.02830028534
18 train loss is 1.05048942566
18 val loss is 1.02100718021
19 train loss is 1.05363321304
19 val loss is 1.01753878593
20 train loss is 1.02052116394
20 val loss is 1.01784431934
21 train loss is 1.11343741417
21 val loss is 1.02225422859
22 train loss is 0.993010163307
22 val loss is 1.01920568943
23 train loss is 0.998250246048
23 val loss is 1.0221350193
24 train loss is 1.03375291824
24 val loss is 1.03113782406
25 train loss is 1.07047736645
25 val loss is 1.02711880207
26 train loss is 0.988011360168
26 val loss is 1.02061033249
27 train loss is 1.02629470825
27 val loss is 1.02347922325
28 train loss is 1.03256440163
28 val loss is 1.02231442928
29 train loss is 0.988003969193
29 val loss is 1.01962971687
30 train loss is 0.986445248127
30 val loss is 1.03049218655
31 train loss is 1.01587629318
31 val loss is 1.04064679146
32 train loss is 1.08298838139
32 val loss is 1.03086876869
33 train loss is 1.00557923317
33 val loss is 1.02272462845
34 train loss is 0.950754284859
34 val loss is 1.02787935734
35 train loss is 0.991865575314
35 val loss is 1.02970504761
36 train loss is 1.05361282825
36 val loss is 1.02030277252
37 train loss is 1.00464618206
37 val loss is 1.02902889252
38 train loss is 0.982366263866
38 val loss is 1.04334235191
39 train loss is 0.99681866169
39 val loss is 1.03273952007
40 train loss is 1.05251646042
40 val loss is 1.02204501629
41 train loss is 1.02572822571
41 val loss is 1.0209376812
42 train loss is 1.02775931358
42 val loss is 1.02673482895
43 train loss is 0.976105868816
43 val loss is 1.02974140644
44 train loss is 1.02384531498
44 val loss is 1.03241539001
45 train loss is 0.989125549793
45 val loss is 1.038007617
46 train loss is 1.14505171776
46 val loss is 1.0386685133
47 train loss is 1.06285893917
47 val loss is 1.04095053673
48 train loss is 1.14594316483
48 val loss is 1.03751349449
49 train loss is 1.06807303429
49 val loss is 1.0218886137
50 train loss is 1.06589126587
50 val loss is 1.02703428268
51 train loss is 0.906591892242
51 val loss is 1.05450248718
52 train loss is 1.00640487671
52 val loss is 1.05931007862
53 train loss is 0.953998088837
53 val loss is 1.03809010983
54 train loss is 1.05151581764
54 val loss is 1.02975928783
55 train loss is 0.964452564716
55 val loss is 1.0432677269
56 train loss is 1.04686141014
56 val loss is 1.02776050568
57 train loss is 1.01024365425
57 val loss is 1.0130636692
58 train loss is 0.949420213699
58 val loss is 1.04943311214
59 train loss is 1.07329070568
59 val loss is 1.05772829056
60 train loss is 1.07948899269
60 val loss is 1.02118778229
61 train loss is 1.0277094841
61 val loss is 1.03750932217
62 train loss is 1.03934025764
62 val loss is 1.05974626541
63 train loss is 1.02607285976
63 val loss is 1.0257755518
64 train loss is 0.995906174183
64 val loss is 1.02443563938
65 train loss is 1.05931043625
65 val loss is 1.07097971439
66 train loss is 0.992409110069
66 val loss is 1.06224238873
67 train loss is 0.972244203091
67 val loss is 1.01925182343
68 train loss is 0.937546730042
68 val loss is 1.02702569962
69 train loss is 0.990160942078
69 val loss is 1.03842639923
70 train loss is 1.07969355583
70 val loss is 1.01488876343
71 train loss is 1.05971586704
71 val loss is 1.01432967186
72 train loss is 0.99337387085
72 val loss is 1.04209327698
73 train loss is 0.984471678734
73 val loss is 1.04227602482
74 train loss is 1.0004093647
74 val loss is 1.01867425442
75 train loss is 1.03530132771
75 val loss is 1.02409505844
76 train loss is 0.987915992737
76 val loss is 1.03050065041
77 train loss is 0.973765611649
77 val loss is 1.01257514954
78 train loss is 1.0202524662
78 val loss is 1.02675294876
79 train loss is 0.990022540092
79 val loss is 1.04011917114
80 train loss is 1.03548252583
80 val loss is 1.02684402466
81 train loss is 1.02695226669
81 val loss is 1.01315748692
82 train loss is 0.949968039989
82 val loss is 1.01839435101
83 train loss is 0.911450982094
83 val loss is 1.01455068588
84 train loss is 1.01071238518
84 val loss is 1.00010800362
85 train loss is 0.946895360947
85 val loss is 1.01746726036
86 train loss is 1.00330364704
86 val loss is 1.03920006752
87 train loss is 1.07905435562
87 val loss is 1.02262043953
88 train loss is 1.02403879166
88 val loss is 1.00911140442
89 train loss is 0.944190382957
89 val loss is 1.01859009266
90 train loss is 0.944588899612
90 val loss is 1.01624298096
91 train loss is 0.939049243927
91 val loss is 0.998956143856
92 train loss is 1.02607488632
92 val loss is 1.00756430626
93 train loss is 1.04986381531
93 val loss is 1.02424383163
94 train loss is 1.01463794708
94 val loss is 1.0202382803
95 train loss is 1.05944538116
95 val loss is 1.01385831833
96 train loss is 1.03050363064
96 val loss is 1.01090812683
97 train loss is 1.05602908134
97 val loss is 1.00637471676
98 train loss is 1.0335214138
98 val loss is 0.999612510204
99 train loss is 1.00930941105
99 val loss is 1.01332068443
100 train loss is 1.01047539711
100 val loss is 1.01560461521
101 train loss is 0.982322692871
101 val loss is 1.00900006294
102 train loss is 0.993946433067
102 val loss is 1.01904165745
103 train loss is 0.922808885574
103 val loss is 1.01485347748
104 train loss is 0.998257756233
104 val loss is 0.996003329754
105 train loss is 0.971787750721
105 val loss is 0.99437379837
106 train loss is 1.00644886494
106 val loss is 0.999788999557
107 train loss is 0.949501991272
107 val loss is 1.00102770329
108 train loss is 1.04101121426
108 val loss is 1.0042154789
109 train loss is 0.977299273014
109 val loss is 0.994122207165
110 train loss is 0.931696474552
110 val loss is 0.989780128002
111 train loss is 0.905367970467
111 val loss is 0.999076426029
112 train loss is 0.96934735775
112 val loss is 0.995920538902
113 train loss is 1.00936889648
113 val loss is 0.986720144749
114 train loss is 0.965071082115
114 val loss is 0.995923280716
115 train loss is 0.961502790451
115 val loss is 0.995157659054
116 train loss is 1.03846371174
116 val loss is 0.987540781498
117 train loss is 0.971943736076
117 val loss is 0.987639009953
118 train loss is 0.982065618038
118 val loss is 0.989096462727
119 train loss is 1.00944328308
119 val loss is 0.978218793869
120 train loss is 1.03297936916
120 val loss is 0.98118686676
121 train loss is 0.921440958977
121 val loss is 0.993006169796
122 train loss is 0.955832839012
122 val loss is 0.986192464828
123 train loss is 0.975569784641
123 val loss is 0.974585533142
124 train loss is 0.952467441559
124 val loss is 0.975001096725
125 train loss is 0.995201468468
125 val loss is 0.972185134888
126 train loss is 0.934515714645
126 val loss is 0.967422783375
127 train loss is 0.948688447475
127 val loss is 0.975812673569
128 train loss is 1.00411677361
128 val loss is 0.992140769958
129 train loss is 0.960516571999
129 val loss is 0.990563869476
130 train loss is 0.912413656712
130 val loss is 0.976594209671
131 train loss is 0.883835792542
131 val loss is 0.982609510422
132 train loss is 0.980178177357
132 val loss is 0.980801284313
133 train loss is 0.934251070023
133 val loss is 0.963085830212
134 train loss is 0.973110795021
134 val loss is 0.968100726604
135 train loss is 0.902683794498
135 val loss is 0.987162351608
136 train loss is 0.952094495296
136 val loss is 0.979742109776
137 train loss is 0.906314849854
137 val loss is 0.967055499554
138 train loss is 0.967713117599
138 val loss is 0.969056010246
139 train loss is 0.99859982729
139 val loss is 0.970219016075
140 train loss is 0.979943990707
140 val loss is 0.959669947624
141 train loss is 0.955838799477
141 val loss is 0.962675094604
142 train loss is 0.934090435505
142 val loss is 0.983772158623
143 train loss is 1.02851939201
143 val loss is 0.97919023037
144 train loss is 1.0302271843
144 val loss is 0.960183382034
145 train loss is 0.939168810844
145 val loss is 0.960339844227
146 train loss is 1.02291250229
146 val loss is 0.971909344196
147 train loss is 0.961667358875
147 val loss is 0.96302729845
148 train loss is 0.923597455025
148 val loss is 0.959780275822
149 train loss is 0.957276701927
149 val loss is 0.977069139481
150 train loss is 0.917005896568
150 val loss is 0.98170620203
151 train loss is 0.992483615875
151 val loss is 0.957797288895
152 train loss is 0.972869575024
152 val loss is 0.952925741673
153 train loss is 0.88296854496
153 val loss is 0.974716544151
154 train loss is 0.964226722717
154 val loss is 0.976302683353
155 train loss is 0.863250792027
155 val loss is 0.961021184921
156 train loss is 0.969973146915
156 val loss is 0.981386482716
157 train loss is 0.908190727234
157 val loss is 0.991173744202
158 train loss is 0.979141592979
158 val loss is 0.963299393654
159 train loss is 0.978264212608
159 val loss is 0.954540133476
160 train loss is 0.896679580212
160 val loss is 0.969007611275
161 train loss is 0.976352930069
161 val loss is 0.958274424076
162 train loss is 0.961653828621
162 val loss is 0.950738787651
163 train loss is 0.950538158417
163 val loss is 0.978148818016
164 train loss is 0.961175143719
164 val loss is 0.971657454967
165 train loss is 0.890516161919
165 val loss is 0.946846604347
166 train loss is 0.880269765854
166 val loss is 0.951695382595
167 train loss is 0.890944421291
167 val loss is 0.965100049973
168 train loss is 0.942680895329
168 val loss is 0.956196784973
169 train loss is 0.889006078243
169 val loss is 0.953835487366
170 train loss is 0.929661273956
170 val loss is 0.968535780907
171 train loss is 0.878914177418
171 val loss is 0.966857552528
172 train loss is 0.903923153877
172 val loss is 0.952593326569
173 train loss is 0.92439442873
173 val loss is 0.942948043346
174 train loss is 0.908576071262
174 val loss is 0.955356299877
175 train loss is 0.981975913048
175 val loss is 0.957531094551
176 train loss is 0.941520988941
176 val loss is 0.95884346962
177 train loss is 0.912033319473
177 val loss is 0.971035420895
178 train loss is 1.01825761795
178 val loss is 0.968567669392
179 train loss is 0.965959489346
179 val loss is 0.954471111298
180 train loss is 0.919784069061
180 val loss is 0.952389717102
181 train loss is 0.98306787014
181 val loss is 0.950640201569
182 train loss is 0.951290845871
182 val loss is 0.952596783638
183 train loss is 0.941327750683
183 val loss is 0.960924625397
184 train loss is 0.929879844189
184 val loss is 0.977583765984
185 train loss is 0.960723042488
185 val loss is 0.971568048
186 train loss is 0.99467921257
186 val loss is 0.94729924202
187 train loss is 1.00397324562
187 val loss is 0.947380840778
188 train loss is 0.964648425579
188 val loss is 0.960627675056
189 train loss is 0.928898453712
189 val loss is 0.952426493168
190 train loss is 1.00443601608
190 val loss is 0.946573257446
191 train loss is 0.92600184679
191 val loss is 0.960750341415
192 train loss is 0.918625771999
192 val loss is 0.974998235703
193 train loss is 0.957362651825
193 val loss is 0.946018815041
194 train loss is 0.906740307808
194 val loss is 0.936446905136
195 train loss is 0.942842483521
195 val loss is 0.954556465149
196 train loss is 0.998613715172
196 val loss is 0.943351864815
197 train loss is 0.947416305542
197 val loss is 0.931300103664
198 train loss is 0.88208091259
198 val loss is 0.95473587513
199 train loss is 0.959230661392
199 val loss is 0.964324951172
200 train loss is 0.906527280807
200 val loss is 0.932890415192
201 train loss is 0.894224703312
201 val loss is 0.918317735195
202 train loss is 0.868036627769
202 val loss is 0.946546912193
203 train loss is 0.922105312347
203 val loss is 0.941435217857
204 train loss is 0.940612375736
204 val loss is 0.921852707863
205 train loss is 0.921352207661
205 val loss is 0.942243456841
206 train loss is 0.919389307499
206 val loss is 0.962215065956
207 train loss is 0.925070524216
207 val loss is 0.938684463501
208 train loss is 0.904195070267
208 val loss is 0.918173849583
209 train loss is 0.964215099812
209 val loss is 0.940198421478
210 train loss is 0.889684200287
210 val loss is 0.939049959183
211 train loss is 0.849294245243
211 val loss is 0.920119166374
212 train loss is 0.878071546555
212 val loss is 0.930128693581
213 train loss is 0.908435225487
213 val loss is 0.94805753231
214 train loss is 0.932475805283
214 val loss is 0.926988661289
215 train loss is 1.0562274456
215 val loss is 0.907522916794
216 train loss is 0.92515450716
216 val loss is 0.931003808975
217 train loss is 0.959706366062
217 val loss is 0.941854596138
218 train loss is 0.937283277512
218 val loss is 0.913388967514
219 train loss is 0.935275793076
219 val loss is 0.921860635281
220 train loss is 0.877098798752
220 val loss is 0.951818466187
221 train loss is 0.949064016342
221 val loss is 0.933990120888
222 train loss is 0.893194019794
222 val loss is 0.907723665237
223 train loss is 0.811628341675
223 val loss is 0.921231269836
224 train loss is 1.01482057571
224 val loss is 0.923870742321
225 train loss is 0.874815583229
225 val loss is 0.915488362312
226 train loss is 0.892260193825
226 val loss is 0.927742183208
227 train loss is 0.834000170231
227 val loss is 0.943123877048
228 train loss is 0.947695672512
228 val loss is 0.924653530121
229 train loss is 0.870578467846
229 val loss is 0.90959829092
230 train loss is 0.905110895634
230 val loss is 0.919171750546
231 train loss is 0.870103180408
231 val loss is 0.930683970451
232 train loss is 0.903522014618
232 val loss is 0.920789301395
233 train loss is 0.917858719826
233 val loss is 0.920547664165
234 train loss is 0.92051255703
234 val loss is 0.922037124634
235 train loss is 0.913122415543
235 val loss is 0.91601151228
236 train loss is 0.879967987537
236 val loss is 0.905233383179
237 train loss is 0.883187651634
237 val loss is 0.908685684204
238 train loss is 0.938038825989
238 val loss is 0.907602488995
239 train loss is 0.855811238289
239 val loss is 0.904521882534
240 train loss is 0.93056678772
240 val loss is 0.922233879566
241 train loss is 0.980399847031
241 val loss is 0.917421102524
242 train loss is 0.94669085741
242 val loss is 0.895129978657
243 train loss is 0.905104160309
243 val loss is 0.903005182743
244 train loss is 0.896098971367
244 val loss is 0.910812973976
245 train loss is 0.917958915234
245 val loss is 0.899409413338
246 train loss is 0.856305360794
246 val loss is 0.898643791676
247 train loss is 0.893605530262
247 val loss is 0.925510168076
248 train loss is 0.907715857029
248 val loss is 0.920043587685
249 train loss is 0.977228701115
249 val loss is 0.89870262146
250 train loss is 0.903000593185
250 val loss is 0.906777083874
251 train loss is 0.844845592976
251 val loss is 0.914955377579
252 train loss is 0.91355919838
252 val loss is 0.891716241837
253 train loss is 0.910749435425
253 val loss is 0.901032686234
254 train loss is 0.916615486145
254 val loss is 0.93391251564
255 train loss is 0.865635693073
255 val loss is 0.916705191135
256 train loss is 0.848648130894
256 val loss is 0.885544776917
257 train loss is 0.933183014393
257 val loss is 0.902966141701
258 train loss is 0.921485483646
258 val loss is 0.908618032932
259 train loss is 0.902042448521
259 val loss is 0.879389703274
260 train loss is 0.846400201321
260 val loss is 0.891070604324
261 train loss is 0.811538159847
261 val loss is 0.931768774986
262 train loss is 0.945904076099
262 val loss is 0.910698533058
263 train loss is 0.904701828957
263 val loss is 0.883039534092
264 train loss is 0.813958406448
264 val loss is 0.905076265335
265 train loss is 0.940275549889
265 val loss is 0.909337162971
266 train loss is 0.827671647072
266 val loss is 0.877830922604
267 train loss is 0.852969527245
267 val loss is 0.889740943909
268 train loss is 0.901431381702
268 val loss is 0.918691754341
269 train loss is 0.860034883022
269 val loss is 0.899766802788
270 train loss is 0.930465936661
270 val loss is 0.87547492981
271 train loss is 0.862459361553
271 val loss is 0.902612447739
272 train loss is 0.858316242695
272 val loss is 0.895260810852
273 train loss is 0.921875536442
273 val loss is 0.862353205681
274 train loss is 0.875711798668
274 val loss is 0.893747866154
275 train loss is 0.939381480217
275 val loss is 0.925155282021
276 train loss is 0.876498878002
276 val loss is 0.891916334629
277 train loss is 0.807023644447
277 val loss is 0.868742465973
278 train loss is 0.889436006546
278 val loss is 0.912612974644
279 train loss is 0.910135686398
279 val loss is 0.90604019165
280 train loss is 0.945380568504
280 val loss is 0.860437273979
281 train loss is 0.872801780701
281 val loss is 0.893388330936
282 train loss is 0.877327620983
282 val loss is 0.934459686279
283 train loss is 0.957193017006
283 val loss is 0.889628410339
284 train loss is 0.933095991611
284 val loss is 0.867913722992
285 train loss is 0.81927973032
285 val loss is 0.91823464632
286 train loss is 0.902393698692
286 val loss is 0.905867218971
287 train loss is 0.888686776161
287 val loss is 0.857727050781
288 train loss is 0.871029376984
288 val loss is 0.879818499088
289 train loss is 0.866199374199
289 val loss is 0.926547288895
290 train loss is 0.934456110001
290 val loss is 0.891638457775
291 train loss is 0.856526017189
291 val loss is 0.853420853615
292 train loss is 0.780844569206
292 val loss is 0.888594388962
293 train loss is 0.933394491673
293 val loss is 0.905808806419
294 train loss is 0.897465348244
294 val loss is 0.857764959335
295 train loss is 0.906321942806
295 val loss is 0.859398424625
296 train loss is 0.794008433819
296 val loss is 0.914430677891
297 train loss is 0.984062254429
297 val loss is 0.892879962921
298 train loss is 0.879516422749
298 val loss is 0.843300104141
299 train loss is 0.798808097839
299 val loss is 0.881301522255
300 train loss is 0.856830835342
300 val loss is 0.904799878597
301 train loss is 0.89656239748
301 val loss is 0.861050665379
302 train loss is 0.886019825935
302 val loss is 0.851776659489
303 train loss is 0.778671503067
303 val loss is 0.912111997604
304 train loss is 0.869092524052
304 val loss is 0.895390450954
305 train loss is 0.902865886688
305 val loss is 0.838097572327
306 train loss is 0.841610491276
306 val loss is 0.866867423058
307 train loss is 0.834299921989
307 val loss is 0.908832728863
308 train loss is 0.987992286682
308 val loss is 0.859681844711
309 train loss is 0.843908786774
309 val loss is 0.844548165798
310 train loss is 0.797997355461
310 val loss is 0.906161427498
311 train loss is 0.894278585911
311 val loss is 0.892760753632
312 train loss is 0.880808889866
312 val loss is 0.837546765804
313 train loss is 0.909373402596
313 val loss is 0.87214165926
314 train loss is 0.920231699944
314 val loss is 0.898322939873
315 train loss is 0.858674526215
315 val loss is 0.845775902271
316 train loss is 0.880877673626
316 val loss is 0.845413446426
317 train loss is 0.863972306252
317 val loss is 0.890534281731
318 train loss is 0.933105647564
318 val loss is 0.864008843899
319 train loss is 0.902917444706
319 val loss is 0.834375321865
320 train loss is 0.863574266434
320 val loss is 0.867177605629
321 train loss is 0.911244273186
321 val loss is 0.872045278549
322 train loss is 0.878293216228
322 val loss is 0.843037486076
323 train loss is 0.86598944664
323 val loss is 0.849824488163
324 train loss is 0.833423852921
324 val loss is 0.871598720551
325 train loss is 0.831416606903
325 val loss is 0.854765117168
326 train loss is 0.794746041298
326 val loss is 0.834674596786
327 train loss is 0.839707970619
327 val loss is 0.857510507107
328 train loss is 0.901370823383
328 val loss is 0.862710595131
329 train loss is 0.877815842628
329 val loss is 0.839946210384
330 train loss is 0.872572422028
330 val loss is 0.846292376518
331 train loss is 0.842943906784
331 val loss is 0.869210541248
332 train loss is 0.825928270817
332 val loss is 0.851958751678
333 train loss is 0.869759440422
333 val loss is 0.835698306561
334 train loss is 0.807535469532
334 val loss is 0.852655172348
335 train loss is 0.855036020279
335 val loss is 0.848966598511
336 train loss is 0.828996598721
336 val loss is 0.832210659981
337 train loss is 0.830938756466
337 val loss is 0.84520983696
338 train loss is 0.819303095341
338 val loss is 0.855488777161
339 train loss is 0.857297241688
339 val loss is 0.839284300804
340 train loss is 0.827380895615
340 val loss is 0.831115186214
341 train loss is 0.838821053505
341 val loss is 0.841712594032
342 train loss is 0.87549674511
342 val loss is 0.846790194511
343 train loss is 0.828341782093
343 val loss is 0.836216807365
344 train loss is 0.815523326397
344 val loss is 0.840850651264
345 train loss is 0.842252254486
345 val loss is 0.855415761471
346 train loss is 0.844927191734
346 val loss is 0.844764113426
347 train loss is 0.828708767891
347 val loss is 0.830239713192
348 train loss is 0.85085952282
348 val loss is 0.840214550495
349 train loss is 0.909407675266
349 val loss is 0.843054533005
350 train loss is 0.807426929474
350 val loss is 0.831810414791
351 train loss is 0.851256728172
351 val loss is 0.835200965405
352 train loss is 0.845038175583
352 val loss is 0.850518345833
353 train loss is 0.836664915085
353 val loss is 0.844850242138
354 train loss is 0.895486593246
354 val loss is 0.834086298943
355 train loss is 0.769118309021
355 val loss is 0.841583788395
356 train loss is 0.844526350498
356 val loss is 0.837863206863
357 train loss is 0.824419617653
357 val loss is 0.839505255222
358 train loss is 0.885393023491
358 val loss is 0.841092169285
359 train loss is 0.792588114738
359 val loss is 0.850929558277
360 train loss is 0.865408778191
360 val loss is 0.849168181419
361 train loss is 0.849986612797
361 val loss is 0.841244220734
362 train loss is 0.834585189819
362 val loss is 0.843671560287
363 train loss is 0.842972695827
363 val loss is 0.848395109177
364 train loss is 0.770825147629
364 val loss is 0.838624477386
365 train loss is 0.798360466957
365 val loss is 0.838732659817
366 train loss is 0.830127060413
366 val loss is 0.84983497858
367 train loss is 0.827086210251
367 val loss is 0.851553976536
368 train loss is 0.829206824303
368 val loss is 0.83065032959
369 train loss is 0.877445936203
369 val loss is 0.82243847847
370 train loss is 0.808767914772
370 val loss is 0.832657396793
371 train loss is 0.867628931999
371 val loss is 0.829549074173
372 train loss is 0.791498064995
372 val loss is 0.82141494751
373 train loss is 0.855976223946
373 val loss is 0.830342650414
374 train loss is 0.87126159668
374 val loss is 0.836137592793
375 train loss is 0.814682602882
375 val loss is 0.81963044405
376 train loss is 0.756937623024
376 val loss is 0.8118019104
377 train loss is 0.798187971115
377 val loss is 0.818363845348
378 train loss is 0.783370554447
378 val loss is 0.815173685551
379 train loss is 0.80487793684
379 val loss is 0.81388938427
380 train loss is 0.806466937065
380 val loss is 0.823211252689
381 train loss is 0.78980410099
381 val loss is 0.815184593201
382 train loss is 0.732696294785
382 val loss is 0.800625145435
383 train loss is 0.72337436676
383 val loss is 0.806411743164
384 train loss is 0.819228231907
384 val loss is 0.811922311783
385 train loss is 0.760526895523
385 val loss is 0.79978710413
386 train loss is 0.707695484161
386 val loss is 0.808333754539
387 train loss is 0.770190477371
387 val loss is 0.824434161186
388 train loss is 0.795004367828
388 val loss is 0.814202070236
389 train loss is 0.788987159729
389 val loss is 0.797840893269
390 train loss is 0.787748098373
390 val loss is 0.803692758083
391 train loss is 0.783408999443
391 val loss is 0.812146067619
392 train loss is 0.704146623611
392 val loss is 0.80044054985
393 train loss is 0.84019523859
393 val loss is 0.798865258694
394 train loss is 0.773731708527
394 val loss is 0.814896643162
395 train loss is 0.844000458717
395 val loss is 0.810085892677
396 train loss is 0.734899759293
396 val loss is 0.794617176056
397 train loss is 0.818123281002
397 val loss is 0.799595355988
398 train loss is 0.796475350857
398 val loss is 0.812586128712
399 train loss is 0.834535896778
399 val loss is 0.801958322525
400 train loss is 0.838950991631
400 val loss is 0.796832084656
401 train loss is 0.812696099281
401 val loss is 0.810205996037
402 train loss is 0.826809883118
402 val loss is 0.81579297781
403 train loss is 0.795546293259
403 val loss is 0.801222801208
404 train loss is 0.80795443058
404 val loss is 0.792192518711
405 train loss is 0.787132978439
405 val loss is 0.81055533886
406 train loss is 0.85051047802
406 val loss is 0.813329696655
407 train loss is 0.767070651054
407 val loss is 0.796496868134
408 train loss is 0.786167860031
408 val loss is 0.797025918961
409 train loss is 0.7874969244
409 val loss is 0.816914081573
410 train loss is 0.851271927357
410 val loss is 0.802861452103
411 train loss is 0.77186024189
411 val loss is 0.785170853138
412 train loss is 0.730650544167
412 val loss is 0.796034812927
413 train loss is 0.806585252285
413 val loss is 0.802331626415
414 train loss is 0.858895003796
414 val loss is 0.783965587616
415 train loss is 0.768596291542
415 val loss is 0.784542262554
416 train loss is 0.759966850281
416 val loss is 0.802374124527
417 train loss is 0.804449677467
417 val loss is 0.79668712616
418 train loss is 0.806179404259
418 val loss is 0.781814336777
419 train loss is 0.74377810955
419 val loss is 0.786137938499
420 train loss is 0.829711794853
420 val loss is 0.795362830162
421 train loss is 0.790003478527
421 val loss is 0.783115506172
422 train loss is 0.815718412399
422 val loss is 0.783209562302
423 train loss is 0.785430312157
423 val loss is 0.801917374134
424 train loss is 0.801398336887
424 val loss is 0.794399142265
425 train loss is 0.773928880692
425 val loss is 0.771909952164
426 train loss is 0.814899086952
426 val loss is 0.789090931416
427 train loss is 0.779268562794
427 val loss is 0.806530237198
428 train loss is 0.82329249382
428 val loss is 0.781625032425
429 train loss is 0.840247273445
429 val loss is 0.771085739136
430 train loss is 0.781854093075
430 val loss is 0.795317411423
431 train loss is 0.841746866703
431 val loss is 0.796642124653
432 train loss is 0.812575936317
432 val loss is 0.768924474716
433 train loss is 0.764033317566
433 val loss is 0.782032012939
434 train loss is 0.745182514191
434 val loss is 0.808160305023
435 train loss is 0.767442464828
435 val loss is 0.781752347946
436 train loss is 0.805175125599
436 val loss is 0.767385721207
437 train loss is 0.750465989113
437 val loss is 0.793146848679
438 train loss is 0.725175738335
438 val loss is 0.792163968086
439 train loss is 0.81031537056
439 val loss is 0.768033087254
440 train loss is 0.762755155563
440 val loss is 0.775846123695
441 train loss is 0.723134756088
441 val loss is 0.794177353382
442 train loss is 0.80575543642
442 val loss is 0.774530529976
443 train loss is 0.775982439518
443 val loss is 0.763391494751
444 train loss is 0.792479634285
444 val loss is 0.782982110977
445 train loss is 0.814207136631
445 val loss is 0.785755217075
446 train loss is 0.763481378555
446 val loss is 0.767056405544
447 train loss is 0.781900882721
447 val loss is 0.77434617281
448 train loss is 0.79953032732
448 val loss is 0.786255598068
449 train loss is 0.819664537907
449 val loss is 0.771247386932
450 train loss is 0.758521854877
450 val loss is 0.767322182655
451 train loss is 0.820314645767
451 val loss is 0.787602365017
452 train loss is 0.80547618866
452 val loss is 0.788858830929
453 train loss is 0.772942841053
453 val loss is 0.769250690937
454 train loss is 0.849532544613
454 val loss is 0.775886058807
455 train loss is 0.805581450462
455 val loss is 0.776935100555
456 train loss is 0.790321111679
456 val loss is 0.768720984459
457 train loss is 0.783810198307
457 val loss is 0.768952727318
458 train loss is 0.777453422546
458 val loss is 0.776312291622
459 train loss is 0.826001286507
459 val loss is 0.776348173618
460 train loss is 0.858149826527
460 val loss is 0.770324647427
461 train loss is 0.757575750351
461 val loss is 0.771553397179
462 train loss is 0.76484388113
462 val loss is 0.770649671555
463 train loss is 0.806241512299
463 val loss is 0.76365673542
464 train loss is 0.802919507027
464 val loss is 0.766038000584
465 train loss is 0.820860147476
465 val loss is 0.766074299812
466 train loss is 0.761235594749
466 val loss is 0.760031461716
467 train loss is 0.798985779285
467 val loss is 0.762937903404
468 train loss is 0.788897335529
468 val loss is 0.763761758804
469 train loss is 0.756718754768
469 val loss is 0.758595645428
470 train loss is 0.800299584866
470 val loss is 0.755328774452
471 train loss is 0.785068035126
471 val loss is 0.757971048355
472 train loss is 0.767683625221
472 val loss is 0.758579730988
473 train loss is 0.737597644329
473 val loss is 0.754190027714
474 train loss is 0.721121907234
474 val loss is 0.754344105721
475 train loss is 0.732777118683
475 val loss is 0.761453211308
476 train loss is 0.765438973904
476 val loss is 0.758215546608
477 train loss is 0.736704230309
477 val loss is 0.746521711349
478 train loss is 0.747472167015
478 val loss is 0.750665068626
479 train loss is 0.780701756477
479 val loss is 0.757569313049
480 train loss is 0.730906665325
480 val loss is 0.745953738689
481 train loss is 0.729595720768
481 val loss is 0.74101048708
482 train loss is 0.782136082649
482 val loss is 0.754613220692
483 train loss is 0.723994791508
483 val loss is 0.755409836769
484 train loss is 0.766011714935
484 val loss is 0.744482040405
485 train loss is 0.727399766445
485 val loss is 0.748448491096
486 train loss is 0.749406576157
486 val loss is 0.754708826542
487 train loss is 0.750391244888
487 val loss is 0.744452834129
488 train loss is 0.765603482723
488 val loss is 0.739093720913
489 train loss is 0.735759496689
489 val loss is 0.758142054081
490 train loss is 0.731542885303
490 val loss is 0.759715914726
491 train loss is 0.753599405289
491 val loss is 0.744259655476
492 train loss is 0.671112537384
492 val loss is 0.752453386784
493 train loss is 0.742236256599
493 val loss is 0.758417844772
494 train loss is 0.769317746162
494 val loss is 0.743105590343
495 train loss is 0.792502939701
495 val loss is 0.738968133926
496 train loss is 0.696193277836
496 val loss is 0.757730603218
497 train loss is 0.762960672379
497 val loss is 0.75753647089
498 train loss is 0.733730196953
498 val loss is 0.738996386528
499 train loss is 0.735250234604
499 val loss is 0.741286873817
500 train loss is 0.717062950134
500 val loss is 0.754111647606
501 train loss is 0.699779272079
501 val loss is 0.745823681355
502 train loss is 0.759818792343
502 val loss is 0.730228602886
503 train loss is 0.731768965721
503 val loss is 0.746340632439
504 train loss is 0.760633230209
504 val loss is 0.760499894619
505 train loss is 0.745615303516
505 val loss is 0.741389513016
506 train loss is 0.685344338417
506 val loss is 0.733345985413
507 train loss is 0.662136316299
507 val loss is 0.748649716377
508 train loss is 0.699153959751
508 val loss is 0.741997003555
509 train loss is 0.751979827881
509 val loss is 0.727640628815
510 train loss is 0.703063368797
510 val loss is 0.737627327442
511 train loss is 0.759047925472
511 val loss is 0.749054789543
512 train loss is 0.74530684948
512 val loss is 0.738715350628
513 train loss is 0.707138001919
513 val loss is 0.735311150551
514 train loss is 0.728770792484
514 val loss is 0.745546340942
515 train loss is 0.702302753925
515 val loss is 0.739944219589
516 train loss is 0.752570986748
516 val loss is 0.725264072418
517 train loss is 0.770054459572
517 val loss is 0.737635135651
518 train loss is 0.729245185852
518 val loss is 0.75495326519
519 train loss is 0.830430030823
519 val loss is 0.740906178951
520 train loss is 0.747261404991
520 val loss is 0.729482710361
521 train loss is 0.730339825153
521 val loss is 0.739918649197
522 train loss is 0.692075610161
522 val loss is 0.74185103178
523 train loss is 0.678131699562
523 val loss is 0.726959764957
524 train loss is 0.687885284424
524 val loss is 0.734014153481
525 train loss is 0.718099176884
525 val loss is 0.746358633041
526 train loss is 0.725069046021
526 val loss is 0.73607224226
527 train loss is 0.676670789719
527 val loss is 0.72938144207
528 train loss is 0.695524513721
528 val loss is 0.735895752907
529 train loss is 0.726108491421
529 val loss is 0.738841056824
530 train loss is 0.746289372444
530 val loss is 0.729702949524
531 train loss is 0.721052765846
531 val loss is 0.733159124851
532 train loss is 0.660718917847
532 val loss is 0.747308135033
533 train loss is 0.787737131119
533 val loss is 0.739987015724
534 train loss is 0.742334246635
534 val loss is 0.72807765007
535 train loss is 0.723668038845
535 val loss is 0.734080612659
536 train loss is 0.704152107239
536 val loss is 0.7337692976
537 train loss is 0.743108570576
537 val loss is 0.725108504295
538 train loss is 0.726647913456
538 val loss is 0.729434072971
539 train loss is 0.701868116856
539 val loss is 0.736380577087
540 train loss is 0.711325645447
540 val loss is 0.73081445694
541 train loss is 0.730555057526
541 val loss is 0.727974832058
542 train loss is 0.686666727066
542 val loss is 0.726911962032
543 train loss is 0.7156868577
543 val loss is 0.725545704365
544 train loss is 0.736547708511
544 val loss is 0.727190256119
545 train loss is 0.70009124279
545 val loss is 0.72607511282
546 train loss is 0.70455300808
546 val loss is 0.722967267036
547 train loss is 0.725971519947
547 val loss is 0.728243708611
548 train loss is 0.74132412672
548 val loss is 0.732380509377
549 train loss is 0.752340435982
549 val loss is 0.720871567726
550 train loss is 0.774126887321
550 val loss is 0.716340303421
551 train loss is 0.731590569019
551 val loss is 0.724811673164
552 train loss is 0.781501889229
552 val loss is 0.721522808075
553 train loss is 0.70252263546
553 val loss is 0.718160808086
554 train loss is 0.719624638557
554 val loss is 0.725064277649
555 train loss is 0.687530457973
555 val loss is 0.727628827095
556 train loss is 0.765868604183
556 val loss is 0.718586027622
557 train loss is 0.692959308624
557 val loss is 0.714810371399
558 train loss is 0.763420403004
558 val loss is 0.721732616425
559 train loss is 0.790573954582
559 val loss is 0.7205914855
560 train loss is 0.755660295486
560 val loss is 0.714897990227
561 train loss is 0.661644399166
561 val loss is 0.728311002254
562 train loss is 0.752735733986
562 val loss is 0.731670796871
563 train loss is 0.689104259014
563 val loss is 0.71561229229
564 train loss is 0.726401209831
564 val loss is 0.715661287308
565 train loss is 0.704563498497
565 val loss is 0.724858403206
566 train loss is 0.703752577305
566 val loss is 0.71546882391
567 train loss is 0.649548411369
567 val loss is 0.711857199669
568 train loss is 0.705875873566
568 val loss is 0.724951982498
569 train loss is 0.71962761879
569 val loss is 0.722425758839
570 train loss is 0.682840585709
570 val loss is 0.70588517189
571 train loss is 0.738663315773
571 val loss is 0.70434743166
572 train loss is 0.734644174576
572 val loss is 0.715446710587
573 train loss is 0.724620223045
573 val loss is 0.714141249657
574 train loss is 0.741729259491
574 val loss is 0.704579055309
575 train loss is 0.747374653816
575 val loss is 0.712039709091
576 train loss is 0.67470240593
576 val loss is 0.720588564873
577 train loss is 0.704326152802
577 val loss is 0.707306146622
578 train loss is 0.709220767021
578 val loss is 0.698626637459
579 train loss is 0.707751691341
579 val loss is 0.712683677673
580 train loss is 0.704356193542
580 val loss is 0.71366161108
581 train loss is 0.693476438522
581 val loss is 0.703344583511
582 train loss is 0.657792448997
582 val loss is 0.709547400475
583 train loss is 0.702946603298
583 val loss is 0.716657996178
584 train loss is 0.65706384182
584 val loss is 0.702845692635
585 train loss is 0.709891498089
585 val loss is 0.700038552284
586 train loss is 0.801491618156
586 val loss is 0.70856654644
587 train loss is 0.751261353493
587 val loss is 0.70488524437
588 train loss is 0.683726608753
588 val loss is 0.699003398418
589 train loss is 0.659093022346
589 val loss is 0.710453987122
590 train loss is 0.75250184536
590 val loss is 0.709373474121
591 train loss is 0.713660299778
591 val loss is 0.696043610573
592 train loss is 0.665664851665
592 val loss is 0.700488269329
593 train loss is 0.70244717598
593 val loss is 0.710954546928
594 train loss is 0.742336332798
594 val loss is 0.699718296528
595 train loss is 0.753871321678
595 val loss is 0.697938919067
596 train loss is 0.697832107544
596 val loss is 0.713289618492
597 train loss is 0.65898680687
597 val loss is 0.709613204002
598 train loss is 0.712904274464
598 val loss is 0.692496299744
599 train loss is 0.724891901016
599 val loss is 0.699685633183
600 train loss is 0.654997944832
600 val loss is 0.713086366653
601 train loss is 0.740703821182
601 val loss is 0.700648665428
602 train loss is 0.695663452148
602 val loss is 0.697044372559
603 train loss is 0.737517893314
603 val loss is 0.716626286507
604 train loss is 0.717298150063
604 val loss is 0.714497685432
605 train loss is 0.713169336319
605 val loss is 0.694171071053
606 train loss is 0.73485904932
606 val loss is 0.697814643383
607 train loss is 0.780484080315
607 val loss is 0.71518945694
608 train loss is 0.697721719742
608 val loss is 0.70524764061
609 train loss is 0.740470468998
609 val loss is 0.694968879223
610 train loss is 0.686172068119
610 val loss is 0.70874273777
611 train loss is 0.711883187294
611 val loss is 0.711863636971
612 train loss is 0.655623316765
612 val loss is 0.697448372841
613 train loss is 0.761074185371
613 val loss is 0.693745553493
614 train loss is 0.682810604572
614 val loss is 0.70974779129
615 train loss is 0.689170897007
615 val loss is 0.704535782337
616 train loss is 0.728867053986
616 val loss is 0.691990911961
617 train loss is 0.733319699764
617 val loss is 0.702653288841
618 train loss is 0.713968873024
618 val loss is 0.706098198891
619 train loss is 0.705539107323
619 val loss is 0.691575944424
620 train loss is 0.655610799789
620 val loss is 0.690106272697
621 train loss is 0.646479010582
621 val loss is 0.700182616711
622 train loss is 0.694462716579
622 val loss is 0.697961330414
623 train loss is 0.703788936138
623 val loss is 0.691305816174
624 train loss is 0.688596367836
624 val loss is 0.696329236031
625 train loss is 0.729811787605
625 val loss is 0.705739378929
626 train loss is 0.766852259636
626 val loss is 0.69691580534
627 train loss is 0.685675144196
627 val loss is 0.685179710388
628 train loss is 0.702494621277
628 val loss is 0.699081540108
629 train loss is 0.767930030823
629 val loss is 0.702996551991
630 train loss is 0.722458779812
630 val loss is 0.690380871296
631 train loss is 0.720779657364
631 val loss is 0.691433548927
632 train loss is 0.670630633831
632 val loss is 0.700639903545
633 train loss is 0.717533111572
633 val loss is 0.693219542503
634 train loss is 0.67692553997
634 val loss is 0.682244539261
635 train loss is 0.686991631985
635 val loss is 0.690036594868
636 train loss is 0.72768342495
636 val loss is 0.695116758347
637 train loss is 0.698542118073
637 val loss is 0.684132933617
638 train loss is 0.717937469482
638 val loss is 0.683631122112
639 train loss is 0.677860438824
639 val loss is 0.693806886673
640 train loss is 0.70517462492
640 val loss is 0.688788950443
641 train loss is 0.676313519478
641 val loss is 0.679939985275
642 train loss is 0.641629636288
642 val loss is 0.685066699982
643 train loss is 0.653051733971
643 val loss is 0.690314650536
644 train loss is 0.676163971424
644 val loss is 0.679152488708
645 train loss is 0.715365052223
645 val loss is 0.681901454926
646 train loss is 0.683568358421
646 val loss is 0.693080306053
647 train loss is 0.700151085854
647 val loss is 0.686736166477
648 train loss is 0.663628637791
648 val loss is 0.676939964294
649 train loss is 0.673654198647
649 val loss is 0.682584404945
650 train loss is 0.665438711643
650 val loss is 0.686044335365
651 train loss is 0.705476045609
651 val loss is 0.677870929241
652 train loss is 0.664896130562
652 val loss is 0.67817479372
653 train loss is 0.600907921791
653 val loss is 0.682512402534
654 train loss is 0.716904401779
654 val loss is 0.682863891125
655 train loss is 0.714485526085
655 val loss is 0.678842008114
656 train loss is 0.66402733326
656 val loss is 0.683046996593
657 train loss is 0.713922858238
657 val loss is 0.68152910471
658 train loss is 0.679425597191
658 val loss is 0.678008675575
659 train loss is 0.67326259613
659 val loss is 0.676724791527
660 train loss is 0.646147549152
660 val loss is 0.680245101452
661 train loss is 0.65650677681
661 val loss is 0.683624505997
662 train loss is 0.658690929413
662 val loss is 0.67682492733
663 train loss is 0.703189849854
663 val loss is 0.675006747246
664 train loss is 0.724265396595
664 val loss is 0.68177396059
665 train loss is 0.671461641788
665 val loss is 0.682084679604
666 train loss is 0.674342513084
666 val loss is 0.674003243446
667 train loss is 0.672121226788
667 val loss is 0.670700669289
668 train loss is 0.643077850342
668 val loss is 0.683061480522
669 train loss is 0.713989138603
669 val loss is 0.683558642864
670 train loss is 0.698433756828
670 val loss is 0.666880369186
671 train loss is 0.606930792332
671 val loss is 0.669510960579
672 train loss is 0.702964067459
672 val loss is 0.679876625538
673 train loss is 0.635581493378
673 val loss is 0.671628475189
674 train loss is 0.718595266342
674 val loss is 0.665391206741
675 train loss is 0.640422224998
675 val loss is 0.676696360111
676 train loss is 0.642959952354
676 val loss is 0.675926864147
677 train loss is 0.712942659855
677 val loss is 0.663413345814
678 train loss is 0.621782183647
678 val loss is 0.668756008148
679 train loss is 0.70222568512
679 val loss is 0.675082087517
680 train loss is 0.671525537968
680 val loss is 0.667198777199
681 train loss is 0.650323987007
681 val loss is 0.664487421513
682 train loss is 0.674828827381
682 val loss is 0.674929380417
683 train loss is 0.638163685799
683 val loss is 0.674480557442
684 train loss is 0.680903911591
684 val loss is 0.663930475712
685 train loss is 0.649532496929
685 val loss is 0.66817843914
686 train loss is 0.698596358299
686 val loss is 0.674636781216
687 train loss is 0.684145450592
687 val loss is 0.664567053318
688 train loss is 0.661434829235
688 val loss is 0.662993252277
689 train loss is 0.682611942291
689 val loss is 0.673204183578
690 train loss is 0.674777626991
690 val loss is 0.671828389168
691 train loss is 0.632521867752
691 val loss is 0.664454162121
692 train loss is 0.665195345879
692 val loss is 0.663296937943
693 train loss is 0.636035978794
693 val loss is 0.669588088989
694 train loss is 0.605715751648
694 val loss is 0.66649055481
695 train loss is 0.696007907391
695 val loss is 0.658781409264
696 train loss is 0.66602909565
696 val loss is 0.664157390594
697 train loss is 0.651264667511
697 val loss is 0.674851596355
698 train loss is 0.676251769066
698 val loss is 0.669153273106
699 train loss is 0.60239136219
699 val loss is 0.657738029957
700 train loss is 0.684718430042
700 val loss is 0.663952291012
701 train loss is 0.654762268066
701 val loss is 0.669285476208
702 train loss is 0.68564748764
702 val loss is 0.657719254494
703 train loss is 0.594645738602
703 val loss is 0.661888659
704 train loss is 0.654487609863
704 val loss is 0.680095493793
705 train loss is 0.651633560658
705 val loss is 0.671105027199
706 train loss is 0.696360886097
706 val loss is 0.656834244728
707 train loss is 0.624454259872
707 val loss is 0.663290143013
708 train loss is 0.640224575996
708 val loss is 0.668046951294
709 train loss is 0.676648378372
709 val loss is 0.657795608044
710 train loss is 0.632943212986
710 val loss is 0.658935785294
711 train loss is 0.705689787865
711 val loss is 0.669115841389
712 train loss is 0.638340950012
712 val loss is 0.661560118198
713 train loss is 0.610171735287
713 val loss is 0.6542314291
714 train loss is 0.577614068985
714 val loss is 0.661358773708
715 train loss is 0.660914957523
715 val loss is 0.662025868893
716 train loss is 0.678114295006
716 val loss is 0.653011202812
717 train loss is 0.611479580402
717 val loss is 0.656874656677
718 train loss is 0.637399315834
718 val loss is 0.665542960167
719 train loss is 0.702818870544
719 val loss is 0.664315700531
720 train loss is 0.650992035866
720 val loss is 0.657127737999
721 train loss is 0.688081622124
721 val loss is 0.657540619373
722 train loss is 0.672420859337
722 val loss is 0.658664762974
723 train loss is 0.708604454994
723 val loss is 0.652799010277
724 train loss is 0.650137126446
724 val loss is 0.656535744667
725 train loss is 0.616383850574
725 val loss is 0.662064909935
726 train loss is 0.654210329056
726 val loss is 0.660858869553
727 train loss is 0.676171183586
727 val loss is 0.655308365822
728 train loss is 0.616429507732
728 val loss is 0.656169176102
729 train loss is 0.665347397327
729 val loss is 0.655411779881
730 train loss is 0.629945278168
730 val loss is 0.651495575905
731 train loss is 0.631344854832
731 val loss is 0.656717300415
732 train loss is 0.668870985508
732 val loss is 0.660102188587
733 train loss is 0.635949194431
733 val loss is 0.655287206173
734 train loss is 0.67153853178
734 val loss is 0.655584692955
735 train loss is 0.689701259136
735 val loss is 0.660131335258
736 train loss is 0.663041472435
736 val loss is 0.650794029236
737 train loss is 0.637011110783
737 val loss is 0.645088076591
738 train loss is 0.592248678207
738 val loss is 0.654108345509
739 train loss is 0.647272586823
739 val loss is 0.660331010818
740 train loss is 0.660492062569
740 val loss is 0.652676343918
741 train loss is 0.639587283134
741 val loss is 0.650286257267
742 train loss is 0.60771638155
742 val loss is 0.656950116158
743 train loss is 0.666118562222
743 val loss is 0.654547452927
744 train loss is 0.65259885788
744 val loss is 0.642976880074
745 train loss is 0.676710546017
745 val loss is 0.654674232006
746 train loss is 0.569722414017
746 val loss is 0.662693202496
747 train loss is 0.653878748417
747 val loss is 0.650862336159
748 train loss is 0.616037964821
748 val loss is 0.647140264511
749 train loss is 0.678814888
749 val loss is 0.657343804836
750 train loss is 0.681413888931
750 val loss is 0.655754566193
751 train loss is 0.652315378189
751 val loss is 0.643242061138
752 train loss is 0.605104386806
752 val loss is 0.64806330204
753 train loss is 0.621444582939
753 val loss is 0.659722507
754 train loss is 0.620619952679
754 val loss is 0.651876270771
755 train loss is 0.653942346573
755 val loss is 0.643284976482
756 train loss is 0.644105553627
756 val loss is 0.648481488228
757 train loss is 0.646717727184
757 val loss is 0.650899767876
758 train loss is 0.686233341694
758 val loss is 0.649375200272
759 train loss is 0.638365268707
759 val loss is 0.646921992302
760 train loss is 0.631558358669
760 val loss is 0.647159218788
761 train loss is 0.65386813879
761 val loss is 0.650911331177
762 train loss is 0.600429952145
762 val loss is 0.649617612362
763 train loss is 0.626294493675
763 val loss is 0.644534707069
764 train loss is 0.633585572243
764 val loss is 0.646544873714
765 train loss is 0.620873451233
765 val loss is 0.648463487625
766 train loss is 0.619197070599
766 val loss is 0.645626783371
767 train loss is 0.671793580055
767 val loss is 0.645126521587
768 train loss is 0.634623765945
768 val loss is 0.644538223743
769 train loss is 0.675390005112
769 val loss is 0.641782641411
770 train loss is 0.623638212681
770 val loss is 0.640967845917
771 train loss is 0.630261421204
771 val loss is 0.641643285751
772 train loss is 0.655455470085
772 val loss is 0.641564249992
773 train loss is 0.665435910225
773 val loss is 0.644218742847
774 train loss is 0.599678695202
774 val loss is 0.643338322639
775 train loss is 0.624999523163
775 val loss is 0.639397859573
776 train loss is 0.617164731026
776 val loss is 0.641291558743
777 train loss is 0.61493742466
777 val loss is 0.64104360342
778 train loss is 0.623509764671
778 val loss is 0.636370062828
779 train loss is 0.619562447071
779 val loss is 0.63733458519
780 train loss is 0.650496602058
780 val loss is 0.642729401588
781 train loss is 0.611872315407
781 val loss is 0.641972899437
782 train loss is 0.64217710495
782 val loss is 0.638557136059
783 train loss is 0.654338896275
783 val loss is 0.640773177147
784 train loss is 0.662129044533
784 val loss is 0.639149606228
785 train loss is 0.657862365246
785 val loss is 0.633252084255
786 train loss is 0.654575228691
786 val loss is 0.640821099281
787 train loss is 0.672632098198
787 val loss is 0.644693553448
788 train loss is 0.643552064896
788 val loss is 0.635570049286
789 train loss is 0.642784357071
789 val loss is 0.636440992355
790 train loss is 0.638160347939
790 val loss is 0.645216405392
791 train loss is 0.627337276936
791 val loss is 0.63511121273
792 train loss is 0.675330877304
792 val loss is 0.626512289047
793 train loss is 0.611508488655
793 val loss is 0.636641800404
794 train loss is 0.636554121971
794 val loss is 0.639713943005
795 train loss is 0.643582820892
795 val loss is 0.63665419817
796 train loss is 0.669110894203
796 val loss is 0.633951187134
797 train loss is 0.601390123367
797 val loss is 0.640516936779
798 train loss is 0.668117403984
798 val loss is 0.636767923832
799 train loss is 0.648077487946
799 val loss is 0.629030108452
800 train loss is 0.62826693058
800 val loss is 0.635179638863
801 train loss is 0.660034775734
801 val loss is 0.639271855354
802 train loss is 0.632647633553
802 val loss is 0.634304821491
803 train loss is 0.58743005991
803 val loss is 0.63261371851
804 train loss is 0.645041704178
804 val loss is 0.639274835587
805 train loss is 0.630218267441
805 val loss is 0.633980751038
806 train loss is 0.634671270847
806 val loss is 0.625349581242
807 train loss is 0.589198231697
807 val loss is 0.630791604519
808 train loss is 0.637858629227
808 val loss is 0.638222932816
809 train loss is 0.635923862457
809 val loss is 0.634419739246
810 train loss is 0.629596114159
810 val loss is 0.630549073219
811 train loss is 0.658219277859
811 val loss is 0.63504076004
812 train loss is 0.656075954437
812 val loss is 0.633411586285
813 train loss is 0.575949907303
813 val loss is 0.627706289291
814 train loss is 0.59932500124
814 val loss is 0.628059446812
815 train loss is 0.620751082897
815 val loss is 0.636982738972
816 train loss is 0.59748506546
816 val loss is 0.633948028088
817 train loss is 0.626924455166
817 val loss is 0.628648042679
818 train loss is 0.629480004311
818 val loss is 0.629933357239
819 train loss is 0.628575801849
819 val loss is 0.628160715103
820 train loss is 0.61635518074
820 val loss is 0.62802118063
821 train loss is 0.613271653652
821 val loss is 0.627747654915
822 train loss is 0.574817359447
822 val loss is 0.629936635494
823 train loss is 0.640632629395
823 val loss is 0.63653087616
824 train loss is 0.628954291344
824 val loss is 0.630632460117
825 train loss is 0.611061573029
825 val loss is 0.626114308834
826 train loss is 0.649374425411
826 val loss is 0.631780266762
827 train loss is 0.653330147266
827 val loss is 0.631925821304
828 train loss is 0.597355902195
828 val loss is 0.622752428055
829 train loss is 0.641985297203
829 val loss is 0.629112064838
830 train loss is 0.642785847187
830 val loss is 0.641467034817
831 train loss is 0.643974840641
831 val loss is 0.628179252148
832 train loss is 0.640110015869
832 val loss is 0.619273245335
833 train loss is 0.623331069946
833 val loss is 0.626710951328
834 train loss is 0.6484811306
834 val loss is 0.627693533897
835 train loss is 0.64634335041
835 val loss is 0.617371678352
836 train loss is 0.670370638371
836 val loss is 0.625276148319
837 train loss is 0.578389167786
837 val loss is 0.638054251671
838 train loss is 0.60794878006
838 val loss is 0.623617827892
839 train loss is 0.594342768192
839 val loss is 0.613891601562
840 train loss is 0.591393828392
840 val loss is 0.626260042191
841 train loss is 0.668288528919
841 val loss is 0.625909090042
842 train loss is 0.664695739746
842 val loss is 0.617733359337
843 train loss is 0.702889323235
843 val loss is 0.629609942436
844 train loss is 0.655869066715
844 val loss is 0.641164362431
845 train loss is 0.651632487774
845 val loss is 0.623371601105
846 train loss is 0.632099509239
846 val loss is 0.619681477547
847 train loss is 0.601307332516
847 val loss is 0.631915986538
848 train loss is 0.62046033144
848 val loss is 0.628329336643
849 train loss is 0.630983352661
849 val loss is 0.61565887928
850 train loss is 0.572892665863
850 val loss is 0.623614668846
851 train loss is 0.603106081486
851 val loss is 0.630917549133
852 train loss is 0.66484695673
852 val loss is 0.622382700443
853 train loss is 0.644960522652
853 val loss is 0.616911649704
854 train loss is 0.637303113937
854 val loss is 0.624426007271
855 train loss is 0.605820894241
855 val loss is 0.626915812492
856 train loss is 0.638120055199
856 val loss is 0.619170546532
857 train loss is 0.581262111664
857 val loss is 0.621030330658
858 train loss is 0.617529153824
858 val loss is 0.628167748451
859 train loss is 0.64511269331
859 val loss is 0.624781727791
860 train loss is 0.63991189003
860 val loss is 0.616747796535
861 train loss is 0.61274009943
861 val loss is 0.620924055576
862 train loss is 0.615256071091
862 val loss is 0.622925162315
863 train loss is 0.604918420315
863 val loss is 0.621058106422
864 train loss is 0.627242922783
864 val loss is 0.621858656406
865 train loss is 0.619114100933
865 val loss is 0.625778138638
866 train loss is 0.63127219677
866 val loss is 0.624741613865
867 train loss is 0.675781607628
867 val loss is 0.618769645691
868 train loss is 0.674639940262
868 val loss is 0.616829037666
869 train loss is 0.608588755131
869 val loss is 0.623935639858
870 train loss is 0.65006840229
870 val loss is 0.628223836422
871 train loss is 0.641906797886
871 val loss is 0.620400547981
872 train loss is 0.642531216145
872 val loss is 0.617707192898
873 train loss is 0.621574819088
873 val loss is 0.629841148853
874 train loss is 0.583231627941
874 val loss is 0.630401730537
875 train loss is 0.639650344849
875 val loss is 0.612270772457
876 train loss is 0.615051865578
876 val loss is 0.620549201965
877 train loss is 0.60243499279
877 val loss is 0.637531042099
878 train loss is 0.672887206078
878 val loss is 0.622495889664
879 train loss is 0.587231874466
879 val loss is 0.617189466953
880 train loss is 0.637989938259
880 val loss is 0.630515217781
881 train loss is 0.683127403259
881 val loss is 0.626276016235
882 train loss is 0.590255200863
882 val loss is 0.608892679214
883 train loss is 0.646977543831
883 val loss is 0.618507385254
884 train loss is 0.619903862476
884 val loss is 0.628405928612
885 train loss is 0.628349483013
885 val loss is 0.616700530052
886 train loss is 0.655819356441
886 val loss is 0.612494647503
887 train loss is 0.62440854311
887 val loss is 0.624199151993
888 train loss is 0.61789226532
888 val loss is 0.619533538818
889 train loss is 0.610643267632
889 val loss is 0.606998324394
890 train loss is 0.604375302792
890 val loss is 0.614269971848
891 train loss is 0.604702234268
891 val loss is 0.622954845428
892 train loss is 0.70682156086
892 val loss is 0.617751300335
893 train loss is 0.570653438568
893 val loss is 0.607656180859
894 train loss is 0.633725583553
894 val loss is 0.618522942066
895 train loss is 0.628877043724
895 val loss is 0.624334216118
896 train loss is 0.627693712711
896 val loss is 0.610607028008
897 train loss is 0.592116415501
897 val loss is 0.60989433527
898 train loss is 0.638161957264
898 val loss is 0.623479068279
899 train loss is 0.651508450508
899 val loss is 0.617754101753
900 train loss is 0.643856525421
900 val loss is 0.606025099754
901 train loss is 0.594601690769
901 val loss is 0.619181513786
902 train loss is 0.642832994461
902 val loss is 0.628626942635
903 train loss is 0.611046671867
903 val loss is 0.607864916325
904 train loss is 0.580993652344
904 val loss is 0.60256332159
905 train loss is 0.577429771423
905 val loss is 0.625897049904
906 train loss is 0.648116528988
906 val loss is 0.624252676964
907 train loss is 0.603774249554
907 val loss is 0.604453265667
908 train loss is 0.581389725208
908 val loss is 0.606849610806
909 train loss is 0.628158807755
909 val loss is 0.616063654423
910 train loss is 0.627548217773
910 val loss is 0.607324540615
911 train loss is 0.611858963966
911 val loss is 0.598546922207
912 train loss is 0.608623743057
912 val loss is 0.60773897171
913 train loss is 0.576231837273
913 val loss is 0.613370716572
914 train loss is 0.622139334679
914 val loss is 0.604428052902
915 train loss is 0.622284173965
915 val loss is 0.602616786957
916 train loss is 0.597060799599
916 val loss is 0.608849525452
917 train loss is 0.599466145039
917 val loss is 0.60514819622
918 train loss is 0.608837068081
918 val loss is 0.598757743835
919 train loss is 0.64704978466
919 val loss is 0.603172719479
920 train loss is 0.598002076149
920 val loss is 0.610566675663
921 train loss is 0.652374386787
921 val loss is 0.604441404343
922 train loss is 0.601050376892
922 val loss is 0.600202560425
923 train loss is 0.625195503235
923 val loss is 0.606313884258
924 train loss is 0.639007747173
924 val loss is 0.603712439537
925 train loss is 0.581134319305
925 val loss is 0.595765531063
926 train loss is 0.601478755474
926 val loss is 0.599039673805
927 train loss is 0.596185326576
927 val loss is 0.603607058525
928 train loss is 0.644575357437
928 val loss is 0.602068245411
929 train loss is 0.585920929909
929 val loss is 0.597321152687
930 train loss is 0.635183691978
930 val loss is 0.597440242767
931 train loss is 0.586687207222
931 val loss is 0.600381374359
932 train loss is 0.590028703213
932 val loss is 0.600348234177
933 train loss is 0.595310986042
933 val loss is 0.59558069706
934 train loss is 0.557327747345
934 val loss is 0.59783411026
935 train loss is 0.598985850811
935 val loss is 0.600419104099
936 train loss is 0.617941200733
936 val loss is 0.596199512482
937 train loss is 0.563230037689
937 val loss is 0.593257129192
938 train loss is 0.560036659241
938 val loss is 0.5960496068
939 train loss is 0.626566827297
939 val loss is 0.594934940338
940 train loss is 0.605224192142
940 val loss is 0.58974981308
941 train loss is 0.562014818192
941 val loss is 0.589321017265
942 train loss is 0.5732421875
942 val loss is 0.594004571438
943 train loss is 0.600742220879
943 val loss is 0.593083977699
944 train loss is 0.543559908867
944 val loss is 0.594899892807
945 train loss is 0.648275613785
945 val loss is 0.593831896782
946 train loss is 0.596068739891
946 val loss is 0.590096116066
947 train loss is 0.596694588661
947 val loss is 0.590790212154
948 train loss is 0.573717415333
948 val loss is 0.591951131821
949 train loss is 0.603303551674
949 val loss is 0.593917191029
950 train loss is 0.603264510632
950 val loss is 0.594306588173
951 train loss is 0.600250005722
951 val loss is 0.592058420181
952 train loss is 0.621419906616
952 val loss is 0.594962835312
953 train loss is 0.558823287487
953 val loss is 0.591713964939
954 train loss is 0.599265098572
954 val loss is 0.585231900215
955 train loss is 0.582581341267
955 val loss is 0.590783119202
956 train loss is 0.580509662628
956 val loss is 0.595644116402
957 train loss is 0.588074207306
957 val loss is 0.587100625038
958 train loss is 0.576946675777
958 val loss is 0.583248972893
959 train loss is 0.625483870506
959 val loss is 0.58958029747
960 train loss is 0.598197937012
960 val loss is 0.587344706059
961 train loss is 0.601692855358
961 val loss is 0.581826210022
962 train loss is 0.558939218521
962 val loss is 0.585804104805
963 train loss is 0.61324942112
963 val loss is 0.588592529297
964 train loss is 0.589457094669
964 val loss is 0.586160242558
965 train loss is 0.622167408466
965 val loss is 0.582912325859
966 train loss is 0.584607601166
966 val loss is 0.588578462601
967 train loss is 0.589061617851
967 val loss is 0.585179388523
968 train loss is 0.608796596527
968 val loss is 0.579427540302
969 train loss is 0.589466333389
969 val loss is 0.583160281181
970 train loss is 0.607976794243
970 val loss is 0.585245788097
971 train loss is 0.590055286884
971 val loss is 0.582281351089
972 train loss is 0.574664413929
972 val loss is 0.581431031227
973 train loss is 0.59198486805
973 val loss is 0.584974646568
974 train loss is 0.625351846218
974 val loss is 0.587704002857
975 train loss is 0.649548470974
975 val loss is 0.583524346352
976 train loss is 0.55732190609
976 val loss is 0.582172036171
977 train loss is 0.609522104263
977 val loss is 0.586433291435
978 train loss is 0.529339790344
978 val loss is 0.58434933424
979 train loss is 0.575763583183
979 val loss is 0.58246421814
980 train loss is 0.592443287373
980 val loss is 0.584254264832
981 train loss is 0.557600021362
981 val loss is 0.583624303341
982 train loss is 0.649235904217
982 val loss is 0.581214547157
983 train loss is 0.590896904469
983 val loss is 0.583302795887
984 train loss is 0.592849493027
984 val loss is 0.582015633583
985 train loss is 0.543327510357
985 val loss is 0.577004849911
986 train loss is 0.596572339535
986 val loss is 0.579107522964
987 train loss is 0.575604379177
987 val loss is 0.582376599312
988 train loss is 0.606379151344
988 val loss is 0.580035924911
989 train loss is 0.593861877918
989 val loss is 0.58009493351
990 train loss is 0.570442974567
990 val loss is 0.583757162094
991 train loss is 0.620305716991
991 val loss is 0.583245515823
992 train loss is 0.599630117416
992 val loss is 0.577936053276
993 train loss is 0.526480674744
993 val loss is 0.583677768707
994 train loss is 0.596123218536
994 val loss is 0.585010111332
995 train loss is 0.57728523016
995 val loss is 0.579171657562
996 train loss is 0.56261330843
996 val loss is 0.583221912384
997 train loss is 0.580024242401
997 val loss is 0.58716571331
998 train loss is 0.580295443535
998 val loss is 0.580701708794
999 train loss is 0.545946240425
999 val loss is 0.579682707787
1000 train loss is 0.560815274715
1000 val loss is 0.582557916641
1001 train loss is 0.565890312195
1001 val loss is 0.582681536674
1002 train loss is 0.56285572052
1002 val loss is 0.580907344818
1003 train loss is 0.573472440243
1003 val loss is 0.578217506409
1004 train loss is 0.583041667938
1004 val loss is 0.580058157444
1005 train loss is 0.574386656284
1005 val loss is 0.583362102509
1006 train loss is 0.599988520145
1006 val loss is 0.580362975597
1007 train loss is 0.639331877232
1007 val loss is 0.577817559242
1008 train loss is 0.60958391428
1008 val loss is 0.584239721298
1009 train loss is 0.602620840073
1009 val loss is 0.585560917854
1010 train loss is 0.576944172382
1010 val loss is 0.578376412392
1011 train loss is 0.60725748539
1011 val loss is 0.581594347954
1012 train loss is 0.586711168289
1012 val loss is 0.588446259499
1013 train loss is 0.570128560066
1013 val loss is 0.584804058075
1014 train loss is 0.569065213203
1014 val loss is 0.580550253391
1015 train loss is 0.556877672672
1015 val loss is 0.58104634285
1016 train loss is 0.571580410004
1016 val loss is 0.579489588737
1017 train loss is 0.593420803547
1017 val loss is 0.577886164188
1018 train loss is 0.637619614601
1018 val loss is 0.581380486488
1019 train loss is 0.550394237041
1019 val loss is 0.5808994174
1020 train loss is 0.568702638149
1020 val loss is 0.577200055122
1021 train loss is 0.562753200531
1021 val loss is 0.576794981956
1022 train loss is 0.563776016235
1022 val loss is 0.581622183323
1023 train loss is 0.60463643074
1023 val loss is 0.577487051487
1024 train loss is 0.566362142563
1024 val loss is 0.573366880417
1025 train loss is 0.601051986217
1025 val loss is 0.575485229492
1026 train loss is 0.616412460804
1026 val loss is 0.576937437057
1027 train loss is 0.537428617477
1027 val loss is 0.576634585857
1028 train loss is 0.582767605782
1028 val loss is 0.573831558228
1029 train loss is 0.562430679798
1029 val loss is 0.573770165443
1030 train loss is 0.56955242157
1030 val loss is 0.57717269659
1031 train loss is 0.598697304726
1031 val loss is 0.578987896442
1032 train loss is 0.572134137154
1032 val loss is 0.574597716331
1033 train loss is 0.587236821651
1033 val loss is 0.573538899422
1034 train loss is 0.547884404659
1034 val loss is 0.578675985336
1035 train loss is 0.589948773384
1035 val loss is 0.577616274357
1036 train loss is 0.593027353287
1036 val loss is 0.57409620285
1037 train loss is 0.552346885204
1037 val loss is 0.576521992683
1038 train loss is 0.571534514427
1038 val loss is 0.579371988773
1039 train loss is 0.591149449348
1039 val loss is 0.575225055218
1040 train loss is 0.58284509182
1040 val loss is 0.570281326771
1041 train loss is 0.561451494694
1041 val loss is 0.574772119522
1042 train loss is 0.562458992004
1042 val loss is 0.58014857769
1043 train loss is 0.607650816441
1043 val loss is 0.573563039303
1044 train loss is 0.6137611866
1044 val loss is 0.569513618946
1045 train loss is 0.566993713379
1045 val loss is 0.580167174339
1046 train loss is 0.58261936903
1046 val loss is 0.578613996506
1047 train loss is 0.582339823246
1047 val loss is 0.564699828625
1048 train loss is 0.58036082983
1048 val loss is 0.568547487259
1049 train loss is 0.612138450146
1049 val loss is 0.579460382462
1050 train loss is 0.556422352791
1050 val loss is 0.57176810503
1051 train loss is 0.582197785378
1051 val loss is 0.563788771629
1052 train loss is 0.548068702221
1052 val loss is 0.574479103088
1053 train loss is 0.575755357742
1053 val loss is 0.574570119381
1054 train loss is 0.562580227852
1054 val loss is 0.562816381454
1055 train loss is 0.588148236275
1055 val loss is 0.566718459129
1056 train loss is 0.534402966499
1056 val loss is 0.576262831688
1057 train loss is 0.577619671822
1057 val loss is 0.568918466568
1058 train loss is 0.577732503414
1058 val loss is 0.565477967262
1059 train loss is 0.605570673943
1059 val loss is 0.576676428318
1060 train loss is 0.596892476082
1060 val loss is 0.573390483856
1061 train loss is 0.56688284874
1061 val loss is 0.559662222862
1062 train loss is 0.540158987045
1062 val loss is 0.563545703888
1063 train loss is 0.609445333481
1063 val loss is 0.573990464211
1064 train loss is 0.58304131031
1064 val loss is 0.568674504757
1065 train loss is 0.565972447395
1065 val loss is 0.56302523613
1066 train loss is 0.597312748432
1066 val loss is 0.57125890255
1067 train loss is 0.601325392723
1067 val loss is 0.570974707603
1068 train loss is 0.574741721153
1068 val loss is 0.561972022057
1069 train loss is 0.53829151392
1069 val loss is 0.562227547169
1070 train loss is 0.542465746403
1070 val loss is 0.57003057003
1071 train loss is 0.543368458748
1071 val loss is 0.568119525909
1072 train loss is 0.521591186523
1072 val loss is 0.563614964485
1073 train loss is 0.571319937706
1073 val loss is 0.567237734795
1074 train loss is 0.539010286331
1074 val loss is 0.570594966412
1075 train loss is 0.615310847759
1075 val loss is 0.563633441925
1076 train loss is 0.614313423634
1076 val loss is 0.557960450649
1077 train loss is 0.588296115398
1077 val loss is 0.562740087509
1078 train loss is 0.541429340839
1078 val loss is 0.565512537956
1079 train loss is 0.502210378647
1079 val loss is 0.565199613571
1080 train loss is 0.557994484901
1080 val loss is 0.563342571259
1081 train loss is 0.581887245178
1081 val loss is 0.564247608185
1082 train loss is 0.550256252289
1082 val loss is 0.563964426517
1083 train loss is 0.555077791214
1083 val loss is 0.562388598919
1084 train loss is 0.556769132614
1084 val loss is 0.561750113964
1085 train loss is 0.523926258087
1085 val loss is 0.564725160599
1086 train loss is 0.63633453846
1086 val loss is 0.565907239914
1087 train loss is 0.579310953617
1087 val loss is 0.565046191216
1088 train loss is 0.551414012909
1088 val loss is 0.568948030472
1089 train loss is 0.577393889427
1089 val loss is 0.568461537361
1090 train loss is 0.566439151764
1090 val loss is 0.562227010727
1091 train loss is 0.593867242336
1091 val loss is 0.561559557915
1092 train loss is 0.569978296757
1092 val loss is 0.56690955162
1093 train loss is 0.628753125668
1093 val loss is 0.566324532032
1094 train loss is 0.586638450623
1094 val loss is 0.562119185925
1095 train loss is 0.538518071175
1095 val loss is 0.564989626408
1096 train loss is 0.563861072063
1096 val loss is 0.565989851952
1097 train loss is 0.563279271126
1097 val loss is 0.559504508972
1098 train loss is 0.569362521172
1098 val loss is 0.557608664036
1099 train loss is 0.57770138979
1099 val loss is 0.557936429977
1100 train loss is 0.540037989616
1100 val loss is 0.556972920895
1101 train loss is 0.558135867119
1101 val loss is 0.554738521576
1102 train loss is 0.607099056244
1102 val loss is 0.553486585617
1103 train loss is 0.563148975372
1103 val loss is 0.554915428162
1104 train loss is 0.533574879169
1104 val loss is 0.557487905025
1105 train loss is 0.536568641663
1105 val loss is 0.554394423962
1106 train loss is 0.57323795557
1106 val loss is 0.54894888401
1107 train loss is 0.51432543993
1107 val loss is 0.551477730274
1108 train loss is 0.542069196701
1108 val loss is 0.554437756538
1109 train loss is 0.506777882576
1109 val loss is 0.549988150597
1110 train loss is 0.590473711491
1110 val loss is 0.546881973743
1111 train loss is 0.567329406738
1111 val loss is 0.551463782787
1112 train loss is 0.537845432758
1112 val loss is 0.552557528019
1113 train loss is 0.530032098293
1113 val loss is 0.545637607574
1114 train loss is 0.537224769592
1114 val loss is 0.54561650753
1115 train loss is 0.545293986797
1115 val loss is 0.553007781506
1116 train loss is 0.542831063271
1116 val loss is 0.54914444685
1117 train loss is 0.554627180099
1117 val loss is 0.545165777206
1118 train loss is 0.525979876518
1118 val loss is 0.552907347679
1119 train loss is 0.541478037834
1119 val loss is 0.555436491966
1120 train loss is 0.573859453201
1120 val loss is 0.545977532864
1121 train loss is 0.537649989128
1121 val loss is 0.545768380165
1122 train loss is 0.518610835075
1122 val loss is 0.554642081261
1123 train loss is 0.535188913345
1123 val loss is 0.552313685417
1124 train loss is 0.559033513069
1124 val loss is 0.546461045742
1125 train loss is 0.577412128448
1125 val loss is 0.553584933281
1126 train loss is 0.558355867863
1126 val loss is 0.558107852936
1127 train loss is 0.571094512939
1127 val loss is 0.546952068806
1128 train loss is 0.529564261436
1128 val loss is 0.543034911156
1129 train loss is 0.579697728157
1129 val loss is 0.550419747829
1130 train loss is 0.555967509747
1130 val loss is 0.552720248699
1131 train loss is 0.556150734425
1131 val loss is 0.545891404152
1132 train loss is 0.552213311195
1132 val loss is 0.548451066017
1133 train loss is 0.562037825584
1133 val loss is 0.555663585663
1134 train loss is 0.561435043812
1134 val loss is 0.551443994045
1135 train loss is 0.572290122509
1135 val loss is 0.542834043503
1136 train loss is 0.537681460381
1136 val loss is 0.548778533936
1137 train loss is 0.543671131134
1137 val loss is 0.552440285683
1138 train loss is 0.521582245827
1138 val loss is 0.546679019928
1139 train loss is 0.519638299942
1139 val loss is 0.550127983093
1140 train loss is 0.53693318367
1140 val loss is 0.55502396822
1141 train loss is 0.57039308548
1141 val loss is 0.546629309654
1142 train loss is 0.552685976028
1142 val loss is 0.540161848068
1143 train loss is 0.504766285419
1143 val loss is 0.545641839504
1144 train loss is 0.518951952457
1144 val loss is 0.549126267433
1145 train loss is 0.540926456451
1145 val loss is 0.543353378773
1146 train loss is 0.522524237633
1146 val loss is 0.543874740601
1147 train loss is 0.542327880859
1147 val loss is 0.548269510269
1148 train loss is 0.52735209465
1148 val loss is 0.542936980724
1149 train loss is 0.522090315819
1149 val loss is 0.537314355373
1150 train loss is 0.570081293583
1150 val loss is 0.539404034615
1151 train loss is 0.546932697296
1151 val loss is 0.54309284687
1152 train loss is 0.535969257355
1152 val loss is 0.541474640369
1153 train loss is 0.541661858559
1153 val loss is 0.542470693588
1154 train loss is 0.537585318089
1154 val loss is 0.54327583313
1155 train loss is 0.547896444798
1155 val loss is 0.542374074459
1156 train loss is 0.526379108429
1156 val loss is 0.540986835957
1157 train loss is 0.573734343052
1157 val loss is 0.541505813599
1158 train loss is 0.560696065426
1158 val loss is 0.543291687965
1159 train loss is 0.543343544006
1159 val loss is 0.543149888515
1160 train loss is 0.538524746895
1160 val loss is 0.544705212116
1161 train loss is 0.595016598701
1161 val loss is 0.544786930084
1162 train loss is 0.569251418114
1162 val loss is 0.542934954166
1163 train loss is 0.519207596779
1163 val loss is 0.539618134499
1164 train loss is 0.511386215687
1164 val loss is 0.540320813656
1165 train loss is 0.539261698723
1165 val loss is 0.546046614647
1166 train loss is 0.535297513008
1166 val loss is 0.545085608959
1167 train loss is 0.54191583395
1167 val loss is 0.540997505188
1168 train loss is 0.551803350449
1168 val loss is 0.541575849056
1169 train loss is 0.549253702164
1169 val loss is 0.544168710709
1170 train loss is 0.565786421299
1170 val loss is 0.539938151836
1171 train loss is 0.557595491409
1171 val loss is 0.537991166115
1172 train loss is 0.561989486217
1172 val loss is 0.542253673077
1173 train loss is 0.543905854225
1173 val loss is 0.542780041695
1174 train loss is 0.485796928406
1174 val loss is 0.541159749031
1175 train loss is 0.510903894901
1175 val loss is 0.540105223656
1176 train loss is 0.514018177986
1176 val loss is 0.538744270802
1177 train loss is 0.549444198608
1177 val loss is 0.538280844688
1178 train loss is 0.514124810696
1178 val loss is 0.537650227547
1179 train loss is 0.519265651703
1179 val loss is 0.540440797806
1180 train loss is 0.545580506325
1180 val loss is 0.542404174805
1181 train loss is 0.562135517597
1181 val loss is 0.538333773613
1182 train loss is 0.512894570827
1182 val loss is 0.539090752602
1183 train loss is 0.535767257214
1183 val loss is 0.539382040501
1184 train loss is 0.567191183567
1184 val loss is 0.533456861973
1185 train loss is 0.529454469681
1185 val loss is 0.531743824482
1186 train loss is 0.549506783485
1186 val loss is 0.536257147789
1187 train loss is 0.524362206459
1187 val loss is 0.53859770298
1188 train loss is 0.54059523344
1188 val loss is 0.535275936127
1189 train loss is 0.52509945631
1189 val loss is 0.533889591694
1190 train loss is 0.537391602993
1190 val loss is 0.536924600601
1191 train loss is 0.515383303165
1191 val loss is 0.534510970116
1192 train loss is 0.543780207634
1192 val loss is 0.529842019081
1193 train loss is 0.544102609158
1193 val loss is 0.533585786819
1194 train loss is 0.55645853281
1194 val loss is 0.540592670441
1195 train loss is 0.564933538437
1195 val loss is 0.535572290421
1196 train loss is 0.570388197899
1196 val loss is 0.530067801476
1197 train loss is 0.524363279343
1197 val loss is 0.534887909889
1198 train loss is 0.547671020031
1198 val loss is 0.537755489349
1199 train loss is 0.489880144596
1199 val loss is 0.530821621418
1200 train loss is 0.52454906702
1200 val loss is 0.534331798553
1201 train loss is 0.559639930725
1201 val loss is 0.541513681412
1202 train loss is 0.544344305992
1202 val loss is 0.536485910416
1203 train loss is 0.524409413338
1203 val loss is 0.531621396542
1204 train loss is 0.522407054901
1204 val loss is 0.539577543736
1205 train loss is 0.555186629295
1205 val loss is 0.537484109402
1206 train loss is 0.515880644321
1206 val loss is 0.527974426746
1207 train loss is 0.496014356613
1207 val loss is 0.535446763039
1208 train loss is 0.567517757416
1208 val loss is 0.542249917984
1209 train loss is 0.519301533699
1209 val loss is 0.534122347832
1210 train loss is 0.52496945858
1210 val loss is 0.531171798706
1211 train loss is 0.550941824913
1211 val loss is 0.536993980408
1212 train loss is 0.509341001511
1212 val loss is 0.537951827049
1213 train loss is 0.558181881905
1213 val loss is 0.530299961567
1214 train loss is 0.547377586365
1214 val loss is 0.531137168407
1215 train loss is 0.566507339478
1215 val loss is 0.539280951023
1216 train loss is 0.559149265289
1216 val loss is 0.534934878349
1217 train loss is 0.559830605984
1217 val loss is 0.529570102692
1218 train loss is 0.529077291489
1218 val loss is 0.536211490631
1219 train loss is 0.563391208649
1219 val loss is 0.538808226585
1220 train loss is 0.585170269012
1220 val loss is 0.531496882439
1221 train loss is 0.553111374378
1221 val loss is 0.530496120453
1222 train loss is 0.532670974731
1222 val loss is 0.537503540516
1223 train loss is 0.573871850967
1223 val loss is 0.539108633995
1224 train loss is 0.511350750923
1224 val loss is 0.532907366753
1225 train loss is 0.549515902996
1225 val loss is 0.531602025032
1226 train loss is 0.544770598412
1226 val loss is 0.535098314285
1227 train loss is 0.580306529999
1227 val loss is 0.533456623554
1228 train loss is 0.547330021858
1228 val loss is 0.529452323914
1229 train loss is 0.528554260731
1229 val loss is 0.532904148102
1230 train loss is 0.502312302589
1230 val loss is 0.539163768291
1231 train loss is 0.547486305237
1231 val loss is 0.533673167229
1232 train loss is 0.574985861778
1232 val loss is 0.528909742832
1233 train loss is 0.502038598061
1233 val loss is 0.533276617527
1234 train loss is 0.578280329704
1234 val loss is 0.532958805561
1235 train loss is 0.513726353645
1235 val loss is 0.530629515648
1236 train loss is 0.525593221188
1236 val loss is 0.535680770874
1237 train loss is 0.509834527969
1237 val loss is 0.53802639246
1238 train loss is 0.519411385059
1238 val loss is 0.532552242279
1239 train loss is 0.536824762821
1239 val loss is 0.531212568283
1240 train loss is 0.520095527172
1240 val loss is 0.533949792385
1241 train loss is 0.564828038216
1241 val loss is 0.528961658478
1242 train loss is 0.511814832687
1242 val loss is 0.527893662453
1243 train loss is 0.493043541908
1243 val loss is 0.534359037876
1244 train loss is 0.516456604004
1244 val loss is 0.536023974419
1245 train loss is 0.503856837749
1245 val loss is 0.52937912941
1246 train loss is 0.523083806038
1246 val loss is 0.52842849493
1247 train loss is 0.521804571152
1247 val loss is 0.529158055782
1248 train loss is 0.526867687702
1248 val loss is 0.528917491436
1249 train loss is 0.540889084339
1249 val loss is 0.527870416641
1250 train loss is 0.529445052147
1250 val loss is 0.529168605804
1251 train loss is 0.515641093254
1251 val loss is 0.530379533768
1252 train loss is 0.605659127235
1252 val loss is 0.529399693012
1253 train loss is 0.534269809723
1253 val loss is 0.528855264187
1254 train loss is 0.511260807514
1254 val loss is 0.527920722961
1255 train loss is 0.52407258749
1255 val loss is 0.526522397995
1256 train loss is 0.577466547489
1256 val loss is 0.526172697544
1257 train loss is 0.497083038092
1257 val loss is 0.529546976089
1258 train loss is 0.560225963593
1258 val loss is 0.531053066254
1259 train loss is 0.508803367615
1259 val loss is 0.531094789505
1260 train loss is 0.477147579193
1260 val loss is 0.531423687935
1261 train loss is 0.491542518139
1261 val loss is 0.526183307171
1262 train loss is 0.490782320499
1262 val loss is 0.524321615696
1263 train loss is 0.559464871883
1263 val loss is 0.530230760574
1264 train loss is 0.520671486855
1264 val loss is 0.530660450459
1265 train loss is 0.560323178768
1265 val loss is 0.530192255974
1266 train loss is 0.531415700912
1266 val loss is 0.53104531765
1267 train loss is 0.52963745594
1267 val loss is 0.534876346588
1268 train loss is 0.55729752779
1268 val loss is 0.527856171131
1269 train loss is 0.540686607361
1269 val loss is 0.522911608219
1270 train loss is 0.508827567101
1270 val loss is 0.529845654964
1271 train loss is 0.535579383373
1271 val loss is 0.53188252449
1272 train loss is 0.560871779919
1272 val loss is 0.526629090309
1273 train loss is 0.515365064144
1273 val loss is 0.531055927277
1274 train loss is 0.505438327789
1274 val loss is 0.534207582474
1275 train loss is 0.512983381748
1275 val loss is 0.528694033623
1276 train loss is 0.574744105339
1276 val loss is 0.525357246399
1277 train loss is 0.559694051743
1277 val loss is 0.531254410744
1278 train loss is 0.498500198126
1278 val loss is 0.53485262394
1279 train loss is 0.51157450676
1279 val loss is 0.532907605171
1280 train loss is 0.540412425995
1280 val loss is 0.532853960991
1281 train loss is 0.536049246788
1281 val loss is 0.532865464687
1282 train loss is 0.569711089134
1282 val loss is 0.530221819878
1283 train loss is 0.513652861118
1283 val loss is 0.529582083225
1284 train loss is 0.592116892338
1284 val loss is 0.531313657761
1285 train loss is 0.542814731598
1285 val loss is 0.533470034599
1286 train loss is 0.553505063057
1286 val loss is 0.531172633171
1287 train loss is 0.508425116539
1287 val loss is 0.533342182636
1288 train loss is 0.560324013233
1288 val loss is 0.533449709415
1289 train loss is 0.513217806816
1289 val loss is 0.528084754944
1290 train loss is 0.545842766762
1290 val loss is 0.528383374214
1291 train loss is 0.538400232792
1291 val loss is 0.534501314163
1292 train loss is 0.559425830841
1292 val loss is 0.532233834267
1293 train loss is 0.530234515667
1293 val loss is 0.529382646084
1294 train loss is 0.564496397972
1294 val loss is 0.532661557198
1295 train loss is 0.54959321022
1295 val loss is 0.533412218094
1296 train loss is 0.526661634445
1296 val loss is 0.525895237923
1297 train loss is 0.545538365841
1297 val loss is 0.526564359665
1298 train loss is 0.499753475189
1298 val loss is 0.534232378006
1299 train loss is 0.50409245491
1299 val loss is 0.530109643936
1300 train loss is 0.560915112495
1300 val loss is 0.527195036411
1301 train loss is 0.525547206402
1301 val loss is 0.536725521088
1302 train loss is 0.546086192131
1302 val loss is 0.53514111042
1303 train loss is 0.539608836174
1303 val loss is 0.527670145035
1304 train loss is 0.509530723095
1304 val loss is 0.529868721962
1305 train loss is 0.549545526505
1305 val loss is 0.532254576683
1306 train loss is 0.515888154507
1306 val loss is 0.530803859234
1307 train loss is 0.521799921989
1307 val loss is 0.529674291611
1308 train loss is 0.578859508038
1308 val loss is 0.532036244869
1309 train loss is 0.529786109924
1309 val loss is 0.53303861618
1310 train loss is 0.544649839401
1310 val loss is 0.529350459576
1311 train loss is 0.509358823299
1311 val loss is 0.528854012489
1312 train loss is 0.50800049305
1312 val loss is 0.526477277279
1313 train loss is 0.535017609596
1313 val loss is 0.524542570114
1314 train loss is 0.505902290344
1314 val loss is 0.530343174934
1315 train loss is 0.546455979347
1315 val loss is 0.533837914467
1316 train loss is 0.505417048931
1316 val loss is 0.530699133873
1317 train loss is 0.535287201405
1317 val loss is 0.526002109051
1318 train loss is 0.471437692642
1318 val loss is 0.528083205223
1319 train loss is 0.550683617592
1319 val loss is 0.529909729958
1320 train loss is 0.536539196968
1320 val loss is 0.528432488441
1321 train loss is 0.535473227501
1321 val loss is 0.529565632343
1322 train loss is 0.489359647036
1322 val loss is 0.532182335854
1323 train loss is 0.533141434193
1323 val loss is 0.529521465302
1324 train loss is 0.580692350864
1324 val loss is 0.526749372482
1325 train loss is 0.543176054955
1325 val loss is 0.528920710087
1326 train loss is 0.574845194817
1326 val loss is 0.525479435921
1327 train loss is 0.515645384789
1327 val loss is 0.522075891495
1328 train loss is 0.533456087112
1328 val loss is 0.529124379158
1329 train loss is 0.517066121101
1329 val loss is 0.533879578114
1330 train loss is 0.511752009392
1330 val loss is 0.523126006126
1331 train loss is 0.580004692078
1331 val loss is 0.521275520325
1332 train loss is 0.526951909065
1332 val loss is 0.531498789787
1333 train loss is 0.519489645958
1333 val loss is 0.523810267448
1334 train loss is 0.551817774773
1334 val loss is 0.515259504318
1335 train loss is 0.509531974792
1335 val loss is 0.526352882385
1336 train loss is 0.52618432045
1336 val loss is 0.533266544342
1337 train loss is 0.496363073587
1337 val loss is 0.521631121635
1338 train loss is 0.52605766058
1338 val loss is 0.516693472862
1339 train loss is 0.526542365551
1339 val loss is 0.529097676277
1340 train loss is 0.529439926147
1340 val loss is 0.52797293663
1341 train loss is 0.505087912083
1341 val loss is 0.514949262142
1342 train loss is 0.556040644646
1342 val loss is 0.521050453186
1343 train loss is 0.54852694273
1343 val loss is 0.534439563751
1344 train loss is 0.538111627102
1344 val loss is 0.524907052517
1345 train loss is 0.521186769009
1345 val loss is 0.514784038067
1346 train loss is 0.500170588493
1346 val loss is 0.525500118732
1347 train loss is 0.555072069168
1347 val loss is 0.527152121067
1348 train loss is 0.536432862282
1348 val loss is 0.515725970268
1349 train loss is 0.521395206451
1349 val loss is 0.518788337708
1350 train loss is 0.489290118217
1350 val loss is 0.530226051807
1351 train loss is 0.556306600571
1351 val loss is 0.521004617214
1352 train loss is 0.510914266109
1352 val loss is 0.510794341564
1353 train loss is 0.495467603207
1353 val loss is 0.51917552948
1354 train loss is 0.562437474728
1354 val loss is 0.520463526249
1355 train loss is 0.543825685978
1355 val loss is 0.513440608978
1356 train loss is 0.506947219372
1356 val loss is 0.516851663589
1357 train loss is 0.536255478859
1357 val loss is 0.526189923286
1358 train loss is 0.508111596107
1358 val loss is 0.521676123142
1359 train loss is 0.50593984127
1359 val loss is 0.513509869576
1360 train loss is 0.512507021427
1360 val loss is 0.518927693367
1361 train loss is 0.533905565739
1361 val loss is 0.52080643177
1362 train loss is 0.552544414997
1362 val loss is 0.51325404644
1363 train loss is 0.512324512005
1363 val loss is 0.517508625984
1364 train loss is 0.516249001026
1364 val loss is 0.524402439594
1365 train loss is 0.563890278339
1365 val loss is 0.519621491432
1366 train loss is 0.49324914813
1366 val loss is 0.514064013958
1367 train loss is 0.505706191063
1367 val loss is 0.51932913065
1368 train loss is 0.467149764299
1368 val loss is 0.520607590675
1369 train loss is 0.493483304977
1369 val loss is 0.512156188488
1370 train loss is 0.529938578606
1370 val loss is 0.513177573681
1371 train loss is 0.501576542854
1371 val loss is 0.522612333298
1372 train loss is 0.5239341259
1372 val loss is 0.520827114582
1373 train loss is 0.555454969406
1373 val loss is 0.513919830322
1374 train loss is 0.534772217274
1374 val loss is 0.515835940838
1375 train loss is 0.521211087704
1375 val loss is 0.516895055771
1376 train loss is 0.516723155975
1376 val loss is 0.511852502823
1377 train loss is 0.541277348995
1377 val loss is 0.513105690479
1378 train loss is 0.494847118855
1378 val loss is 0.52042555809
1379 train loss is 0.517704486847
1379 val loss is 0.517374932766
1380 train loss is 0.532201945782
1380 val loss is 0.512769341469
1381 train loss is 0.517593860626
1381 val loss is 0.516793847084
1382 train loss is 0.51320207119
1382 val loss is 0.519643306732
1383 train loss is 0.513381719589
1383 val loss is 0.512219190598
1384 train loss is 0.520156085491
1384 val loss is 0.511538028717
1385 train loss is 0.526814818382
1385 val loss is 0.521724760532
1386 train loss is 0.535665273666
1386 val loss is 0.52033495903
1387 train loss is 0.517609000206
1387 val loss is 0.513527393341
1388 train loss is 0.520659029484
1388 val loss is 0.514691948891
1389 train loss is 0.518316686153
1389 val loss is 0.517167329788
1390 train loss is 0.479541867971
1390 val loss is 0.509418129921
1391 train loss is 0.503460586071
1391 val loss is 0.509670913219
1392 train loss is 0.496380656958
1392 val loss is 0.518800079823
1393 train loss is 0.498107194901
1393 val loss is 0.516376376152
1394 train loss is 0.492081820965
1394 val loss is 0.508752465248
1395 train loss is 0.462241560221
1395 val loss is 0.516714513302
1396 train loss is 0.522401213646
1396 val loss is 0.520752429962
1397 train loss is 0.504843592644
1397 val loss is 0.506402909756
1398 train loss is 0.488239228725
1398 val loss is 0.507731199265
1399 train loss is 0.516287565231
1399 val loss is 0.523034691811
1400 train loss is 0.533057868481
1400 val loss is 0.515303492546
1401 train loss is 0.528491735458
1401 val loss is 0.505856573582
1402 train loss is 0.538472533226
1402 val loss is 0.51696896553
1403 train loss is 0.521974086761
1403 val loss is 0.519703507423
1404 train loss is 0.500827670097
1404 val loss is 0.503294527531
1405 train loss is 0.520221590996
1405 val loss is 0.506704092026
1406 train loss is 0.481352448463
1406 val loss is 0.523705542088
1407 train loss is 0.508013963699
1407 val loss is 0.514352202415
1408 train loss is 0.482584297657
1408 val loss is 0.504679858685
1409 train loss is 0.489962160587
1409 val loss is 0.517195820808
1410 train loss is 0.534593462944
1410 val loss is 0.52145332098
1411 train loss is 0.496353983879
1411 val loss is 0.503301382065
1412 train loss is 0.521487951279
1412 val loss is 0.503266692162
1413 train loss is 0.518206238747
1413 val loss is 0.519236803055
1414 train loss is 0.561430871487
1414 val loss is 0.516422212124
1415 train loss is 0.542565822601
1415 val loss is 0.503288447857
1416 train loss is 0.492981880903
1416 val loss is 0.510083675385
1417 train loss is 0.558089256287
1417 val loss is 0.514750659466
1418 train loss is 0.534422278404
1418 val loss is 0.501661062241
1419 train loss is 0.505138218403
1419 val loss is 0.500889241695
1420 train loss is 0.501360297203
1420 val loss is 0.511335849762
1421 train loss is 0.507429838181
1421 val loss is 0.509356915951
1422 train loss is 0.484169661999
1422 val loss is 0.500411391258
1423 train loss is 0.516626298428
1423 val loss is 0.507225334644
1424 train loss is 0.501950502396
1424 val loss is 0.511183142662
1425 train loss is 0.527045488358
1425 val loss is 0.501517772675
1426 train loss is 0.517095208168
1426 val loss is 0.500196576118
1427 train loss is 0.498390614986
1427 val loss is 0.51054662466
1428 train loss is 0.518017113209
1428 val loss is 0.510955393314
1429 train loss is 0.519303381443
1429 val loss is 0.502687573433
1430 train loss is 0.487668931484
1430 val loss is 0.507038116455
1431 train loss is 0.499177485704
1431 val loss is 0.513854265213
1432 train loss is 0.528999865055
1432 val loss is 0.505406618118
1433 train loss is 0.537436008453
1433 val loss is 0.499964147806
1434 train loss is 0.47675126791
1434 val loss is 0.508515536785
1435 train loss is 0.517040252686
1435 val loss is 0.51053249836
1436 train loss is 0.50615131855
1436 val loss is 0.502828240395
1437 train loss is 0.503144860268
1437 val loss is 0.50256383419
1438 train loss is 0.502152562141
1438 val loss is 0.509057641029
1439 train loss is 0.540782928467
1439 val loss is 0.504128456116
1440 train loss is 0.499415308237
1440 val loss is 0.497627109289
1441 train loss is 0.492573320866
1441 val loss is 0.507775783539
1442 train loss is 0.49693736434
1442 val loss is 0.5115493536
1443 train loss is 0.535417079926
1443 val loss is 0.501505672932
1444 train loss is 0.531293451786
1444 val loss is 0.498309642076
1445 train loss is 0.458841830492
1445 val loss is 0.503915190697
1446 train loss is 0.528631091118
1446 val loss is 0.502096056938
1447 train loss is 0.499339520931
1447 val loss is 0.494386821985
1448 train loss is 0.529398739338
1448 val loss is 0.498466908932
1449 train loss is 0.501024246216
1449 val loss is 0.506517112255
1450 train loss is 0.497938990593
1450 val loss is 0.500274538994
1451 train loss is 0.492848277092
1451 val loss is 0.493012070656
1452 train loss is 0.492575228214
1452 val loss is 0.499958097935
1453 train loss is 0.479115843773
1453 val loss is 0.500342130661
1454 train loss is 0.504436612129
1454 val loss is 0.490340650082
1455 train loss is 0.488395631313
1455 val loss is 0.495045363903
1456 train loss is 0.502666115761
1456 val loss is 0.507455408573
1457 train loss is 0.492835998535
1457 val loss is 0.502264499664
1458 train loss is 0.474514991045
1458 val loss is 0.494361579418
1459 train loss is 0.5422976017
1459 val loss is 0.498685359955
1460 train loss is 0.513904511929
1460 val loss is 0.500410795212
1461 train loss is 0.510663926601
1461 val loss is 0.491887718439
1462 train loss is 0.52332919836
1462 val loss is 0.492936998606
1463 train loss is 0.483465284109
1463 val loss is 0.503261506557
1464 train loss is 0.528537511826
1464 val loss is 0.499711185694
1465 train loss is 0.490497231483
1465 val loss is 0.492924928665
1466 train loss is 0.497065365314
1466 val loss is 0.498791754246
1467 train loss is 0.519602060318
1467 val loss is 0.498154073954
1468 train loss is 0.537203550339
1468 val loss is 0.488942921162
1469 train loss is 0.468029916286
1469 val loss is 0.491957128048
1470 train loss is 0.47748374939
1470 val loss is 0.49986204505
1471 train loss is 0.476772367954
1471 val loss is 0.497150719166
1472 train loss is 0.52257502079
1472 val loss is 0.491484642029
1473 train loss is 0.47224932909
1473 val loss is 0.492274105549
1474 train loss is 0.489956617355
1474 val loss is 0.492839515209
1475 train loss is 0.486003547907
1475 val loss is 0.487567216158
1476 train loss is 0.559211432934
1476 val loss is 0.487015575171
1477 train loss is 0.48915502429
1477 val loss is 0.491776645184
1478 train loss is 0.502885341644
1478 val loss is 0.493144661188
1479 train loss is 0.501706242561
1479 val loss is 0.491660267115
1480 train loss is 0.538018405437
1480 val loss is 0.49057379365
1481 train loss is 0.490182220936
1481 val loss is 0.489891886711
1482 train loss is 0.495916843414
1482 val loss is 0.49038541317
1483 train loss is 0.474344074726
1483 val loss is 0.486658573151
1484 train loss is 0.539367794991
1484 val loss is 0.4891718328
1485 train loss is 0.483617186546
1485 val loss is 0.496539592743
1486 train loss is 0.457322716713
1486 val loss is 0.491667717695
1487 train loss is 0.553967535496
1487 val loss is 0.487518042326
1488 train loss is 0.501161813736
1488 val loss is 0.490339189768
1489 train loss is 0.537002325058
1489 val loss is 0.490127384663
1490 train loss is 0.520269751549
1490 val loss is 0.488501489162
1491 train loss is 0.441165030003
1491 val loss is 0.493447482586
1492 train loss is 0.480188637972
1492 val loss is 0.499035656452
1493 train loss is 0.491176605225
1493 val loss is 0.492731541395
1494 train loss is 0.509789228439
1494 val loss is 0.487092077732
1495 train loss is 0.512474894524
1495 val loss is 0.492197215557
1496 train loss is 0.509316384792
1496 val loss is 0.495202362537
1497 train loss is 0.528508663177
1497 val loss is 0.488614141941
1498 train loss is 0.496611922979
1498 val loss is 0.49046459794
1499 train loss is 0.511730849743
1499 val loss is 0.496433138847
1500 train loss is 0.50672185421
1500 val loss is 0.506272494793
1501 train loss is 0.520751237869
1501 val loss is 0.50605225563
1502 train loss is 0.489646434784
1502 val loss is 0.495003312826
1503 train loss is 0.495807409286
1503 val loss is 0.487136751413
1504 train loss is 0.503885865211
1504 val loss is 0.492147564888
1505 train loss is 0.509006738663
1505 val loss is 0.501386880875
1506 train loss is 0.468651592731
1506 val loss is 0.501605570316
1507 train loss is 0.492064416409
1507 val loss is 0.49212795496
1508 train loss is 0.500615239143
1508 val loss is 0.487452566624
1509 train loss is 0.492554962635
1509 val loss is 0.492243409157
1510 train loss is 0.503977775574
1510 val loss is 0.498894065619
1511 train loss is 0.486579030752
1511 val loss is 0.49970304966
1512 train loss is 0.460181713104
1512 val loss is 0.492765545845
1513 train loss is 0.484280109406
1513 val loss is 0.485434353352
1514 train loss is 0.477597773075
1514 val loss is 0.486456602812
1515 train loss is 0.487707912922
1515 val loss is 0.4922336936
1516 train loss is 0.507915318012
1516 val loss is 0.494447112083
1517 train loss is 0.497849702835
1517 val loss is 0.489106893539
1518 train loss is 0.470858067274
1518 val loss is 0.484223306179
1519 train loss is 0.476195007563
1519 val loss is 0.487074762583
1520 train loss is 0.487908065319
1520 val loss is 0.495293915272
1521 train loss is 0.497550338507
1521 val loss is 0.497355282307
1522 train loss is 0.488756656647
1522 val loss is 0.489376187325
1523 train loss is 0.483115524054
1523 val loss is 0.482154846191
1524 train loss is 0.491655170918
1524 val loss is 0.484070539474
1525 train loss is 0.444130510092
1525 val loss is 0.490675330162
1526 train loss is 0.50890737772
1526 val loss is 0.492220133543
1527 train loss is 0.495637893677
1527 val loss is 0.486849755049
1528 train loss is 0.495556712151
1528 val loss is 0.482314556837
1529 train loss is 0.537655830383
1529 val loss is 0.484014958143
1530 train loss is 0.483951628208
1530 val loss is 0.490564107895
1531 train loss is 0.506690204144
1531 val loss is 0.494229376316
1532 train loss is 0.483734577894
1532 val loss is 0.489717721939
1533 train loss is 0.478743314743
1533 val loss is 0.481813937426
1534 train loss is 0.475605666637
1534 val loss is 0.479766607285
1535 train loss is 0.478007256985
1535 val loss is 0.483377695084
1536 train loss is 0.465723335743
1536 val loss is 0.486879318953
1537 train loss is 0.493331491947
1537 val loss is 0.484528720379
1538 train loss is 0.470851093531
1538 val loss is 0.480210781097
1539 train loss is 0.460734307766
1539 val loss is 0.481002926826
1540 train loss is 0.466559886932
1540 val loss is 0.486077874899
1541 train loss is 0.48912358284
1541 val loss is 0.489685714245
1542 train loss is 0.4675129354
1542 val loss is 0.486692667007
1543 train loss is 0.495874285698
1543 val loss is 0.480297654867
1544 train loss is 0.487780809402
1544 val loss is 0.47739765048
1545 train loss is 0.489910066128
1545 val loss is 0.480745017529
1546 train loss is 0.506182491779
1546 val loss is 0.486108422279
1547 train loss is 0.486089676619
1547 val loss is 0.486844062805
1548 train loss is 0.497496008873
1548 val loss is 0.482206583023
1549 train loss is 0.489472389221
1549 val loss is 0.478689521551
1550 train loss is 0.475663542747
1550 val loss is 0.481202691793
1551 train loss is 0.478599280119
1551 val loss is 0.485623538494
1552 train loss is 0.512792348862
1552 val loss is 0.486967414618
1553 train loss is 0.431925415993
1553 val loss is 0.482682704926
1554 train loss is 0.471408754587
1554 val loss is 0.477245599031
1555 train loss is 0.48005604744
1555 val loss is 0.476304918528
1556 train loss is 0.470507442951
1556 val loss is 0.479240655899
1557 train loss is 0.463605880737
1557 val loss is 0.48348402977
1558 train loss is 0.483851492405
1558 val loss is 0.48379561305
1559 train loss is 0.49802750349
1559 val loss is 0.480192154646
1560 train loss is 0.479282140732
1560 val loss is 0.477290302515
1561 train loss is 0.475881367922
1561 val loss is 0.478371024132
1562 train loss is 0.496152102947
1562 val loss is 0.481707930565
1563 train loss is 0.506398797035
1563 val loss is 0.483084350824
1564 train loss is 0.462703287601
1564 val loss is 0.481102347374
1565 train loss is 0.498186886311
1565 val loss is 0.477955818176
1566 train loss is 0.517677903175
1566 val loss is 0.477320671082
1567 train loss is 0.490318834782
1567 val loss is 0.478945434093
1568 train loss is 0.499312877655
1568 val loss is 0.479882657528
1569 train loss is 0.473272919655
1569 val loss is 0.477883934975
1570 train loss is 0.45525842905
1570 val loss is 0.476405978203
1571 train loss is 0.47860699892
1571 val loss is 0.476928204298
1572 train loss is 0.489771574736
1572 val loss is 0.47775799036
1573 train loss is 0.516093790531
1573 val loss is 0.477520406246
1574 train loss is 0.513753652573
1574 val loss is 0.475398778915
1575 train loss is 0.45486497879
1575 val loss is 0.473977863789
1576 train loss is 0.456664115191
1576 val loss is 0.473782509565
1577 train loss is 0.441340297461
1577 val loss is 0.474431395531
1578 train loss is 0.483963429928
1578 val loss is 0.47541642189
1579 train loss is 0.456674307585
1579 val loss is 0.475314855576
1580 train loss is 0.461972177029
1580 val loss is 0.473518192768
1581 train loss is 0.491509377956
1581 val loss is 0.472337722778
1582 train loss is 0.487256228924
1582 val loss is 0.472807526588
1583 train loss is 0.495468199253
1583 val loss is 0.473901897669
1584 train loss is 0.457052946091
1584 val loss is 0.474565923214
1585 train loss is 0.487393498421
1585 val loss is 0.474191248417
1586 train loss is 0.413722991943
1586 val loss is 0.473576784134
1587 train loss is 0.490700781345
1587 val loss is 0.474138081074
1588 train loss is 0.474665850401
1588 val loss is 0.474676340818
1589 train loss is 0.472072064877
1589 val loss is 0.474777042866
1590 train loss is 0.482073187828
1590 val loss is 0.472210347652
1591 train loss is 0.501425147057
1591 val loss is 0.469834119081
1592 train loss is 0.47665554285
1592 val loss is 0.469958305359
1593 train loss is 0.470046877861
1593 val loss is 0.47269269824
1594 train loss is 0.452970564365
1594 val loss is 0.474652349949
1595 train loss is 0.468931525946
1595 val loss is 0.473080158234
1596 train loss is 0.434398114681
1596 val loss is 0.47075688839
1597 train loss is 0.496061593294
1597 val loss is 0.471318185329
1598 train loss is 0.475751429796
1598 val loss is 0.473814547062
1599 train loss is 0.500331163406
1599 val loss is 0.473208487034
1600 train loss is 0.467060148716
1600 val loss is 0.469931453466
1601 train loss is 0.489391207695
1601 val loss is 0.466944009066
1602 train loss is 0.462649822235
1602 val loss is 0.467754870653
1603 train loss is 0.491376459599
1603 val loss is 0.470694959164
1604 train loss is 0.46274381876
1604 val loss is 0.472219526768
1605 train loss is 0.439673483372
1605 val loss is 0.471032500267
1606 train loss is 0.501894712448
1606 val loss is 0.469671547413
1607 train loss is 0.457093209028
1607 val loss is 0.470828950405
1608 train loss is 0.46810901165
1608 val loss is 0.472934693098
1609 train loss is 0.487681984901
1609 val loss is 0.472344100475
1610 train loss is 0.460765451193
1610 val loss is 0.46898162365
1611 train loss is 0.504062652588
1611 val loss is 0.466436892748
1612 train loss is 0.455546498299
1612 val loss is 0.468149125576
1613 train loss is 0.483322203159
1613 val loss is 0.472018033266
1614 train loss is 0.4509370327
1614 val loss is 0.47311013937
1615 train loss is 0.483894586563
1615 val loss is 0.470816731453
1616 train loss is 0.473770856857
1616 val loss is 0.468923270702
1617 train loss is 0.456281423569
1617 val loss is 0.470191776752
1618 train loss is 0.438563257456
1618 val loss is 0.473293125629
1619 train loss is 0.441819489002
1619 val loss is 0.472967624664
1620 train loss is 0.496223717928
1620 val loss is 0.468515187502
1621 train loss is 0.470921814442
1621 val loss is 0.465360105038
1622 train loss is 0.516154587269
1622 val loss is 0.466253370047
1623 train loss is 0.460249900818
1623 val loss is 0.470760077238
1624 train loss is 0.478313803673
1624 val loss is 0.4741332829
1625 train loss is 0.48255687952
1625 val loss is 0.473397612572
1626 train loss is 0.458740055561
1626 val loss is 0.470193266869
1627 train loss is 0.500615715981
1627 val loss is 0.469160556793
1628 train loss is 0.484190046787
1628 val loss is 0.470538377762
1629 train loss is 0.456863224506
1629 val loss is 0.471148371696
1630 train loss is 0.500614762306
1630 val loss is 0.468414753675
1631 train loss is 0.495332300663
1631 val loss is 0.46521872282
1632 train loss is 0.469420403242
1632 val loss is 0.465078800917
1633 train loss is 0.440038889647
1633 val loss is 0.468402862549
1634 train loss is 0.498294591904
1634 val loss is 0.470769166946
1635 train loss is 0.45752453804
1635 val loss is 0.470134109259
1636 train loss is 0.476649045944
1636 val loss is 0.468202531338
1637 train loss is 0.503450334072
1637 val loss is 0.468277275562
1638 train loss is 0.48452565074
1638 val loss is 0.469357073307
1639 train loss is 0.47670379281
1639 val loss is 0.469445168972
1640 train loss is 0.491353064775
1640 val loss is 0.467209130526
1641 train loss is 0.504022121429
1641 val loss is 0.464938998222
1642 train loss is 0.499763846397
1642 val loss is 0.465070098639
1643 train loss is 0.460982561111
1643 val loss is 0.46733045578
1644 train loss is 0.452585697174
1644 val loss is 0.46908980608
1645 train loss is 0.48422780633
1645 val loss is 0.467891603708
1646 train loss is 0.490583896637
1646 val loss is 0.465822577477
1647 train loss is 0.465649873018
1647 val loss is 0.466323077679
1648 train loss is 0.473928749561
1648 val loss is 0.468406021595
1649 train loss is 0.450253665447
1649 val loss is 0.468746244907
1650 train loss is 0.499612569809
1650 val loss is 0.466151595116
1651 train loss is 0.453153401613
1651 val loss is 0.463262200356
1652 train loss is 0.482796341181
1652 val loss is 0.464161336422
1653 train loss is 0.491218954325
1653 val loss is 0.467628151178
1654 train loss is 0.450040757656
1654 val loss is 0.468612134457
1655 train loss is 0.480123311281
1655 val loss is 0.466511726379
1656 train loss is 0.457282185555
1656 val loss is 0.464364230633
1657 train loss is 0.516506671906
1657 val loss is 0.4656894207
1658 train loss is 0.509694576263
1658 val loss is 0.468811154366
1659 train loss is 0.422488123178
1659 val loss is 0.469005823135
1660 train loss is 0.466881245375
1660 val loss is 0.466328084469
1661 train loss is 0.490023553371
1661 val loss is 0.463860571384
1662 train loss is 0.47539421916
1662 val loss is 0.46396446228
1663 train loss is 0.444912582636
1663 val loss is 0.465514153242
1664 train loss is 0.455272734165
1664 val loss is 0.466446936131
1665 train loss is 0.4591794312
1665 val loss is 0.465396046638
1666 train loss is 0.501874625683
1666 val loss is 0.463998258114
1667 train loss is 0.437920153141
1667 val loss is 0.464436739683
1668 train loss is 0.449873954058
1668 val loss is 0.46641010046
1669 train loss is 0.492539286613
1669 val loss is 0.46649107337
1670 train loss is 0.474815011024
1670 val loss is 0.465233385563
1671 train loss is 0.427806198597
1671 val loss is 0.462665915489
1672 train loss is 0.480903565884
1672 val loss is 0.461993455887
1673 train loss is 0.476336121559
1673 val loss is 0.463207244873
1674 train loss is 0.446555823088
1674 val loss is 0.464057594538
1675 train loss is 0.468660235405
1675 val loss is 0.463576585054
1676 train loss is 0.453673064709
1676 val loss is 0.463101685047
1677 train loss is 0.495490670204
1677 val loss is 0.46409073472
1678 train loss is 0.464493870735
1678 val loss is 0.465574324131
1679 train loss is 0.438838809729
1679 val loss is 0.465840041637
1680 train loss is 0.478050589561
1680 val loss is 0.465089321136
1681 train loss is 0.468639701605
1681 val loss is 0.46334373951
1682 train loss is 0.435688346624
1682 val loss is 0.462596267462
1683 train loss is 0.486302673817
1683 val loss is 0.462408810854
1684 train loss is 0.455220252275
1684 val loss is 0.462807476521
1685 train loss is 0.477465510368
1685 val loss is 0.463366985321
1686 train loss is 0.4427498281
1686 val loss is 0.464112222195
1687 train loss is 0.475729852915
1687 val loss is 0.464275956154
1688 train loss is 0.472195744514
1688 val loss is 0.46431902051
1689 train loss is 0.443593531847
1689 val loss is 0.464590340853
1690 train loss is 0.459525853395
1690 val loss is 0.4649733603
1691 train loss is 0.467829197645
1691 val loss is 0.464274376631
1692 train loss is 0.459758728743
1692 val loss is 0.462912589312
1693 train loss is 0.487665981054
1693 val loss is 0.462463319302
1694 train loss is 0.434997320175
1694 val loss is 0.463483422995
1695 train loss is 0.442674279213
1695 val loss is 0.464586377144
1696 train loss is 0.504764616489
1696 val loss is 0.464149028063
1697 train loss is 0.447269558907
1697 val loss is 0.46369189024
1698 train loss is 0.480402290821
1698 val loss is 0.464207649231
1699 train loss is 0.471226513386
1699 val loss is 0.465574920177
1700 train loss is 0.469950377941
1700 val loss is 0.466349929571
1701 train loss is 0.51816534996
1701 val loss is 0.465561717749
1702 train loss is 0.459389358759
1702 val loss is 0.464740604162
1703 train loss is 0.438725173473
1703 val loss is 0.464204013348
1704 train loss is 0.466294229031
1704 val loss is 0.464471906424
1705 train loss is 0.521358251572
1705 val loss is 0.46415039897
1706 train loss is 0.453327953815
1706 val loss is 0.464217185974
1707 train loss is 0.468493193388
1707 val loss is 0.464764714241
1708 train loss is 0.491227954626
1708 val loss is 0.466406792402
1709 train loss is 0.470886051655
1709 val loss is 0.4669932127
1710 train loss is 0.541004657745
1710 val loss is 0.466105848551
1711 train loss is 0.455878764391
1711 val loss is 0.464904725552
1712 train loss is 0.458508163691
1712 val loss is 0.46407276392
1713 train loss is 0.472400426865
1713 val loss is 0.464088261127
1714 train loss is 0.459141582251
1714 val loss is 0.464402973652
1715 train loss is 0.468445271254
1715 val loss is 0.464374363422
1716 train loss is 0.476804852486
1716 val loss is 0.464191019535
1717 train loss is 0.47474116087
1717 val loss is 0.464761137962
1718 train loss is 0.453212559223
1718 val loss is 0.465568482876
1719 train loss is 0.434485822916
1719 val loss is 0.465833812952
1720 train loss is 0.474941462278
1720 val loss is 0.464068263769
1721 train loss is 0.4812053442
1721 val loss is 0.462482452393
1722 train loss is 0.473859369755
1722 val loss is 0.462749928236
1723 train loss is 0.452397674322
1723 val loss is 0.463389068842
1724 train loss is 0.438385277987
1724 val loss is 0.462709128857
1725 train loss is 0.512180089951
1725 val loss is 0.461953014135
1726 train loss is 0.448209285736
1726 val loss is 0.462262094021
1727 train loss is 0.42516797781
1727 val loss is 0.462717086077
1728 train loss is 0.468584001064
1728 val loss is 0.463212579489
1729 train loss is 0.478779315948
1729 val loss is 0.463164001703
1730 train loss is 0.436203420162
1730 val loss is 0.462944179773
1731 train loss is 0.455176591873
1731 val loss is 0.462485969067
1732 train loss is 0.428444564342
1732 val loss is 0.461391419172
1733 train loss is 0.469477534294
1733 val loss is 0.460054934025
1734 train loss is 0.502228617668
1734 val loss is 0.459912121296
1735 train loss is 0.466885447502
1735 val loss is 0.460899233818
1736 train loss is 0.511328518391
1736 val loss is 0.461222201586
1737 train loss is 0.494654148817
1737 val loss is 0.461050391197
1738 train loss is 0.437989681959
1738 val loss is 0.460862100124
1739 train loss is 0.467363327742
1739 val loss is 0.462079107761
1740 train loss is 0.453048586845
1740 val loss is 0.462650358677
1741 train loss is 0.495024889708
1741 val loss is 0.462049663067
1742 train loss is 0.473539352417
1742 val loss is 0.461084246635
1743 train loss is 0.48826110363
1743 val loss is 0.460670799017
1744 train loss is 0.461258888245
1744 val loss is 0.460717618465
1745 train loss is 0.46188428998
1745 val loss is 0.460204780102
1746 train loss is 0.475100874901
1746 val loss is 0.45974624157
1747 train loss is 0.434583246708
1747 val loss is 0.459623575211
1748 train loss is 0.497391521931
1748 val loss is 0.461173504591
1749 train loss is 0.486750364304
1749 val loss is 0.462401032448
1750 train loss is 0.48062390089
1750 val loss is 0.461972892284
1751 train loss is 0.462763249874
1751 val loss is 0.461173653603
1752 train loss is 0.455887764692
1752 val loss is 0.460837155581
1753 train loss is 0.510080754757
1753 val loss is 0.461127012968
1754 train loss is 0.480880320072
1754 val loss is 0.460925281048
1755 train loss is 0.500003576279
1755 val loss is 0.459345042706
1756 train loss is 0.457710981369
1756 val loss is 0.457802474499
1757 train loss is 0.465512603521
1757 val loss is 0.458591043949
1758 train loss is 0.460889339447
1758 val loss is 0.460962742567
1759 train loss is 0.457196116447
1759 val loss is 0.462316423655
1760 train loss is 0.464703530073
1760 val loss is 0.461187511683
1761 train loss is 0.447440057993
1761 val loss is 0.459376096725
1762 train loss is 0.473238378763
1762 val loss is 0.45902711153
1763 train loss is 0.464226126671
1763 val loss is 0.460187286139
1764 train loss is 0.437805235386
1764 val loss is 0.460328400135
1765 train loss is 0.459815233946
1765 val loss is 0.459077864885
1766 train loss is 0.435404062271
1766 val loss is 0.456980854273
1767 train loss is 0.492472857237
1767 val loss is 0.457349896431
1768 train loss is 0.46793448925
1768 val loss is 0.459816962481
1769 train loss is 0.453536629677
1769 val loss is 0.461823135614
1770 train loss is 0.50029951334
1770 val loss is 0.460833311081
1771 train loss is 0.478315919638
1771 val loss is 0.458653986454
1772 train loss is 0.511162519455
1772 val loss is 0.45787268877
1773 train loss is 0.471168637276
1773 val loss is 0.460005521774
1774 train loss is 0.46365904808
1774 val loss is 0.460807561874
1775 train loss is 0.465609699488
1775 val loss is 0.458807170391
1776 train loss is 0.491326242685
1776 val loss is 0.45576608181
1777 train loss is 0.460019260645
1777 val loss is 0.45533567667
1778 train loss is 0.432387769222
1778 val loss is 0.457656741142
1779 train loss is 0.487035095692
1779 val loss is 0.459724605083
1780 train loss is 0.44079041481
1780 val loss is 0.459433019161
1781 train loss is 0.499315828085
1781 val loss is 0.4577229321
1782 train loss is 0.460032045841
1782 val loss is 0.457077354193
1783 train loss is 0.446174025536
1783 val loss is 0.45778247714
1784 train loss is 0.500908493996
1784 val loss is 0.45807659626
1785 train loss is 0.43973878026
1785 val loss is 0.456580102444
1786 train loss is 0.464165687561
1786 val loss is 0.455082446337
1787 train loss is 0.48569098115
1787 val loss is 0.45474332571
1788 train loss is 0.454525768757
1788 val loss is 0.455921381712
1789 train loss is 0.480257958174
1789 val loss is 0.45762693882
1790 train loss is 0.445271342993
1790 val loss is 0.457845360041
1791 train loss is 0.474836170673
1791 val loss is 0.457803666592
1792 train loss is 0.482922464609
1792 val loss is 0.456840902567
1793 train loss is 0.471723675728
1793 val loss is 0.456334203482
1794 train loss is 0.440009951591
1794 val loss is 0.456862568855
1795 train loss is 0.450072437525
1795 val loss is 0.456881761551
1796 train loss is 0.456721663475
1796 val loss is 0.456281453371
1797 train loss is 0.443484038115
1797 val loss is 0.454903960228
1798 train loss is 0.484552502632
1798 val loss is 0.455040067434
1799 train loss is 0.439967602491
1799 val loss is 0.456647068262
1800 train loss is 0.426585435867
1800 val loss is 0.458150058985
1801 train loss is 0.493245095015
1801 val loss is 0.457458943129
1802 train loss is 0.487134099007
1802 val loss is 0.456351101398
1803 train loss is 0.461279630661
1803 val loss is 0.456396400928
1804 train loss is 0.483844429255
1804 val loss is 0.456993252039
1805 train loss is 0.445086658001
1805 val loss is 0.457133352757
1806 train loss is 0.438169151545
1806 val loss is 0.456290304661
1807 train loss is 0.44883364439
1807 val loss is 0.455296516418
1808 train loss is 0.488169968128
1808 val loss is 0.455129444599
1809 train loss is 0.472934007645
1809 val loss is 0.455883204937
1810 train loss is 0.481337934732
1810 val loss is 0.456629514694
1811 train loss is 0.469542741776
1811 val loss is 0.456985712051
1812 train loss is 0.48979189992
1812 val loss is 0.456733167171
1813 train loss is 0.439231693745
1813 val loss is 0.456802427769
1814 train loss is 0.4271684587
1814 val loss is 0.45711055398
1815 train loss is 0.454522162676
1815 val loss is 0.456836700439
1816 train loss is 0.492063254118
1816 val loss is 0.456314235926
1817 train loss is 0.413938730955
1817 val loss is 0.455414503813
1818 train loss is 0.467076867819
1818 val loss is 0.454660952091
1819 train loss is 0.439861029387
1819 val loss is 0.455516546965
1820 train loss is 0.473400235176
1820 val loss is 0.456399142742
1821 train loss is 0.443966090679
1821 val loss is 0.456179738045
1822 train loss is 0.473797500134
1822 val loss is 0.455355465412
1823 train loss is 0.441356986761
1823 val loss is 0.455987334251
1824 train loss is 0.440744251013
1824 val loss is 0.457378387451
1825 train loss is 0.467876732349
1825 val loss is 0.458396583796
1826 train loss is 0.42971521616
1826 val loss is 0.45726147294
1827 train loss is 0.466354727745
1827 val loss is 0.455342501402
1828 train loss is 0.452327102423
1828 val loss is 0.453438788652
1829 train loss is 0.45223903656
1829 val loss is 0.453143000603
1830 train loss is 0.473441421986
1830 val loss is 0.454385966063
1831 train loss is 0.456861615181
1831 val loss is 0.455715566874
1832 train loss is 0.463640630245
1832 val loss is 0.455054461956
1833 train loss is 0.447492599487
1833 val loss is 0.45377266407
1834 train loss is 0.464255154133
1834 val loss is 0.453938931227
1835 train loss is 0.471299022436
1835 val loss is 0.454946100712
1836 train loss is 0.45106318593
1836 val loss is 0.455750793219
1837 train loss is 0.46149533987
1837 val loss is 0.454548180103
1838 train loss is 0.464575111866
1838 val loss is 0.452015936375
1839 train loss is 0.443407416344
1839 val loss is 0.45161151886
1840 train loss is 0.474519193172
1840 val loss is 0.453589141369
1841 train loss is 0.445508599281
1841 val loss is 0.454842329025
1842 train loss is 0.450388640165
1842 val loss is 0.453929126263
1843 train loss is 0.458080738783
1843 val loss is 0.45323163271
1844 train loss is 0.456060677767
1844 val loss is 0.453775465488
1845 train loss is 0.466398239136
1845 val loss is 0.455636024475
1846 train loss is 0.444912970066
1846 val loss is 0.455796986818
1847 train loss is 0.427788645029
1847 val loss is 0.454042255878
1848 train loss is 0.464345008135
1848 val loss is 0.452528208494
1849 train loss is 0.491123318672
1849 val loss is 0.452452659607
1850 train loss is 0.471765398979
1850 val loss is 0.453368246555
1851 train loss is 0.453034639359
1851 val loss is 0.454182744026
1852 train loss is 0.429261356592
1852 val loss is 0.453788906336
1853 train loss is 0.453641712666
1853 val loss is 0.452559649944
1854 train loss is 0.478617429733
1854 val loss is 0.452297121286
1855 train loss is 0.45756778121
1855 val loss is 0.45356747508
1856 train loss is 0.444686472416
1856 val loss is 0.454656839371
1857 train loss is 0.454290986061
1857 val loss is 0.454663157463
1858 train loss is 0.490921854973
1858 val loss is 0.453514665365
1859 train loss is 0.471622109413
1859 val loss is 0.453121900558
1860 train loss is 0.436531841755
1860 val loss is 0.453351736069
1861 train loss is 0.426434338093
1861 val loss is 0.454197824001
1862 train loss is 0.432147055864
1862 val loss is 0.453917503357
1863 train loss is 0.488618642092
1863 val loss is 0.452983558178
1864 train loss is 0.459866136312
1864 val loss is 0.452521622181
1865 train loss is 0.410629034042
1865 val loss is 0.453153133392
1866 train loss is 0.440921187401
1866 val loss is 0.454385727644
1867 train loss is 0.427896410227
1867 val loss is 0.455245673656
1868 train loss is 0.437033683062
1868 val loss is 0.454529941082
1869 train loss is 0.442156165838
1869 val loss is 0.453594148159
1870 train loss is 0.462781786919
1870 val loss is 0.453565239906
1871 train loss is 0.446479797363
1871 val loss is 0.453803539276
1872 train loss is 0.424276709557
1872 val loss is 0.453958630562
1873 train loss is 0.475161135197
1873 val loss is 0.453315585852
1874 train loss is 0.440389662981
1874 val loss is 0.452711731195
1875 train loss is 0.425312519073
1875 val loss is 0.452554821968
1876 train loss is 0.450581490993
1876 val loss is 0.452353447676
1877 train loss is 0.472742915154
1877 val loss is 0.452671378851
1878 train loss is 0.471185743809
1878 val loss is 0.454140305519
1879 train loss is 0.442022591829
1879 val loss is 0.454777389765
1880 train loss is 0.41543751955
1880 val loss is 0.454600989819
1881 train loss is 0.502940297127
1881 val loss is 0.453633546829
1882 train loss is 0.430813789368
1882 val loss is 0.452299386263
1883 train loss is 0.466660320759
1883 val loss is 0.452600240707
1884 train loss is 0.457642197609
1884 val loss is 0.452869534492
1885 train loss is 0.448774755001
1885 val loss is 0.452656984329
1886 train loss is 0.440274149179
1886 val loss is 0.452225863934
1887 train loss is 0.466272771358
1887 val loss is 0.45224237442
1888 train loss is 0.444684714079
1888 val loss is 0.452674359083
1889 train loss is 0.477892577648
1889 val loss is 0.4536460042
1890 train loss is 0.457312166691
1890 val loss is 0.454596608877
1891 train loss is 0.462431281805
1891 val loss is 0.454095780849
1892 train loss is 0.448522388935
1892 val loss is 0.452042728662
1893 train loss is 0.44957986474
1893 val loss is 0.450804173946
1894 train loss is 0.467080146074
1894 val loss is 0.45119035244
1895 train loss is 0.508010208607
1895 val loss is 0.4526476264
1896 train loss is 0.446640759706
1896 val loss is 0.453116357327
1897 train loss is 0.43885192275
1897 val loss is 0.452356755733
1898 train loss is 0.448758542538
1898 val loss is 0.451249212027
1899 train loss is 0.480847924948
1899 val loss is 0.45113709569
1900 train loss is 0.457506746054
1900 val loss is 0.452135324478
1901 train loss is 0.44431656599
1901 val loss is 0.452852338552
1902 train loss is 0.456561595201
1902 val loss is 0.451880931854
1903 train loss is 0.436573833227
1903 val loss is 0.449677020311
1904 train loss is 0.450189590454
1904 val loss is 0.448877185583
1905 train loss is 0.455360293388
1905 val loss is 0.450610876083
1906 train loss is 0.423787623644
1906 val loss is 0.452491372824
1907 train loss is 0.457309275866
1907 val loss is 0.45177641511
1908 train loss is 0.451396405697
1908 val loss is 0.450453072786
1909 train loss is 0.439670801163
1909 val loss is 0.450669407845
1910 train loss is 0.471903562546
1910 val loss is 0.451880693436
1911 train loss is 0.487226247787
1911 val loss is 0.451939582825
1912 train loss is 0.475531160831
1912 val loss is 0.450236797333
1913 train loss is 0.441684931517
1913 val loss is 0.448187500238
1914 train loss is 0.466260790825
1914 val loss is 0.447742462158
1915 train loss is 0.440203756094
1915 val loss is 0.449256420135
1916 train loss is 0.45825111866
1916 val loss is 0.450130164623
1917 train loss is 0.436555147171
1917 val loss is 0.449475288391
1918 train loss is 0.472060441971
1918 val loss is 0.448719501495
1919 train loss is 0.439054995775
1919 val loss is 0.448687165976
1920 train loss is 0.448571503162
1920 val loss is 0.449303627014
1921 train loss is 0.46599316597
1921 val loss is 0.449935138226
1922 train loss is 0.479788869619
1922 val loss is 0.449440896511
1923 train loss is 0.461939454079
1923 val loss is 0.44785118103
1924 train loss is 0.46195524931
1924 val loss is 0.44732517004
1925 train loss is 0.472611874342
1925 val loss is 0.448763221502
1926 train loss is 0.415154218674
1926 val loss is 0.450557410717
1927 train loss is 0.440966546535
1927 val loss is 0.450356990099
1928 train loss is 0.47514885664
1928 val loss is 0.448742866516
1929 train loss is 0.422588288784
1929 val loss is 0.448484301567
1930 train loss is 0.46104118228
1930 val loss is 0.449862271547
1931 train loss is 0.458126842976
1931 val loss is 0.450326383114
1932 train loss is 0.436941057444
1932 val loss is 0.4495921731
1933 train loss is 0.455790966749
1933 val loss is 0.44756925106
1934 train loss is 0.487755358219
1934 val loss is 0.446811795235
1935 train loss is 0.456451654434
1935 val loss is 0.4483063519
1936 train loss is 0.424855828285
1936 val loss is 0.450197964907
1937 train loss is 0.45065754652
1937 val loss is 0.451263338327
1938 train loss is 0.455052852631
1938 val loss is 0.451807379723
1939 train loss is 0.466831833124
1939 val loss is 0.452105402946
1940 train loss is 0.438397049904
1940 val loss is 0.451797515154
1941 train loss is 0.453747957945
1941 val loss is 0.451248466969
1942 train loss is 0.419269502163
1942 val loss is 0.450770795345
1943 train loss is 0.453220933676
1943 val loss is 0.450083225965
1944 train loss is 0.486977159977
1944 val loss is 0.448719531298
1945 train loss is 0.461301267147
1945 val loss is 0.447735220194
1946 train loss is 0.455351114273
1946 val loss is 0.448221504688
1947 train loss is 0.458552479744
1947 val loss is 0.449777185917
1948 train loss is 0.441727489233
1948 val loss is 0.451498746872
1949 train loss is 0.438528716564
1949 val loss is 0.452797353268
1950 train loss is 0.453765541315
1950 val loss is 0.452265232801
1951 train loss is 0.470972537994
1951 val loss is 0.451174974442
1952 train loss is 0.47085994482
1952 val loss is 0.450811862946
1953 train loss is 0.45356413722
1953 val loss is 0.451249569654
1954 train loss is 0.435161203146
1954 val loss is 0.450673013926
1955 train loss is 0.491140723228
1955 val loss is 0.449141174555
1956 train loss is 0.42684596777
1956 val loss is 0.447906404734
1957 train loss is 0.435881495476
1957 val loss is 0.448810368776
1958 train loss is 0.436932086945
1958 val loss is 0.451277107
1959 train loss is 0.458895921707
1959 val loss is 0.45277634263
1960 train loss is 0.460280060768
1960 val loss is 0.451535671949
1961 train loss is 0.452521115541
1961 val loss is 0.449386566877
1962 train loss is 0.493121743202
1962 val loss is 0.449061542749
1963 train loss is 0.421253919601
1963 val loss is 0.450631827116
1964 train loss is 0.412261724472
1964 val loss is 0.45009803772
1965 train loss is 0.441828221083
1965 val loss is 0.447569310665
1966 train loss is 0.453885614872
1966 val loss is 0.446802735329
1967 train loss is 0.444982618093
1967 val loss is 0.449484914541
1968 train loss is 0.466503769159
1968 val loss is 0.451822549105
1969 train loss is 0.468131631613
1969 val loss is 0.45118445158
1970 train loss is 0.413345962763
1970 val loss is 0.449078798294
1971 train loss is 0.425566494465
1971 val loss is 0.448240339756
1972 train loss is 0.457369357347
1972 val loss is 0.449991881847
1973 train loss is 0.423254549503
1973 val loss is 0.451108694077
1974 train loss is 0.425927817822
1974 val loss is 0.448795050383
1975 train loss is 0.48151153326
1975 val loss is 0.445599198341
1976 train loss is 0.447446286678
1976 val loss is 0.446064382792
1977 train loss is 0.473962426186
1977 val loss is 0.449720710516
1978 train loss is 0.439011275768
1978 val loss is 0.45219835639
1979 train loss is 0.435024559498
1979 val loss is 0.450499266386
1980 train loss is 0.465227425098
1980 val loss is 0.447273641825
1981 train loss is 0.458113342524
1981 val loss is 0.44617754221
1982 train loss is 0.469799607992
1982 val loss is 0.447737753391
1983 train loss is 0.460578143597
1983 val loss is 0.449571013451
1984 train loss is 0.443503558636
1984 val loss is 0.448927491903
1985 train loss is 0.441055953503
1985 val loss is 0.44631934166
1986 train loss is 0.452283859253
1986 val loss is 0.444894760847
1987 train loss is 0.433393061161
1987 val loss is 0.445695698261
1988 train loss is 0.448404252529
1988 val loss is 0.447545200586
1989 train loss is 0.443100273609
1989 val loss is 0.447965621948
1990 train loss is 0.426905632019
1990 val loss is 0.446545392275
1991 train loss is 0.428537607193
1991 val loss is 0.445392549038
1992 train loss is 0.458082795143
1992 val loss is 0.445871293545
1993 train loss is 0.476220190525
1993 val loss is 0.447551846504
1994 train loss is 0.440952837467
1994 val loss is 0.447407454252
1995 train loss is 0.426367014647
1995 val loss is 0.445800513029
1996 train loss is 0.454415142536
1996 val loss is 0.444587856531
1997 train loss is 0.444187998772
1997 val loss is 0.445164531469
1998 train loss is 0.462166368961
1998 val loss is 0.446612983942
1999 train loss is 0.444145143032
1999 val loss is 0.447530955076
2000 train loss is 0.457575529814
2000 val loss is 0.447014331818
2001 train loss is 0.450842618942
2001 val loss is 0.446372449398
2002 train loss is 0.45873260498
2002 val loss is 0.446272075176
2003 train loss is 0.410024344921
2003 val loss is 0.44702360034
2004 train loss is 0.453733563423
2004 val loss is 0.447407931089
2005 train loss is 0.438732355833
2005 val loss is 0.446499317884
2006 train loss is 0.429217338562
2006 val loss is 0.445043563843
2007 train loss is 0.442102581263
2007 val loss is 0.445122182369
2008 train loss is 0.478576242924
2008 val loss is 0.445956707001
2009 train loss is 0.460197359324
2009 val loss is 0.445937871933
2010 train loss is 0.450282424688
2010 val loss is 0.444817394018
2011 train loss is 0.445500731468
2011 val loss is 0.444457709789
2012 train loss is 0.453573226929
2012 val loss is 0.445486754179
2013 train loss is 0.479630589485
2013 val loss is 0.445954501629
2014 train loss is 0.440984666348
2014 val loss is 0.44529619813
2015 train loss is 0.453292131424
2015 val loss is 0.444268107414
2016 train loss is 0.471124559641
2016 val loss is 0.444486349821
2017 train loss is 0.455294132233
2017 val loss is 0.444393336773
2018 train loss is 0.440009444952
2018 val loss is 0.443817257881
2019 train loss is 0.471159100533
2019 val loss is 0.443432152271
2020 train loss is 0.426539301872
2020 val loss is 0.443540155888
2021 train loss is 0.449298560619
2021 val loss is 0.444716244936
2022 train loss is 0.432104706764
2022 val loss is 0.445293009281
2023 train loss is 0.455137461424
2023 val loss is 0.444927453995
2024 train loss is 0.441284805536
2024 val loss is 0.443706959486
2025 train loss is 0.457404196262
2025 val loss is 0.443014979362
2026 train loss is 0.459191381931
2026 val loss is 0.44378387928
2027 train loss is 0.447009146214
2027 val loss is 0.444499790668
2028 train loss is 0.448809742928
2028 val loss is 0.444245159626
2029 train loss is 0.454535365105
2029 val loss is 0.443277180195
2030 train loss is 0.439428716898
2030 val loss is 0.442833214998
2031 train loss is 0.424161046743
2031 val loss is 0.443243324757
2032 train loss is 0.430964410305
2032 val loss is 0.443605840206
2033 train loss is 0.456801712513
2033 val loss is 0.44370380044
2034 train loss is 0.464836508036
2034 val loss is 0.443241745234
2035 train loss is 0.424789875746
2035 val loss is 0.443731099367
2036 train loss is 0.417065083981
2036 val loss is 0.444265007973
2037 train loss is 0.45888864994
2037 val loss is 0.443803429604
2038 train loss is 0.465611100197
2038 val loss is 0.442627459764
2039 train loss is 0.46507358551
2039 val loss is 0.442603766918
2040 train loss is 0.45163166523
2040 val loss is 0.444137960672
2041 train loss is 0.429619193077
2041 val loss is 0.445030927658
2042 train loss is 0.43212017417
2042 val loss is 0.444700628519
2043 train loss is 0.469465255737
2043 val loss is 0.443053662777
2044 train loss is 0.469800919294
2044 val loss is 0.441715925932
2045 train loss is 0.425020396709
2045 val loss is 0.442735046148
2046 train loss is 0.469971597195
2046 val loss is 0.44464430213
2047 train loss is 0.433544278145
2047 val loss is 0.445043206215
2048 train loss is 0.422324895859
2048 val loss is 0.443265169859
2049 train loss is 0.432913959026
2049 val loss is 0.441320478916
2050 train loss is 0.480329543352
2050 val loss is 0.441813647747
2051 train loss is 0.433274179697
2051 val loss is 0.444272994995
2052 train loss is 0.430971682072
2052 val loss is 0.444823861122
2053 train loss is 0.447159409523
2053 val loss is 0.442845404148
2054 train loss is 0.436186462641
2054 val loss is 0.44122928381
2055 train loss is 0.454811990261
2055 val loss is 0.441479474306
2056 train loss is 0.423411726952
2056 val loss is 0.442722350359
2057 train loss is 0.424306571484
2057 val loss is 0.44297260046
2058 train loss is 0.439567625523
2058 val loss is 0.441885918379
2059 train loss is 0.431804805994
2059 val loss is 0.440927952528
2060 train loss is 0.459846526384
2060 val loss is 0.441551506519
2061 train loss is 0.438230663538
2061 val loss is 0.443588137627
2062 train loss is 0.417541503906
2062 val loss is 0.444332927465
2063 train loss is 0.44960975647
2063 val loss is 0.442560911179
2064 train loss is 0.453032165766
2064 val loss is 0.440998315811
2065 train loss is 0.414006173611
2065 val loss is 0.441776335239
2066 train loss is 0.400877863169
2066 val loss is 0.444091916084
2067 train loss is 0.445366919041
2067 val loss is 0.443877458572
2068 train loss is 0.406023234129
2068 val loss is 0.441953480244
2069 train loss is 0.453779011965
2069 val loss is 0.440360456705
2070 train loss is 0.461541682482
2070 val loss is 0.441008478403
2071 train loss is 0.423103481531
2071 val loss is 0.442921161652
2072 train loss is 0.463376641273
2072 val loss is 0.443429708481
2073 train loss is 0.454740524292
2073 val loss is 0.441914200783
2074 train loss is 0.473083555698
2074 val loss is 0.440127462149
2075 train loss is 0.461977362633
2075 val loss is 0.440255999565
2076 train loss is 0.464262336493
2076 val loss is 0.442804217339
2077 train loss is 0.461805522442
2077 val loss is 0.444779992104
2078 train loss is 0.444120228291
2078 val loss is 0.442867279053
2079 train loss is 0.445398509502
2079 val loss is 0.439592599869
2080 train loss is 0.461155831814
2080 val loss is 0.438994079828
2081 train loss is 0.417412400246
2081 val loss is 0.44230350852
2082 train loss is 0.473946779966
2082 val loss is 0.445277392864
2083 train loss is 0.463501781225
2083 val loss is 0.443694800138
2084 train loss is 0.451078087091
2084 val loss is 0.439832150936
2085 train loss is 0.446515321732
2085 val loss is 0.439014554024
2086 train loss is 0.443503588438
2086 val loss is 0.44255849719
2087 train loss is 0.417760431767
2087 val loss is 0.4458578825
2088 train loss is 0.475735872984
2088 val loss is 0.444120466709
2089 train loss is 0.438493460417
2089 val loss is 0.439326882362
2090 train loss is 0.445105016232
2090 val loss is 0.438532859087
2091 train loss is 0.468226194382
2091 val loss is 0.443379878998
2092 train loss is 0.409551143646
2092 val loss is 0.446841180325
2093 train loss is 0.407454878092
2093 val loss is 0.444883465767
2094 train loss is 0.413502991199
2094 val loss is 0.440309345722
2095 train loss is 0.426421791315
2095 val loss is 0.437989830971
2096 train loss is 0.417544543743
2096 val loss is 0.440761774778
2097 train loss is 0.439965635538
2097 val loss is 0.444208830595
2098 train loss is 0.482939600945
2098 val loss is 0.443802088499
2099 train loss is 0.461589962244
2099 val loss is 0.440358042717
2100 train loss is 0.443650990725
2100 val loss is 0.438692331314
2101 train loss is 0.450049549341
2101 val loss is 0.441253632307
2102 train loss is 0.429490983486
2102 val loss is 0.444726526737
2103 train loss is 0.428899049759
2103 val loss is 0.444736719131
2104 train loss is 0.443198621273
2104 val loss is 0.44184589386
2105 train loss is 0.468666195869
2105 val loss is 0.439274013042
2106 train loss is 0.440889745951
2106 val loss is 0.439955770969
2107 train loss is 0.437717884779
2107 val loss is 0.442893654108
2108 train loss is 0.427013933659
2108 val loss is 0.443842470646
2109 train loss is 0.484733045101
2109 val loss is 0.44157487154
2110 train loss is 0.461063325405
2110 val loss is 0.438892483711
2111 train loss is 0.453672260046
2111 val loss is 0.438742399216
2112 train loss is 0.412916839123
2112 val loss is 0.440618216991
2113 train loss is 0.434256881475
2113 val loss is 0.442318320274
2114 train loss is 0.457724571228
2114 val loss is 0.440779209137
2115 train loss is 0.459025621414
2115 val loss is 0.438275784254
2116 train loss is 0.487085044384
2116 val loss is 0.437590837479
2117 train loss is 0.436968713999
2117 val loss is 0.439141452312
2118 train loss is 0.479242861271
2118 val loss is 0.440763682127
2119 train loss is 0.427134275436
2119 val loss is 0.440461993217
2120 train loss is 0.413740724325
2120 val loss is 0.438489735126
2121 train loss is 0.486890435219
2121 val loss is 0.437543690205
2122 train loss is 0.446451634169
2122 val loss is 0.43928194046
2123 train loss is 0.471772104502
2123 val loss is 0.440799742937
2124 train loss is 0.421159446239
2124 val loss is 0.439299106598
2125 train loss is 0.437231004238
2125 val loss is 0.437252998352
2126 train loss is 0.483570605516
2126 val loss is 0.436954855919
2127 train loss is 0.476286917925
2127 val loss is 0.438284754753
2128 train loss is 0.455969512463
2128 val loss is 0.439125150442
2129 train loss is 0.428839892149
2129 val loss is 0.438099771738
2130 train loss is 0.44667083025
2130 val loss is 0.437030076981
2131 train loss is 0.417482256889
2131 val loss is 0.437249362469
2132 train loss is 0.433252125978
2132 val loss is 0.43883395195
2133 train loss is 0.461083233356
2133 val loss is 0.439273834229
2134 train loss is 0.439318329096
2134 val loss is 0.437932878733
2135 train loss is 0.417809069157
2135 val loss is 0.436066240072
2136 train loss is 0.423620164394
2136 val loss is 0.435827821493
2137 train loss is 0.446699619293
2137 val loss is 0.437199801207
2138 train loss is 0.433726131916
2138 val loss is 0.438043177128
2139 train loss is 0.451289981604
2139 val loss is 0.437248170376
2140 train loss is 0.447140485048
2140 val loss is 0.436636775732
2141 train loss is 0.447275400162
2141 val loss is 0.437794685364
2142 train loss is 0.472854614258
2142 val loss is 0.439539760351
2143 train loss is 0.437164336443
2143 val loss is 0.439774125814
2144 train loss is 0.446789562702
2144 val loss is 0.437822282314
2145 train loss is 0.414673686028
2145 val loss is 0.436147928238
2146 train loss is 0.420350730419
2146 val loss is 0.436730384827
2147 train loss is 0.420103013515
2147 val loss is 0.438765764236
2148 train loss is 0.453540802002
2148 val loss is 0.439978539944
2149 train loss is 0.438584268093
2149 val loss is 0.438728451729
2150 train loss is 0.454603075981
2150 val loss is 0.437385261059
2151 train loss is 0.43628013134
2151 val loss is 0.437485814095
2152 train loss is 0.442900508642
2152 val loss is 0.439342439175
2153 train loss is 0.464291840792
2153 val loss is 0.440318018198
2154 train loss is 0.40065959096
2154 val loss is 0.438920676708
2155 train loss is 0.435167878866
2155 val loss is 0.436470657587
2156 train loss is 0.455306440592
2156 val loss is 0.436360299587
2157 train loss is 0.431777358055
2157 val loss is 0.437917500734
2158 train loss is 0.454350560904
2158 val loss is 0.439301580191
2159 train loss is 0.444817483425
2159 val loss is 0.43855831027
2160 train loss is 0.451285272837
2160 val loss is 0.436693131924
2161 train loss is 0.427621483803
2161 val loss is 0.436006575823
2162 train loss is 0.418087601662
2162 val loss is 0.437520027161
2163 train loss is 0.442666232586
2163 val loss is 0.438699752092
2164 train loss is 0.442770510912
2164 val loss is 0.437902778387
2165 train loss is 0.436719477177
2165 val loss is 0.436114639044
2166 train loss is 0.446150630713
2166 val loss is 0.435216069221
2167 train loss is 0.428010225296
2167 val loss is 0.43631991744
2168 train loss is 0.431592434645
2168 val loss is 0.438009947538
2169 train loss is 0.433447778225
2169 val loss is 0.438736617565
2170 train loss is 0.444029211998
2170 val loss is 0.437427222729
2171 train loss is 0.439815819263
2171 val loss is 0.435503333807
2172 train loss is 0.411276221275
2172 val loss is 0.435552656651
2173 train loss is 0.444938540459
2173 val loss is 0.436902284622
2174 train loss is 0.443292111158
2174 val loss is 0.436864763498
2175 train loss is 0.423816978931
2175 val loss is 0.435491830111
2176 train loss is 0.479607284069
2176 val loss is 0.434721142054
2177 train loss is 0.43598651886
2177 val loss is 0.436213076115
2178 train loss is 0.433310329914
2178 val loss is 0.437726259232
2179 train loss is 0.450691401958
2179 val loss is 0.437199354172
2180 train loss is 0.458243489265
2180 val loss is 0.435956805944
2181 train loss is 0.44732400775
2181 val loss is 0.435500741005
2182 train loss is 0.435901224613
2182 val loss is 0.435847461224
2183 train loss is 0.460335493088
2183 val loss is 0.43627011776
2184 train loss is 0.441502571106
2184 val loss is 0.436290830374
2185 train loss is 0.423360139132
2185 val loss is 0.435441792011
2186 train loss is 0.393017411232
2186 val loss is 0.435170471668
2187 train loss is 0.442299038172
2187 val loss is 0.43611240387
2188 train loss is 0.476480901241
2188 val loss is 0.437067657709
2189 train loss is 0.44306832552
2189 val loss is 0.437141537666
2190 train loss is 0.434202432632
2190 val loss is 0.43657886982
2191 train loss is 0.437784075737
2191 val loss is 0.436311095953
2192 train loss is 0.460467994213
2192 val loss is 0.436275243759
2193 train loss is 0.447789430618
2193 val loss is 0.437081545591
2194 train loss is 0.434296101332
2194 val loss is 0.436911642551
2195 train loss is 0.422204107046
2195 val loss is 0.435803979635
2196 train loss is 0.450223982334
2196 val loss is 0.434688359499
2197 train loss is 0.480734527111
2197 val loss is 0.434879481792
2198 train loss is 0.422095656395
2198 val loss is 0.435736000538
2199 train loss is 0.424251198769
2199 val loss is 0.436098098755
2200 train loss is 0.438977301121
2200 val loss is 0.435261666775
2201 train loss is 0.441567122936
2201 val loss is 0.435458153486
2202 train loss is 0.419871270657
2202 val loss is 0.436897486448
2203 train loss is 0.478249043226
2203 val loss is 0.437464058399
2204 train loss is 0.43283033371
2204 val loss is 0.436895936728
2205 train loss is 0.40233668685
2205 val loss is 0.436294525862
2206 train loss is 0.402826189995
2206 val loss is 0.435772538185
2207 train loss is 0.445373475552
2207 val loss is 0.436188340187
2208 train loss is 0.431873589754
2208 val loss is 0.437162399292
2209 train loss is 0.413937449455
2209 val loss is 0.43822401762
2210 train loss is 0.483535259962
2210 val loss is 0.437368631363
2211 train loss is 0.435476481915
2211 val loss is 0.436754316092
2212 train loss is 0.467858403921
2212 val loss is 0.436365872622
2213 train loss is 0.449860572815
2213 val loss is 0.436634123325
2214 train loss is 0.429903388023
2214 val loss is 0.43734818697
2215 train loss is 0.444410443306
2215 val loss is 0.436949968338
2216 train loss is 0.441392600536
2216 val loss is 0.435942411423
2217 train loss is 0.49048858881
2217 val loss is 0.435277700424
2218 train loss is 0.43038880825
2218 val loss is 0.434918344021
2219 train loss is 0.448351085186
2219 val loss is 0.434790492058
2220 train loss is 0.435641169548
2220 val loss is 0.435392171144
2221 train loss is 0.408535003662
2221 val loss is 0.434985727072
2222 train loss is 0.450927466154
2222 val loss is 0.43361055851
2223 train loss is 0.43061375618
2223 val loss is 0.433361411095
2224 train loss is 0.479096293449
2224 val loss is 0.434675812721
2225 train loss is 0.464806675911
2225 val loss is 0.435859978199
2226 train loss is 0.422212660313
2226 val loss is 0.435754537582
2227 train loss is 0.454422920942
2227 val loss is 0.43411809206
2228 train loss is 0.448071837425
2228 val loss is 0.432373225689
2229 train loss is 0.450826644897
2229 val loss is 0.432536900043
2230 train loss is 0.458400040865
2230 val loss is 0.434067696333
2231 train loss is 0.417234838009
2231 val loss is 0.435221284628
2232 train loss is 0.461612433195
2232 val loss is 0.434349358082
2233 train loss is 0.458194583654
2233 val loss is 0.433354854584
2234 train loss is 0.437314659357
2234 val loss is 0.433693051338
2235 train loss is 0.451701492071
2235 val loss is 0.434432536364
2236 train loss is 0.453687518835
2236 val loss is 0.434158265591
2237 train loss is 0.452696323395
2237 val loss is 0.43209373951
2238 train loss is 0.449599713087
2238 val loss is 0.430305808783
2239 train loss is 0.439629971981
2239 val loss is 0.431268393993
2240 train loss is 0.437699377537
2240 val loss is 0.434096395969
2241 train loss is 0.432234525681
2241 val loss is 0.4349167943
2242 train loss is 0.394063025713
2242 val loss is 0.432920128107
2243 train loss is 0.431600779295
2243 val loss is 0.431330919266
2244 train loss is 0.437849789858
2244 val loss is 0.433011323214
2245 train loss is 0.460199892521
2245 val loss is 0.434935927391
2246 train loss is 0.447203069925
2246 val loss is 0.434352517128
2247 train loss is 0.430003404617
2247 val loss is 0.431485950947
2248 train loss is 0.446688830853
2248 val loss is 0.429757773876
2249 train loss is 0.412620306015
2249 val loss is 0.431117802858
2250 train loss is 0.450974315405
2250 val loss is 0.433254003525
2251 train loss is 0.472940146923
2251 val loss is 0.434097915888
2252 train loss is 0.467539519072
2252 val loss is 0.43276321888
2253 train loss is 0.457145631313
2253 val loss is 0.431314498186
2254 train loss is 0.422663211823
2254 val loss is 0.432744622231
2255 train loss is 0.42336294055
2255 val loss is 0.434124082327
2256 train loss is 0.448715984821
2256 val loss is 0.43374440074
2257 train loss is 0.486001372337
2257 val loss is 0.431734293699
2258 train loss is 0.432056993246
2258 val loss is 0.429636836052
2259 train loss is 0.454804241657
2259 val loss is 0.430430144072
2260 train loss is 0.429756462574
2260 val loss is 0.432314753532
2261 train loss is 0.458404868841
2261 val loss is 0.432767689228
2262 train loss is 0.474048733711
2262 val loss is 0.431484520435
2263 train loss is 0.41977339983
2263 val loss is 0.429804027081
2264 train loss is 0.401299387217
2264 val loss is 0.429375231266
2265 train loss is 0.436199188232
2265 val loss is 0.430795550346
2266 train loss is 0.44840580225
2266 val loss is 0.431313872337
2267 train loss is 0.426833599806
2267 val loss is 0.430374979973
2268 train loss is 0.424923658371
2268 val loss is 0.429471880198
2269 train loss is 0.413793951273
2269 val loss is 0.429825633764
2270 train loss is 0.443384885788
2270 val loss is 0.431157439947
2271 train loss is 0.402024060488
2271 val loss is 0.431612640619
2272 train loss is 0.398138821125
2272 val loss is 0.430600911379
2273 train loss is 0.450754225254
2273 val loss is 0.429171323776
2274 train loss is 0.405803382397
2274 val loss is 0.428835093975
2275 train loss is 0.424984157085
2275 val loss is 0.430343151093
2276 train loss is 0.4363758564
2276 val loss is 0.43143209815
2277 train loss is 0.404491424561
2277 val loss is 0.430535316467
2278 train loss is 0.438231706619
2278 val loss is 0.428917050362
2279 train loss is 0.416285395622
2279 val loss is 0.429472863674
2280 train loss is 0.432862401009
2280 val loss is 0.430909514427
2281 train loss is 0.433615207672
2281 val loss is 0.431573837996
2282 train loss is 0.430088996887
2282 val loss is 0.430113136768
2283 train loss is 0.414624720812
2283 val loss is 0.428655207157
2284 train loss is 0.428725630045
2284 val loss is 0.428301542997
2285 train loss is 0.457283556461
2285 val loss is 0.429063200951
2286 train loss is 0.460038900375
2286 val loss is 0.429198473692
2287 train loss is 0.455446541309
2287 val loss is 0.428776800632
2288 train loss is 0.414991885424
2288 val loss is 0.428641170263
2289 train loss is 0.426577180624
2289 val loss is 0.428808867931
2290 train loss is 0.448962509632
2290 val loss is 0.429645299911
2291 train loss is 0.44727241993
2291 val loss is 0.430138319731
2292 train loss is 0.419858843088
2292 val loss is 0.430052936077
2293 train loss is 0.419501125813
2293 val loss is 0.429751336575
2294 train loss is 0.42731449008
2294 val loss is 0.429081618786
2295 train loss is 0.423870801926
2295 val loss is 0.428771823645
2296 train loss is 0.441531121731
2296 val loss is 0.429366052151
2297 train loss is 0.427850008011
2297 val loss is 0.430086135864
2298 train loss is 0.445697337389
2298 val loss is 0.429920583963
2299 train loss is 0.421247243881
2299 val loss is 0.429352253675
2300 train loss is 0.459055304527
2300 val loss is 0.429071694613
2301 train loss is 0.428408324718
2301 val loss is 0.430256515741
2302 train loss is 0.427314609289
2302 val loss is 0.431300461292
2303 train loss is 0.443496227264
2303 val loss is 0.431232154369
2304 train loss is 0.447205960751
2304 val loss is 0.430092811584
2305 train loss is 0.441794395447
2305 val loss is 0.428746342659
2306 train loss is 0.433032542467
2306 val loss is 0.428898155689
2307 train loss is 0.402585268021
2307 val loss is 0.430299520493
2308 train loss is 0.410434007645
2308 val loss is 0.431091278791
2309 train loss is 0.430500894785
2309 val loss is 0.431061625481
2310 train loss is 0.437684595585
2310 val loss is 0.430145025253
2311 train loss is 0.433369338512
2311 val loss is 0.429363787174
2312 train loss is 0.403805762529
2312 val loss is 0.429362535477
2313 train loss is 0.431388348341
2313 val loss is 0.429747849703
2314 train loss is 0.415480643511
2314 val loss is 0.429133355618
2315 train loss is 0.441959440708
2315 val loss is 0.428672254086
2316 train loss is 0.404376506805
2316 val loss is 0.428936511278
2317 train loss is 0.443407982588
2317 val loss is 0.429541826248
2318 train loss is 0.437869518995
2318 val loss is 0.429984867573
2319 train loss is 0.432042658329
2319 val loss is 0.42910733819
2320 train loss is 0.426341861486
2320 val loss is 0.428732097149
2321 train loss is 0.418150097132
2321 val loss is 0.429313004017
2322 train loss is 0.437732756138
2322 val loss is 0.429411381483
2323 train loss is 0.448930025101
2323 val loss is 0.428878128529
2324 train loss is 0.45513561368
2324 val loss is 0.428107649088
2325 train loss is 0.419391959906
2325 val loss is 0.42815476656
2326 train loss is 0.415344059467
2326 val loss is 0.428499668837
2327 train loss is 0.419155478477
2327 val loss is 0.428503513336
2328 train loss is 0.435663431883
2328 val loss is 0.428494989872
2329 train loss is 0.436280429363
2329 val loss is 0.429019927979
2330 train loss is 0.47014516592
2330 val loss is 0.429423987865
2331 train loss is 0.416121095419
2331 val loss is 0.429499059916
2332 train loss is 0.414860457182
2332 val loss is 0.429194569588
2333 train loss is 0.467112720013
2333 val loss is 0.428622931242
2334 train loss is 0.425632685423
2334 val loss is 0.42770922184
2335 train loss is 0.448539078236
2335 val loss is 0.426406055689
2336 train loss is 0.429372817278
2336 val loss is 0.426222234964
2337 train loss is 0.422281086445
2337 val loss is 0.427230149508
2338 train loss is 0.414197146893
2338 val loss is 0.428014308214
2339 train loss is 0.427149474621
2339 val loss is 0.427890211344
2340 train loss is 0.43888604641
2340 val loss is 0.427534282207
2341 train loss is 0.386228173971
2341 val loss is 0.428113788366
2342 train loss is 0.413193434477
2342 val loss is 0.428601413965
2343 train loss is 0.400684505701
2343 val loss is 0.428207039833
2344 train loss is 0.435673058033
2344 val loss is 0.426739573479
2345 train loss is 0.456904858351
2345 val loss is 0.425310850143
2346 train loss is 0.446974158287
2346 val loss is 0.425855576992
2347 train loss is 0.416793704033
2347 val loss is 0.427406787872
2348 train loss is 0.46211001277
2348 val loss is 0.427759230137
2349 train loss is 0.417676657438
2349 val loss is 0.426435470581
2350 train loss is 0.409845858812
2350 val loss is 0.425863921642
2351 train loss is 0.439970523119
2351 val loss is 0.426908046007
2352 train loss is 0.428528398275
2352 val loss is 0.428427755833
2353 train loss is 0.414578855038
2353 val loss is 0.42824831605
2354 train loss is 0.451300919056
2354 val loss is 0.425951182842
2355 train loss is 0.448482871056
2355 val loss is 0.424168288708
2356 train loss is 0.497881710529
2356 val loss is 0.424933493137
2357 train loss is 0.407499521971
2357 val loss is 0.426898270845
2358 train loss is 0.417376995087
2358 val loss is 0.427467852831
2359 train loss is 0.431741088629
2359 val loss is 0.425679832697
2360 train loss is 0.425435423851
2360 val loss is 0.424453228712
2361 train loss is 0.435423463583
2361 val loss is 0.42545697093
2362 train loss is 0.424412488937
2362 val loss is 0.427129626274
2363 train loss is 0.453374832869
2363 val loss is 0.427378535271
2364 train loss is 0.436392426491
2364 val loss is 0.426033765078
2365 train loss is 0.414237350225
2365 val loss is 0.425181120634
2366 train loss is 0.470136940479
2366 val loss is 0.425547033548
2367 train loss is 0.432489931583
2367 val loss is 0.426261395216
2368 train loss is 0.41890668869
2368 val loss is 0.426249206066
2369 train loss is 0.453896343708
2369 val loss is 0.425996422768
2370 train loss is 0.44157102704
2370 val loss is 0.426176667213
2371 train loss is 0.439654618502
2371 val loss is 0.426772087812
2372 train loss is 0.456296592951
2372 val loss is 0.427268087864
2373 train loss is 0.463180154562
2373 val loss is 0.427219748497
2374 train loss is 0.466171205044
2374 val loss is 0.426120072603
2375 train loss is 0.432276785374
2375 val loss is 0.4261957407
2376 train loss is 0.421223282814
2376 val loss is 0.428029954433
2377 train loss is 0.421678900719
2377 val loss is 0.429486572742
2378 train loss is 0.423426628113
2378 val loss is 0.428557485342
2379 train loss is 0.432230055332
2379 val loss is 0.426484018564
2380 train loss is 0.432372927666
2380 val loss is 0.425966948271
2381 train loss is 0.448751181364
2381 val loss is 0.427752077579
2382 train loss is 0.404359459877
2382 val loss is 0.42984777689
2383 train loss is 0.433198451996
2383 val loss is 0.429769009352
2384 train loss is 0.452089458704
2384 val loss is 0.427851229906
2385 train loss is 0.41101577878
2385 val loss is 0.426636755466
2386 train loss is 0.437700152397
2386 val loss is 0.427729517221
2387 train loss is 0.415104061365
2387 val loss is 0.429300576448
2388 train loss is 0.437388777733
2388 val loss is 0.428270757198
2389 train loss is 0.445930510759
2389 val loss is 0.426413178444
2390 train loss is 0.431652545929
2390 val loss is 0.425749003887
2391 train loss is 0.458948850632
2391 val loss is 0.426640510559
2392 train loss is 0.409532546997
2392 val loss is 0.427700102329
2393 train loss is 0.456425637007
2393 val loss is 0.426502048969
2394 train loss is 0.459815621376
2394 val loss is 0.425379931927
2395 train loss is 0.427898913622
2395 val loss is 0.426104158163
2396 train loss is 0.421439111233
2396 val loss is 0.427425771952
2397 train loss is 0.412286937237
2397 val loss is 0.427817046642
2398 train loss is 0.449451178312
2398 val loss is 0.426996737719
2399 train loss is 0.417846739292
2399 val loss is 0.425711482763
2400 train loss is 0.411977380514
2400 val loss is 0.425614446402
2401 train loss is 0.462811201811
2401 val loss is 0.425848275423
2402 train loss is 0.387975931168
2402 val loss is 0.425428241491
2403 train loss is 0.442040354013
2403 val loss is 0.424779862165
2404 train loss is 0.424662470818
2404 val loss is 0.424761354923
2405 train loss is 0.423046350479
2405 val loss is 0.425232827663
2406 train loss is 0.395983219147
2406 val loss is 0.425861537457
2407 train loss is 0.439066767693
2407 val loss is 0.424884617329
2408 train loss is 0.41400796175
2408 val loss is 0.423864334822
2409 train loss is 0.40609356761
2409 val loss is 0.423934936523
2410 train loss is 0.424602895975
2410 val loss is 0.42458564043
2411 train loss is 0.418269217014
2411 val loss is 0.424832105637
2412 train loss is 0.406608402729
2412 val loss is 0.423941373825
2413 train loss is 0.427709370852
2413 val loss is 0.423519402742
2414 train loss is 0.424263596535
2414 val loss is 0.42370095849
2415 train loss is 0.403495430946
2415 val loss is 0.424619168043
2416 train loss is 0.426206111908
2416 val loss is 0.425317585468
2417 train loss is 0.441467285156
2417 val loss is 0.424986302853
2418 train loss is 0.401308178902
2418 val loss is 0.424388468266
2419 train loss is 0.406577527523
2419 val loss is 0.423972606659
2420 train loss is 0.453464031219
2420 val loss is 0.42387676239
2421 train loss is 0.421999931335
2421 val loss is 0.423453986645
2422 train loss is 0.393380403519
2422 val loss is 0.423069983721
2423 train loss is 0.455255568027
2423 val loss is 0.423265576363
2424 train loss is 0.430500298738
2424 val loss is 0.423461288214
2425 train loss is 0.431222259998
2425 val loss is 0.423633396626
2426 train loss is 0.394870877266
2426 val loss is 0.424350768328
2427 train loss is 0.429606944323
2427 val loss is 0.425260007381
2428 train loss is 0.46460133791
2428 val loss is 0.424558639526
2429 train loss is 0.404017925262
2429 val loss is 0.423581808805
2430 train loss is 0.456768482924
2430 val loss is 0.423398196697
2431 train loss is 0.404394477606
2431 val loss is 0.424564301968
2432 train loss is 0.441429197788
2432 val loss is 0.425012409687
2433 train loss is 0.433103203773
2433 val loss is 0.423937380314
2434 train loss is 0.410502612591
2434 val loss is 0.422867923975
2435 train loss is 0.432258874178
2435 val loss is 0.423116564751
2436 train loss is 0.398158580065
2436 val loss is 0.424467325211
2437 train loss is 0.42069786787
2437 val loss is 0.424871474504
2438 train loss is 0.43113848567
2438 val loss is 0.423760503531
2439 train loss is 0.434601068497
2439 val loss is 0.422238379717
2440 train loss is 0.431572943926
2440 val loss is 0.422473162413
2441 train loss is 0.42565742135
2441 val loss is 0.423356384039
2442 train loss is 0.458380520344
2442 val loss is 0.423366963863
2443 train loss is 0.41698846221
2443 val loss is 0.422635525465
2444 train loss is 0.426513165236
2444 val loss is 0.422871112823
2445 train loss is 0.424711674452
2445 val loss is 0.423845797777
2446 train loss is 0.437927007675
2446 val loss is 0.424454987049
2447 train loss is 0.418093979359
2447 val loss is 0.423853725195
2448 train loss is 0.424190938473
2448 val loss is 0.422363251448
2449 train loss is 0.408810138702
2449 val loss is 0.421346545219
2450 train loss is 0.428308427334
2450 val loss is 0.422282993793
2451 train loss is 0.434775233269
2451 val loss is 0.423207700253
2452 train loss is 0.406022489071
2452 val loss is 0.423285663128
2453 train loss is 0.428874671459
2453 val loss is 0.422187626362
2454 train loss is 0.398958444595
2454 val loss is 0.422288805246
2455 train loss is 0.460931688547
2455 val loss is 0.423662543297
2456 train loss is 0.487138032913
2456 val loss is 0.424554586411
2457 train loss is 0.399359464645
2457 val loss is 0.42355132103
2458 train loss is 0.416903465986
2458 val loss is 0.421231031418
2459 train loss is 0.424130558968
2459 val loss is 0.420450717211
2460 train loss is 0.41425716877
2460 val loss is 0.421853899956
2461 train loss is 0.418628424406
2461 val loss is 0.424030959606
2462 train loss is 0.400945574045
2462 val loss is 0.423705875874
2463 train loss is 0.464030951262
2463 val loss is 0.422537386417
2464 train loss is 0.465526163578
2464 val loss is 0.42203193903
2465 train loss is 0.453819990158
2465 val loss is 0.423349261284
2466 train loss is 0.395535498857
2466 val loss is 0.424837082624
2467 train loss is 0.462046712637
2467 val loss is 0.424333095551
2468 train loss is 0.410934329033
2468 val loss is 0.421798884869
2469 train loss is 0.396223068237
2469 val loss is 0.420431375504
2470 train loss is 0.430720567703
2470 val loss is 0.421278387308
2471 train loss is 0.426997601986
2471 val loss is 0.423950761557
2472 train loss is 0.451000094414
2472 val loss is 0.424961298704
2473 train loss is 0.406471550465
2473 val loss is 0.422998189926
2474 train loss is 0.428495436907
2474 val loss is 0.420998096466
2475 train loss is 0.394007146358
2475 val loss is 0.421527206898
2476 train loss is 0.420609176159
2476 val loss is 0.423900097609
2477 train loss is 0.42449182272
2477 val loss is 0.424654811621
2478 train loss is 0.448908388615
2478 val loss is 0.422766029835
2479 train loss is 0.435686469078
2479 val loss is 0.421277582645
2480 train loss is 0.410471200943
2480 val loss is 0.421268820763
2481 train loss is 0.441714257002
2481 val loss is 0.422940045595
2482 train loss is 0.421444237232
2482 val loss is 0.423556834459
2483 train loss is 0.435547024012
2483 val loss is 0.422536343336
2484 train loss is 0.443229138851
2484 val loss is 0.420930862427
2485 train loss is 0.425166875124
2485 val loss is 0.421538174152
2486 train loss is 0.424948990345
2486 val loss is 0.423852056265
2487 train loss is 0.399402946234
2487 val loss is 0.425349384546
2488 train loss is 0.404152750969
2488 val loss is 0.422843277454
2489 train loss is 0.433944374323
2489 val loss is 0.420254528522
2490 train loss is 0.43136677146
2490 val loss is 0.420498073101
2491 train loss is 0.415328085423
2491 val loss is 0.422863274813
2492 train loss is 0.448862224817
2492 val loss is 0.423803985119
2493 train loss is 0.428957641125
2493 val loss is 0.423220217228
2494 train loss is 0.390077888966
2494 val loss is 0.421440005302
2495 train loss is 0.425768136978
2495 val loss is 0.42170894146
2496 train loss is 0.458603531122
2496 val loss is 0.423417627811
2497 train loss is 0.421783357859
2497 val loss is 0.424349844456
2498 train loss is 0.427269667387
2498 val loss is 0.422494053841
2499 train loss is 0.443665117025
2499 val loss is 0.420627087355
2500 train loss is 0.405984580517
2500 val loss is 0.42020624876
2501 train loss is 0.426532030106
2501 val loss is 0.421176612377
2502 train loss is 0.442188769579
2502 val loss is 0.422184705734
2503 train loss is 0.433325529099
2503 val loss is 0.422462850809
2504 train loss is 0.477058053017
2504 val loss is 0.421791821718
2505 train loss is 0.406683236361
2505 val loss is 0.421069473028
2506 train loss is 0.418181240559
2506 val loss is 0.420899808407
2507 train loss is 0.406420767307
2507 val loss is 0.420702278614
2508 train loss is 0.436132729053
2508 val loss is 0.42082464695
2509 train loss is 0.43959364295
2509 val loss is 0.420311897993
2510 train loss is 0.457068830729
2510 val loss is 0.419661253691
2511 train loss is 0.392592608929
2511 val loss is 0.419363021851
2512 train loss is 0.415823400021
2512 val loss is 0.420400261879
2513 train loss is 0.400946319103
2513 val loss is 0.42147397995
2514 train loss is 0.432901293039
2514 val loss is 0.421553969383
2515 train loss is 0.424959778786
2515 val loss is 0.421903163195
2516 train loss is 0.411948859692
2516 val loss is 0.421882390976
2517 train loss is 0.408956199884
2517 val loss is 0.420950114727
2518 train loss is 0.424938678741
2518 val loss is 0.420167952776
2519 train loss is 0.425410211086
2519 val loss is 0.419821768999
2520 train loss is 0.464193701744
2520 val loss is 0.41908377409
2521 train loss is 0.433332085609
2521 val loss is 0.419332116842
2522 train loss is 0.404938161373
2522 val loss is 0.420932114124
2523 train loss is 0.445564985275
2523 val loss is 0.42249327898
2524 train loss is 0.435919433832
2524 val loss is 0.42243874073
2525 train loss is 0.420427620411
2525 val loss is 0.421126425266
2526 train loss is 0.426378935575
2526 val loss is 0.420039176941
2527 train loss is 0.416439592838
2527 val loss is 0.420109063387
2528 train loss is 0.403074085712
2528 val loss is 0.420573443174
2529 train loss is 0.39097854495
2529 val loss is 0.420548200607
2530 train loss is 0.445714950562
2530 val loss is 0.419881850481
2531 train loss is 0.400254964828
2531 val loss is 0.419794052839
2532 train loss is 0.443826168776
2532 val loss is 0.420693516731
2533 train loss is 0.422270357609
2533 val loss is 0.421729832888
2534 train loss is 0.440959215164
2534 val loss is 0.421981930733
2535 train loss is 0.468083560467
2535 val loss is 0.421247065067
2536 train loss is 0.390061438084
2536 val loss is 0.421305954456
2537 train loss is 0.428299427032
2537 val loss is 0.421184360981
2538 train loss is 0.453564435244
2538 val loss is 0.42022049427
2539 train loss is 0.434603840113
2539 val loss is 0.419410765171
2540 train loss is 0.418626844883
2540 val loss is 0.419295489788
2541 train loss is 0.405578941107
2541 val loss is 0.419787973166
2542 train loss is 0.45827794075
2542 val loss is 0.419879108667
2543 train loss is 0.413020700216
2543 val loss is 0.419592916965
2544 train loss is 0.409249603748
2544 val loss is 0.419935911894
2545 train loss is 0.429235517979
2545 val loss is 0.420577615499
2546 train loss is 0.421670615673
2546 val loss is 0.420425057411
2547 train loss is 0.392458498478
2547 val loss is 0.419312447309
2548 train loss is 0.414941728115
2548 val loss is 0.418720245361
2549 train loss is 0.405495882034
2549 val loss is 0.418583601713
2550 train loss is 0.411122083664
2550 val loss is 0.418023586273
2551 train loss is 0.417318671942
2551 val loss is 0.416846960783
2552 train loss is 0.375634223223
2552 val loss is 0.416564464569
2553 train loss is 0.452795535326
2553 val loss is 0.417781561613
2554 train loss is 0.410203933716
2554 val loss is 0.420203268528
2555 train loss is 0.430900990963
2555 val loss is 0.420798957348
2556 train loss is 0.392662882805
2556 val loss is 0.419435024261
2557 train loss is 0.418862640858
2557 val loss is 0.417227476835
2558 train loss is 0.431727975607
2558 val loss is 0.416255712509
2559 train loss is 0.382459968328
2559 val loss is 0.416931658983
2560 train loss is 0.440008074045
2560 val loss is 0.418079793453
2561 train loss is 0.437359929085
2561 val loss is 0.417663902044
2562 train loss is 0.418987005949
2562 val loss is 0.416291177273
2563 train loss is 0.408110290766
2563 val loss is 0.416483044624
2564 train loss is 0.438145548105
2564 val loss is 0.418469846249
2565 train loss is 0.398073166609
2565 val loss is 0.419662535191
2566 train loss is 0.419704407454
2566 val loss is 0.418943107128
2567 train loss is 0.397325098515
2567 val loss is 0.417216509581
2568 train loss is 0.422470033169
2568 val loss is 0.416518062353
2569 train loss is 0.409411996603
2569 val loss is 0.417337983847
2570 train loss is 0.402108728886
2570 val loss is 0.41796875
2571 train loss is 0.436691582203
2571 val loss is 0.416668385267
2572 train loss is 0.439874738455
2572 val loss is 0.415733277798
2573 train loss is 0.42220851779
2573 val loss is 0.417271137238
2574 train loss is 0.402802497149
2574 val loss is 0.419346362352
2575 train loss is 0.425398916006
2575 val loss is 0.41946041584
2576 train loss is 0.400808691978
2576 val loss is 0.418189764023
2577 train loss is 0.419482171535
2577 val loss is 0.417456150055
2578 train loss is 0.416124284267
2578 val loss is 0.417486667633
2579 train loss is 0.449317067862
2579 val loss is 0.417954355478
2580 train loss is 0.410364449024
2580 val loss is 0.417296230793
2581 train loss is 0.400670975447
2581 val loss is 0.415743112564
2582 train loss is 0.406171143055
2582 val loss is 0.415353119373
2583 train loss is 0.458588540554
2583 val loss is 0.416273742914
2584 train loss is 0.43641358614
2584 val loss is 0.41813313961
2585 train loss is 0.419186085463
2585 val loss is 0.418938159943
2586 train loss is 0.418815165758
2586 val loss is 0.418248057365
2587 train loss is 0.416506528854
2587 val loss is 0.416697651148
2588 train loss is 0.428699821234
2588 val loss is 0.416082203388
2589 train loss is 0.409799218178
2589 val loss is 0.416446089745
2590 train loss is 0.457964986563
2590 val loss is 0.416598111391
2591 train loss is 0.439848065376
2591 val loss is 0.415726989508
2592 train loss is 0.447028130293
2592 val loss is 0.415359675884
2593 train loss is 0.4264754951
2593 val loss is 0.416071176529
2594 train loss is 0.42669776082
2594 val loss is 0.417626678944
2595 train loss is 0.424836993217
2595 val loss is 0.418440699577
2596 train loss is 0.401420980692
2596 val loss is 0.417396843433
2597 train loss is 0.443303287029
2597 val loss is 0.415956914425
2598 train loss is 0.417700588703
2598 val loss is 0.416277199984
2599 train loss is 0.405390322208
2599 val loss is 0.41720277071
2600 train loss is 0.422901809216
2600 val loss is 0.417536139488
2601 train loss is 0.402590334415
2601 val loss is 0.416861474514
2602 train loss is 0.437640011311
2602 val loss is 0.415912151337
2603 train loss is 0.414683192968
2603 val loss is 0.416436523199
2604 train loss is 0.432062417269
2604 val loss is 0.418057590723
2605 train loss is 0.464272320271
2605 val loss is 0.419141620398
2606 train loss is 0.46319013834
2606 val loss is 0.419109284878
2607 train loss is 0.385802507401
2607 val loss is 0.418414533138
2608 train loss is 0.443047523499
2608 val loss is 0.417391240597
2609 train loss is 0.42058801651
2609 val loss is 0.416683137417
2610 train loss is 0.443491667509
2610 val loss is 0.416403353214
2611 train loss is 0.437178105116
2611 val loss is 0.416141033173
2612 train loss is 0.414974838495
2612 val loss is 0.415712922812
2613 train loss is 0.411077022552
2613 val loss is 0.41555583477
2614 train loss is 0.408513069153
2614 val loss is 0.416140556335
2615 train loss is 0.40170148015
2615 val loss is 0.417130202055
2616 train loss is 0.409196913242
2616 val loss is 0.417355835438
2617 train loss is 0.428506016731
2617 val loss is 0.416799008846
2618 train loss is 0.437427610159
2618 val loss is 0.416095465422
2619 train loss is 0.40169107914
2619 val loss is 0.415202707052
2620 train loss is 0.417497426271
2620 val loss is 0.414787828922
2621 train loss is 0.412554174662
2621 val loss is 0.414501607418
2622 train loss is 0.42325976491
2622 val loss is 0.41414090991
2623 train loss is 0.422644078732
2623 val loss is 0.414834976196
2624 train loss is 0.452114671469
2624 val loss is 0.416076004505
2625 train loss is 0.412306904793
2625 val loss is 0.417190372944
2626 train loss is 0.417518794537
2626 val loss is 0.41684654355
2627 train loss is 0.42574095726
2627 val loss is 0.415248334408
2628 train loss is 0.41504907608
2628 val loss is 0.413451611996
2629 train loss is 0.436768472195
2629 val loss is 0.413228690624
2630 train loss is 0.399777889252
2630 val loss is 0.414062619209
2631 train loss is 0.437623292208
2631 val loss is 0.414303958416
2632 train loss is 0.423957079649
2632 val loss is 0.414047062397
2633 train loss is 0.402290910482
2633 val loss is 0.4138225317
2634 train loss is 0.42101174593
2634 val loss is 0.414653033018
2635 train loss is 0.433729588985
2635 val loss is 0.416197836399
2636 train loss is 0.427043110132
2636 val loss is 0.417050302029
2637 train loss is 0.43610355258
2637 val loss is 0.416020125151
2638 train loss is 0.456693023443
2638 val loss is 0.414023756981
2639 train loss is 0.41807115078
2639 val loss is 0.41285520792
2640 train loss is 0.401772022247
2640 val loss is 0.41344922781
2641 train loss is 0.425024390221
2641 val loss is 0.414449572563
2642 train loss is 0.408144056797
2642 val loss is 0.414090484381
2643 train loss is 0.426968991756
2643 val loss is 0.413356661797
2644 train loss is 0.412954717875
2644 val loss is 0.414520561695
2645 train loss is 0.433037638664
2645 val loss is 0.416874408722
2646 train loss is 0.458499848843
2646 val loss is 0.417670071125
2647 train loss is 0.414775431156
2647 val loss is 0.415958166122
2648 train loss is 0.430418252945
2648 val loss is 0.413392215967
2649 train loss is 0.415817320347
2649 val loss is 0.412179589272
2650 train loss is 0.437189102173
2650 val loss is 0.412791579962
2651 train loss is 0.422304153442
2651 val loss is 0.41420635581
2652 train loss is 0.476789027452
2652 val loss is 0.414630055428
2653 train loss is 0.407145440578
2653 val loss is 0.414263725281
2654 train loss is 0.417826771736
2654 val loss is 0.415038853884
2655 train loss is 0.418379873037
2655 val loss is 0.416248738766
2656 train loss is 0.432570725679
2656 val loss is 0.416730165482
2657 train loss is 0.395474791527
2657 val loss is 0.415500760078
2658 train loss is 0.441413789988
2658 val loss is 0.413265585899
2659 train loss is 0.415334999561
2659 val loss is 0.411671102047
2660 train loss is 0.390818089247
2660 val loss is 0.411836832762
2661 train loss is 0.412405014038
2661 val loss is 0.412911504507
2662 train loss is 0.424144655466
2662 val loss is 0.412784934044
2663 train loss is 0.373591661453
2663 val loss is 0.41220369935
2664 train loss is 0.45093524456
2664 val loss is 0.412780821323
2665 train loss is 0.424592643976
2665 val loss is 0.414660096169
2666 train loss is 0.412588059902
2666 val loss is 0.416071027517
2667 train loss is 0.435893774033
2667 val loss is 0.414741396904
2668 train loss is 0.423612117767
2668 val loss is 0.412401378155
2669 train loss is 0.446319758892
2669 val loss is 0.410948187113
2670 train loss is 0.392925620079
2670 val loss is 0.410809546709
2671 train loss is 0.402003288269
2671 val loss is 0.411560356617
2672 train loss is 0.427955210209
2672 val loss is 0.41177085042
2673 train loss is 0.41991558671
2673 val loss is 0.411739677191
2674 train loss is 0.459854245186
2674 val loss is 0.412908792496
2675 train loss is 0.458390086889
2675 val loss is 0.414957940578
2676 train loss is 0.446900188923
2676 val loss is 0.415190666914
2677 train loss is 0.423011541367
2677 val loss is 0.413807153702
2678 train loss is 0.450459957123
2678 val loss is 0.411693513393
2679 train loss is 0.400710940361
2679 val loss is 0.41083419323
2680 train loss is 0.406380861998
2680 val loss is 0.41137573123
2681 train loss is 0.459237605333
2681 val loss is 0.41192907095
2682 train loss is 0.412322729826
2682 val loss is 0.411766678095
2683 train loss is 0.374277710915
2683 val loss is 0.41114616394
2684 train loss is 0.381876528263
2684 val loss is 0.411329269409
2685 train loss is 0.425153940916
2685 val loss is 0.412841558456
2686 train loss is 0.406930923462
2686 val loss is 0.413720726967
2687 train loss is 0.456643044949
2687 val loss is 0.413000434637
2688 train loss is 0.421665936708
2688 val loss is 0.411293596029
2689 train loss is 0.423478633165
2689 val loss is 0.410850673914
2690 train loss is 0.398067414761
2690 val loss is 0.411675453186
2691 train loss is 0.451623290777
2691 val loss is 0.411896318197
2692 train loss is 0.430637717247
2692 val loss is 0.410976588726
2693 train loss is 0.412976324558
2693 val loss is 0.410221844912
2694 train loss is 0.422454833984
2694 val loss is 0.410538911819
2695 train loss is 0.425694435835
2695 val loss is 0.411474049091
2696 train loss is 0.452057272196
2696 val loss is 0.412013828754
2697 train loss is 0.442232251167
2697 val loss is 0.411514788866
2698 train loss is 0.413526117802
2698 val loss is 0.410455465317
2699 train loss is 0.386861115694
2699 val loss is 0.409890294075
2700 train loss is 0.40828537941
2700 val loss is 0.410354137421
2701 train loss is 0.426831543446
2701 val loss is 0.410867094994
2702 train loss is 0.420504927635
2702 val loss is 0.411368340254
2703 train loss is 0.429827272892
2703 val loss is 0.411374777555
2704 train loss is 0.419797897339
2704 val loss is 0.411359518766
2705 train loss is 0.407115399837
2705 val loss is 0.412507414818
2706 train loss is 0.386478483677
2706 val loss is 0.413535237312
2707 train loss is 0.433155924082
2707 val loss is 0.412874102592
2708 train loss is 0.393115967512
2708 val loss is 0.41138869524
2709 train loss is 0.443204760551
2709 val loss is 0.410722374916
2710 train loss is 0.411399185658
2710 val loss is 0.410877078772
2711 train loss is 0.391335785389
2711 val loss is 0.411177307367
2712 train loss is 0.442788213491
2712 val loss is 0.411176294088
2713 train loss is 0.395686715841
2713 val loss is 0.411093235016
2714 train loss is 0.396713137627
2714 val loss is 0.411463290453
2715 train loss is 0.411491572857
2715 val loss is 0.412754356861
2716 train loss is 0.416330337524
2716 val loss is 0.413512408733
2717 train loss is 0.424340069294
2717 val loss is 0.4130641222
2718 train loss is 0.445279330015
2718 val loss is 0.411794245243
2719 train loss is 0.43362224102
2719 val loss is 0.410718739033
2720 train loss is 0.398828476667
2720 val loss is 0.41213914752
2721 train loss is 0.425522595644
2721 val loss is 0.413545310497
2722 train loss is 0.413737237453
2722 val loss is 0.413084208965
2723 train loss is 0.411668628454
2723 val loss is 0.4112611413
2724 train loss is 0.412170767784
2724 val loss is 0.410483121872
2725 train loss is 0.412498474121
2725 val loss is 0.412196367979
2726 train loss is 0.402363270521
2726 val loss is 0.414891183376
2727 train loss is 0.388325452805
2727 val loss is 0.415022462606
2728 train loss is 0.414287567139
2728 val loss is 0.412416994572
2729 train loss is 0.39853271842
2729 val loss is 0.409069746733
2730 train loss is 0.414240598679
2730 val loss is 0.409275352955
2731 train loss is 0.392437636852
2731 val loss is 0.412014335394
2732 train loss is 0.419073760509
2732 val loss is 0.41331499815
2733 train loss is 0.430242836475
2733 val loss is 0.411310076714
2734 train loss is 0.421661555767
2734 val loss is 0.409856200218
2735 train loss is 0.376306712627
2735 val loss is 0.410740733147
2736 train loss is 0.432508647442
2736 val loss is 0.412379384041
2737 train loss is 0.414636254311
2737 val loss is 0.412932872772
2738 train loss is 0.41828930378
2738 val loss is 0.411195486784
2739 train loss is 0.39723020792
2739 val loss is 0.408395826817
2740 train loss is 0.400147527456
2740 val loss is 0.407916843891
2741 train loss is 0.43477076292
2741 val loss is 0.410038858652
2742 train loss is 0.416898131371
2742 val loss is 0.411941587925
2743 train loss is 0.415874183178
2743 val loss is 0.411158084869
2744 train loss is 0.432674795389
2744 val loss is 0.408955425024
2745 train loss is 0.397878229618
2745 val loss is 0.408295631409
2746 train loss is 0.420986056328
2746 val loss is 0.40971109271
2747 train loss is 0.428730070591
2747 val loss is 0.411569535732
2748 train loss is 0.399091750383
2748 val loss is 0.411379009485
2749 train loss is 0.417315810919
2749 val loss is 0.409509778023
2750 train loss is 0.408968806267
2750 val loss is 0.40781930089
2751 train loss is 0.421458244324
2751 val loss is 0.408569008112
2752 train loss is 0.433730751276
2752 val loss is 0.409878104925
2753 train loss is 0.404877364635
2753 val loss is 0.409951806068
2754 train loss is 0.440803170204
2754 val loss is 0.408658623695
2755 train loss is 0.420954436064
2755 val loss is 0.408028364182
2756 train loss is 0.387851417065
2756 val loss is 0.408850967884
2757 train loss is 0.403486013412
2757 val loss is 0.409725874662
2758 train loss is 0.428695291281
2758 val loss is 0.409378260374
2759 train loss is 0.404192507267
2759 val loss is 0.408158034086
2760 train loss is 0.397984564304
2760 val loss is 0.407372832298
2761 train loss is 0.421094328165
2761 val loss is 0.407732993364
2762 train loss is 0.382178753614
2762 val loss is 0.408431500196
2763 train loss is 0.422273516655
2763 val loss is 0.408794105053
2764 train loss is 0.42150247097
2764 val loss is 0.408227682114
2765 train loss is 0.414374709129
2765 val loss is 0.407759398222
2766 train loss is 0.387697994709
2766 val loss is 0.408358752728
2767 train loss is 0.432922959328
2767 val loss is 0.409090459347
2768 train loss is 0.425917863846
2768 val loss is 0.409531652927
2769 train loss is 0.413763463497
2769 val loss is 0.409287244081
2770 train loss is 0.400092035532
2770 val loss is 0.408040583134
2771 train loss is 0.4376770854
2771 val loss is 0.407430976629
2772 train loss is 0.417123585939
2772 val loss is 0.40789976716
2773 train loss is 0.402533054352
2773 val loss is 0.408154666424
2774 train loss is 0.429108798504
2774 val loss is 0.407772749662
2775 train loss is 0.458602249622
2775 val loss is 0.407193660736
2776 train loss is 0.411995321512
2776 val loss is 0.407604783773
2777 train loss is 0.390817552805
2777 val loss is 0.408873826265
2778 train loss is 0.39651080966
2778 val loss is 0.408751487732
2779 train loss is 0.43268057704
2779 val loss is 0.40742957592
2780 train loss is 0.41890412569
2780 val loss is 0.406356990337
2781 train loss is 0.442243397236
2781 val loss is 0.406889915466
2782 train loss is 0.401107370853
2782 val loss is 0.408258199692
2783 train loss is 0.386505901814
2783 val loss is 0.408451974392
2784 train loss is 0.413514018059
2784 val loss is 0.407401710749
2785 train loss is 0.410643070936
2785 val loss is 0.40675085783
2786 train loss is 0.419005513191
2786 val loss is 0.407006025314
2787 train loss is 0.414446294308
2787 val loss is 0.407980769873
2788 train loss is 0.420513272285
2788 val loss is 0.407904326916
2789 train loss is 0.413415312767
2789 val loss is 0.40676254034
2790 train loss is 0.448592633009
2790 val loss is 0.406155765057
2791 train loss is 0.417427957058
2791 val loss is 0.406234204769
2792 train loss is 0.395770311356
2792 val loss is 0.406394720078
2793 train loss is 0.433727353811
2793 val loss is 0.406136274338
2794 train loss is 0.394096076488
2794 val loss is 0.405771315098
2795 train loss is 0.402949780226
2795 val loss is 0.405613541603
2796 train loss is 0.432482898235
2796 val loss is 0.405680954456
2797 train loss is 0.407952785492
2797 val loss is 0.40630453825
2798 train loss is 0.420766443014
2798 val loss is 0.407282888889
2799 train loss is 0.412039786577
2799 val loss is 0.407425999641
2800 train loss is 0.406389683485
2800 val loss is 0.407769441605
2801 train loss is 0.403249502182
2801 val loss is 0.408099710941
2802 train loss is 0.410581916571
2802 val loss is 0.407932370901
2803 train loss is 0.432327330112
2803 val loss is 0.4069455266
2804 train loss is 0.409760951996
2804 val loss is 0.405750870705
2805 train loss is 0.412210673094
2805 val loss is 0.405706703663
2806 train loss is 0.438328415155
2806 val loss is 0.406883180141
2807 train loss is 0.420049905777
2807 val loss is 0.407675564289
2808 train loss is 0.400283455849
2808 val loss is 0.408026635647
2809 train loss is 0.424782514572
2809 val loss is 0.407484382391
2810 train loss is 0.395811378956
2810 val loss is 0.407563894987
2811 train loss is 0.418302774429
2811 val loss is 0.408301532269
2812 train loss is 0.441517055035
2812 val loss is 0.408317238092
2813 train loss is 0.46198746562
2813 val loss is 0.407594144344
2814 train loss is 0.399850338697
2814 val loss is 0.406632483006
2815 train loss is 0.4178647995
2815 val loss is 0.40647354722
2816 train loss is 0.40899515152
2816 val loss is 0.406903862953
2817 train loss is 0.401594698429
2817 val loss is 0.407600164413
2818 train loss is 0.411433875561
2818 val loss is 0.407745361328
2819 train loss is 0.399541765451
2819 val loss is 0.407839477062
2820 train loss is 0.390891849995
2820 val loss is 0.407874047756
2821 train loss is 0.424948275089
2821 val loss is 0.408229351044
2822 train loss is 0.386826783419
2822 val loss is 0.407994538546
2823 train loss is 0.411960542202
2823 val loss is 0.406813651323
2824 train loss is 0.385765075684
2824 val loss is 0.405820548534
2825 train loss is 0.417544752359
2825 val loss is 0.405488967896
2826 train loss is 0.42986920476
2826 val loss is 0.405098378658
2827 train loss is 0.421151161194
2827 val loss is 0.405223190784
2828 train loss is 0.406020641327
2828 val loss is 0.406614720821
2829 train loss is 0.430235922337
2829 val loss is 0.407943099737
2830 train loss is 0.396942436695
2830 val loss is 0.408203303814
2831 train loss is 0.380202800035
2831 val loss is 0.407513201237
2832 train loss is 0.417925775051
2832 val loss is 0.406490057707
2833 train loss is 0.402220547199
2833 val loss is 0.406093776226
2834 train loss is 0.398645818233
2834 val loss is 0.406329572201
2835 train loss is 0.390160381794
2835 val loss is 0.406333744526
2836 train loss is 0.415704727173
2836 val loss is 0.405641973019
2837 train loss is 0.414507955313
2837 val loss is 0.404828429222
2838 train loss is 0.380006968975
2838 val loss is 0.405118405819
2839 train loss is 0.410683900118
2839 val loss is 0.406308740377
2840 train loss is 0.414221227169
2840 val loss is 0.406889736652
2841 train loss is 0.404264837503
2841 val loss is 0.406128525734
2842 train loss is 0.413240373135
2842 val loss is 0.405157119036
2843 train loss is 0.408213615417
2843 val loss is 0.404677271843
2844 train loss is 0.388987600803
2844 val loss is 0.405008614063
2845 train loss is 0.401026189327
2845 val loss is 0.405173659325
2846 train loss is 0.402623653412
2846 val loss is 0.404757797718
2847 train loss is 0.398804605007
2847 val loss is 0.404327392578
2848 train loss is 0.449893444777
2848 val loss is 0.404606729746
2849 train loss is 0.423495709896
2849 val loss is 0.405327737331
2850 train loss is 0.391760438681
2850 val loss is 0.406073391438
2851 train loss is 0.421376645565
2851 val loss is 0.406220674515
2852 train loss is 0.409295409918
2852 val loss is 0.405264556408
2853 train loss is 0.408347725868
2853 val loss is 0.404182910919
2854 train loss is 0.430357605219
2854 val loss is 0.403918385506
2855 train loss is 0.390242546797
2855 val loss is 0.40409553051
2856 train loss is 0.411893486977
2856 val loss is 0.404647469521
2857 train loss is 0.4409917593
2857 val loss is 0.405042469501
2858 train loss is 0.408216834068
2858 val loss is 0.405099093914
2859 train loss is 0.404690742493
2859 val loss is 0.405060440302
2860 train loss is 0.435805380344
2860 val loss is 0.405729115009
2861 train loss is 0.434250533581
2861 val loss is 0.406273394823
2862 train loss is 0.407243490219
2862 val loss is 0.406122505665
2863 train loss is 0.399354219437
2863 val loss is 0.405027925968
2864 train loss is 0.404493123293
2864 val loss is 0.404141157866
2865 train loss is 0.415182501078
2865 val loss is 0.403921723366
2866 train loss is 0.417676448822
2866 val loss is 0.404879152775
2867 train loss is 0.425605624914
2867 val loss is 0.405955135822
2868 train loss is 0.403817713261
2868 val loss is 0.405841886997
2869 train loss is 0.413587957621
2869 val loss is 0.4044662714
2870 train loss is 0.377954781055
2870 val loss is 0.404067307711
2871 train loss is 0.436893135309
2871 val loss is 0.404868811369
2872 train loss is 0.429957985878
2872 val loss is 0.405674695969
2873 train loss is 0.424663126469
2873 val loss is 0.405430644751
2874 train loss is 0.42190527916
2874 val loss is 0.404451727867
2875 train loss is 0.425180912018
2875 val loss is 0.404359102249
2876 train loss is 0.366270393133
2876 val loss is 0.405349552631
2877 train loss is 0.424218565226
2877 val loss is 0.406501889229
2878 train loss is 0.417245477438
2878 val loss is 0.406375437975
2879 train loss is 0.403743714094
2879 val loss is 0.405289888382
2880 train loss is 0.402407616377
2880 val loss is 0.404949873686
2881 train loss is 0.411003649235
2881 val loss is 0.405699282885
2882 train loss is 0.392532885075
2882 val loss is 0.40591314435
2883 train loss is 0.411783307791
2883 val loss is 0.40453761816
2884 train loss is 0.438159525394
2884 val loss is 0.403005570173
2885 train loss is 0.412883073092
2885 val loss is 0.403352975845
2886 train loss is 0.387433230877
2886 val loss is 0.405174463987
2887 train loss is 0.456029474735
2887 val loss is 0.406729310751
2888 train loss is 0.406015574932
2888 val loss is 0.406147658825
2889 train loss is 0.387974143028
2889 val loss is 0.404982060194
2890 train loss is 0.408106833696
2890 val loss is 0.404418408871
2891 train loss is 0.422340512276
2891 val loss is 0.40498560667
2892 train loss is 0.410868287086
2892 val loss is 0.406088769436
2893 train loss is 0.406907856464
2893 val loss is 0.404959797859
2894 train loss is 0.443820595741
2894 val loss is 0.403002262115
2895 train loss is 0.416382312775
2895 val loss is 0.402753055096
2896 train loss is 0.420391201973
2896 val loss is 0.404719591141
2897 train loss is 0.371875166893
2897 val loss is 0.406671673059
2898 train loss is 0.382363200188
2898 val loss is 0.40604352951
2899 train loss is 0.429524838924
2899 val loss is 0.404440194368
2900 train loss is 0.441969841719
2900 val loss is 0.403607934713
2901 train loss is 0.409578621387
2901 val loss is 0.405443966389
2902 train loss is 0.397999793291
2902 val loss is 0.40688431263
2903 train loss is 0.420943200588
2903 val loss is 0.405992239714
2904 train loss is 0.402228087187
2904 val loss is 0.403037339449
2905 train loss is 0.402812600136
2905 val loss is 0.40205180645
2906 train loss is 0.422478556633
2906 val loss is 0.404232919216
2907 train loss is 0.434665501118
2907 val loss is 0.406830102205
2908 train loss is 0.414529502392
2908 val loss is 0.407038450241
2909 train loss is 0.388017684221
2909 val loss is 0.404768705368
2910 train loss is 0.413564920425
2910 val loss is 0.402835518122
2911 train loss is 0.396519303322
2911 val loss is 0.403381615877
2912 train loss is 0.403479963541
2912 val loss is 0.405063927174
2913 train loss is 0.417271524668
2913 val loss is 0.405086606741
2914 train loss is 0.371664166451
2914 val loss is 0.402961105108
2915 train loss is 0.426150202751
2915 val loss is 0.401494473219
2916 train loss is 0.429425776005
2916 val loss is 0.402719378471
2917 train loss is 0.412427663803
2917 val loss is 0.405313283205
2918 train loss is 0.390770375729
2918 val loss is 0.406111627817
2919 train loss is 0.421218603849
2919 val loss is 0.404284566641
2920 train loss is 0.382937192917
2920 val loss is 0.402221739292
2921 train loss is 0.404728889465
2921 val loss is 0.401998966932
2922 train loss is 0.411185026169
2922 val loss is 0.4031932652
2923 train loss is 0.404071092606
2923 val loss is 0.403649508953
2924 train loss is 0.417112290859
2924 val loss is 0.402289867401
2925 train loss is 0.398530900478
2925 val loss is 0.400846242905
2926 train loss is 0.412482470274
2926 val loss is 0.401705503464
2927 train loss is 0.39165225625
2927 val loss is 0.403857827187
2928 train loss is 0.423120379448
2928 val loss is 0.404731720686
2929 train loss is 0.42424556613
2929 val loss is 0.403423219919
2930 train loss is 0.390233814716
2930 val loss is 0.402103722095
2931 train loss is 0.380641192198
2931 val loss is 0.40294277668
2932 train loss is 0.408484846354
2932 val loss is 0.404251784086
2933 train loss is 0.404579371214
2933 val loss is 0.403796523809
2934 train loss is 0.431368947029
2934 val loss is 0.401580452919
2935 train loss is 0.421256124973
2935 val loss is 0.40023124218
2936 train loss is 0.420358002186
2936 val loss is 0.401702344418
2937 train loss is 0.413374722004
2937 val loss is 0.403945207596
2938 train loss is 0.421221077442
2938 val loss is 0.403814733028
2939 train loss is 0.405847072601
2939 val loss is 0.402507573366
2940 train loss is 0.401952475309
2940 val loss is 0.401664555073
2941 train loss is 0.403380304575
2941 val loss is 0.402540504932
2942 train loss is 0.435619235039
2942 val loss is 0.403537124395
2943 train loss is 0.402943104506
2943 val loss is 0.40279853344
2944 train loss is 0.430505901575
2944 val loss is 0.401052713394
2945 train loss is 0.412496358156
2945 val loss is 0.400291264057
2946 train loss is 0.407326310873
2946 val loss is 0.401196122169
2947 train loss is 0.398604214191
2947 val loss is 0.402115702629
2948 train loss is 0.374557167292
2948 val loss is 0.402163088322
2949 train loss is 0.370303183794
2949 val loss is 0.401951223612
2950 train loss is 0.395213633776
2950 val loss is 0.402489125729
2951 train loss is 0.413982897997
2951 val loss is 0.40325409174
2952 train loss is 0.41085010767
2952 val loss is 0.403185904026
2953 train loss is 0.408358067274
2953 val loss is 0.402400255203
2954 train loss is 0.395406097174
2954 val loss is 0.401483982801
2955 train loss is 0.383044838905
2955 val loss is 0.400625497103
2956 train loss is 0.411115378141
2956 val loss is 0.400206148624
2957 train loss is 0.409681797028
2957 val loss is 0.400658220053
2958 train loss is 0.446078658104
2958 val loss is 0.401594012976
2959 train loss is 0.417517781258
2959 val loss is 0.403096556664
2960 train loss is 0.417010754347
2960 val loss is 0.404201298952
2961 train loss is 0.404571712017
2961 val loss is 0.404050856829
2962 train loss is 0.391185581684
2962 val loss is 0.403851866722
2963 train loss is 0.411109775305
2963 val loss is 0.404306650162
2964 train loss is 0.388236403465
2964 val loss is 0.403698951006
2965 train loss is 0.396720588207
2965 val loss is 0.401725053787
2966 train loss is 0.412361204624
2966 val loss is 0.400158107281
2967 train loss is 0.423995792866
2967 val loss is 0.400927096605
2968 train loss is 0.414259582758
2968 val loss is 0.404222786427
2969 train loss is 0.425477921963
2969 val loss is 0.406756609678
2970 train loss is 0.399026989937
2970 val loss is 0.405988395214
2971 train loss is 0.403308659792
2971 val loss is 0.404355108738
2972 train loss is 0.40783265233
2972 val loss is 0.404190480709
2973 train loss is 0.411975443363
2973 val loss is 0.405602842569
2974 train loss is 0.387763917446
2974 val loss is 0.405760347843
2975 train loss is 0.405986964703
2975 val loss is 0.403223752975
2976 train loss is 0.402802050114
2976 val loss is 0.400547742844
2977 train loss is 0.405830949545
2977 val loss is 0.400344252586
2978 train loss is 0.390231996775
2978 val loss is 0.403644442558
2979 train loss is 0.442689180374
2979 val loss is 0.406425267458
2980 train loss is 0.419014692307
2980 val loss is 0.406603038311
2981 train loss is 0.39550536871
2981 val loss is 0.404714345932
2982 train loss is 0.378317713737
2982 val loss is 0.403024941683
2983 train loss is 0.44316893816
2983 val loss is 0.403411328793
2984 train loss is 0.442723333836
2984 val loss is 0.403890967369
2985 train loss is 0.404374063015
2985 val loss is 0.403200000525
2986 train loss is 0.422356903553
2986 val loss is 0.401344567537
2987 train loss is 0.442526757717
2987 val loss is 0.399393707514
2988 train loss is 0.423841774464
2988 val loss is 0.400335729122
2989 train loss is 0.39952865243
2989 val loss is 0.404248327017
2990 train loss is 0.414672583342
2990 val loss is 0.406657874584
2991 train loss is 0.395032525063
2991 val loss is 0.405324459076
2992 train loss is 0.406065404415
2992 val loss is 0.402398407459
2993 train loss is 0.426066994667
2993 val loss is 0.400941371918
2994 train loss is 0.385602235794
2994 val loss is 0.401333004236
2995 train loss is 0.402392357588
2995 val loss is 0.401592373848
2996 train loss is 0.421433329582
2996 val loss is 0.400128424168
2997 train loss is 0.408357024193
2997 val loss is 0.398829251528
2998 train loss is 0.409339308739
2998 val loss is 0.398907423019
2999 train loss is 0.405816674232
2999 val loss is 0.400839984417
3000 train loss is 0.421901851892
3000 val loss is 0.405954748392
3001 train loss is 0.432415544987
3001 val loss is 0.410808622837
3002 train loss is 0.391888707876
3002 val loss is 0.412235677242
3003 train loss is 0.423087477684
3003 val loss is 0.409802734852
3004 train loss is 0.408482372761
3004 val loss is 0.405074954033
3005 train loss is 0.403501152992
3005 val loss is 0.400957167149
3006 train loss is 0.410010188818
3006 val loss is 0.39964273572
3007 train loss is 0.426911532879
3007 val loss is 0.401278793812
3008 train loss is 0.434526532888
3008 val loss is 0.403869718313
3009 train loss is 0.393515467644
3009 val loss is 0.405057281256
3010 train loss is 0.401813149452
3010 val loss is 0.403841376305
3011 train loss is 0.441675633192
3011 val loss is 0.401020020247
3012 train loss is 0.423324584961
3012 val loss is 0.398561656475
3013 train loss is 0.413482785225
3013 val loss is 0.398322463036
3014 train loss is 0.40766659379
3014 val loss is 0.400763988495
3015 train loss is 0.435980945826
3015 val loss is 0.40450027585
3016 train loss is 0.412253558636
3016 val loss is 0.407249331474
3017 train loss is 0.435751706362
3017 val loss is 0.407139718533
3018 train loss is 0.405211299658
3018 val loss is 0.404442340136
3019 train loss is 0.412819772959
3019 val loss is 0.401038020849
3020 train loss is 0.404982119799
3020 val loss is 0.398948669434
3021 train loss is 0.389623701572
3021 val loss is 0.398774474859
3022 train loss is 0.374972403049
3022 val loss is 0.399913072586
3023 train loss is 0.39788427949
3023 val loss is 0.400875508785
3024 train loss is 0.41633310914
3024 val loss is 0.400886237621
3025 train loss is 0.385655403137
3025 val loss is 0.399892359972
3026 train loss is 0.418500751257
3026 val loss is 0.398220121861
3027 train loss is 0.411644369364
3027 val loss is 0.397449046373
3028 train loss is 0.397015213966
3028 val loss is 0.398544102907
3029 train loss is 0.434976428747
3029 val loss is 0.401195973158
3030 train loss is 0.402015239
3030 val loss is 0.403609782457
3031 train loss is 0.380929410458
3031 val loss is 0.404592931271
3032 train loss is 0.416615366936
3032 val loss is 0.403644025326
3033 train loss is 0.424944281578
3033 val loss is 0.401242315769
3034 train loss is 0.392235606909
3034 val loss is 0.398654192686
3035 train loss is 0.386919140816
3035 val loss is 0.397304713726
3036 train loss is 0.419304341078
3036 val loss is 0.397806376219
3037 train loss is 0.401299059391
3037 val loss is 0.399536818266
3038 train loss is 0.384723961353
3038 val loss is 0.400701224804
3039 train loss is 0.388772636652
3039 val loss is 0.400428920984
3040 train loss is 0.380811840296
3040 val loss is 0.398807823658
3041 train loss is 0.435715556145
3041 val loss is 0.397039800882
3042 train loss is 0.408231437206
3042 val loss is 0.396347343922
3043 train loss is 0.392598927021
3043 val loss is 0.397308826447
3044 train loss is 0.426998585463
3044 val loss is 0.399770259857
3045 train loss is 0.403396010399
3045 val loss is 0.402251273394
3046 train loss is 0.377616763115
3046 val loss is 0.403452426195
3047 train loss is 0.404927641153
3047 val loss is 0.402462393045
3048 train loss is 0.42097941041
3048 val loss is 0.399831324816
3049 train loss is 0.402215361595
3049 val loss is 0.397248357534
3050 train loss is 0.397179305553
3050 val loss is 0.39581489563
3051 train loss is 0.41298019886
3051 val loss is 0.396023988724
3052 train loss is 0.365535140038
3052 val loss is 0.397311866283
3053 train loss is 0.414231002331
3053 val loss is 0.39836075902
3054 train loss is 0.406013906002
3054 val loss is 0.398110210896
3055 train loss is 0.396209597588
3055 val loss is 0.397103965282
3056 train loss is 0.390993446112
3056 val loss is 0.395746648312
3057 train loss is 0.391763269901
3057 val loss is 0.395059764385
3058 train loss is 0.402323693037
3058 val loss is 0.395690619946
3059 train loss is 0.38468798995
3059 val loss is 0.397242426872
3060 train loss is 0.392169088125
3060 val loss is 0.399030923843
3061 train loss is 0.412763595581
3061 val loss is 0.400042682886
3062 train loss is 0.406003534794
3062 val loss is 0.399691402912
3063 train loss is 0.399109870195
3063 val loss is 0.3984593153
3064 train loss is 0.391038507223
3064 val loss is 0.396919816732
3065 train loss is 0.385900139809
3065 val loss is 0.395518302917
3066 train loss is 0.376200079918
3066 val loss is 0.394945561886
3067 train loss is 0.394621819258
3067 val loss is 0.395577728748
3068 train loss is 0.433635890484
3068 val loss is 0.396436184645
3069 train loss is 0.420442461967
3069 val loss is 0.396877795458
3070 train loss is 0.426349252462
3070 val loss is 0.396412193775
3071 train loss is 0.389655858278
3071 val loss is 0.395489692688
3072 train loss is 0.385161608458
3072 val loss is 0.395046830177
3073 train loss is 0.406559169292
3073 val loss is 0.395676314831
3074 train loss is 0.422949910164
3074 val loss is 0.397476434708
3075 train loss is 0.424557447433
3075 val loss is 0.399303555489
3076 train loss is 0.381279438734
3076 val loss is 0.400166481733
3077 train loss is 0.408332437277
3077 val loss is 0.399502933025
3078 train loss is 0.404947042465
3078 val loss is 0.39749750495
3079 train loss is 0.38366279006
3079 val loss is 0.395121395588
3080 train loss is 0.391406953335
3080 val loss is 0.393789201975
3081 train loss is 0.411128997803
3081 val loss is 0.393916070461
3082 train loss is 0.379998207092
3082 val loss is 0.394994556904
3083 train loss is 0.412887811661
3083 val loss is 0.396026194096
3084 train loss is 0.406126409769
3084 val loss is 0.396541655064
3085 train loss is 0.428965777159
3085 val loss is 0.395920962095
3086 train loss is 0.39165943861
3086 val loss is 0.394982814789
3087 train loss is 0.421372175217
3087 val loss is 0.394624978304
3088 train loss is 0.410994648933
3088 val loss is 0.395258516073
3089 train loss is 0.367929816246
3089 val loss is 0.396643459797
3090 train loss is 0.403035908937
3090 val loss is 0.397875994444
3091 train loss is 0.403513401747
3091 val loss is 0.398155242205
3092 train loss is 0.386010438204
3092 val loss is 0.397021532059
3093 train loss is 0.387656211853
3093 val loss is 0.395466089249
3094 train loss is 0.392998874187
3094 val loss is 0.394010722637
3095 train loss is 0.37246131897
3095 val loss is 0.393319129944
3096 train loss is 0.392466396093
3096 val loss is 0.393597453833
3097 train loss is 0.382954269648
3097 val loss is 0.394291400909
3098 train loss is 0.377001583576
3098 val loss is 0.394794255495
3099 train loss is 0.418760567904
3099 val loss is 0.394854575396
3100 train loss is 0.410418093204
3100 val loss is 0.394555389881
3101 train loss is 0.398835062981
3101 val loss is 0.394214123487
3102 train loss is 0.395549327135
3102 val loss is 0.394609779119
3103 train loss is 0.418963670731
3103 val loss is 0.395580798388
3104 train loss is 0.431369334459
3104 val loss is 0.396741449833
3105 train loss is 0.415178894997
3105 val loss is 0.397265434265
3106 train loss is 0.396940737963
3106 val loss is 0.396919578314
3107 train loss is 0.391619116068
3107 val loss is 0.395580768585
3108 train loss is 0.399771243334
3108 val loss is 0.394123613834
3109 train loss is 0.39945858717
3109 val loss is 0.393218159676
3110 train loss is 0.38462895155
3110 val loss is 0.393157333136
3111 train loss is 0.381061017513
3111 val loss is 0.393703877926
3112 train loss is 0.354360342026
3112 val loss is 0.394235432148
3113 train loss is 0.429870545864
3113 val loss is 0.39429628849
3114 train loss is 0.397410333157
3114 val loss is 0.394214808941
3115 train loss is 0.399454593658
3115 val loss is 0.393971443176
3116 train loss is 0.39189851284
3116 val loss is 0.394035965204
3117 train loss is 0.430409878492
3117 val loss is 0.394632995129
3118 train loss is 0.407444387674
3118 val loss is 0.395353913307
3119 train loss is 0.38527905941
3119 val loss is 0.395910561085
3120 train loss is 0.365855157375
3120 val loss is 0.395907193422
3121 train loss is 0.383450031281
3121 val loss is 0.395269930363
3122 train loss is 0.368719995022
3122 val loss is 0.394060790539
3123 train loss is 0.424887418747
3123 val loss is 0.393147855997
3124 train loss is 0.377436757088
3124 val loss is 0.392651677132
3125 train loss is 0.401001393795
3125 val loss is 0.392794489861
3126 train loss is 0.410682737827
3126 val loss is 0.393227577209
3127 train loss is 0.389199614525
3127 val loss is 0.393468230963
3128 train loss is 0.390997171402
3128 val loss is 0.393336176872
3129 train loss is 0.433340132236
3129 val loss is 0.393151819706
3130 train loss is 0.396515369415
3130 val loss is 0.393375247717
3131 train loss is 0.396693825722
3131 val loss is 0.394253909588
3132 train loss is 0.384799093008
3132 val loss is 0.395353406668
3133 train loss is 0.390916466713
3133 val loss is 0.396213531494
3134 train loss is 0.374607384205
3134 val loss is 0.396197915077
3135 train loss is 0.403312444687
3135 val loss is 0.395266294479
3136 train loss is 0.401866406202
3136 val loss is 0.393863707781
3137 train loss is 0.369283735752
3137 val loss is 0.392612397671
3138 train loss is 0.39810603857
3138 val loss is 0.392182379961
3139 train loss is 0.427258551121
3139 val loss is 0.392538428307
3140 train loss is 0.407226324081
3140 val loss is 0.393105208874
3141 train loss is 0.387469530106
3141 val loss is 0.39310964942
3142 train loss is 0.412957489491
3142 val loss is 0.392573148012
3143 train loss is 0.378484249115
3143 val loss is 0.39204865694
3144 train loss is 0.387685388327
3144 val loss is 0.39227065444
3145 train loss is 0.411180019379
3145 val loss is 0.39341339469
3146 train loss is 0.378684937954
3146 val loss is 0.394903331995
3147 train loss is 0.398143023252
3147 val loss is 0.395797908306
3148 train loss is 0.420586466789
3148 val loss is 0.395703285933
3149 train loss is 0.399747878313
3149 val loss is 0.394658774137
3150 train loss is 0.403365850449
3150 val loss is 0.393369913101
3151 train loss is 0.404599249363
3151 val loss is 0.392529964447
3152 train loss is 0.388386964798
3152 val loss is 0.392411649227
3153 train loss is 0.430279314518
3153 val loss is 0.392789840698
3154 train loss is 0.424621105194
3154 val loss is 0.393157064915
3155 train loss is 0.363820254803
3155 val loss is 0.393060058355
3156 train loss is 0.374376416206
3156 val loss is 0.392402142286
3157 train loss is 0.384040355682
3157 val loss is 0.391827791929
3158 train loss is 0.417820066214
3158 val loss is 0.391987174749
3159 train loss is 0.443351268768
3159 val loss is 0.392751038074
3160 train loss is 0.410174965858
3160 val loss is 0.394008755684
3161 train loss is 0.426367551088
3161 val loss is 0.394889593124
3162 train loss is 0.381100654602
3162 val loss is 0.394955933094
3163 train loss is 0.391323328018
3163 val loss is 0.394340962172
3164 train loss is 0.402860194445
3164 val loss is 0.393440485001
3165 train loss is 0.380838513374
3165 val loss is 0.392593353987
3166 train loss is 0.398924291134
3166 val loss is 0.392224311829
3167 train loss is 0.391412496567
3167 val loss is 0.392292976379
3168 train loss is 0.400871098042
3168 val loss is 0.392401099205
3169 train loss is 0.380411833525
3169 val loss is 0.392357409
3170 train loss is 0.373780041933
3170 val loss is 0.391956210136
3171 train loss is 0.390612602234
3171 val loss is 0.391427010298
3172 train loss is 0.378106236458
3172 val loss is 0.391495943069
3173 train loss is 0.360631227493
3173 val loss is 0.392226845026
3174 train loss is 0.420768380165
3174 val loss is 0.393302023411
3175 train loss is 0.415502637625
3175 val loss is 0.39424097538
3176 train loss is 0.367692947388
3176 val loss is 0.394573032856
3177 train loss is 0.37196457386
3177 val loss is 0.3943400383
3178 train loss is 0.410698741674
3178 val loss is 0.393339693546
3179 train loss is 0.410396575928
3179 val loss is 0.392487049103
3180 train loss is 0.376990139484
3180 val loss is 0.391943454742
3181 train loss is 0.368846237659
3181 val loss is 0.391857177019
3182 train loss is 0.390617638826
3182 val loss is 0.392222166061
3183 train loss is 0.39050090313
3183 val loss is 0.392557889223
3184 train loss is 0.424743354321
3184 val loss is 0.39254462719
3185 train loss is 0.388583540916
3185 val loss is 0.39206084609
3186 train loss is 0.431288719177
3186 val loss is 0.391512751579
3187 train loss is 0.422898769379
3187 val loss is 0.391434073448
3188 train loss is 0.383426874876
3188 val loss is 0.392109066248
3189 train loss is 0.407117247581
3189 val loss is 0.393170535564
3190 train loss is 0.354605674744
3190 val loss is 0.393632054329
3191 train loss is 0.386626124382
3191 val loss is 0.393559485674
3192 train loss is 0.390023559332
3192 val loss is 0.392982423306
3193 train loss is 0.39154869318
3193 val loss is 0.392410546541
3194 train loss is 0.403718203306
3194 val loss is 0.392229050398
3195 train loss is 0.388655513525
3195 val loss is 0.392329066992
3196 train loss is 0.359785079956
3196 val loss is 0.392627120018
3197 train loss is 0.409132599831
3197 val loss is 0.392764210701
3198 train loss is 0.402099788189
3198 val loss is 0.392643392086
3199 train loss is 0.397937953472
3199 val loss is 0.392276674509
3200 train loss is 0.401240855455
3200 val loss is 0.392056107521
3201 train loss is 0.437729537487
3201 val loss is 0.392116576433
3202 train loss is 0.382631272078
3202 val loss is 0.392393499613
3203 train loss is 0.404112666845
3203 val loss is 0.39269131422
3204 train loss is 0.384206444025
3204 val loss is 0.392750829458
3205 train loss is 0.405050903559
3205 val loss is 0.392616629601
3206 train loss is 0.388501018286
3206 val loss is 0.392519205809
3207 train loss is 0.424246370792
3207 val loss is 0.392474889755
3208 train loss is 0.396657526493
3208 val loss is 0.392333120108
3209 train loss is 0.38030359149
3209 val loss is 0.392332077026
3210 train loss is 0.435444355011
3210 val loss is 0.39241284132
3211 train loss is 0.411589026451
3211 val loss is 0.392725765705
3212 train loss is 0.410460889339
3212 val loss is 0.393058896065
3213 train loss is 0.396311014891
3213 val loss is 0.392932593822
3214 train loss is 0.415181338787
3214 val loss is 0.392234712839
3215 train loss is 0.369409829378
3215 val loss is 0.391600131989
3216 train loss is 0.373431146145
3216 val loss is 0.391425937414
3217 train loss is 0.41936725378
3217 val loss is 0.391753524542
3218 train loss is 0.426740407944
3218 val loss is 0.392190933228
3219 train loss is 0.398447185755
3219 val loss is 0.39255553484
3220 train loss is 0.417749077082
3220 val loss is 0.392624020576
3221 train loss is 0.429572582245
3221 val loss is 0.392325043678
3222 train loss is 0.374507218599
3222 val loss is 0.391935527325
3223 train loss is 0.406819164753
3223 val loss is 0.391670644283
3224 train loss is 0.401037216187
3224 val loss is 0.391672700644
3225 train loss is 0.393704712391
3225 val loss is 0.391866624355
3226 train loss is 0.394406527281
3226 val loss is 0.392132759094
3227 train loss is 0.381172209978
3227 val loss is 0.392079055309
3228 train loss is 0.35859644413
3228 val loss is 0.391859292984
3229 train loss is 0.3903670609
3229 val loss is 0.391537368298
3230 train loss is 0.395191073418
3230 val loss is 0.391435742378
3231 train loss is 0.391831457615
3231 val loss is 0.391683340073
3232 train loss is 0.42172318697
3232 val loss is 0.392019808292
3233 train loss is 0.418100893497
3233 val loss is 0.39237973094
3234 train loss is 0.37773168087
3234 val loss is 0.392688930035
3235 train loss is 0.380130320787
3235 val loss is 0.392746090889
3236 train loss is 0.404252529144
3236 val loss is 0.392422884703
3237 train loss is 0.398067772388
3237 val loss is 0.392012059689
3238 train loss is 0.382848262787
3238 val loss is 0.391684919596
3239 train loss is 0.392648756504
3239 val loss is 0.391638100147
3240 train loss is 0.389540970325
3240 val loss is 0.391700088978
3241 train loss is 0.392000257969
3241 val loss is 0.391675055027
3242 train loss is 0.385935127735
3242 val loss is 0.391571164131
3243 train loss is 0.419339478016
3243 val loss is 0.39136120677
3244 train loss is 0.399874746799
3244 val loss is 0.391091436148
3245 train loss is 0.40483546257
3245 val loss is 0.391142189503
3246 train loss is 0.410566389561
3246 val loss is 0.391612887383
3247 train loss is 0.392137944698
3247 val loss is 0.392302840948
3248 train loss is 0.410091161728
3248 val loss is 0.392808198929
3249 train loss is 0.396605491638
3249 val loss is 0.392717599869
3250 train loss is 0.430094689131
3250 val loss is 0.39221149683
3251 train loss is 0.406746685505
3251 val loss is 0.391569018364
3252 train loss is 0.389657139778
3252 val loss is 0.391296923161
3253 train loss is 0.427913576365
3253 val loss is 0.391377687454
3254 train loss is 0.397606521845
3254 val loss is 0.391575992107
3255 train loss is 0.409588843584
3255 val loss is 0.391725182533
3256 train loss is 0.390227407217
3256 val loss is 0.391562759876
3257 train loss is 0.399926960468
3257 val loss is 0.391124427319
3258 train loss is 0.397755503654
3258 val loss is 0.390564441681
3259 train loss is 0.404242604971
3259 val loss is 0.390324831009
3260 train loss is 0.380097478628
3260 val loss is 0.390615403652
3261 train loss is 0.378988862038
3261 val loss is 0.391228318214
3262 train loss is 0.398474603891
3262 val loss is 0.391958653927
3263 train loss is 0.398975789547
3263 val loss is 0.392143011093
3264 train loss is 0.39472219348
3264 val loss is 0.391834527254
3265 train loss is 0.412340939045
3265 val loss is 0.391167670488
3266 train loss is 0.400893121958
3266 val loss is 0.390682607889
3267 train loss is 0.393814504147
3267 val loss is 0.39078605175
3268 train loss is 0.375528156757
3268 val loss is 0.391225755215
3269 train loss is 0.375594377518
3269 val loss is 0.391858637333
3270 train loss is 0.3859385252
3270 val loss is 0.391928076744
3271 train loss is 0.393407285213
3271 val loss is 0.391607671976
3272 train loss is 0.405239641666
3272 val loss is 0.39108812809
3273 train loss is 0.394130378962
3273 val loss is 0.39080452919
3274 train loss is 0.386259406805
3274 val loss is 0.390632897615
3275 train loss is 0.377208560705
3275 val loss is 0.390950292349
3276 train loss is 0.379807442427
3276 val loss is 0.391472399235
3277 train loss is 0.412170052528
3277 val loss is 0.391838550568
3278 train loss is 0.400135040283
3278 val loss is 0.391818702221
3279 train loss is 0.388031154871
3279 val loss is 0.391455024481
3280 train loss is 0.375928044319
3280 val loss is 0.390797913074
3281 train loss is 0.379971861839
3281 val loss is 0.390507519245
3282 train loss is 0.374217450619
3282 val loss is 0.390657126904
3283 train loss is 0.413259446621
3283 val loss is 0.390905916691
3284 train loss is 0.405984163284
3284 val loss is 0.39116448164
3285 train loss is 0.396488964558
3285 val loss is 0.390905678272
3286 train loss is 0.387349009514
3286 val loss is 0.390597522259
3287 train loss is 0.422807127237
3287 val loss is 0.390252649784
3288 train loss is 0.399352669716
3288 val loss is 0.390176653862
3289 train loss is 0.389735639095
3289 val loss is 0.390398442745
3290 train loss is 0.409173190594
3290 val loss is 0.390994012356
3291 train loss is 0.417167305946
3291 val loss is 0.391515851021
3292 train loss is 0.364589005709
3292 val loss is 0.391951858997
3293 train loss is 0.395111858845
3293 val loss is 0.391789257526
3294 train loss is 0.381274282932
3294 val loss is 0.391134619713
3295 train loss is 0.394799023867
3295 val loss is 0.390231311321
3296 train loss is 0.398587137461
3296 val loss is 0.389621466398
3297 train loss is 0.361798226833
3297 val loss is 0.389626353979
3298 train loss is 0.369665801525
3298 val loss is 0.390362083912
3299 train loss is 0.38523426652
3299 val loss is 0.391042500734
3300 train loss is 0.362960785627
3300 val loss is 0.391288429499
3301 train loss is 0.374581933022
3301 val loss is 0.390679895878
3302 train loss is 0.374582529068
3302 val loss is 0.389705359936
3303 train loss is 0.389555215836
3303 val loss is 0.389015614986
3304 train loss is 0.385948032141
3304 val loss is 0.389143586159
3305 train loss is 0.357474803925
3305 val loss is 0.39001262188
3306 train loss is 0.396858304739
3306 val loss is 0.391113728285
3307 train loss is 0.409203350544
3307 val loss is 0.391859769821
3308 train loss is 0.405585289001
3308 val loss is 0.391832232475
3309 train loss is 0.40548813343
3309 val loss is 0.391209691763
3310 train loss is 0.411124825478
3310 val loss is 0.390308052301
3311 train loss is 0.406299471855
3311 val loss is 0.389679521322
3312 train loss is 0.38975673914
3312 val loss is 0.389736831188
3313 train loss is 0.403141915798
3313 val loss is 0.390114188194
3314 train loss is 0.384267061949
3314 val loss is 0.390549778938
3315 train loss is 0.411280274391
3315 val loss is 0.390797793865
3316 train loss is 0.373082131147
3316 val loss is 0.390488445759
3317 train loss is 0.417678594589
3317 val loss is 0.389800608158
3318 train loss is 0.371420025826
3318 val loss is 0.389206826687
3319 train loss is 0.403861284256
3319 val loss is 0.388962179422
3320 train loss is 0.39653429389
3320 val loss is 0.389236062765
3321 train loss is 0.379559874535
3321 val loss is 0.390000343323
3322 train loss is 0.395235896111
3322 val loss is 0.390949487686
3323 train loss is 0.384365409613
3323 val loss is 0.391430079937
3324 train loss is 0.382268607616
3324 val loss is 0.390981078148
3325 train loss is 0.373485356569
3325 val loss is 0.389897197485
3326 train loss is 0.403097420931
3326 val loss is 0.388876736164
3327 train loss is 0.408685535192
3327 val loss is 0.388504773378
3328 train loss is 0.429411947727
3328 val loss is 0.388857364655
3329 train loss is 0.402499884367
3329 val loss is 0.389263629913
3330 train loss is 0.398685991764
3330 val loss is 0.389245510101
3331 train loss is 0.389330148697
3331 val loss is 0.388706177473
3332 train loss is 0.368431359529
3332 val loss is 0.388055354357
3333 train loss is 0.406843453646
3333 val loss is 0.388113260269
3334 train loss is 0.400312006474
3334 val loss is 0.389137744904
3335 train loss is 0.365130662918
3335 val loss is 0.390680491924
3336 train loss is 0.425772964954
3336 val loss is 0.392029166222
3337 train loss is 0.397891640663
3337 val loss is 0.392409473658
3338 train loss is 0.355134248734
3338 val loss is 0.391467243433
3339 train loss is 0.400250613689
3339 val loss is 0.389763683081
3340 train loss is 0.407069563866
3340 val loss is 0.388334512711
3341 train loss is 0.395156532526
3341 val loss is 0.387960702181
3342 train loss is 0.396256864071
3342 val loss is 0.388570725918
3343 train loss is 0.399683445692
3343 val loss is 0.38939255476
3344 train loss is 0.411831140518
3344 val loss is 0.389403998852
3345 train loss is 0.420681267977
3345 val loss is 0.388784259558
3346 train loss is 0.388215988874
3346 val loss is 0.388056874275
3347 train loss is 0.378317385912
3347 val loss is 0.387869358063
3348 train loss is 0.38656052947
3348 val loss is 0.388524353504
3349 train loss is 0.403042703867
3349 val loss is 0.389671385288
3350 train loss is 0.402124583721
3350 val loss is 0.390926897526
3351 train loss is 0.383753240108
3351 val loss is 0.39138135314
3352 train loss is 0.355818659067
3352 val loss is 0.390941441059
3353 train loss is 0.414813280106
3353 val loss is 0.389980554581
3354 train loss is 0.383721888065
3354 val loss is 0.389049142599
3355 train loss is 0.398272514343
3355 val loss is 0.388677179813
3356 train loss is 0.404296547174
3356 val loss is 0.388646632433
3357 train loss is 0.379947692156
3357 val loss is 0.388740122318
3358 train loss is 0.395986020565
3358 val loss is 0.388820379972
3359 train loss is 0.382351458073
3359 val loss is 0.388682365417
3360 train loss is 0.40377664566
3360 val loss is 0.388355672359
3361 train loss is 0.386907577515
3361 val loss is 0.388109505177
3362 train loss is 0.414398491383
3362 val loss is 0.388308495283
3363 train loss is 0.397444546223
3363 val loss is 0.388987869024
3364 train loss is 0.412047356367
3364 val loss is 0.389786094427
3365 train loss is 0.387415111065
3365 val loss is 0.39024451375
3366 train loss is 0.38374760747
3366 val loss is 0.390118896961
3367 train loss is 0.37649923563
3367 val loss is 0.389460027218
3368 train loss is 0.397665917873
3368 val loss is 0.388902485371
3369 train loss is 0.412540018559
3369 val loss is 0.388730615377
3370 train loss is 0.373475581408
3370 val loss is 0.389024764299
3371 train loss is 0.38238760829
3371 val loss is 0.389537870884
3372 train loss is 0.400701999664
3372 val loss is 0.389536380768
3373 train loss is 0.414389401674
3373 val loss is 0.388936817646
3374 train loss is 0.415235161781
3374 val loss is 0.388223588467
3375 train loss is 0.406555712223
3375 val loss is 0.387881278992
3376 train loss is 0.420055776834
3376 val loss is 0.388160973787
3377 train loss is 0.392639994621
3377 val loss is 0.388999968767
3378 train loss is 0.393447220325
3378 val loss is 0.389738708735
3379 train loss is 0.389245092869
3379 val loss is 0.389948248863
3380 train loss is 0.395137548447
3380 val loss is 0.389689534903
3381 train loss is 0.411112606525
3381 val loss is 0.389184892178
3382 train loss is 0.379938989878
3382 val loss is 0.388732254505
3383 train loss is 0.364968329668
3383 val loss is 0.388806402683
3384 train loss is 0.414134502411
3384 val loss is 0.389189094305
3385 train loss is 0.37060290575
3385 val loss is 0.389472693205
3386 train loss is 0.379007101059
3386 val loss is 0.389366805553
3387 train loss is 0.393020272255
3387 val loss is 0.38877427578
3388 train loss is 0.387180119753
3388 val loss is 0.388142228127
3389 train loss is 0.422084450722
3389 val loss is 0.38774099946
3390 train loss is 0.414500772953
3390 val loss is 0.387914717197
3391 train loss is 0.387526512146
3391 val loss is 0.388319820166
3392 train loss is 0.389911353588
3392 val loss is 0.388680517673
3393 train loss is 0.389939635992
3393 val loss is 0.38887232542
3394 train loss is 0.38349211216
3394 val loss is 0.388683199883
3395 train loss is 0.437330693007
3395 val loss is 0.388280600309
3396 train loss is 0.382849812508
3396 val loss is 0.388043552637
3397 train loss is 0.384789407253
3397 val loss is 0.38818898797
3398 train loss is 0.391736924648
3398 val loss is 0.388750374317
3399 train loss is 0.390093833208
3399 val loss is 0.38918119669
3400 train loss is 0.401496171951
3400 val loss is 0.389347583055
3401 train loss is 0.401294589043
3401 val loss is 0.388986259699
3402 train loss is 0.383690863848
3402 val loss is 0.388582319021
3403 train loss is 0.424187213182
3403 val loss is 0.388310074806
3404 train loss is 0.390155553818
3404 val loss is 0.388175815344
3405 train loss is 0.376888930798
3405 val loss is 0.388266980648
3406 train loss is 0.404997885227
3406 val loss is 0.388470500708
3407 train loss is 0.395902365446
3407 val loss is 0.388610124588
3408 train loss is 0.392529845238
3408 val loss is 0.388603329659
3409 train loss is 0.372178822756
3409 val loss is 0.388462394476
3410 train loss is 0.352394908667
3410 val loss is 0.388324171305
3411 train loss is 0.354930490255
3411 val loss is 0.388484627008
3412 train loss is 0.401090621948
3412 val loss is 0.388736873865
3413 train loss is 0.372512370348
3413 val loss is 0.388846457005
3414 train loss is 0.391413450241
3414 val loss is 0.388786882162
3415 train loss is 0.396848231554
3415 val loss is 0.388529598713
3416 train loss is 0.404440194368
3416 val loss is 0.388222008944
3417 train loss is 0.375327199697
3417 val loss is 0.388127654791
3418 train loss is 0.391951978207
3418 val loss is 0.388291180134
3419 train loss is 0.406787157059
3419 val loss is 0.388448029757
3420 train loss is 0.38802665472
3420 val loss is 0.388471603394
3421 train loss is 0.406392335892
3421 val loss is 0.388230979443
3422 train loss is 0.401557266712
3422 val loss is 0.387966454029
3423 train loss is 0.355437815189
3423 val loss is 0.387764900923
3424 train loss is 0.391086220741
3424 val loss is 0.387863457203
3425 train loss is 0.418798238039
3425 val loss is 0.388119280338
3426 train loss is 0.390697568655
3426 val loss is 0.3883677423
3427 train loss is 0.371429383755
3427 val loss is 0.388354480267
3428 train loss is 0.402517467737
3428 val loss is 0.388073027134
3429 train loss is 0.406466394663
3429 val loss is 0.387618839741
3430 train loss is 0.39780703187
3430 val loss is 0.387198656797
3431 train loss is 0.400991171598
3431 val loss is 0.387162327766
3432 train loss is 0.39165353775
3432 val loss is 0.387448996305
3433 train loss is 0.383017539978
3433 val loss is 0.387878715992
3434 train loss is 0.388465493917
3434 val loss is 0.388090729713
3435 train loss is 0.394888162613
3435 val loss is 0.387952834368
3436 train loss is 0.411456733942
3436 val loss is 0.387646913528
3437 train loss is 0.397274106741
3437 val loss is 0.387252748013
3438 train loss is 0.382919758558
3438 val loss is 0.386982351542
3439 train loss is 0.386263847351
3439 val loss is 0.38714697957
3440 train loss is 0.394943058491
3440 val loss is 0.387617141008
3441 train loss is 0.416984111071
3441 val loss is 0.38810646534
3442 train loss is 0.443690747023
3442 val loss is 0.388363450766
3443 train loss is 0.418025493622
3443 val loss is 0.388273596764
3444 train loss is 0.44133245945
3444 val loss is 0.387854158878
3445 train loss is 0.399450480938
3445 val loss is 0.387464612722
3446 train loss is 0.388758987188
3446 val loss is 0.387407004833
3447 train loss is 0.388221085072
3447 val loss is 0.38759636879
3448 train loss is 0.388769328594
3448 val loss is 0.387868106365
3449 train loss is 0.430870950222
3449 val loss is 0.387815594673
3450 train loss is 0.401607573032
3450 val loss is 0.38742184639
3451 train loss is 0.390533179045
3451 val loss is 0.386922836304
3452 train loss is 0.37855181098
3452 val loss is 0.386522948742
3453 train loss is 0.395321905613
3453 val loss is 0.386524349451
3454 train loss is 0.397999733686
3454 val loss is 0.386835217476
3455 train loss is 0.387403249741
3455 val loss is 0.387284576893
3456 train loss is 0.398078113794
3456 val loss is 0.387680768967
3457 train loss is 0.373305648565
3457 val loss is 0.387812316418
3458 train loss is 0.405014306307
3458 val loss is 0.387781769037
3459 train loss is 0.397570282221
3459 val loss is 0.387629300356
3460 train loss is 0.383421301842
3460 val loss is 0.38753592968
3461 train loss is 0.402296930552
3461 val loss is 0.38760176301
3462 train loss is 0.391713351011
3462 val loss is 0.387803077698
3463 train loss is 0.383305639029
3463 val loss is 0.388027846813
3464 train loss is 0.375491142273
3464 val loss is 0.388009250164
3465 train loss is 0.385640919209
3465 val loss is 0.387677639723
3466 train loss is 0.40633893013
3466 val loss is 0.387099206448
3467 train loss is 0.418765902519
3467 val loss is 0.386569112539
3468 train loss is 0.379991412163
3468 val loss is 0.386315226555
3469 train loss is 0.397766590118
3469 val loss is 0.386384010315
3470 train loss is 0.379583984613
3470 val loss is 0.386444538832
3471 train loss is 0.379572898149
3471 val loss is 0.386483848095
3472 train loss is 0.38592132926
3472 val loss is 0.386498868465
3473 train loss is 0.385089546442
3473 val loss is 0.386436760426
3474 train loss is 0.392815291882
3474 val loss is 0.386571824551
3475 train loss is 0.398988932371
3475 val loss is 0.386743426323
3476 train loss is 0.358936041594
3476 val loss is 0.386887282133
3477 train loss is 0.400250911713
3477 val loss is 0.386766433716
3478 train loss is 0.409100830555
3478 val loss is 0.386496186256
3479 train loss is 0.424108654261
3479 val loss is 0.386333674192
3480 train loss is 0.408747494221
3480 val loss is 0.386188983917
3481 train loss is 0.386546581984
3481 val loss is 0.386206716299
3482 train loss is 0.359533965588
3482 val loss is 0.386209636927
3483 train loss is 0.427682310343
3483 val loss is 0.386297911406
3484 train loss is 0.408662468195
3484 val loss is 0.386367082596
3485 train loss is 0.418727844954
3485 val loss is 0.386289536953
3486 train loss is 0.393663495779
3486 val loss is 0.386215150356
3487 train loss is 0.362557470798
3487 val loss is 0.386335492134
3488 train loss is 0.374777376652
3488 val loss is 0.386609971523
3489 train loss is 0.389073371887
3489 val loss is 0.386890590191
3490 train loss is 0.387093007565
3490 val loss is 0.386821448803
3491 train loss is 0.384203076363
3491 val loss is 0.386388093233
3492 train loss is 0.415582478046
3492 val loss is 0.386094510555
3493 train loss is 0.400280058384
3493 val loss is 0.385998338461
3494 train loss is 0.370284795761
3494 val loss is 0.385986000299
3495 train loss is 0.411329388618
3495 val loss is 0.386048078537
3496 train loss is 0.353290051222
3496 val loss is 0.386066615582
3497 train loss is 0.386075794697
3497 val loss is 0.386070787907
3498 train loss is 0.369198739529
3498 val loss is 0.386183977127
3499 train loss is 0.382761567831
3499 val loss is 0.386328577995
3500 train loss is 0.361446917057
3500 val loss is 0.386640518904
3501 train loss is 0.361960977316
3501 val loss is 0.386913686991
3502 train loss is 0.395306527615
3502 val loss is 0.387060821056
3503 train loss is 0.398962050676
3503 val loss is 0.3870216012
3504 train loss is 0.36318820715
3504 val loss is 0.386802792549
3505 train loss is 0.408400088549
3505 val loss is 0.386475801468
3506 train loss is 0.39461684227
3506 val loss is 0.386199861765
3507 train loss is 0.396944344044
3507 val loss is 0.386026829481
3508 train loss is 0.378934234381
3508 val loss is 0.385847151279
3509 train loss is 0.362558364868
3509 val loss is 0.38572704792
3510 train loss is 0.373019993305
3510 val loss is 0.385635375977
3511 train loss is 0.349235445261
3511 val loss is 0.385567367077
3512 train loss is 0.386873424053
3512 val loss is 0.385517656803
3513 train loss is 0.389683634043
3513 val loss is 0.38555765152
3514 train loss is 0.384127497673
3514 val loss is 0.385834902525
3515 train loss is 0.385914832354
3515 val loss is 0.386463284492
3516 train loss is 0.39046767354
3516 val loss is 0.387041330338
3517 train loss is 0.410169005394
3517 val loss is 0.387552529573
3518 train loss is 0.424476653337
3518 val loss is 0.387458264828
3519 train loss is 0.407532155514
3519 val loss is 0.387018203735
3520 train loss is 0.361181735992
3520 val loss is 0.386447161436
3521 train loss is 0.38681152463
3521 val loss is 0.385919868946
3522 train loss is 0.384125590324
3522 val loss is 0.38572126627
3523 train loss is 0.39966699481
3523 val loss is 0.385860770941
3524 train loss is 0.365820169449
3524 val loss is 0.385980129242
3525 train loss is 0.393257200718
3525 val loss is 0.385853528976
3526 train loss is 0.391179263592
3526 val loss is 0.385464817286
3527 train loss is 0.362671077251
3527 val loss is 0.385051876307
3528 train loss is 0.376071482897
3528 val loss is 0.385055780411
3529 train loss is 0.399701982737
3529 val loss is 0.385515719652
3530 train loss is 0.369193941355
3530 val loss is 0.386231094599
3531 train loss is 0.396192103624
3531 val loss is 0.386819779873
3532 train loss is 0.381437420845
3532 val loss is 0.387164264917
3533 train loss is 0.394051849842
3533 val loss is 0.387014508247
3534 train loss is 0.401026010513
3534 val loss is 0.386578172445
3535 train loss is 0.386713683605
3535 val loss is 0.385900229216
3536 train loss is 0.420393645763
3536 val loss is 0.38550761342
3537 train loss is 0.379624933004
3537 val loss is 0.385327577591
3538 train loss is 0.405474305153
3538 val loss is 0.385477006435
3539 train loss is 0.407607913017
3539 val loss is 0.385584890842
3540 train loss is 0.38234013319
3540 val loss is 0.385413587093
3541 train loss is 0.39889985323
3541 val loss is 0.38512557745
3542 train loss is 0.412369459867
3542 val loss is 0.38487225771
3543 train loss is 0.373055815697
3543 val loss is 0.385001957417
3544 train loss is 0.368763238192
3544 val loss is 0.385488927364
3545 train loss is 0.380289822817
3545 val loss is 0.385924220085
3546 train loss is 0.408951550722
3546 val loss is 0.386134922504
3547 train loss is 0.35731613636
3547 val loss is 0.385946065187
3548 train loss is 0.404619455338
3548 val loss is 0.385460913181
3549 train loss is 0.40049636364
3549 val loss is 0.384859651327
3550 train loss is 0.388791501522
3550 val loss is 0.384464919567
3551 train loss is 0.413319319487
3551 val loss is 0.384486138821
3552 train loss is 0.393859684467
3552 val loss is 0.384857535362
3553 train loss is 0.391565203667
3553 val loss is 0.385117679834
3554 train loss is 0.406031370163
3554 val loss is 0.385206997395
3555 train loss is 0.392751693726
3555 val loss is 0.385063380003
3556 train loss is 0.36430683732
3556 val loss is 0.384944081306
3557 train loss is 0.369249880314
3557 val loss is 0.384937703609
3558 train loss is 0.402053833008
3558 val loss is 0.385250449181
3559 train loss is 0.379199385643
3559 val loss is 0.38579505682
3560 train loss is 0.391017735004
3560 val loss is 0.386490404606
3561 train loss is 0.402784317732
3561 val loss is 0.386758029461
3562 train loss is 0.401092886925
3562 val loss is 0.386419802904
3563 train loss is 0.389319121838
3563 val loss is 0.385709583759
3564 train loss is 0.384901285172
3564 val loss is 0.385067403316
3565 train loss is 0.392135828733
3565 val loss is 0.384696662426
3566 train loss is 0.400165557861
3566 val loss is 0.384729206562
3567 train loss is 0.401387363672
3567 val loss is 0.384962499142
3568 train loss is 0.368597865105
3568 val loss is 0.385071307421
3569 train loss is 0.409189015627
3569 val loss is 0.385009765625
3570 train loss is 0.40222916007
3570 val loss is 0.384715616703
3571 train loss is 0.411085635424
3571 val loss is 0.384345471859
3572 train loss is 0.402844339609
3572 val loss is 0.384084612131
3573 train loss is 0.41522821784
3573 val loss is 0.384293347597
3574 train loss is 0.363633155823
3574 val loss is 0.384991794825
3575 train loss is 0.385912328959
3575 val loss is 0.385611146688
3576 train loss is 0.393957197666
3576 val loss is 0.386118739843
3577 train loss is 0.401903003454
3577 val loss is 0.385929226875
3578 train loss is 0.375039964914
3578 val loss is 0.385270059109
3579 train loss is 0.424110025167
3579 val loss is 0.38441067934
3580 train loss is 0.377635926008
3580 val loss is 0.383942365646
3581 train loss is 0.385338366032
3581 val loss is 0.384048998356
3582 train loss is 0.376742631197
3582 val loss is 0.384422779083
3583 train loss is 0.398861378431
3583 val loss is 0.384728729725
3584 train loss is 0.393056571484
3584 val loss is 0.384727776051
3585 train loss is 0.407546371222
3585 val loss is 0.384309411049
3586 train loss is 0.401383578777
3586 val loss is 0.383885145187
3587 train loss is 0.388803362846
3587 val loss is 0.38387721777
3588 train loss is 0.379958152771
3588 val loss is 0.38443082571
3589 train loss is 0.387764304876
3589 val loss is 0.385126411915
3590 train loss is 0.352481007576
3590 val loss is 0.385824382305
3591 train loss is 0.40307828784
3591 val loss is 0.386044979095
3592 train loss is 0.425185382366
3592 val loss is 0.385662376881
3593 train loss is 0.393977165222
3593 val loss is 0.385129868984
3594 train loss is 0.419388204813
3594 val loss is 0.38477742672
3595 train loss is 0.388850927353
3595 val loss is 0.384492456913
3596 train loss is 0.375646740198
3596 val loss is 0.384406417608
3597 train loss is 0.37147295475
3597 val loss is 0.384504109621
3598 train loss is 0.407743394375
3598 val loss is 0.384585678577
3599 train loss is 0.390316426754
3599 val loss is 0.384564995766
3600 train loss is 0.373005241156
3600 val loss is 0.384503126144
3601 train loss is 0.368784844875
3601 val loss is 0.384459078312
3602 train loss is 0.362914949656
3602 val loss is 0.384742319584
3603 train loss is 0.376948326826
3603 val loss is 0.385474681854
3604 train loss is 0.401569128036
3604 val loss is 0.385988235474
3605 train loss is 0.3780644238
3605 val loss is 0.386208057404
3606 train loss is 0.399277180433
3606 val loss is 0.385828763247
3607 train loss is 0.393830806017
3607 val loss is 0.385213315487
3608 train loss is 0.390131473541
3608 val loss is 0.384589523077
3609 train loss is 0.399740457535
3609 val loss is 0.384122759104
3610 train loss is 0.356044858694
3610 val loss is 0.383976221085
3611 train loss is 0.388426244259
3611 val loss is 0.384158372879
3612 train loss is 0.393103599548
3612 val loss is 0.384409368038
3613 train loss is 0.3714376688
3613 val loss is 0.384366124868
3614 train loss is 0.396749436855
3614 val loss is 0.384149312973
3615 train loss is 0.417818188667
3615 val loss is 0.383751213551
3616 train loss is 0.370376288891
3616 val loss is 0.383876144886
3617 train loss is 0.38060104847
3617 val loss is 0.384798765182
3618 train loss is 0.38765335083
3618 val loss is 0.385807335377
3619 train loss is 0.384836137295
3619 val loss is 0.386479139328
3620 train loss is 0.386499613523
3620 val loss is 0.386384367943
3621 train loss is 0.380119264126
3621 val loss is 0.385580927134
3622 train loss is 0.405642271042
3622 val loss is 0.384627819061
3623 train loss is 0.406357169151
3623 val loss is 0.383994102478
3624 train loss is 0.377934724092
3624 val loss is 0.38390058279
3625 train loss is 0.388041108847
3625 val loss is 0.383935570717
3626 train loss is 0.359195768833
3626 val loss is 0.383775562048
3627 train loss is 0.383910179138
3627 val loss is 0.3834438622
3628 train loss is 0.420406639576
3628 val loss is 0.383166491985
3629 train loss is 0.385283380747
3629 val loss is 0.383174240589
3630 train loss is 0.379538983107
3630 val loss is 0.383636534214
3631 train loss is 0.39537602663
3631 val loss is 0.384488672018
3632 train loss is 0.37011796236
3632 val loss is 0.385356217623
3633 train loss is 0.400150716305
3633 val loss is 0.385863721371
3634 train loss is 0.3982835114
3634 val loss is 0.385798484087
3635 train loss is 0.402981817722
3635 val loss is 0.385434061289
3636 train loss is 0.387044787407
3636 val loss is 0.384935289621
3637 train loss is 0.400179624557
3637 val loss is 0.384326010942
3638 train loss is 0.392047762871
3638 val loss is 0.383797109127
3639 train loss is 0.378312945366
3639 val loss is 0.383639574051
3640 train loss is 0.372926592827
3640 val loss is 0.383652687073
3641 train loss is 0.417747586966
3641 val loss is 0.383622199297
3642 train loss is 0.401748001575
3642 val loss is 0.383627653122
3643 train loss is 0.392813503742
3643 val loss is 0.383519351482
3644 train loss is 0.385914862156
3644 val loss is 0.383356302977
3645 train loss is 0.39221560955
3645 val loss is 0.383221805096
3646 train loss is 0.400947868824
3646 val loss is 0.383208394051
3647 train loss is 0.421015113592
3647 val loss is 0.38352304697
3648 train loss is 0.408646583557
3648 val loss is 0.384105414152
3649 train loss is 0.384439408779
3649 val loss is 0.384656250477
3650 train loss is 0.366004288197
3650 val loss is 0.384817361832
3651 train loss is 0.396505475044
3651 val loss is 0.384559065104
3652 train loss is 0.384280472994
3652 val loss is 0.384091168642
3653 train loss is 0.41633617878
3653 val loss is 0.383636832237
3654 train loss is 0.418185949326
3654 val loss is 0.383357077837
3655 train loss is 0.407078444958
3655 val loss is 0.383232831955
3656 train loss is 0.405716359615
3656 val loss is 0.38331708312
3657 train loss is 0.402482867241
3657 val loss is 0.383391618729
3658 train loss is 0.345074653625
3658 val loss is 0.383287400007
3659 train loss is 0.37315350771
3659 val loss is 0.383114725351
3660 train loss is 0.379028707743
3660 val loss is 0.383049100637
3661 train loss is 0.39186874032
3661 val loss is 0.383240103722
3662 train loss is 0.401210665703
3662 val loss is 0.383575588465
3663 train loss is 0.384602040052
3663 val loss is 0.384113460779
3664 train loss is 0.387132108212
3664 val loss is 0.38438886404
3665 train loss is 0.382400393486
3665 val loss is 0.384537786245
3666 train loss is 0.412449836731
3666 val loss is 0.384384453297
3667 train loss is 0.400203347206
3667 val loss is 0.384001463652
3668 train loss is 0.344811737537
3668 val loss is 0.383505553007
3669 train loss is 0.40756431222
3669 val loss is 0.383112192154
3670 train loss is 0.412760406733
3670 val loss is 0.382813036442
3671 train loss is 0.382126867771
3671 val loss is 0.382694453001
3672 train loss is 0.404674708843
3672 val loss is 0.3828574121
3673 train loss is 0.402548342943
3673 val loss is 0.38308775425
3674 train loss is 0.386453777552
3674 val loss is 0.383230805397
3675 train loss is 0.35075199604
3675 val loss is 0.383226335049
3676 train loss is 0.379795730114
3676 val loss is 0.383288562298
3677 train loss is 0.379846990108
3677 val loss is 0.383376479149
3678 train loss is 0.384604215622
3678 val loss is 0.383668005466
3679 train loss is 0.41724845767
3679 val loss is 0.383887648582
3680 train loss is 0.434637308121
3680 val loss is 0.38413771987
3681 train loss is 0.383047163486
3681 val loss is 0.384217560291
3682 train loss is 0.392749369144
3682 val loss is 0.383886635303
3683 train loss is 0.37324783206
3683 val loss is 0.383392512798
3684 train loss is 0.410136222839
3684 val loss is 0.382933646441
3685 train loss is 0.396318376064
3685 val loss is 0.382498145103
3686 train loss is 0.392371207476
3686 val loss is 0.382332712412
3687 train loss is 0.410840451717
3687 val loss is 0.382519811392
3688 train loss is 0.420934259892
3688 val loss is 0.382845014334
3689 train loss is 0.403021365404
3689 val loss is 0.383077144623
3690 train loss is 0.381931275129
3690 val loss is 0.383241504431
3691 train loss is 0.402784347534
3691 val loss is 0.383060574532
3692 train loss is 0.389553785324
3692 val loss is 0.383094608784
3693 train loss is 0.42220646143
3693 val loss is 0.383680939674
3694 train loss is 0.36531484127
3694 val loss is 0.384325325489
3695 train loss is 0.394226700068
3695 val loss is 0.384743154049
3696 train loss is 0.395861297846
3696 val loss is 0.384623467922
3697 train loss is 0.41379699111
3697 val loss is 0.383994191885
3698 train loss is 0.371780395508
3698 val loss is 0.383276641369
3699 train loss is 0.398411780596
3699 val loss is 0.382696062326
3700 train loss is 0.38993871212
3700 val loss is 0.382662922144
3701 train loss is 0.378517508507
3701 val loss is 0.383030354977
3702 train loss is 0.381359577179
3702 val loss is 0.383561640978
3703 train loss is 0.367796272039
3703 val loss is 0.383971452713
3704 train loss is 0.420713990927
3704 val loss is 0.383945703506
3705 train loss is 0.376421093941
3705 val loss is 0.383865654469
3706 train loss is 0.381494879723
3706 val loss is 0.383655667305
3707 train loss is 0.383628726006
3707 val loss is 0.383780181408
3708 train loss is 0.390977919102
3708 val loss is 0.384225189686
3709 train loss is 0.376372843981
3709 val loss is 0.384507477283
3710 train loss is 0.376126110554
3710 val loss is 0.384473919868
3711 train loss is 0.407115221024
3711 val loss is 0.38406932354
3712 train loss is 0.382636100054
3712 val loss is 0.38338008523
3713 train loss is 0.375533938408
3713 val loss is 0.382622808218
3714 train loss is 0.392272949219
3714 val loss is 0.382067650557
3715 train loss is 0.378028929234
3715 val loss is 0.382036268711
3716 train loss is 0.351833879948
3716 val loss is 0.382506668568
3717 train loss is 0.378158271313
3717 val loss is 0.383353471756
3718 train loss is 0.413585215807
3718 val loss is 0.384130954742
3719 train loss is 0.379594445229
3719 val loss is 0.384612590075
3720 train loss is 0.430661320686
3720 val loss is 0.385117053986
3721 train loss is 0.402840286493
3721 val loss is 0.385497301817
3722 train loss is 0.425203979015
3722 val loss is 0.385570198298
3723 train loss is 0.408839464188
3723 val loss is 0.385346859694
3724 train loss is 0.401296496391
3724 val loss is 0.385034650564
3725 train loss is 0.391363233328
3725 val loss is 0.384500145912
3726 train loss is 0.376252412796
3726 val loss is 0.383899748325
3727 train loss is 0.35574400425
3727 val loss is 0.3831641078
3728 train loss is 0.380309134722
3728 val loss is 0.382559776306
3729 train loss is 0.392679959536
3729 val loss is 0.382300496101
3730 train loss is 0.381434679031
3730 val loss is 0.382611334324
3731 train loss is 0.38671964407
3731 val loss is 0.383235603571
3732 train loss is 0.39873456955
3732 val loss is 0.383920133114
3733 train loss is 0.374012351036
3733 val loss is 0.384422898293
3734 train loss is 0.396834313869
3734 val loss is 0.384654134512
3735 train loss is 0.371015131474
3735 val loss is 0.384551644325
3736 train loss is 0.394549012184
3736 val loss is 0.384441286325
3737 train loss is 0.384072780609
3737 val loss is 0.384610831738
3738 train loss is 0.388740777969
3738 val loss is 0.384534239769
3739 train loss is 0.38292619586
3739 val loss is 0.38392713666
3740 train loss is 0.387207150459
3740 val loss is 0.38310867548
3741 train loss is 0.357604265213
3741 val loss is 0.382293105125
3742 train loss is 0.398524075747
3742 val loss is 0.381966590881
3743 train loss is 0.390758693218
3743 val loss is 0.382069945335
3744 train loss is 0.363058596849
3744 val loss is 0.382373183966
3745 train loss is 0.377868384123
3745 val loss is 0.38273409009
3746 train loss is 0.398131608963
3746 val loss is 0.382914036512
3747 train loss is 0.375686764717
3747 val loss is 0.383146494627
3748 train loss is 0.388707697392
3748 val loss is 0.383383512497
3749 train loss is 0.377054274082
3749 val loss is 0.383690178394
3750 train loss is 0.399463474751
3750 val loss is 0.384016901255
3751 train loss is 0.392462909222
3751 val loss is 0.384223043919
3752 train loss is 0.373380243778
3752 val loss is 0.384177953005
3753 train loss is 0.404484957457
3753 val loss is 0.383751749992
3754 train loss is 0.429918110371
3754 val loss is 0.383149325848
3755 train loss is 0.388331025839
3755 val loss is 0.382870197296
3756 train loss is 0.381400585175
3756 val loss is 0.382890582085
3757 train loss is 0.386089384556
3757 val loss is 0.382758200169
3758 train loss is 0.373527109623
3758 val loss is 0.382606476545
3759 train loss is 0.382898211479
3759 val loss is 0.382491230965
3760 train loss is 0.397851288319
3760 val loss is 0.382696598768
3761 train loss is 0.388904869556
3761 val loss is 0.383269309998
3762 train loss is 0.374650210142
3762 val loss is 0.383943319321
3763 train loss is 0.355746895075
3763 val loss is 0.384370923042
3764 train loss is 0.403532505035
3764 val loss is 0.384391725063
3765 train loss is 0.404020905495
3765 val loss is 0.384052544832
3766 train loss is 0.394682437181
3766 val loss is 0.383520066738
3767 train loss is 0.386309236288
3767 val loss is 0.383045375347
3768 train loss is 0.396918922663
3768 val loss is 0.382956027985
3769 train loss is 0.401039898396
3769 val loss is 0.382990598679
3770 train loss is 0.395972847939
3770 val loss is 0.382922589779
3771 train loss is 0.368204563856
3771 val loss is 0.38282263279
3772 train loss is 0.351025342941
3772 val loss is 0.382696509361
3773 train loss is 0.37855643034
3773 val loss is 0.382400810719
3774 train loss is 0.389978647232
3774 val loss is 0.382295846939
3775 train loss is 0.423171281815
3775 val loss is 0.382395982742
3776 train loss is 0.382232189178
3776 val loss is 0.382813155651
3777 train loss is 0.406547933817
3777 val loss is 0.383407205343
3778 train loss is 0.39964735508
3778 val loss is 0.383936196566
3779 train loss is 0.415724098682
3779 val loss is 0.384050369263
3780 train loss is 0.385426133871
3780 val loss is 0.383749246597
3781 train loss is 0.396249622107
3781 val loss is 0.383087158203
3782 train loss is 0.420113861561
3782 val loss is 0.382311373949
3783 train loss is 0.393689066172
3783 val loss is 0.381894797087
3784 train loss is 0.364310979843
3784 val loss is 0.381996929646
3785 train loss is 0.407272517681
3785 val loss is 0.382527917624
3786 train loss is 0.379050761461
3786 val loss is 0.382785379887
3787 train loss is 0.389026641846
3787 val loss is 0.382732599974
3788 train loss is 0.400838077068
3788 val loss is 0.382430166006
3789 train loss is 0.408550977707
3789 val loss is 0.382062345743
3790 train loss is 0.398558169603
3790 val loss is 0.381874978542
3791 train loss is 0.365867882967
3791 val loss is 0.382111012936
3792 train loss is 0.395292133093
3792 val loss is 0.382619798183
3793 train loss is 0.373197227716
3793 val loss is 0.383172929287
3794 train loss is 0.417258560658
3794 val loss is 0.38349545002
3795 train loss is 0.371930122375
3795 val loss is 0.383258402348
3796 train loss is 0.384677410126
3796 val loss is 0.382447063923
3797 train loss is 0.381226092577
3797 val loss is 0.381659507751
3798 train loss is 0.417104423046
3798 val loss is 0.381342798471
3799 train loss is 0.37058147788
3799 val loss is 0.381555408239
3800 train loss is 0.382145911455
3800 val loss is 0.382023185492
3801 train loss is 0.386169046164
3801 val loss is 0.382348269224
3802 train loss is 0.399711698294
3802 val loss is 0.38221129775
3803 train loss is 0.382355332375
3803 val loss is 0.381780952215
3804 train loss is 0.361987531185
3804 val loss is 0.381394445896
3805 train loss is 0.414925664663
3805 val loss is 0.381504118443
3806 train loss is 0.377725422382
3806 val loss is 0.381928324699
3807 train loss is 0.395851045847
3807 val loss is 0.382626801729
3808 train loss is 0.383073657751
3808 val loss is 0.382810771465
3809 train loss is 0.3702057302
3809 val loss is 0.382712215185
3810 train loss is 0.411257654428
3810 val loss is 0.382371932268
3811 train loss is 0.38171890378
3811 val loss is 0.381936788559
3812 train loss is 0.348841875792
3812 val loss is 0.381581157446
3813 train loss is 0.414044857025
3813 val loss is 0.381659924984
3814 train loss is 0.39558377862
3814 val loss is 0.381993979216
3815 train loss is 0.386892557144
3815 val loss is 0.382070422173
3816 train loss is 0.388984560966
3816 val loss is 0.381838262081
3817 train loss is 0.389647275209
3817 val loss is 0.381414711475
3818 train loss is 0.399182081223
3818 val loss is 0.381015986204
3819 train loss is 0.396024495363
3819 val loss is 0.380698472261
3820 train loss is 0.353688418865
3820 val loss is 0.380629956722
3821 train loss is 0.371142625809
3821 val loss is 0.380722790956
3822 train loss is 0.395083785057
3822 val loss is 0.380940794945
3823 train loss is 0.363553345203
3823 val loss is 0.38128438592
3824 train loss is 0.382999002934
3824 val loss is 0.381585240364
3825 train loss is 0.384413897991
3825 val loss is 0.381754755974
3826 train loss is 0.381629943848
3826 val loss is 0.381714254618
3827 train loss is 0.41270211339
3827 val loss is 0.381641209126
3828 train loss is 0.377578139305
3828 val loss is 0.381521880627
3829 train loss is 0.380447983742
3829 val loss is 0.381260335445
3830 train loss is 0.361502051353
3830 val loss is 0.380970001221
3831 train loss is 0.404611170292
3831 val loss is 0.380854427814
3832 train loss is 0.40381860733
3832 val loss is 0.380766630173
3833 train loss is 0.406637966633
3833 val loss is 0.380736291409
3834 train loss is 0.418061196804
3834 val loss is 0.380667090416
3835 train loss is 0.395223259926
3835 val loss is 0.380686014891
3836 train loss is 0.394975543022
3836 val loss is 0.380747646093
3837 train loss is 0.384587824345
3837 val loss is 0.380873650312
3838 train loss is 0.403281897306
3838 val loss is 0.381256580353
3839 train loss is 0.40084695816
3839 val loss is 0.381684303284
3840 train loss is 0.392562806606
3840 val loss is 0.381950289011
3841 train loss is 0.395238399506
3841 val loss is 0.381962269545
3842 train loss is 0.380955755711
3842 val loss is 0.381703138351
3843 train loss is 0.37869361043
3843 val loss is 0.381049871445
3844 train loss is 0.405787795782
3844 val loss is 0.38050955534
3845 train loss is 0.371305525303
3845 val loss is 0.38048183918
3846 train loss is 0.393907189369
3846 val loss is 0.380732744932
3847 train loss is 0.370620012283
3847 val loss is 0.380993485451
3848 train loss is 0.395404040813
3848 val loss is 0.381129384041
3849 train loss is 0.364735841751
3849 val loss is 0.381052166224
3850 train loss is 0.402317345142
3850 val loss is 0.380841761827
3851 train loss is 0.356158792973
3851 val loss is 0.38073065877
3852 train loss is 0.365818977356
3852 val loss is 0.38065713644
3853 train loss is 0.379354506731
3853 val loss is 0.381000041962
3854 train loss is 0.390784293413
3854 val loss is 0.381269276142
3855 train loss is 0.377233177423
3855 val loss is 0.381264418364
3856 train loss is 0.394940674305
3856 val loss is 0.381040990353
3857 train loss is 0.406606703997
3857 val loss is 0.380630552769
3858 train loss is 0.382765203714
3858 val loss is 0.38020375371
3859 train loss is 0.402868151665
3859 val loss is 0.380111008883
3860 train loss is 0.406764447689
3860 val loss is 0.38018488884
3861 train loss is 0.383116364479
3861 val loss is 0.380351960659
3862 train loss is 0.406807661057
3862 val loss is 0.380426287651
3863 train loss is 0.400457561016
3863 val loss is 0.380295962095
3864 train loss is 0.374892234802
3864 val loss is 0.380246639252
3865 train loss is 0.410868704319
3865 val loss is 0.380167722702
3866 train loss is 0.396045863628
3866 val loss is 0.380387961864
3867 train loss is 0.385698646307
3867 val loss is 0.380950212479
3868 train loss is 0.394156455994
3868 val loss is 0.38153848052
3869 train loss is 0.404550850391
3869 val loss is 0.381894677877
3870 train loss is 0.383002847433
3870 val loss is 0.38170415163
3871 train loss is 0.396551400423
3871 val loss is 0.381007045507
3872 train loss is 0.38267442584
3872 val loss is 0.380184829235
3873 train loss is 0.383524149656
3873 val loss is 0.379751056433
3874 train loss is 0.359490633011
3874 val loss is 0.379864156246
3875 train loss is 0.396495342255
3875 val loss is 0.380297362804
3876 train loss is 0.363787829876
3876 val loss is 0.380792081356
3877 train loss is 0.413632839918
3877 val loss is 0.381053686142
3878 train loss is 0.394332975149
3878 val loss is 0.380851477385
3879 train loss is 0.378984600306
3879 val loss is 0.38045078516
3880 train loss is 0.400012910366
3880 val loss is 0.379936039448
3881 train loss is 0.407929748297
3881 val loss is 0.379865527153
3882 train loss is 0.399366259575
3882 val loss is 0.380725413561
3883 train loss is 0.388053804636
3883 val loss is 0.381718039513
3884 train loss is 0.398657858372
3884 val loss is 0.38231498003
3885 train loss is 0.399395078421
3885 val loss is 0.382201075554
3886 train loss is 0.407139450312
3886 val loss is 0.381051391363
3887 train loss is 0.381397247314
3887 val loss is 0.37973600626
3888 train loss is 0.408536911011
3888 val loss is 0.378959715366
3889 train loss is 0.387239515781
3889 val loss is 0.379133284092
3890 train loss is 0.413922190666
3890 val loss is 0.379898130894
3891 train loss is 0.380968153477
3891 val loss is 0.380492925644
3892 train loss is 0.378951817751
3892 val loss is 0.380546718836
3893 train loss is 0.388385653496
3893 val loss is 0.379957318306
3894 train loss is 0.366124808788
3894 val loss is 0.379493892193
3895 train loss is 0.373396128416
3895 val loss is 0.379442602396
3896 train loss is 0.366426348686
3896 val loss is 0.380195021629
3897 train loss is 0.406095683575
3897 val loss is 0.381330430508
3898 train loss is 0.361793935299
3898 val loss is 0.382183790207
3899 train loss is 0.395585954189
3899 val loss is 0.382081836462
3900 train loss is 0.396496593952
3900 val loss is 0.38122856617
3901 train loss is 0.426978051662
3901 val loss is 0.379965156317
3902 train loss is 0.378130227327
3902 val loss is 0.378946244717
3903 train loss is 0.389105737209
3903 val loss is 0.378808051348
3904 train loss is 0.38198196888
3904 val loss is 0.379324883223
3905 train loss is 0.399411797523
3905 val loss is 0.380197823048
3906 train loss is 0.387169480324
3906 val loss is 0.380667507648
3907 train loss is 0.355166494846
3907 val loss is 0.38047683239
3908 train loss is 0.374540090561
3908 val loss is 0.379794687033
3909 train loss is 0.409613549709
3909 val loss is 0.379216253757
3910 train loss is 0.375492215157
3910 val loss is 0.379372656345
3911 train loss is 0.400542259216
3911 val loss is 0.380298793316
3912 train loss is 0.378907442093
3912 val loss is 0.381453752518
3913 train loss is 0.395072966814
3913 val loss is 0.382036447525
3914 train loss is 0.374144375324
3914 val loss is 0.381938785315
3915 train loss is 0.413589090109
3915 val loss is 0.380871891975
3916 train loss is 0.367217183113
3916 val loss is 0.379588365555
3917 train loss is 0.367355525494
3917 val loss is 0.378831148148
3918 train loss is 0.394250512123
3918 val loss is 0.378909051418
3919 train loss is 0.397469252348
3919 val loss is 0.379680663347
3920 train loss is 0.384118527174
3920 val loss is 0.380486905575
3921 train loss is 0.402264386415
3921 val loss is 0.380967140198
3922 train loss is 0.385368645191
3922 val loss is 0.380731314421
3923 train loss is 0.391603678465
3923 val loss is 0.379976660013
3924 train loss is 0.403712034225
3924 val loss is 0.379332274199
3925 train loss is 0.388894557953
3925 val loss is 0.379484534264
3926 train loss is 0.395716637373
3926 val loss is 0.380305051804
3927 train loss is 0.392102003098
3927 val loss is 0.381559282541
3928 train loss is 0.377648949623
3928 val loss is 0.3824005723
3929 train loss is 0.379878163338
3929 val loss is 0.382038414478
3930 train loss is 0.404453545809
3930 val loss is 0.380944699049
3931 train loss is 0.370570451021
3931 val loss is 0.379773855209
3932 train loss is 0.375709623098
3932 val loss is 0.379335314035
3933 train loss is 0.397634029388
3933 val loss is 0.379611551762
3934 train loss is 0.367354184389
3934 val loss is 0.380195498466
3935 train loss is 0.360680937767
3935 val loss is 0.380689829588
3936 train loss is 0.41487967968
3936 val loss is 0.380976319313
3937 train loss is 0.361917883158
3937 val loss is 0.380631506443
3938 train loss is 0.385959982872
3938 val loss is 0.379925370216
3939 train loss is 0.398663699627
3939 val loss is 0.379584461451
3940 train loss is 0.390917211771
3940 val loss is 0.380088686943
3941 train loss is 0.387287884951
3941 val loss is 0.381184279919
3942 train loss is 0.398013234138
3942 val loss is 0.382351160049
3943 train loss is 0.360384613276
3943 val loss is 0.382873356342
3944 train loss is 0.386146843433
3944 val loss is 0.382711738348
3945 train loss is 0.382185906172
3945 val loss is 0.381589889526
3946 train loss is 0.414969623089
3946 val loss is 0.380047470331
3947 train loss is 0.3755453825
3947 val loss is 0.379260480404
3948 train loss is 0.382163345814
3948 val loss is 0.379461348057
3949 train loss is 0.37611451745
3949 val loss is 0.380238354206
3950 train loss is 0.393016725779
3950 val loss is 0.380945086479
3951 train loss is 0.375726699829
3951 val loss is 0.380863249302
3952 train loss is 0.414803028107
3952 val loss is 0.380098760128
3953 train loss is 0.39366954565
3953 val loss is 0.379358172417
3954 train loss is 0.3507809937
3954 val loss is 0.379283845425
3955 train loss is 0.382094442844
3955 val loss is 0.379967838526
3956 train loss is 0.37339630723
3956 val loss is 0.381315618753
3957 train loss is 0.405922919512
3957 val loss is 0.382418394089
3958 train loss is 0.382880330086
3958 val loss is 0.382722109556
3959 train loss is 0.382851630449
3959 val loss is 0.382117271423
3960 train loss is 0.40969735384
3960 val loss is 0.381081938744
3961 train loss is 0.384392887354
3961 val loss is 0.38020542264
3962 train loss is 0.377381443977
3962 val loss is 0.379726052284
3963 train loss is 0.389552056789
3963 val loss is 0.379603892565
3964 train loss is 0.385024935007
3964 val loss is 0.37980055809
3965 train loss is 0.384421259165
3965 val loss is 0.379943758249
3966 train loss is 0.393694758415
3966 val loss is 0.379692494869
3967 train loss is 0.35732281208
3967 val loss is 0.37922590971
3968 train loss is 0.422150671482
3968 val loss is 0.378675699234
3969 train loss is 0.363421231508
3969 val loss is 0.378529548645
3970 train loss is 0.357720553875
3970 val loss is 0.378899753094
3971 train loss is 0.368418514729
3971 val loss is 0.379597634077
3972 train loss is 0.392083734274
3972 val loss is 0.380255877972
3973 train loss is 0.421085596085
3973 val loss is 0.380801200867
3974 train loss is 0.405052483082
3974 val loss is 0.380648702383
3975 train loss is 0.418160259724
3975 val loss is 0.380120098591
3976 train loss is 0.382172107697
3976 val loss is 0.379670083523
3977 train loss is 0.406136751175
3977 val loss is 0.379424929619
3978 train loss is 0.389945119619
3978 val loss is 0.379359275103
3979 train loss is 0.372441351414
3979 val loss is 0.379468083382
3980 train loss is 0.358074724674
3980 val loss is 0.37952286005
3981 train loss is 0.390062868595
3981 val loss is 0.379335999489
3982 train loss is 0.375838696957
3982 val loss is 0.378855526447
3983 train loss is 0.352814257145
3983 val loss is 0.378431618214
3984 train loss is 0.380570739508
3984 val loss is 0.378636181355
3985 train loss is 0.379783987999
3985 val loss is 0.379484474659
3986 train loss is 0.360118716955
3986 val loss is 0.380364894867
3987 train loss is 0.405037790537
3987 val loss is 0.380830466747
3988 train loss is 0.380794465542
3988 val loss is 0.38047015667
3989 train loss is 0.384117931128
3989 val loss is 0.379700899124
3990 train loss is 0.381131261587
3990 val loss is 0.379013240337
3991 train loss is 0.389800041914
3991 val loss is 0.378766983747
3992 train loss is 0.390168875456
3992 val loss is 0.379024922848
3993 train loss is 0.377812623978
3993 val loss is 0.379438459873
3994 train loss is 0.404551953077
3994 val loss is 0.379582285881
3995 train loss is 0.408891439438
3995 val loss is 0.379405856133
3996 train loss is 0.374336540699
3996 val loss is 0.378802597523
3997 train loss is 0.373632848263
3997 val loss is 0.37820148468
3998 train loss is 0.392430752516
3998 val loss is 0.37798807025
3999 train loss is 0.382734775543
3999 val loss is 0.378368645906
4000 train loss is 0.410480409861
4000 val loss is 0.379092693329
4001 train loss is 0.381513983011
4001 val loss is 0.3797955513
4002 train loss is 0.401113182306
4002 val loss is 0.380220502615
4003 train loss is 0.349878638983
4003 val loss is 0.380513578653
4004 train loss is 0.416944622993
4004 val loss is 0.380181193352
4005 train loss is 0.393504261971
4005 val loss is 0.379341363907
4006 train loss is 0.409162223339
4006 val loss is 0.378674685955
4007 train loss is 0.396868348122
4007 val loss is 0.378580451012
4008 train loss is 0.400648236275
4008 val loss is 0.378686010838
4009 train loss is 0.366616666317
4009 val loss is 0.37868270278
4010 train loss is 0.432400494814
4010 val loss is 0.378426790237
4011 train loss is 0.368514925241
4011 val loss is 0.378055930138
4012 train loss is 0.397178441286
4012 val loss is 0.377823233604
4013 train loss is 0.408436387777
4013 val loss is 0.378168582916
4014 train loss is 0.372563421726
4014 val loss is 0.378772467375
4015 train loss is 0.356973528862
4015 val loss is 0.379480600357
4016 train loss is 0.424255639315
4016 val loss is 0.379964709282
4017 train loss is 0.350268244743
4017 val loss is 0.38003000617
4018 train loss is 0.384184122086
4018 val loss is 0.379820883274
4019 train loss is 0.373572647572
4019 val loss is 0.379411697388
4020 train loss is 0.416389346123
4020 val loss is 0.379122674465
4021 train loss is 0.388086855412
4021 val loss is 0.378942370415
4022 train loss is 0.403376847506
4022 val loss is 0.378785610199
4023 train loss is 0.368742644787
4023 val loss is 0.378501594067
4024 train loss is 0.395406484604
4024 val loss is 0.378062784672
4025 train loss is 0.38009506464
4025 val loss is 0.377651542425
4026 train loss is 0.376194357872
4026 val loss is 0.377544611692
4027 train loss is 0.383785426617
4027 val loss is 0.377668082714
4028 train loss is 0.394159525633
4028 val loss is 0.378105938435
4029 train loss is 0.364146649837
4029 val loss is 0.378765881062
4030 train loss is 0.40042245388
4030 val loss is 0.379313021898
4031 train loss is 0.378902196884
4031 val loss is 0.379584729671
4032 train loss is 0.392870813608
4032 val loss is 0.379404962063
4033 train loss is 0.374718934298
4033 val loss is 0.378941684961
4034 train loss is 0.377505660057
4034 val loss is 0.378462612629
4035 train loss is 0.377297788858
4035 val loss is 0.378186017275
4036 train loss is 0.406155109406
4036 val loss is 0.378122806549
4037 train loss is 0.363918334246
4037 val loss is 0.378009676933
4038 train loss is 0.380908548832
4038 val loss is 0.377578347921
4039 train loss is 0.372260302305
4039 val loss is 0.377158820629
4040 train loss is 0.394998073578
4040 val loss is 0.376842707396
4041 train loss is 0.371698021889
4041 val loss is 0.376864552498
4042 train loss is 0.392716228962
4042 val loss is 0.377241641283
4043 train loss is 0.354058265686
4043 val loss is 0.377899199724
4044 train loss is 0.391194164753
4044 val loss is 0.378501087427
4045 train loss is 0.387165874243
4045 val loss is 0.378960192204
4046 train loss is 0.392790496349
4046 val loss is 0.379053890705
4047 train loss is 0.394832849503
4047 val loss is 0.379097342491
4048 train loss is 0.370401114225
4048 val loss is 0.379042267799
4049 train loss is 0.381761282682
4049 val loss is 0.378877907991
4050 train loss is 0.38799276948
4050 val loss is 0.378531754017
4051 train loss is 0.378436893225
4051 val loss is 0.378091812134
4052 train loss is 0.379069030285
4052 val loss is 0.377499729395
4053 train loss is 0.360447376966
4053 val loss is 0.377093285322
4054 train loss is 0.394476681948
4054 val loss is 0.376992970705
4055 train loss is 0.355902820826
4055 val loss is 0.377171695232
4056 train loss is 0.359386622906
4056 val loss is 0.377605587244
4057 train loss is 0.40107396245
4057 val loss is 0.3782556355
4058 train loss is 0.396916687489
4058 val loss is 0.378504693508
4059 train loss is 0.382718712091
4059 val loss is 0.378680408001
4060 train loss is 0.407132446766
4060 val loss is 0.378750801086
4061 train loss is 0.390503853559
4061 val loss is 0.37891715765
4062 train loss is 0.388205379248
4062 val loss is 0.378950953484
4063 train loss is 0.365432351828
4063 val loss is 0.378853499889
4064 train loss is 0.413793563843
4064 val loss is 0.378508388996
4065 train loss is 0.365702986717
4065 val loss is 0.378161817789
4066 train loss is 0.42012745142
4066 val loss is 0.377937883139
4067 train loss is 0.386230528355
4067 val loss is 0.377446085215
4068 train loss is 0.394305765629
4068 val loss is 0.377041101456
4069 train loss is 0.412031859159
4069 val loss is 0.3768196702
4070 train loss is 0.397918999195
4070 val loss is 0.37687754631
4071 train loss is 0.380821943283
4071 val loss is 0.377319872379
4072 train loss is 0.400228559971
4072 val loss is 0.37785923481
4073 train loss is 0.372149378061
4073 val loss is 0.37826949358
4074 train loss is 0.37845158577
4074 val loss is 0.378438621759
4075 train loss is 0.386891752481
4075 val loss is 0.378595411777
4076 train loss is 0.398410558701
4076 val loss is 0.378635793924
4077 train loss is 0.391953498125
4077 val loss is 0.378639221191
4078 train loss is 0.403846114874
4078 val loss is 0.378390401602
4079 train loss is 0.401850998402
4079 val loss is 0.378191143274
4080 train loss is 0.365484058857
4080 val loss is 0.377822488546
4081 train loss is 0.373971700668
4081 val loss is 0.377438306808
4082 train loss is 0.408020555973
4082 val loss is 0.377182483673
4083 train loss is 0.366865098476
4083 val loss is 0.37686830759
4084 train loss is 0.374670624733
4084 val loss is 0.376652181149
4085 train loss is 0.393201887608
4085 val loss is 0.37673920393
4086 train loss is 0.368085563183
4086 val loss is 0.377074271441
4087 train loss is 0.400902330875
4087 val loss is 0.377554893494
4088 train loss is 0.371803045273
4088 val loss is 0.377992123365
4089 train loss is 0.359412133694
4089 val loss is 0.378573358059
4090 train loss is 0.38848695159
4090 val loss is 0.378921538591
4091 train loss is 0.362047165632
4091 val loss is 0.379039227962
4092 train loss is 0.389325410128
4092 val loss is 0.379007905722
4093 train loss is 0.35827177763
4093 val loss is 0.378733873367
4094 train loss is 0.38886153698
4094 val loss is 0.378255099058
4095 train loss is 0.369405716658
4095 val loss is 0.37737596035
4096 train loss is 0.372390210629
4096 val loss is 0.376480340958
4097 train loss is 0.396656125784
4097 val loss is 0.376072227955
4098 train loss is 0.395267933607
4098 val loss is 0.376243680716
4099 train loss is 0.386147350073
4099 val loss is 0.376609563828
4100 train loss is 0.358665287495
4100 val loss is 0.37716126442
4101 train loss is 0.357732474804
4101 val loss is 0.377543985844
4102 train loss is 0.372546434402
4102 val loss is 0.377575099468
4103 train loss is 0.369546473026
4103 val loss is 0.377384841442
4104 train loss is 0.390779942274
4104 val loss is 0.377460211515
4105 train loss is 0.365350484848
4105 val loss is 0.377756744623
4106 train loss is 0.403791189194
4106 val loss is 0.378182649612
4107 train loss is 0.386101186275
4107 val loss is 0.378348648548
4108 train loss is 0.376805692911
4108 val loss is 0.378380447626
4109 train loss is 0.382590830326
4109 val loss is 0.378009825945
4110 train loss is 0.383489102125
4110 val loss is 0.37729293108
4111 train loss is 0.390852123499
4111 val loss is 0.376290529966
4112 train loss is 0.370634973049
4112 val loss is 0.375733196735
4113 train loss is 0.402379631996
4113 val loss is 0.375996410847
4114 train loss is 0.363659739494
4114 val loss is 0.376866161823
4115 train loss is 0.401050239801
4115 val loss is 0.377566516399
4116 train loss is 0.378181576729
4116 val loss is 0.377884536982
4117 train loss is 0.396084487438
4117 val loss is 0.377549409866
4118 train loss is 0.378531873226
4118 val loss is 0.377124607563
4119 train loss is 0.381360888481
4119 val loss is 0.376962482929
4120 train loss is 0.357930243015
4120 val loss is 0.377308785915
4121 train loss is 0.39878693223
4121 val loss is 0.377874612808
4122 train loss is 0.371429860592
4122 val loss is 0.378214597702
4123 train loss is 0.367901444435
4123 val loss is 0.377825289965
4124 train loss is 0.385508328676
4124 val loss is 0.377069711685
4125 train loss is 0.393430620432
4125 val loss is 0.376274198294
4126 train loss is 0.391685545444
4126 val loss is 0.375922888517
4127 train loss is 0.41994613409
4127 val loss is 0.375996470451
4128 train loss is 0.398966640234
4128 val loss is 0.37642788887
4129 train loss is 0.370234966278
4129 val loss is 0.376984715462
4130 train loss is 0.374443352222
4130 val loss is 0.377186328173
4131 train loss is 0.390125304461
4131 val loss is 0.376866936684
4132 train loss is 0.37345212698
4132 val loss is 0.376276195049
4133 train loss is 0.370266914368
4133 val loss is 0.37590265274
4134 train loss is 0.375441640615
4134 val loss is 0.37608140707
4135 train loss is 0.359814703465
4135 val loss is 0.37675768137
4136 train loss is 0.385175585747
4136 val loss is 0.377371221781
4137 train loss is 0.369163990021
4137 val loss is 0.37739276886
4138 train loss is 0.387810975313
4138 val loss is 0.376978516579
4139 train loss is 0.38731688261
4139 val loss is 0.376241803169
4140 train loss is 0.380557894707
4140 val loss is 0.375648409128
4141 train loss is 0.416383981705
4141 val loss is 0.375605523586
4142 train loss is 0.363956421614
4142 val loss is 0.375950723886
4143 train loss is 0.393704146147
4143 val loss is 0.376382350922
4144 train loss is 0.370981276035
4144 val loss is 0.376471489668
4145 train loss is 0.396032243967
4145 val loss is 0.3761754632
4146 train loss is 0.387979865074
4146 val loss is 0.375784367323
4147 train loss is 0.370873749256
4147 val loss is 0.375552356243
4148 train loss is 0.396853506565
4148 val loss is 0.375791013241
4149 train loss is 0.37416613102
4149 val loss is 0.376471251249
4150 train loss is 0.402480334044
4150 val loss is 0.377060353756
4151 train loss is 0.373587310314
4151 val loss is 0.377358675003
4152 train loss is 0.375758886337
4152 val loss is 0.377393841743
4153 train loss is 0.375315397978
4153 val loss is 0.377045810223
4154 train loss is 0.40272757411
4154 val loss is 0.376384496689
4155 train loss is 0.410540759563
4155 val loss is 0.375758260489
4156 train loss is 0.358012616634
4156 val loss is 0.375544577837
4157 train loss is 0.383037000895
4157 val loss is 0.3757353127
4158 train loss is 0.381875663996
4158 val loss is 0.376121729612
4159 train loss is 0.354239106178
4159 val loss is 0.376411378384
4160 train loss is 0.379514038563
4160 val loss is 0.3764282763
4161 train loss is 0.398232221603
4161 val loss is 0.376332700253
4162 train loss is 0.391296982765
4162 val loss is 0.376226723194
4163 train loss is 0.398447096348
4163 val loss is 0.376156508923
4164 train loss is 0.3820733428
4164 val loss is 0.376245856285
4165 train loss is 0.390449255705
4165 val loss is 0.376456946135
4166 train loss is 0.378342837095
4166 val loss is 0.37678027153
4167 train loss is 0.365083366632
4167 val loss is 0.376902520657
4168 train loss is 0.372328937054
4168 val loss is 0.37660074234
4169 train loss is 0.382487237453
4169 val loss is 0.376159608364
4170 train loss is 0.356357753277
4170 val loss is 0.375951528549
4171 train loss is 0.392730921507
4171 val loss is 0.3758456707
4172 train loss is 0.376229643822
4172 val loss is 0.375729590654
4173 train loss is 0.381533563137
4173 val loss is 0.375726729631
4174 train loss is 0.373924106359
4174 val loss is 0.375650018454
4175 train loss is 0.378424167633
4175 val loss is 0.375520348549
4176 train loss is 0.380612790585
4176 val loss is 0.375619530678
4177 train loss is 0.385490506887
4177 val loss is 0.375758141279
4178 train loss is 0.395474255085
4178 val loss is 0.375853091478
4179 train loss is 0.365115642548
4179 val loss is 0.375885546207
4180 train loss is 0.358364969492
4180 val loss is 0.375850200653
4181 train loss is 0.392190724611
4181 val loss is 0.375806361437
4182 train loss is 0.378692001104
4182 val loss is 0.375909209251
4183 train loss is 0.379456460476
4183 val loss is 0.376069307327
4184 train loss is 0.375988572836
4184 val loss is 0.375936090946
4185 train loss is 0.379205137491
4185 val loss is 0.375734359026
4186 train loss is 0.389775425196
4186 val loss is 0.375784933567
4187 train loss is 0.366222560406
4187 val loss is 0.375728815794
4188 train loss is 0.374132573605
4188 val loss is 0.375684201717
4189 train loss is 0.384995818138
4189 val loss is 0.375687271357
4190 train loss is 0.370321273804
4190 val loss is 0.375643014908
4191 train loss is 0.364941865206
4191 val loss is 0.375684022903
4192 train loss is 0.358534872532
4192 val loss is 0.375763356686
4193 train loss is 0.413215398788
4193 val loss is 0.375957608223
4194 train loss is 0.385192841291
4194 val loss is 0.376237154007
4195 train loss is 0.391678929329
4195 val loss is 0.376481235027
4196 train loss is 0.378899544477
4196 val loss is 0.376640439034
4197 train loss is 0.402355670929
4197 val loss is 0.376634895802
4198 train loss is 0.370839655399
4198 val loss is 0.376233607531
4199 train loss is 0.386137753725
4199 val loss is 0.375535011292
4200 train loss is 0.381310343742
4200 val loss is 0.37503772974
4201 train loss is 0.398601472378
4201 val loss is 0.375037699938
4202 train loss is 0.379437446594
4202 val loss is 0.375267207623
4203 train loss is 0.359653711319
4203 val loss is 0.375606864691
4204 train loss is 0.386901199818
4204 val loss is 0.375869572163
4205 train loss is 0.366570979357
4205 val loss is 0.375851362944
4206 train loss is 0.398993313313
4206 val loss is 0.375583350658
4207 train loss is 0.36219483614
4207 val loss is 0.375667095184
4208 train loss is 0.389052450657
4208 val loss is 0.376069575548
4209 train loss is 0.349399328232
4209 val loss is 0.376519948244
4210 train loss is 0.390804052353
4210 val loss is 0.376599997282
4211 train loss is 0.380745232105
4211 val loss is 0.376266300678
4212 train loss is 0.366929769516
4212 val loss is 0.375819265842
4213 train loss is 0.377676218748
4213 val loss is 0.375342309475
4214 train loss is 0.386455595493
4214 val loss is 0.375065028667
4215 train loss is 0.371482431889
4215 val loss is 0.375060349703
4216 train loss is 0.374940544367
4216 val loss is 0.3752386868
4217 train loss is 0.356274992228
4217 val loss is 0.375581175089
4218 train loss is 0.396724998951
4218 val loss is 0.375986039639
4219 train loss is 0.382866710424
4219 val loss is 0.376258939505
4220 train loss is 0.354943335056
4220 val loss is 0.376228749752
4221 train loss is 0.397978484631
4221 val loss is 0.376088678837
4222 train loss is 0.389498174191
4222 val loss is 0.37576854229
4223 train loss is 0.383643120527
4223 val loss is 0.375498503447
4224 train loss is 0.379155516624
4224 val loss is 0.375538259745
4225 train loss is 0.411877721548
4225 val loss is 0.375701636076
4226 train loss is 0.369266480207
4226 val loss is 0.375849992037
4227 train loss is 0.396930366755
4227 val loss is 0.375812351704
4228 train loss is 0.376531839371
4228 val loss is 0.375455051661
4229 train loss is 0.374436616898
4229 val loss is 0.374829173088
4230 train loss is 0.378154724836
4230 val loss is 0.374361455441
4231 train loss is 0.387200593948
4231 val loss is 0.374257683754
4232 train loss is 0.372028619051
4232 val loss is 0.374699831009
4233 train loss is 0.401636511087
4233 val loss is 0.375479161739
4234 train loss is 0.390622496605
4234 val loss is 0.37605842948
4235 train loss is 0.378573060036
4235 val loss is 0.376314997673
4236 train loss is 0.377556800842
4236 val loss is 0.376119226217
4237 train loss is 0.364002078772
4237 val loss is 0.375566124916
4238 train loss is 0.376756936312
4238 val loss is 0.374976277351
4239 train loss is 0.365229785442
4239 val loss is 0.374553918839
4240 train loss is 0.379550039768
4240 val loss is 0.374546289444
4241 train loss is 0.380531191826
4241 val loss is 0.374716997147
4242 train loss is 0.390411108732
4242 val loss is 0.374658793211
4243 train loss is 0.386274397373
4243 val loss is 0.374321639538
4244 train loss is 0.375914335251
4244 val loss is 0.374048471451
4245 train loss is 0.379285931587
4245 val loss is 0.373859703541
4246 train loss is 0.401208341122
4246 val loss is 0.373902529478
4247 train loss is 0.373855352402
4247 val loss is 0.374244183302
4248 train loss is 0.380321741104
4248 val loss is 0.374511212111
4249 train loss is 0.362729638815
4249 val loss is 0.374764978886
4250 train loss is 0.385102748871
4250 val loss is 0.374722838402
4251 train loss is 0.374357223511
4251 val loss is 0.374454140663
4252 train loss is 0.358659923077
4252 val loss is 0.37432077527
4253 train loss is 0.38339215517
4253 val loss is 0.374266952276
4254 train loss is 0.389619112015
4254 val loss is 0.374367773533
4255 train loss is 0.374089449644
4255 val loss is 0.374457150698
4256 train loss is 0.384684115648
4256 val loss is 0.374434411526
4257 train loss is 0.377205133438
4257 val loss is 0.37428483367
4258 train loss is 0.361158043146
4258 val loss is 0.374064415693
4259 train loss is 0.391705691814
4259 val loss is 0.374003112316
4260 train loss is 0.367355465889
4260 val loss is 0.373961776495
4261 train loss is 0.362042695284
4261 val loss is 0.373868107796
4262 train loss is 0.379049777985
4262 val loss is 0.37402588129
4263 train loss is 0.384463131428
4263 val loss is 0.374222457409
4264 train loss is 0.387024283409
4264 val loss is 0.374323666096
4265 train loss is 0.374684274197
4265 val loss is 0.374373614788
4266 train loss is 0.356760203838
4266 val loss is 0.374242842197
4267 train loss is 0.382369160652
4267 val loss is 0.374160736799
4268 train loss is 0.366287797689
4268 val loss is 0.374161660671
4269 train loss is 0.410365343094
4269 val loss is 0.37411659956
4270 train loss is 0.381980895996
4270 val loss is 0.374107062817
4271 train loss is 0.370763123035
4271 val loss is 0.374032706022
4272 train loss is 0.380616784096
4272 val loss is 0.373827397823
4273 train loss is 0.37221622467
4273 val loss is 0.373664557934
4274 train loss is 0.394787162542
4274 val loss is 0.373647421598
4275 train loss is 0.402338892221
4275 val loss is 0.373757183552
4276 train loss is 0.387689352036
4276 val loss is 0.373844265938
4277 train loss is 0.393646508455
4277 val loss is 0.373805731535
4278 train loss is 0.378323733807
4278 val loss is 0.373732805252
4279 train loss is 0.377663433552
4279 val loss is 0.373546361923
4280 train loss is 0.383385121822
4280 val loss is 0.37333381176
4281 train loss is 0.392671823502
4281 val loss is 0.373113453388
4282 train loss is 0.364491462708
4282 val loss is 0.373137235641
4283 train loss is 0.368944972754
4283 val loss is 0.373422503471
4284 train loss is 0.385897934437
4284 val loss is 0.373849749565
4285 train loss is 0.385689347982
4285 val loss is 0.374129056931
4286 train loss is 0.38740593195
4286 val loss is 0.374124318361
4287 train loss is 0.385177642107
4287 val loss is 0.373902529478
4288 train loss is 0.399637520313
4288 val loss is 0.373654395342
4289 train loss is 0.370255708694
4289 val loss is 0.373439729214
4290 train loss is 0.345551669598
4290 val loss is 0.373420327902
4291 train loss is 0.385727763176
4291 val loss is 0.373443961143
4292 train loss is 0.369913101196
4292 val loss is 0.373531371355
4293 train loss is 0.356591254473
4293 val loss is 0.373680919409
4294 train loss is 0.406151205301
4294 val loss is 0.373560011387
4295 train loss is 0.383942246437
4295 val loss is 0.373198360205
4296 train loss is 0.396175384521
4296 val loss is 0.372834801674
4297 train loss is 0.38946056366
4297 val loss is 0.372633069754
4298 train loss is 0.395164161921
4298 val loss is 0.372780919075
4299 train loss is 0.357335656881
4299 val loss is 0.373190820217
4300 train loss is 0.386261761189
4300 val loss is 0.373676121235
4301 train loss is 0.390393406153
4301 val loss is 0.374128103256
4302 train loss is 0.379349946976
4302 val loss is 0.37414547801
4303 train loss is 0.382448554039
4303 val loss is 0.373817324638
4304 train loss is 0.385488092899
4304 val loss is 0.373253315687
4305 train loss is 0.389235377312
4305 val loss is 0.372803717852
4306 train loss is 0.384286135435
4306 val loss is 0.372579753399
4307 train loss is 0.378318935633
4307 val loss is 0.372791707516
4308 train loss is 0.344547122717
4308 val loss is 0.373085796833
4309 train loss is 0.378734350204
4309 val loss is 0.373268902302
4310 train loss is 0.363440811634
4310 val loss is 0.373064398766
4311 train loss is 0.36934787035
4311 val loss is 0.372695595026
4312 train loss is 0.361709117889
4312 val loss is 0.372338712215
4313 train loss is 0.372733235359
4313 val loss is 0.372349619865
4314 train loss is 0.409934490919
4314 val loss is 0.372993707657
4315 train loss is 0.37888148427
4315 val loss is 0.373784631491
4316 train loss is 0.36602050066
4316 val loss is 0.374263703823
4317 train loss is 0.36757683754
4317 val loss is 0.374183833599
4318 train loss is 0.347352445126
4318 val loss is 0.37357121706
4319 train loss is 0.370971381664
4319 val loss is 0.372887194157
4320 train loss is 0.377407729626
4320 val loss is 0.37241256237
4321 train loss is 0.377502918243
4321 val loss is 0.372390389442
4322 train loss is 0.40425491333
4322 val loss is 0.372816801071
4323 train loss is 0.345842093229
4323 val loss is 0.373137325048
4324 train loss is 0.372735083103
4324 val loss is 0.3731084764
4325 train loss is 0.407458096743
4325 val loss is 0.37271219492
4326 train loss is 0.395772129297
4326 val loss is 0.372033178806
4327 train loss is 0.370157718658
4327 val loss is 0.371872365475
4328 train loss is 0.400632143021
4328 val loss is 0.372699052095
4329 train loss is 0.37087392807
4329 val loss is 0.373883903027
4330 train loss is 0.366653084755
4330 val loss is 0.37456715107
4331 train loss is 0.35392215848
4331 val loss is 0.374491423368
4332 train loss is 0.375311911106
4332 val loss is 0.373779445887
4333 train loss is 0.37881821394
4333 val loss is 0.372895479202
4334 train loss is 0.387347012758
4334 val loss is 0.372231960297
4335 train loss is 0.37808907032
4335 val loss is 0.372320950031
4336 train loss is 0.377090275288
4336 val loss is 0.373030811548
4337 train loss is 0.375710517168
4337 val loss is 0.373275458813
4338 train loss is 0.386588811874
4338 val loss is 0.372949540615
4339 train loss is 0.369698405266
4339 val loss is 0.372567772865
4340 train loss is 0.377220749855
4340 val loss is 0.372213244438
4341 train loss is 0.374583214521
4341 val loss is 0.372196495533
4342 train loss is 0.390327215195
4342 val loss is 0.372527122498
4343 train loss is 0.386536240578
4343 val loss is 0.373021245003
4344 train loss is 0.38542470336
4344 val loss is 0.373218566179
4345 train loss is 0.363900333643
4345 val loss is 0.372962206602
4346 train loss is 0.38212236762
4346 val loss is 0.372524917126
4347 train loss is 0.382529944181
4347 val loss is 0.372096568346
4348 train loss is 0.395243316889
4348 val loss is 0.37206608057
4349 train loss is 0.381464332342
4349 val loss is 0.37221544981
4350 train loss is 0.370075583458
4350 val loss is 0.372362703085
4351 train loss is 0.396872162819
4351 val loss is 0.372327804565
4352 train loss is 0.395612508059
4352 val loss is 0.372098475695
4353 train loss is 0.389799416065
4353 val loss is 0.372063338757
4354 train loss is 0.368240356445
4354 val loss is 0.37247762084
4355 train loss is 0.370786935091
4355 val loss is 0.37314838171
4356 train loss is 0.369428426027
4356 val loss is 0.373870968819
4357 train loss is 0.370373934507
4357 val loss is 0.374265819788
4358 train loss is 0.420229405165
4358 val loss is 0.374085277319
4359 train loss is 0.380251020193
4359 val loss is 0.373250424862
4360 train loss is 0.384776443243
4360 val loss is 0.372369915247
4361 train loss is 0.401641249657
4361 val loss is 0.372014969587
4362 train loss is 0.374190449715
4362 val loss is 0.372151404619
4363 train loss is 0.365682274103
4363 val loss is 0.372258722782
4364 train loss is 0.359853327274
4364 val loss is 0.37227755785
4365 train loss is 0.380823999643
4365 val loss is 0.3720484972
4366 train loss is 0.391516178846
4366 val loss is 0.371660679579
4367 train loss is 0.387225985527
4367 val loss is 0.371463924646
4368 train loss is 0.36416259408
4368 val loss is 0.372012913227
4369 train loss is 0.385755121708
4369 val loss is 0.373042434454
4370 train loss is 0.385999500751
4370 val loss is 0.374213039875
4371 train loss is 0.404435157776
4371 val loss is 0.37483894825
4372 train loss is 0.407091975212
4372 val loss is 0.37457844615
4373 train loss is 0.392585009336
4373 val loss is 0.373540222645
4374 train loss is 0.359756469727
4374 val loss is 0.372531831264
4375 train loss is 0.385833740234
4375 val loss is 0.371777445078
4376 train loss is 0.370841026306
4376 val loss is 0.37166428566
4377 train loss is 0.425616621971
4377 val loss is 0.37215590477
4378 train loss is 0.347685933113
4378 val loss is 0.372632473707
4379 train loss is 0.410347372293
4379 val loss is 0.3725502491
4380 train loss is 0.394065082073
4380 val loss is 0.372106790543
4381 train loss is 0.361179322004
4381 val loss is 0.371846497059
4382 train loss is 0.35919880867
4382 val loss is 0.371953636408
4383 train loss is 0.406919270754
4383 val loss is 0.37247389555
4384 train loss is 0.356440424919
4384 val loss is 0.373343974352
4385 train loss is 0.384454488754
4385 val loss is 0.373840808868
4386 train loss is 0.380731701851
4386 val loss is 0.373748898506
4387 train loss is 0.356774151325
4387 val loss is 0.373197644949
4388 train loss is 0.377407491207
4388 val loss is 0.372422069311
4389 train loss is 0.393972873688
4389 val loss is 0.371937900782
4390 train loss is 0.388541996479
4390 val loss is 0.371683657169
4391 train loss is 0.362156450748
4391 val loss is 0.371493279934
4392 train loss is 0.373990297318
4392 val loss is 0.371542394161
4393 train loss is 0.395021110773
4393 val loss is 0.371676266193
4394 train loss is 0.378824144602
4394 val loss is 0.371877253056
4395 train loss is 0.374236762524
4395 val loss is 0.372039943933
4396 train loss is 0.378690540791
4396 val loss is 0.372114062309
4397 train loss is 0.361800402403
4397 val loss is 0.372178047895
4398 train loss is 0.377204686403
4398 val loss is 0.372255384922
4399 train loss is 0.350418150425
4399 val loss is 0.372301906347
4400 train loss is 0.36289948225
4400 val loss is 0.372206807137
4401 train loss is 0.363176465034
4401 val loss is 0.3720305264
4402 train loss is 0.415512084961
4402 val loss is 0.371789693832
4403 train loss is 0.38163548708
4403 val loss is 0.371740400791
4404 train loss is 0.387912631035
4404 val loss is 0.37175822258
4405 train loss is 0.393755793571
4405 val loss is 0.371638596058
4406 train loss is 0.38093239069
4406 val loss is 0.371386379004
4407 train loss is 0.376446127892
4407 val loss is 0.371196597815
4408 train loss is 0.370437026024
4408 val loss is 0.371447861195
4409 train loss is 0.368077397346
4409 val loss is 0.371968746185
4410 train loss is 0.377506643534
4410 val loss is 0.372491180897
4411 train loss is 0.396981239319
4411 val loss is 0.372856229544
4412 train loss is 0.379204809666
4412 val loss is 0.372703135014
4413 train loss is 0.396466672421
4413 val loss is 0.372002899647
4414 train loss is 0.334794402122
4414 val loss is 0.37138274312
4415 train loss is 0.368418246508
4415 val loss is 0.370981276035
4416 train loss is 0.392618894577
4416 val loss is 0.371062099934
4417 train loss is 0.339727163315
4417 val loss is 0.371397942305
4418 train loss is 0.387189179659
4418 val loss is 0.371758550406
4419 train loss is 0.363270550966
4419 val loss is 0.37172499299
4420 train loss is 0.383493602276
4420 val loss is 0.37132820487
4421 train loss is 0.385556340218
4421 val loss is 0.370961308479
4422 train loss is 0.417843937874
4422 val loss is 0.37095412612
4423 train loss is 0.353893041611
4423 val loss is 0.3714004457
4424 train loss is 0.386013031006
4424 val loss is 0.372183769941
4425 train loss is 0.36945232749
4425 val loss is 0.37276417017
4426 train loss is 0.344183236361
4426 val loss is 0.372787415981
4427 train loss is 0.39144590497
4427 val loss is 0.372194737196
4428 train loss is 0.377029955387
4428 val loss is 0.371455013752
4429 train loss is 0.374287575483
4429 val loss is 0.370810031891
4430 train loss is 0.350332736969
4430 val loss is 0.370609223843
4431 train loss is 0.370620131493
4431 val loss is 0.370898485184
4432 train loss is 0.376082092524
4432 val loss is 0.371433466673
4433 train loss is 0.374254137278
4433 val loss is 0.371680557728
4434 train loss is 0.368214398623
4434 val loss is 0.371713638306
4435 train loss is 0.381995022297
4435 val loss is 0.371579825878
4436 train loss is 0.397729158401
4436 val loss is 0.37143433094
4437 train loss is 0.364793479443
4437 val loss is 0.371597707272
4438 train loss is 0.349055051804
4438 val loss is 0.372118413448
4439 train loss is 0.381452530622
4439 val loss is 0.372838079929
4440 train loss is 0.363395094872
4440 val loss is 0.373196512461
4441 train loss is 0.40563800931
4441 val loss is 0.372770905495
4442 train loss is 0.358426034451
4442 val loss is 0.371827542782
4443 train loss is 0.366133123636
4443 val loss is 0.370963692665
4444 train loss is 0.381868243217
4444 val loss is 0.370567768812
4445 train loss is 0.400179862976
4445 val loss is 0.370465546846
4446 train loss is 0.354112297297
4446 val loss is 0.370630085468
4447 train loss is 0.40668964386
4447 val loss is 0.370888292789
4448 train loss is 0.36666688323
4448 val loss is 0.371111452579
4449 train loss is 0.385974645615
4449 val loss is 0.371253550053
4450 train loss is 0.377032786608
4450 val loss is 0.371271699667
4451 train loss is 0.361716389656
4451 val loss is 0.371214926243
4452 train loss is 0.355906486511
4452 val loss is 0.371255457401
4453 train loss is 0.354121893644
4453 val loss is 0.371541500092
4454 train loss is 0.386743247509
4454 val loss is 0.372108280659
4455 train loss is 0.386344730854
4455 val loss is 0.372527897358
4456 train loss is 0.400053203106
4456 val loss is 0.372461736202
4457 train loss is 0.355859667063
4457 val loss is 0.372003495693
4458 train loss is 0.366503417492
4458 val loss is 0.371118605137
4459 train loss is 0.350197702646
4459 val loss is 0.370241820812
4460 train loss is 0.38640922308
4460 val loss is 0.369922161102
4461 train loss is 0.415934324265
4461 val loss is 0.370205283165
4462 train loss is 0.390277951956
4462 val loss is 0.370979249477
4463 train loss is 0.4043866992
4463 val loss is 0.371725231409
4464 train loss is 0.363399147987
4464 val loss is 0.371968984604
4465 train loss is 0.382264345884
4465 val loss is 0.371809691191
4466 train loss is 0.383075714111
4466 val loss is 0.371270388365
4467 train loss is 0.369732886553
4467 val loss is 0.371014893055
4468 train loss is 0.361694961786
4468 val loss is 0.371355742216
4469 train loss is 0.412826120853
4469 val loss is 0.371973931789
4470 train loss is 0.382103770971
4470 val loss is 0.372366786003
4471 train loss is 0.391783386469
4471 val loss is 0.372082799673
4472 train loss is 0.389523744583
4472 val loss is 0.371308118105
4473 train loss is 0.375349789858
4473 val loss is 0.370461285114
4474 train loss is 0.349099248648
4474 val loss is 0.370135128498
4475 train loss is 0.360880792141
4475 val loss is 0.370318681002
4476 train loss is 0.381800949574
4476 val loss is 0.37074637413
4477 train loss is 0.409663766623
4477 val loss is 0.371197164059
4478 train loss is 0.385358273983
4478 val loss is 0.371317952871
4479 train loss is 0.366693556309
4479 val loss is 0.371194243431
4480 train loss is 0.394220918417
4480 val loss is 0.370859831572
4481 train loss is 0.347585380077
4481 val loss is 0.37068426609
4482 train loss is 0.366347670555
4482 val loss is 0.370964676142
4483 train loss is 0.384865611792
4483 val loss is 0.371530592442
4484 train loss is 0.386655807495
4484 val loss is 0.371998280287
4485 train loss is 0.362919747829
4485 val loss is 0.372558742762
4486 train loss is 0.380873948336
4486 val loss is 0.372731864452
4487 train loss is 0.371532201767
4487 val loss is 0.372117698193
4488 train loss is 0.384351074696
4488 val loss is 0.371153950691
4489 train loss is 0.400872856379
4489 val loss is 0.37051731348
4490 train loss is 0.385680735111
4490 val loss is 0.370387077332
4491 train loss is 0.36881840229
4491 val loss is 0.370778858662
4492 train loss is 0.362731188536
4492 val loss is 0.371285676956
4493 train loss is 0.33746445179
4493 val loss is 0.371678054333
4494 train loss is 0.386444956064
4494 val loss is 0.371656596661
4495 train loss is 0.393987834454
4495 val loss is 0.371202945709
4496 train loss is 0.356296718121
4496 val loss is 0.370767056942
4497 train loss is 0.360458999872
4497 val loss is 0.370734393597
4498 train loss is 0.343336820602
4498 val loss is 0.371017456055
4499 train loss is 0.356394708157
4499 val loss is 0.371479272842
4500 train loss is 0.385834276676
4500 val loss is 0.372563332319
models saved successfully!
